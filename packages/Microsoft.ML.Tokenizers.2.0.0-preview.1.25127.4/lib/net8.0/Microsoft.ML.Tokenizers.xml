<?xml version="1.0"?>
<doc>
    <assembly>
        <name>Microsoft.ML.Tokenizers</name>
    </assembly>
    <members>
        <member name="T:Microsoft.ML.Tokenizers.EncodedToken">
            <summary>
            Represent the token produced from the tokenization process containing the token substring,
            the id associated to the token substring, and the offset mapping to the original string.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.EncodedToken.Id">
            <summary>
            Gets the Id value associated to the token.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.EncodedToken.Value">
            <summary>
            Gets the token string value.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.EncodedToken.Offset">
            <summary>
            Gets the offset mapping to the original string.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.EncodedToken.#ctor(System.Int32,System.String,System.Range)">
            <summary>
            Construct a new Token object using the token value, Id, and the offset mapping to the original string.
            </summary>
            <param name="id">The Id value associated to the token.</param>
            <param name="value">The token string value.</param>
            <param name="offset">The offset mapping to the original string.</param>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.EncodedToken.Equals(Microsoft.ML.Tokenizers.EncodedToken)">
            inherited
        </member>
        <member name="T:Microsoft.ML.Tokenizers.EncodeResults`1">
            <summary>
            The result of encoding a text.
            </summary>
            <typeparam name="T">The type of the tokens.</typeparam>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.EncodeResults`1.Tokens">
            <summary>
            Gets or sets the list of tokens generated from the encoded text.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.EncodeResults`1.NormalizedText">
            <summary>
            Gets or sets the normalized text generated during the encoding process. This can be <see langword="null"/> if the encoding process does not normalize the input text.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.EncodeResults`1.CharsConsumed">
            <summary>
            Gets or sets the count of characters consumed from the input text.
            </summary>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.EncodeSettings">
            <summary>
            The settings used to encode a text.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.EncodeSettings.#ctor">
            <summary>
            Initializes the <see cref="T:Microsoft.ML.Tokenizers.EncodeSettings"/> instance.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.EncodeSettings.ConsiderNormalization">
            <summary>
            Gets or sets a value indicating whether to consider the input normalization during encoding.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.EncodeSettings.ConsiderPreTokenization">
            <summary>
            Gets or sets a value indicating whether to consider the pre-tokenization during encoding.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.EncodeSettings.MaxTokenCount">
            <summary>
            Gets or sets the maximum number of tokens to generate.
            </summary>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.BertOptions">
            <summary>
            Options for the Bert tokenizer.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.BertOptions.LowerCaseBeforeTokenization">
            <summary>
            Gets or sets a value indicating whether to lower case the input before tokenization.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.BertOptions.ApplyBasicTokenization">
            <summary>
            Gets or sets a value indicating whether to apply basic tokenization.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.BertOptions.SplitOnSpecialTokens">
            <summary>
            Gets or sets a value indicating whether to split on special tokens.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.BertOptions.SeparatorToken">
            <summary>
            Gets or sets the separator token to use.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.BertOptions.PaddingToken">
            <summary>
            Gets or sets the padding token to use.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.BertOptions.ClassificationToken">
            <summary>
            Gets or sets the classification token to use.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.BertOptions.MaskingToken">
            <summary>
            Gets or sets the masking token to use.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.BertOptions.IndividuallyTokenizeCjk">
            <summary>
            Gets or sets a value indicating whether to tokenize the CJK characters in separate tokens.
            </summary>
            <remarks>
            This is useful when you want to tokenize CJK characters individually.
            The following Unicode ranges are considered CJK characters for this purpose:
            - U+3400 - U+4DBF   CJK Unified Ideographs Extension A.
            - U+4E00 - U+9FFF   basic set of CJK characters.
            - U+F900 - U+FAFF   CJK Compatibility Ideographs.
            - U+20000 - U+2A6DF CJK Unified Ideographs Extension B.
            - U+2A700 - U+2B73F CJK Unified Ideographs Extension C.
            - U+2B740 - U+2B81F CJK Unified Ideographs Extension D.
            - U+2B820 - U+2CEAF CJK Unified Ideographs Extension E.
            - U+2F800 - U+2FA1F CJK Compatibility Ideographs Supplement.
            </remarks>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.BertOptions.RemoveNonSpacingMarks">
            <summary>
            Gets or sets a value indicating whether to remove non-spacing marks.
            </summary>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.BertTokenizer">
            <summary>
            Tokenizer for Bert model.
            </summary>
            <remarks>
            The BertTokenizer is a based on the WordPieceTokenizer and is used to tokenize text for Bert models.
            The implementation of the BertTokenizer is based on the original Bert implementation in the Hugging Face Transformers library.
            https://huggingface.co/transformers/v3.0.2/model_doc/bert.html?highlight=berttokenizerfast#berttokenizer
            </remarks>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.BertTokenizer.LowerCaseBeforeTokenization">
            <summary>
            Gets a value indicating whether the tokenizer should lowercase the input text.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.BertTokenizer.ApplyBasicTokenization">
            <summary>
            Gets a value indicating whether the tokenizer should do basic tokenization. Like clean text, normalize it, lowercasing, etc.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.BertTokenizer.SplitOnSpecialTokens">
            <summary>
            Gets a value indicating whether the tokenizer should split on the special tokens or treat special tokens as normal text.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.BertTokenizer.SeparatorToken">
            <summary>
            Gets the separator token, which is used when building a sequence from multiple sequences, e.g. two sequences for sequence classification or for a text and a question for question answering.
            It is also used as the last token of a sequence built with special tokens.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.BertTokenizer.SeparatorTokenId">
            <summary>
            Gets the separator token Id
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.BertTokenizer.PaddingToken">
            <summary>
            Gets the token used for padding, for example when batching sequences of different lengths
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.BertTokenizer.PaddingTokenId">
            <summary>
            Gets padding token Id
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.BertTokenizer.ClassificationToken">
            <summary>
            Gets the classifier token which is used when doing sequence classification (classification of the whole sequence instead of per-token classification).
            It is the first token of the sequence when built with special tokens.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.BertTokenizer.ClassificationTokenId">
            <summary>
            Gets the classifier token Id
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.BertTokenizer.MaskingToken">
            <summary>
            Gets the mask token used for masking values. This is the token used when training this model with masked language modeling.
            This is the token which the model will try to predict.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.BertTokenizer.MaskingTokenId">
            <summary>
            Gets the mask token Id
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.BertTokenizer.IndividuallyTokenizeCjk">
            <summary>
            Gets a value indicating whether the tokenizer should split the CJK characters into tokens.
            </summary>
            <remarks>
            This is useful when you want to tokenize CJK characters individually.
            The following Unicode ranges are considered CJK characters for this purpose:
            - U+3400 - U+4DBF   CJK Unified Ideographs Extension A.
            - U+4E00 - U+9FFF   basic set of CJK characters.
            - U+F900 - U+FAFF   CJK Compatibility Ideographs.
            - U+20000 - U+2A6DF CJK Unified Ideographs Extension B.
            - U+2A700 - U+2B73F CJK Unified Ideographs Extension C.
            - U+2B740 - U+2B81F CJK Unified Ideographs Extension D.
            - U+2B820 - U+2CEAF CJK Unified Ideographs Extension E.
            - U+2F800 - U+2FA1F CJK Compatibility Ideographs Supplement.
            </remarks>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.BertTokenizer.RemoveNonSpacingMarks">
            <summary>
            Gets a value indicating whether to remove non-spacing marks.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.BertTokenizer.EncodeToIds(System.String,System.Boolean,System.Boolean)">
            <summary>
            Encodes input text to token Ids.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <returns>The list of encoded Ids.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.BertTokenizer.EncodeToIds(System.ReadOnlySpan{System.Char},System.Boolean,System.Boolean)">
            <summary>
            Encodes input text to token Ids.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <returns>The list of encoded Ids.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.BertTokenizer.EncodeToIds(System.String,System.Boolean,System.Boolean,System.Boolean)">
            <summary>
            Encodes input text to token Ids.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="addSpecialTokens">Indicate whether to add special tokens to the encoded Ids.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <returns>The list of encoded Ids.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.BertTokenizer.EncodeToIds(System.ReadOnlySpan{System.Char},System.Boolean,System.Boolean,System.Boolean)">
            <summary>
            Encodes input text to token Ids.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="addSpecialTokens">Indicate whether to add special tokens to the encoded Ids.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <returns>The list of encoded Ids.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.BertTokenizer.EncodeToIds(System.String,System.Int32,System.String@,System.Int32@,System.Boolean,System.Boolean)">
            <summary>
            Encodes input text to token Ids.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="maxTokenCount">The maximum number of tokens to return.</param>
            <param name="normalizedText">The normalized text.</param>
            <param name="charsConsumed">The number of characters consumed from the input text.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <returns>The list of encoded Ids.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.BertTokenizer.EncodeToIds(System.ReadOnlySpan{System.Char},System.Int32,System.String@,System.Int32@,System.Boolean,System.Boolean)">
            <summary>
            Encodes input text to token Ids.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="maxTokenCount">The maximum number of tokens to return.</param>
            <param name="normalizedText">The normalized text.</param>
            <param name="charsConsumed">The number of characters consumed from the input text.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <returns>The list of encoded Ids.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.BertTokenizer.EncodeToIds(System.String,System.Int32,System.Boolean,System.String@,System.Int32@,System.Boolean,System.Boolean)">
            <summary>
            Encodes input text to token Ids.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="maxTokenCount">The maximum number of tokens to return.</param>
            <param name="addSpecialTokens">Indicate whether to add special tokens to the encoded Ids.</param>
            <param name="normalizedText">The normalized text.</param>
            <param name="charsConsumed">The number of characters consumed from the input text.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <returns>The list of encoded Ids.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.BertTokenizer.EncodeToIds(System.ReadOnlySpan{System.Char},System.Int32,System.Boolean,System.String@,System.Int32@,System.Boolean,System.Boolean)">
            <summary>
            Encodes input text to token Ids.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="maxTokenCount">The maximum number of tokens to return.</param>
            <param name="addSpecialTokens">Indicate whether to add special tokens to the encoded Ids.</param>
            <param name="normalizedText">The normalized text.</param>
            <param name="charsConsumed">The number of characters consumed from the input text.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <returns>The list of encoded Ids.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.BertTokenizer.BuildInputsWithSpecialTokens(System.Collections.Generic.IEnumerable{System.Int32},System.Collections.Generic.IEnumerable{System.Int32})">
            <summary>
            Build model inputs from a sequence or a pair of sequence for sequence classification tasks by concatenating and adding special tokens. A BERT sequence has the following format:
                - single sequence: `[CLS] tokenIds [SEP]`
                - pair of sequences: `[CLS] tokenIds [SEP] additionalTokenIds [SEP]`
            </summary>
            <param name="tokenIds">List of IDs to which the special tokens will be added.</param>
            <param name="additionalTokenIds">Optional second list of IDs for sequence pairs.</param>
            <returns>The list of IDs with special tokens added.</returns>
            <exception cref="T:System.ArgumentNullException">When <paramref name="tokenIds"/> is null.</exception>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.BertTokenizer.BuildInputsWithSpecialTokens(System.Collections.Generic.IEnumerable{System.Int32},System.Span{System.Int32},System.Int32@,System.Collections.Generic.IEnumerable{System.Int32})">
            <summary>
            Build model inputs from a sequence or a pair of sequence for sequence classification tasks by concatenating and adding special tokens. A BERT sequence has the following format:
                - single sequence: `[CLS] tokenIds [SEP]`
                - pair of sequences: `[CLS] tokenIds [SEP] additionalTokenIds [SEP]`
            </summary>
            <param name="tokenIds">List of IDs to which the special tokens will be added.</param>
            <param name="destination">The destination buffer to write the token IDs with special tokens added.</param>
            <param name="valuesWritten">The number of elements written to the destination buffer.</param>
            <param name="additionalTokenIds">Optional second list of IDs for sequence pairs.</param>
            <returns>The status of the operation.</returns>
            <exception cref="T:System.ArgumentNullException">When <paramref name="tokenIds"/> is null.</exception>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.BertTokenizer.GetSpecialTokensMask(System.Collections.Generic.IEnumerable{System.Int32},System.Collections.Generic.IEnumerable{System.Int32},System.Boolean)">
            <summary>
            Retrieve sequence tokens mask from a IDs list.
            </summary>
            <param name="tokenIds">List of IDs.</param>
            <param name="additionalTokenIds">Optional second list of IDs for sequence pairs.</param>
            <param name="alreadyHasSpecialTokens">Indicate whether or not the token list is already formatted with special tokens for the model.</param>
            <returns>A list of integers in the range [0, 1]: 1 for a special token, 0 for a sequence token.</returns>
            <exception cref="T:System.ArgumentNullException"></exception>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.BertTokenizer.GetSpecialTokensMask(System.Collections.Generic.IEnumerable{System.Int32},System.Span{System.Int32},System.Int32@,System.Collections.Generic.IEnumerable{System.Int32},System.Boolean)">
            <summary>
            Retrieve sequence tokens mask from a IDs list.
            </summary>
            <param name="tokenIds">List of IDs.</param>
            <param name="destination">The destination buffer to write the mask. The integers written values are in the range [0, 1]: 1 for a special token, 0 for a sequence token.</param>
            <param name="valuesWritten">The number of elements written to the destination buffer.</param>
            <param name="additionalTokenIds">Optional second list of IDs for sequence pairs.</param>
            <param name="alreadyHasSpecialTokens">Indicate whether or not the token list is already formatted with special tokens for the model.</param>
            <returns>The status of the operation.</returns>
            <exception cref="T:System.ArgumentNullException"></exception>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.BertTokenizer.CreateTokenTypeIdsFromSequences(System.Collections.Generic.IEnumerable{System.Int32},System.Collections.Generic.IEnumerable{System.Int32})">
            <summary>
            Create a mask from the two sequences passed to be used in a sequence-pair classification task. A BERT sequence pair mask has the following format:
                    0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1
                    | first sequence    | second sequence |
            If <paramref name="additionalTokenIds"/> is null, this method only returns the first portion of the type ids (0s).
            </summary>
            <param name="tokenIds">List of token IDs for the first sequence.</param>
            <param name="additionalTokenIds">Optional list of token IDs for the second sequence.</param>
            <returns>List of token type IDs according to the given sequence(s).</returns>
            <exception cref="T:System.ArgumentNullException">When <paramref name="tokenIds"/> is null.</exception>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.BertTokenizer.Create(System.String,Microsoft.ML.Tokenizers.BertOptions)">
            <summary>
            Create a new instance of the <see cref="T:Microsoft.ML.Tokenizers.BertTokenizer"/> class.
            </summary>
            <param name="vocabFilePath">The path to the vocabulary file.</param>
            <param name="options">The options to use for the Bert tokenizer.</param>
            <returns>A new instance of the <see cref="T:Microsoft.ML.Tokenizers.BertTokenizer"/> class.</returns>
            <remarks>
            When creating the tokenizer, ensure that the vocabulary file is sourced from a trusted provider.
            </remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.BertTokenizer.Create(System.IO.Stream,Microsoft.ML.Tokenizers.BertOptions)">
            <summary>
            Create a new instance of the <see cref="T:Microsoft.ML.Tokenizers.BertTokenizer"/> class.
            </summary>
            <param name="vocabStream">The stream containing the vocabulary file.</param>
            <param name="options">The options to use for the Bert tokenizer.</param>
            <returns>A new instance of the <see cref="T:Microsoft.ML.Tokenizers.BertTokenizer"/> class.</returns>
            <remarks>
            When creating the tokenizer, ensure that the vocabulary stream is sourced from a trusted provider.
            </remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.BertTokenizer.CreateAsync(System.IO.Stream,Microsoft.ML.Tokenizers.BertOptions,System.Threading.CancellationToken)">
            <summary>
            Create a new instance of the <see cref="T:Microsoft.ML.Tokenizers.BertTokenizer"/> class asynchronously.
            </summary>
            <param name="vocabStream">The stream containing the vocabulary file.</param>
            <param name="options">The options to use for the Bert tokenizer.</param>
            <param name="cancellationToken">The cancellation token.</param>
            <returns>A task that represents the asynchronous creation of the BertTokenizer.</returns>
            <remarks>
            When creating the tokenizer, ensure that the vocabulary stream is sourced from a trusted provider.
            </remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.BertTokenizer.CreateAsync(System.String,Microsoft.ML.Tokenizers.BertOptions,System.Threading.CancellationToken)">
            <summary>
            Create a new instance of the <see cref="T:Microsoft.ML.Tokenizers.BertTokenizer"/> class asynchronously.
            </summary>
            <param name="vocabFilePath">The path to the vocabulary file.</param>
            <param name="options">The options to use for the Bert tokenizer.</param>
            <param name="cancellationToken">The cancellation token.</param>
            <returns>A task that represents the asynchronous creation of the BertTokenizer.</returns>
            <remarks>
            When creating the tokenizer, ensure that the vocabulary file is sourced from a trusted provider.
            </remarks>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.BpeTokenizer">
            <summary>
            Represent the Byte Pair Encoding model.
            </summary>
        </member>
        <member name="F:Microsoft.ML.Tokenizers.BpeTokenizer.MaxWordLengthToCache">
            A [Byte Pair Encoding](https://www.aclweb.org/anthology/P16-1162/) model.
        </member>
        <member name="P:Microsoft.ML.Tokenizers.BpeTokenizer.SpecialTokens">
            <summary>
            Gets the special tokens.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.BpeTokenizer.UnknownToken">
            <summary>
            Gets or Sets unknown token. The unknown token to be used when we encounter an unknown char
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.BpeTokenizer.ContinuingSubwordPrefix">
            <summary>
            A prefix to be used for every subword that is not a beginning-of-word
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.BpeTokenizer.EndOfWordSuffix">
            <summary>
            An optional suffix to characterize and end-of-word sub-word
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.BpeTokenizer.FuseUnknownTokens">
            <summary>
            Gets or sets whether allowing multiple unknown tokens get fused
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.BpeTokenizer.Create(System.String,System.String)">
            <summary>
            Create a new Bpe tokenizer object to use for text encoding.
            </summary>
            <param name="vocabFile">The JSON file path containing the dictionary of string keys and their ids.</param>
            <param name="mergesFile">The file path containing the tokens's pairs list.</param>
            <remarks>
            When creating the tokenizer, ensure that the vocabulary file is sourced from a trusted provider.
            </remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.BpeTokenizer.Create(System.String,System.String,Microsoft.ML.Tokenizers.PreTokenizer,Microsoft.ML.Tokenizers.Normalizer,System.Collections.Generic.IReadOnlyDictionary{System.String,System.Int32},System.String,System.String,System.String,System.Boolean)">
            <summary>
            Create a new Bpe tokenizer object to use for text encoding.
            </summary>
            <param name="vocabFile">The JSON file path containing the dictionary of string keys and their ids.</param>
            <param name="mergesFile">The file path containing the tokens's pairs list.</param>
            <param name="preTokenizer">The pre-tokenizer to use.</param>
            <param name="normalizer">The normalizer to use.</param>
            <param name="specialTokens">The dictionary mapping special tokens to Ids.</param>
            <param name="unknownToken"> The unknown token to be used by the model.</param>
            <param name="continuingSubwordPrefix">The prefix to attach to sub-word units that don’t represent a beginning of word.</param>
            <param name="endOfWordSuffix">The suffix to attach to sub-word units that represent an end of word.</param>
            <param name="fuseUnknownTokens">Indicate whether allowing multiple unknown tokens get fused.</param>
            <remarks>
            When creating the tokenizer, ensure that the vocabulary file is sourced from a trusted provider.
            </remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.BpeTokenizer.Create(System.IO.Stream,System.IO.Stream)">
            <summary>
            Create a new Bpe tokenizer object to use for text encoding.
            </summary>
            <param name="vocabStream">The JSON stream containing the dictionary of string keys and their ids.</param>
            <param name="mergesStream">The stream containing the tokens's pairs list.</param>
            <remarks>
            When creating the tokenizer, ensure that the vocabulary stream is sourced from a trusted provider.
            </remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.BpeTokenizer.Create(System.IO.Stream,System.IO.Stream,Microsoft.ML.Tokenizers.PreTokenizer,Microsoft.ML.Tokenizers.Normalizer,System.Collections.Generic.IReadOnlyDictionary{System.String,System.Int32},System.String,System.String,System.String,System.Boolean)">
            <summary>
            Create a new Bpe tokenizer object to use for text encoding.
            </summary>
            <param name="vocabStream">The JSON stream containing the dictionary of string keys and their ids.</param>
            <param name="mergesStream">The stream containing the tokens's pairs list.</param>
            <param name="preTokenizer">The pre-tokenizer to use.</param>
            <param name="normalizer">The normalizer to use.</param>
            <param name="specialTokens">The dictionary mapping special tokens to Ids.</param>
            <param name="unknownToken"> The unknown token to be used by the model.</param>
            <param name="continuingSubwordPrefix">The prefix to attach to sub-word units that don’t represent a beginning of word.</param>
            <param name="endOfWordSuffix">The suffix to attach to sub-word units that represent an end of word.</param>
            <param name="fuseUnknownTokens">Indicate whether allowing multiple unknown tokens get fused.</param>
            <remarks>
            When creating the tokenizer, ensure that the vocabulary stream is sourced from a trusted provider.
            </remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.BpeTokenizer.CreateAsync(System.IO.Stream,System.IO.Stream,Microsoft.ML.Tokenizers.PreTokenizer,Microsoft.ML.Tokenizers.Normalizer,System.Collections.Generic.IReadOnlyDictionary{System.String,System.Int32},System.String,System.String,System.String,System.Boolean)">
            <summary>
            Create a new Bpe tokenizer object asynchronously to use for text encoding.
            </summary>
            <param name="vocabStream">The JSON stream containing the dictionary of string keys and their ids.</param>
            <param name="mergesStream">The stream containing the tokens's pairs list.</param>
            <param name="preTokenizer">The pre-tokenizer to use.</param>
            <param name="normalizer">The normalizer to use.</param>
            <param name="specialTokens">The dictionary mapping special tokens to Ids.</param>
            <param name="unknownToken"> The unknown token to be used by the model.</param>
            <param name="continuingSubwordPrefix">The prefix to attach to sub-word units that don’t represent a beginning of word.</param>
            <param name="endOfWordSuffix">The suffix to attach to sub-word units that represent an end of word.</param>
            <param name="fuseUnknownTokens">Indicate whether allowing multiple unknown tokens get fused.</param>
            <remarks>
            When creating the tokenizer, ensure that the vocabulary stream is sourced from a trusted provider.
            </remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.BpeTokenizer.#ctor(System.Collections.Generic.Dictionary{Microsoft.ML.Tokenizers.StringSpanOrdinalKey,System.Int32},Microsoft.ML.Tokenizers.Vec{System.ValueTuple{System.String,System.String}},Microsoft.ML.Tokenizers.PreTokenizer,Microsoft.ML.Tokenizers.Normalizer,System.Collections.Generic.IReadOnlyDictionary{System.String,System.Int32},System.String,System.String,System.String,System.Boolean)">
            <summary>
            Construct a new Bpe model object to use for text encoding.
            </summary>
            <param name="vocab">The dictionary vocabulary mapping token string to ids.</param>
            <param name="merges">The pairs list help in merging tokens during the encoding process.</param>
            <param name="preTokenizer">The pre-tokenizer to use.</param>
            <param name="normalizer">The normalizer to use.</param>
            <param name="specialTokens">The dictionary mapping special tokens to Ids.</param>
            <param name="unknownToken"> The unknown token to be used by the model.</param>
            <param name="continuingSubwordPrefix">The prefix to attach to sub-word units that don’t represent a beginning of word.</param>
            <param name="endOfWordSuffix">The suffix to attach to sub-word units that represent an end of word.</param>
            <param name="fuseUnknownTokens">Indicate whether allowing multiple unknown tokens get fused.</param>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.BpeTokenizer.PreTokenizer">
            <summary>
            Gets the PreTokenizer used by the Tokenizer.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.BpeTokenizer.Normalizer">
            <summary>
            Gets the Normalizer in use by the Tokenizer.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.BpeTokenizer.EncodeToTokens(System.String,System.ReadOnlySpan{System.Char},Microsoft.ML.Tokenizers.EncodeSettings)">
            <summary>
            Encodes input text to a list of <see cref="T:Microsoft.ML.Tokenizers.EncodedToken" />s.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="textSpan">The span of the text to encode which will be used if the <paramref name="text"/> is <see langword="null"/>.</param>
            <param name="settings">The settings used to encode the text.</param>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.BpeTokenizer.EncodeToIds(System.String,System.ReadOnlySpan{System.Char},Microsoft.ML.Tokenizers.EncodeSettings)">
            <summary>
            Encodes input text to token Ids.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="textSpan">The span of the text to encode which will be used if the <paramref name="text"/> is <see langword="null"/>.</param>
            <param name="settings">The settings used to encode the text.</param>
            <returns>The encoded results containing the list of encoded Ids.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.BpeTokenizer.CountTokens(System.String,System.ReadOnlySpan{System.Char},Microsoft.ML.Tokenizers.EncodeSettings)">
            <summary>
            Get the number of tokens that the input text will be encoded to.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="textSpan">The span of the text to encode which will be used if the <paramref name="text"/> is <see langword="null"/>.</param>
            <param name="settings">The settings used to encode the text.</param>
            <returns>The number of token Ids that the input text will be encoded to.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.BpeTokenizer.GetIndexByTokenCount(System.String,System.ReadOnlySpan{System.Char},Microsoft.ML.Tokenizers.EncodeSettings,System.Boolean,System.String@,System.Int32@)">
            <summary>
            Find the index of the maximum encoding capacity without surpassing the token limit.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="textSpan">The span of the text to encode which will be used if the <paramref name="text"/> is <see langword="null"/>.</param>
            <param name="settings">The settings used to encode the text.</param>
            <param name="fromEnd">Indicate whether to find the index from the end of the text.</param>
            <param name="normalizedText">If the tokenizer's normalization is enabled or <paramRef name="settings" /> has <see cref="P:Microsoft.ML.Tokenizers.EncodeSettings.ConsiderNormalization"/> is <see langword="false"/>, this will be set to <paramRef name="text" /> in its normalized form; otherwise, this value will be set to <see langword="null"/>.</param>
            <param name="tokenCount">The token count can be generated which should be smaller than the maximum token count.</param>
            <returns>
            The index of the maximum encoding capacity within the processed text without surpassing the token limit.
            If <paramRef name="fromEnd" /> is <see langword="false"/>, it represents the index immediately following the last character to be included. In cases where no tokens fit, the result will be 0; conversely,
            if all tokens fit, the result will be length of the input text or the <paramref name="normalizedText"/> if the normalization is enabled.
            If <paramRef name="fromEnd" /> is <see langword="true"/>, it represents the index of the first character to be included. In cases where no tokens fit, the result will be the text length; conversely,
            if all tokens fit, the result will be zero.
            </returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.BpeTokenizer.MapTokenToId(System.ReadOnlySpan{System.Char})">
            <summary>
            Map the token to encoded Id.
            </summary>
            <param name="token">The token to map to the Id.</param>
            <returns>The mapped Id of the token.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.BpeTokenizer.MapIdToToken(System.Int32)">
            <summary>
            Map the encoded Id to the token.
            </summary>
            <param name="id">The Id to map to the token.</param>
            <returns>The mapped token of the Id.</returns>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.BpeTokenizer.Vocabulary">
            <summary>
            Gets the dictionary mapping tokens to Ids.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.BpeTokenizer.Decode(System.Collections.Generic.IEnumerable{System.Int32})">
            <summary>
            Decode the given ids, back to a String.
            </summary>
            <param name="ids">The list of ids that we want to decode.</param>
            <returns>The decoded string.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.BpeTokenizer.Decode(System.Collections.Generic.IEnumerable{System.Int32},System.Boolean)">
            <summary>
            Decode the given ids, back to a String.
            </summary>
            <param name="ids">The list of ids that we want to decode.</param>
            <param name="considerSpecialTokens">Indicate whether to consider special tokens or not.</param>
            <returns>The decoded string.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.BpeTokenizer.Decode(System.Collections.Generic.IEnumerable{System.Int32},System.Span{System.Char},System.Int32@,System.Int32@)">
            <summary>
            Decode the given ids back to text and store the result in the <paramref name="destination"/> span.
            </summary>
            <param name="ids">The list of ids that we want to decode.</param>
            <param name="destination">The span to store the decoded text.</param>
            <param name="idsConsumed">The number of ids consumed during the decoding.</param>
            <param name="charsWritten">The number of characters written to the destination span.</param>
            <returns>The operation status indicates whether all IDs were successfully decoded or if the <paramref name="destination"/> is too small to contain the entire decoded result.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.BpeTokenizer.Decode(System.Collections.Generic.IEnumerable{System.Int32},System.Span{System.Char},System.Boolean,System.Int32@,System.Int32@)">
            <summary>
            Decode the given ids back to text and store the result in the <paramref name="destination"/> span.
            </summary>
            <param name="ids">The list of ids that we want to decode.</param>
            <param name="destination">The span to store the decoded text.</param>
            <param name="considerSpecialTokens">Indicate whether to consider special tokens or not.</param>
            <param name="idsConsumed">The number of ids consumed during the decoding.</param>
            <param name="charsWritten">The number of characters written to the destination span.</param>
            <returns>The operation status indicates whether all IDs were successfully decoded or if the <paramref name="destination"/> is too small to contain the entire decoded result.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.BpeTokenizer.ReadModelDataAsync(System.IO.Stream,System.IO.Stream,System.Boolean,System.Threading.CancellationToken)">
            Read the given files to extract the vocab and merges
        </member>
        <member name="F:Microsoft.ML.Tokenizers.BpeTokenizer._vocab">
            The vocabulary assigns a number to each token.
        </member>
        <member name="P:Microsoft.ML.Tokenizers.BpeTokenizer.Merges">
            Contains the mapping between Pairs and their (rank, newId).
        </member>
        <member name="P:Microsoft.ML.Tokenizers.BpeTokenizer.Cache">
            Contains the cache for optimizing the encoding step.
        </member>
        <member name="P:Microsoft.ML.Tokenizers.BpeTokenizer.VocabReverse">
            Reversed vocabulary, to rebuild the text.
        </member>
        <member name="P:Microsoft.ML.Tokenizers.BpeTokenizer.Dropout">
            Dropout probability for merges. 0 = no dropout is the default. At 1.0, tokenization will
            perform no merges, so the result will just be characters.
        </member>
        <member name="M:Microsoft.ML.Tokenizers.BpeTokenizer.ConvertMergesToHashmapAsync(System.IO.Stream,System.Boolean,System.Threading.CancellationToken)">
            Converts the merges strings (for example from `merges.txt` file) with the format
            "{pair_a} {pair_b}" into the format expected by the BPE struct
        </member>
        <member name="T:Microsoft.ML.Tokenizers.CodeGenTokenizer">
            <summary>
            Represent the Byte Pair Encoding model.
            Implement the CodeGen tokenizer described in https://huggingface.co/docs/transformers/main/en/model_doc/codegen#overview
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.CodeGenTokenizer.#ctor(System.String,System.String,Microsoft.ML.Tokenizers.PreTokenizer,Microsoft.ML.Tokenizers.Normalizer,System.Collections.Generic.IReadOnlyDictionary{System.String,System.Int32},System.Boolean,System.Boolean,System.Boolean,System.String,System.String,System.String)">
            <summary>
            Construct tokenizer's model object to use with the English Robert model.
            </summary>
            <param name="vocabularyPath">The JSON file path containing the dictionary of string keys and their ids.</param>
            <param name="mergePath">The file path containing the tokens's pairs list.</param>
            <param name="preTokenizer">The pre-tokenizer to use.</param>
            <param name="normalizer">The normalizer to use.</param>
            <param name="specialTokens">The dictionary mapping special tokens to Ids.</param>
            <param name="addPrefixSpace">Indicate whether to include a leading space before encoding the text.</param>
            <param name="addBeginningOfSentence">Indicate whether to include the beginning of sentence token in the encoding.</param>
            <param name="addEndOfSentence">Indicate whether to include the end of sentence token in the encoding.</param>
            <param name="unknownToken">The unknown token.</param>
            <param name="beginningOfSentenceToken">The beginning of sentence token.</param>
            <param name="endOfSentenceToken">The end of sentence token.</param>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.CodeGenTokenizer.#ctor(System.IO.Stream,System.IO.Stream,Microsoft.ML.Tokenizers.PreTokenizer,Microsoft.ML.Tokenizers.Normalizer,System.Collections.Generic.IReadOnlyDictionary{System.String,System.Int32},System.Boolean,System.Boolean,System.Boolean,System.String,System.String,System.String)">
            <summary>
            Construct tokenizer's model object to use with the English Robert model.
            </summary>
            <param name="vocabularyStream">The stream of a JSON file containing the dictionary of string keys and their ids.</param>
            <param name="mergeStream">The stream of a file containing the tokens's pairs list.</param>
            <param name="preTokenizer">The pre-tokenizer to use.</param>
            <param name="normalizer">The normalizer to use.</param>
            <param name="specialTokens">The dictionary mapping special tokens to Ids.</param>
            <param name="addPrefixSpace">Indicate whether to include a leading space before encoding the text.</param>
            <param name="addBeginningOfSentence">Indicate whether to include the beginning of sentence token in the encoding.</param>
            <param name="addEndOfSentence">Indicate whether to include the end of sentence token in the encoding.</param>
            <param name="unknownToken">The unknown token.</param>
            <param name="beginningOfSentenceToken">The beginning of sentence token.</param>
            <param name="endOfSentenceToken">The end of sentence token.</param>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.CodeGenTokenizer.SpecialTokens">
            <summary>
            Gets the added tokens.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.CodeGenTokenizer.UnknownToken">
            <summary>
            The Unknown token.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.CodeGenTokenizer.UnknownTokenId">
            <summary>
            Gets the Unknown token Id.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.CodeGenTokenizer.AddBeginningOfSentence">
            <summary>
            Gets the flag indicating whether to include the beginning of sentence token in the encoding.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.CodeGenTokenizer.AddEndOfSentence">
            <summary>
            Gets the flag indicating whether to include the end of sentence token in the encoding.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.CodeGenTokenizer.BeginningOfSentenceToken">
            <summary>
            Gets the beginning of sentence token.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.CodeGenTokenizer.BeginningOfSentenceId">
            <summary>
            Gets the end of sentence token Id.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.CodeGenTokenizer.EndOfSentenceId">
            <summary>
            Gets the end of sentence token Id.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.CodeGenTokenizer.EndOfSentenceToken">
            <summary>
            Gets the end of sentence token.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.CodeGenTokenizer.AddPrefixSpace">
            <summary>
            Gets the flag indicating whether to include a leading space before encoding the text.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.CodeGenTokenizer.PreTokenizer">
            <summary>
            Gets the PreTokenizer used by the Tokenizer.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.CodeGenTokenizer.Normalizer">
            <summary>
            Gets the Normalizer in use by the Tokenizer.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.CodeGenTokenizer.Vocabulary">
            <summary>
            Gets the dictionary mapping tokens to Ids.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.CodeGenTokenizer.EncodeToTokens(System.String,System.ReadOnlySpan{System.Char},Microsoft.ML.Tokenizers.EncodeSettings)">
            <summary>
            Encodes input text to a list of <see cref="T:Microsoft.ML.Tokenizers.EncodedToken" />s.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="textSpan">The span of the text to encode which will be used if the <paramref name="text"/> is <see langword="null"/>.</param>
            <param name="settings">The settings used to encode the text.</param>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.CodeGenTokenizer.EncodeToTokens(System.String,System.Boolean,System.Boolean,System.Boolean,System.String@,System.Boolean,System.Boolean)">
            <summary>
            Encodes input text to object has the tokens list, tokens Ids, tokens offset mapping.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="normalizedText">If the tokenizer's normalization is enabled, the input text will be represented in its normalization form; otherwise, it will null.</param>
            <param name="addPrefixSpace">Indicate whether to include a leading space before encoding the text.</param>
            <param name="addBeginningOfSentence">Indicate whether to include the beginning of sentence token in the encoding.</param>
            <param name="addEndOfSentence">Indicate whether to include the end of sentence token in the encoding.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <returns>The tokenization result includes the tokens list, tokens Ids, tokens offset mapping.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.CodeGenTokenizer.EncodeToTokens(System.ReadOnlySpan{System.Char},System.Boolean,System.Boolean,System.Boolean,System.String@,System.Boolean,System.Boolean)">
            <summary>
            Encodes input text to object has the tokens list, tokens Ids, tokens offset mapping.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="normalizedText">If the tokenizer's normalization is enabled, the input text will be represented in its normalization form; otherwise, it will null.</param>
            <param name="addPrefixSpace">Indicate whether to include a leading space before encoding the text.</param>
            <param name="addBeginningOfSentence">Indicate whether to include the beginning of sentence token in the encoding.</param>
            <param name="addEndOfSentence">Indicate whether to include the end of sentence token in the encoding.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <returns>The tokenization result includes the tokens list, tokens Ids, tokens offset mapping.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.CodeGenTokenizer.EncodeInternal(System.String,System.ReadOnlySpan{System.Char},System.Collections.Generic.List{Microsoft.ML.Tokenizers.EncodedToken},System.Boolean,System.Int32,Microsoft.ML.Tokenizers.PriorityQueue{Microsoft.ML.Tokenizers.CodeGenTokenizer.SymbolPair})">
            <summary>
            Encode a text string to a list of tokens.
            </summary>
            <param name="text">The text in form of string to encode if it is available.</param>
            <param name="textSpan">The text in form of span to encode.</param>
            <param name="tokens">The tokens to include in the newly encoded sequence.</param>
            <param name="addPrefixSpace">Indicate whether to include a leading space before encoding the text.</param>
            <param name="offset">The offset to adjust the token's offset.</param>
            <param name="agenda">The priority queue to use for encoding.</param>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.CodeGenTokenizer.EncodeToIds(System.String,System.ReadOnlySpan{System.Char},Microsoft.ML.Tokenizers.EncodeSettings)">
            <summary>
            Encodes input text to token Ids.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="textSpan">The span of the text to encode which will be used if the <paramref name="text"/> is <see langword="null"/>.</param>
            <param name="settings">The settings used to encode the text.</param>
            <returns>The encoded results containing the list of encoded Ids.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.CodeGenTokenizer.EncodeToIds(System.String,System.Boolean,System.Boolean,System.Boolean,System.Boolean,System.Boolean)">
            <summary>
            Encodes input text to tokens Ids.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="addPrefixSpace">Indicate whether to include a leading space before encoding the text.</param>
            <param name="addBeginningOfSentence">Indicate whether to include the beginning of sentence token in the encoding.</param>
            <param name="addEndOfSentence">Indicate whether to include the end of sentence token in the encoding.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <returns>The list of encoded Ids.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.CodeGenTokenizer.EncodeToIds(System.ReadOnlySpan{System.Char},System.Boolean,System.Boolean,System.Boolean,System.Boolean,System.Boolean)">
            <summary>
            Encodes input text to tokens Ids.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="addPrefixSpace">Indicate whether to include a leading space before encoding the text.</param>
            <param name="addBeginningOfSentence">Indicate whether to include the beginning of sentence token in the encoding.</param>
            <param name="addEndOfSentence">Indicate whether to include the end of sentence token in the encoding.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <returns>The list of encoded Ids.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.CodeGenTokenizer.EncodeToIds(System.String,System.Int32,System.Boolean,System.Boolean,System.Boolean,System.String@,System.Int32@,System.Boolean,System.Boolean)">
            <summary>
            Encodes input text to tokens Ids up to maximum number of tokens.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="maxTokenCount">The maximum number of tokens to encode.</param>
            <param name="addPrefixSpace">Indicate whether to include a leading space before encoding the text.</param>
            <param name="addBeginningOfSentence">Indicate whether to include the beginning of sentence token in the encoding.</param>
            <param name="addEndOfSentence">Indicate whether to include the end of sentence token in the encoding.</param>
            <param name="normalizedText">If the tokenizer's normalization is enabled, the input text will be represented in its normalization form; otherwise, it will be null.</param>
            <param name="charsConsumed">The length of the text that encompasses the maximum encoded tokens.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <returns>The list of encoded Ids.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.CodeGenTokenizer.EncodeToIds(System.ReadOnlySpan{System.Char},System.Int32,System.Boolean,System.Boolean,System.Boolean,System.String@,System.Int32@,System.Boolean,System.Boolean)">
            <summary>
            Encodes input text to tokens Ids up to maximum number of tokens.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="maxTokenCount">The maximum number of tokens to encode.</param>
            <param name="addPrefixSpace">Indicate whether to include a leading space before encoding the text.</param>
            <param name="addBeginningOfSentence">Indicate whether to include the beginning of sentence token in the encoding.</param>
            <param name="addEndOfSentence">Indicate whether to include the end of sentence token in the encoding.</param>
            <param name="normalizedText">If the tokenizer's normalization is enabled, the input text will be represented in its normalization form; otherwise, it will be null.</param>
            <param name="charsConsumed">The length of the text that encompasses the maximum encoded tokens.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <returns>The list of encoded Ids.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.CodeGenTokenizer.CountTokens(System.String,System.ReadOnlySpan{System.Char},Microsoft.ML.Tokenizers.EncodeSettings)">
            <summary>
            Get the number of tokens that the input text will be encoded to.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="textSpan">The span of the text to encode which will be used if the <paramref name="text"/> is <see langword="null"/>.</param>
            <param name="settings">The settings used to encode the text.</param>
            <returns>The number of token Ids that the input text will be encoded to.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.CodeGenTokenizer.CountTokens(System.String,System.Boolean,System.Boolean,System.Boolean,System.Boolean,System.Boolean)">
            <summary>
            Get the number of tokens that the input text will be encoded to.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="addPrefixSpace">Indicate whether to include a leading space before encoding the text.</param>
            <param name="addBeginningOfSentence">Indicate whether to include the beginning of sentence token in the encoding.</param>
            <param name="addEndOfSentence">Indicate whether to include the end of sentence token in the encoding.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <returns>The number of tokens Ids that the input text will be encoded to.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.CodeGenTokenizer.CountTokens(System.ReadOnlySpan{System.Char},System.Boolean,System.Boolean,System.Boolean,System.Boolean,System.Boolean)">
            <summary>
            Get the number of tokens that the input text will be encoded to.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="addPrefixSpace">Indicate whether to include a leading space before encoding the text.</param>
            <param name="addBeginningOfSentence">Indicate whether to include the beginning of sentence token in the encoding.</param>
            <param name="addEndOfSentence">Indicate whether to include the end of sentence token in the encoding.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <returns>The number of tokens Ids that the input text will be encoded to.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.CodeGenTokenizer.GetIndexByTokenCount(System.String,System.ReadOnlySpan{System.Char},Microsoft.ML.Tokenizers.EncodeSettings,System.Boolean,System.String@,System.Int32@)">
            <summary>
            Find the index of the maximum encoding capacity without surpassing the token limit.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="textSpan">The span of the text to encode which will be used if the <paramref name="text"/> is <see langword="null"/>.</param>
            <param name="settings">The settings used to encode the text.</param>
            <param name="fromEnd">Indicate whether to find the index from the end of the text.</param>
            <param name="normalizedText">If the tokenizer's normalization is enabled or <paramRef name="settings" /> has <see cref="P:Microsoft.ML.Tokenizers.EncodeSettings.ConsiderNormalization"/> is <see langword="false"/>, this will be set to <paramRef name="text" /> in its normalized form; otherwise, this value will be set to <see langword="null"/>.</param>
            <param name="tokenCount">The token count can be generated which should be smaller than the maximum token count.</param>
            <returns>
            The index of the maximum encoding capacity within the processed text without surpassing the token limit.
            If <paramRef name="fromEnd" /> is <see langword="false"/>, it represents the index immediately following the last character to be included. In cases where no tokens fit, the result will be 0; conversely,
            if all tokens fit, the result will be length of the input text or the <paramref name="normalizedText"/> if the normalization is enabled.
            If <paramRef name="fromEnd" /> is <see langword="true"/>, it represents the index of the first character to be included. In cases where no tokens fit, the result will be the text length; conversely,
            if all tokens fit, the result will be zero.
            </returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.CodeGenTokenizer.GetIndexByTokenCount(System.String,System.Int32,System.Boolean,System.Boolean,System.Boolean,System.String@,System.Int32@,System.Boolean,System.Boolean)">
            <summary>
            Find the index of the maximum encoding capacity from the start within the text without surpassing the token limit.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="maxTokenCount">The maximum token count to limit the encoding capacity.</param>
            <param name="addPrefixSpace">Indicate whether to include a leading space before encoding the text.</param>
            <param name="addBeginningOfSentence">Indicate whether to include the beginning of sentence token in the encoding.</param>
            <param name="addEndOfSentence">Indicate whether to include the end of sentence token in the encoding.</param>
            <param name="normalizedText">If the tokenizer's normalization is enabled, the input text will be represented in its normalization form; otherwise, it will be null.</param>
            <param name="tokenCount">The token count can be generated which should be smaller than the maximum token count.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <returns>
            The index of the maximum encoding capacity within the processed text without surpassing the token limit.
            It represents the index immediately following the last character to be included. In cases where no tokens fit, the result will be 0; conversely,
            if all tokens fit, the result will be length of the text or the <paramref name="normalizedText"/> if the normalization is enabled.
            </returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.CodeGenTokenizer.GetIndexByTokenCount(System.ReadOnlySpan{System.Char},System.Int32,System.Boolean,System.Boolean,System.Boolean,System.String@,System.Int32@,System.Boolean,System.Boolean)">
            <summary>
            Find the index of the maximum encoding capacity from the start within the text without surpassing the token limit.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="maxTokenCount">The maximum token count to limit the encoding capacity.</param>
            <param name="addPrefixSpace">Indicate whether to include a leading space before encoding the text.</param>
            <param name="addBeginningOfSentence">Indicate whether to include the beginning of sentence token in the encoding.</param>
            <param name="addEndOfSentence">Indicate whether to include the end of sentence token in the encoding.</param>
            <param name="normalizedText">If the tokenizer's normalization is enabled, the input text will be represented in its normalization form; otherwise, it will be null.</param>
            <param name="tokenCount">The token count can be generated which should be smaller than the maximum token count.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <returns>
            The index of the maximum encoding capacity within the processed text without surpassing the token limit.
            It represents the index immediately following the last character to be included. In cases where no tokens fit, the result will be 0; conversely,
            if all tokens fit, the result will be length of the text or the <paramref name="normalizedText"/> if the normalization is enabled.
            </returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.CodeGenTokenizer.GetIndexByTokenCountFromEnd(System.String,System.Int32,System.Boolean,System.Boolean,System.Boolean,System.String@,System.Int32@,System.Boolean,System.Boolean)">
            <summary>
            Find the index of the maximum encoding capacity from the end within the text without surpassing the token limit.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="maxTokenCount">The maximum token count to limit the encoding capacity.</param>
            <param name="addPrefixSpace">Indicate whether to include a leading space before encoding the text.</param>
            <param name="addBeginningOfSentence">Indicate whether to include the beginning of sentence token in the encoding.</param>
            <param name="addEndOfSentence">Indicate whether to include the end of sentence token in the encoding.</param>
            <param name="normalizedText">If the tokenizer's normalization is enabled, the input text will be represented in its normalization form; otherwise, it will be null.</param>
            <param name="tokenCount">The token count can be generated which should be smaller than the maximum token count.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <returns>
            The start index of the maximum encoding capacity within the processed text without surpassing the token limit.
            It represents the index at the first character to be included. In cases where no tokens fit, the result will be length of the text or the <paramref name="normalizedText"/> if normalization is enabled;
            conversely, if all tokens fit, the result will be 0.
            </returns>
            <remarks>
            If the whole text can be encoded within the token limit, the returned index will be 0.
            </remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.CodeGenTokenizer.GetIndexByTokenCountFromEnd(System.ReadOnlySpan{System.Char},System.Int32,System.Boolean,System.Boolean,System.Boolean,System.String@,System.Int32@,System.Boolean,System.Boolean)">
            <summary>
            Find the index of the maximum encoding capacity from the end within the text without surpassing the token limit.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="maxTokenCount">The maximum token count to limit the encoding capacity.</param>
            <param name="addPrefixSpace">Indicate whether to include a leading space before encoding the text.</param>
            <param name="addBeginningOfSentence">Indicate whether to include the beginning of sentence token in the encoding.</param>
            <param name="addEndOfSentence">Indicate whether to include the end of sentence token in the encoding.</param>
            <param name="normalizedText">If the tokenizer's normalization is enabled, the input text will be represented in its normalization form; otherwise, it will be null.</param>
            <param name="tokenCount">The token count can be generated which should be smaller than the maximum token count.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <returns>
            The start index of the maximum encoding capacity within the processed text without surpassing the token limit.
            It represents the index at the first character to be included. In cases where no tokens fit, the result will be length of the <paramref name="normalizedText"/>; conversely, if all tokens fit, the result will be 0.
            </returns>
            <remarks>
            If the whole text can be encoded within the token limit, the returned index will be 0.
            </remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.CodeGenTokenizer.Decode(System.Collections.Generic.IEnumerable{System.Int32})">
            <summary>
            Decode the given ids, back to a String.
            </summary>
            <param name="ids">The list of ids that we want to decode.</param>
            <returns>The decoded string.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.CodeGenTokenizer.Decode(System.Collections.Generic.IEnumerable{System.Int32},System.Boolean,System.Boolean)">
            <summary>
            Decode the given ids, back to a String.
            </summary>
            <param name="ids">The list of ids that we want to decode.</param>
            <param name="hasPrefixSpace">Indicate whether the encoded string has a leading space.</param>
            <param name="considerSpecialTokens">Indicate whether to consider special tokens during decoding.</param>
            <returns>The decoded string.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.CodeGenTokenizer.Decode(System.Collections.Generic.IEnumerable{System.Int32},System.Span{System.Char},System.Int32@,System.Int32@)">
             <summary>
             Decode the given ids back to text and store the result in the <paramref name="destination"/> span.
             </summary>
             <param name="ids">The list of ids that we want to decode.</param>
             <param name="destination">The span to store the decoded text.</param>
            
             <param name="idsConsumed">The number of ids consumed during the decoding.</param>
             <param name="charsWritten">The number of characters written to the destination span.</param>
             <returns>The operation status indicates whether all IDs were successfully decoded or if the <paramref name="destination"/> is too small to contain the entire decoded result.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.CodeGenTokenizer.Decode(System.Collections.Generic.IEnumerable{System.Int32},System.Span{System.Char},System.Boolean,System.Boolean,System.Int32@,System.Int32@)">
            <summary>
            Decode the given ids back to text and store the result in the <paramref name="destination"/> span.
            </summary>
            <param name="ids">The list of ids that we want to decode.</param>
            <param name="destination">The span to store the decoded text.</param>
            <param name="hasPrefixSpace">Indicate whether the encoded string has a leading space.</param>
            <param name="considerSpecialTokens">Indicate whether to consider special tokens during decoding.</param>
            <param name="idsConsumed">The number of ids consumed during the decoding.</param>
            <param name="charsWritten">The number of characters written to the destination span.</param>
            <returns>The operation status indicates whether all IDs were successfully decoded or if the <paramref name="destination"/> is too small to contain the entire decoded result.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.CodeGenTokenizer.MapIdToToken(System.Int32)">
            <summary>
            Map the encoded Id to the token.
            </summary>
            <param name="id">The Id to map to the string.</param>
            <returns>The mapped token of the Id.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.CodeGenTokenizer.MapTokenToId(System.ReadOnlySpan{System.Char})">
            <summary>
            Map the token to encoded Id.
            </summary>
            <param name="token">The token to map to the Id.</param>
            <returns>The mapped Id of the token.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.CodeGenTokenizer.EncodeToTokens(System.Span{System.Char},System.Span{System.Int32},System.ReadOnlySpan{System.Char},Microsoft.ML.Tokenizers.PriorityQueue{Microsoft.ML.Tokenizers.CodeGenTokenizer.SymbolPair})">
            <summary>
            Encode a token into BPE-ed sub-tokens. E.g., "playing" into ["play", "ing"].
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.CodeGenTokenizer.Create(System.IO.Stream,System.IO.Stream,System.Boolean,System.Boolean,System.Boolean)">
            <summary>
            Create a CodeGen tokenizer from the given vocab and merges streams.
            </summary>
            <param name="vocabStream">The stream containing the vocab file.</param>
            <param name="mergesStream">The stream containing the merges file.</param>
            <param name="addPrefixSpace">Indicate whether to add a space before the token.</param>
            <param name="addBeginOfSentence">Indicate emitting the beginning of sentence token during the encoding.</param>
            <param name="addEndOfSentence">Indicate emitting the end of sentence token during the encoding.</param>
            <returns>The CodeGen tokenizer object.</returns>
            <remarks>
            The tokenizer will be created according to the configuration specified in https://huggingface.co/Salesforce/codegen-350M-mono/raw/main/tokenizer.json.
            It is important to provide the similar vocab and merges files to the ones used in the training of the model.
            The vocab and merges files can be downloaded from the following links:
                https://huggingface.co/Salesforce/codegen-350M-mono/resolve/main/vocab.json?download=true
                https://huggingface.co/Salesforce/codegen-350M-mono/resolve/main/merges.txt?download=true
            When creating the tokenizer, ensure that the vocabulary stream is sourced from a trusted provider.
            </remarks>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.EnglishRobertaTokenizer">
            <summary>
            Represent the Byte Pair Encoding model.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.EnglishRobertaTokenizer.FilterUnsupportedChars">
            <summary>
            Indicate if want to filter the unsupported characters during the decoding.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.EnglishRobertaTokenizer.Create(System.String,System.String,System.String)">
            <summary>
            Create tokenizer's model object to use with the English Robert model.
            </summary>
            <param name="vocabularyPath">The JSON file path containing the dictionary of string keys and their ids.</param>
            <param name="mergePath">The file path containing the tokens's pairs list.</param>
            <param name="highestOccurrenceMappingPath">Remap the original GPT-2 model Ids to high occurrence ranks and values.</param>
            <remarks>
            When creating the tokenizer, ensure that the vocabulary file is sourced from a trusted provider.
            </remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.EnglishRobertaTokenizer.Create(System.String,System.String,System.String,Microsoft.ML.Tokenizers.PreTokenizer,Microsoft.ML.Tokenizers.Normalizer,System.Boolean)">
            <summary>
            Create tokenizer's model object to use with the English Robert model.
            </summary>
            <param name="vocabularyPath">The JSON file path containing the dictionary of string keys and their ids.</param>
            <param name="mergePath">The file path containing the tokens's pairs list.</param>
            <param name="highestOccurrenceMappingPath">Remap the original GPT-2 model Ids to high occurrence ranks and values.</param>
            <param name="preTokenizer">The pre-tokenizer to use.</param>
            <param name="normalizer">The normalizer to use.</param>
            <param name="filterUnsupportedChars">Indicate if want to filter the unsupported characters during the decoding.</param>
            <remarks>
            When creating the tokenizer, ensure that the vocabulary file is sourced from a trusted provider.
            </remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.EnglishRobertaTokenizer.Create(System.IO.Stream,System.IO.Stream,System.IO.Stream)">
            <summary>
            Create tokenizer's model object to use with the English Robert model.
            </summary>
            <param name="vocabularyStream">The stream of a JSON file containing the dictionary of string keys and their ids.</param>
            <param name="mergeStream">The stream of a file containing the tokens's pairs list.</param>
            <param name="highestOccurrenceMappingStream">Remap the original GPT-2 model Ids to high occurrence ranks and values.</param>
            <remarks>
            When creating the tokenizer, ensure that the vocabulary stream is sourced from a trusted provider.
            </remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.EnglishRobertaTokenizer.Create(System.IO.Stream,System.IO.Stream,System.IO.Stream,Microsoft.ML.Tokenizers.PreTokenizer,Microsoft.ML.Tokenizers.Normalizer,System.Boolean)">
            <summary>
            Create tokenizer's model object to use with the English Robert model.
            </summary>
            <param name="vocabularyStream">The stream of a JSON file containing the dictionary of string keys and their ids.</param>
            <param name="mergeStream">The stream of a file containing the tokens's pairs list.</param>
            <param name="highestOccurrenceMappingStream">Remap the original GPT-2 model Ids to high occurrence ranks and values.</param>
            <param name="preTokenizer">The pre-tokenizer to use.</param>
            <param name="normalizer">The normalizer to use.</param>
            <param name="filterUnsupportedChars">Indicate if want to filter the unsupported characters during the decoding.</param>
            <remarks>
            When creating the tokenizer, ensure that the vocabulary stream is sourced from a trusted provider.
            </remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.EnglishRobertaTokenizer.#ctor(System.String,System.String,System.String,Microsoft.ML.Tokenizers.PreTokenizer,Microsoft.ML.Tokenizers.Normalizer,System.Boolean)">
            <summary>
            Construct tokenizer's model object to use with the English Robert model.
            </summary>
            <param name="vocabularyPath">The JSON file path containing the dictionary of string keys and their ids.</param>
            <param name="mergePath">The file path containing the tokens's pairs list.</param>
            <param name="highestOccurrenceMappingPath">Remap the original GPT-2 model Ids to high occurrence ranks and values.</param>
            <param name="preTokenizer">The pre-tokenizer to use.</param>
            <param name="normalizer">The normalizer to use.</param>
            <param name="filterUnsupportedChars">Indicate if want to filter the unsupported characters during the decoding.</param>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.EnglishRobertaTokenizer.#ctor(System.IO.Stream,System.IO.Stream,System.IO.Stream,Microsoft.ML.Tokenizers.PreTokenizer,Microsoft.ML.Tokenizers.Normalizer,System.Boolean)">
            <summary>
            Construct tokenizer's model object to use with the English Robert model.
            </summary>
            <param name="vocabularyStream">The stream of a JSON file containing the dictionary of string keys and their ids.</param>
            <param name="mergeStream">The stream of a file containing the tokens's pairs list.</param>
            <param name="highestOccurrenceMappingStream">Remap the original GPT-2 model Ids to high occurrence ranks and values.</param>
            <param name="preTokenizer">The pre-tokenizer to use.</param>
            <param name="normalizer">The normalizer to use.</param>
            <param name="filterUnsupportedChars">Indicate if want to filter the unsupported characters during the decoding.</param>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.EnglishRobertaTokenizer.PreTokenizer">
            <summary>
            Gets the PreTokenizer used by the Tokenizer.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.EnglishRobertaTokenizer.Normalizer">
            <summary>
            Gets the Normalizer in use by the Tokenizer.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.EnglishRobertaTokenizer.Vocabulary">
            <summary>
            Gets the dictionary mapping tokens to Ids.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.EnglishRobertaTokenizer.MapIdToToken(System.Int32)">
            <summary>
            Map the encoded Id to the token.
            </summary>
            <param name="id">The Id to map to the string.</param>
            <returns>The mapped token of the Id.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.EnglishRobertaTokenizer.EncodeToTokens(System.String,System.ReadOnlySpan{System.Char},Microsoft.ML.Tokenizers.EncodeSettings)">
            <summary>
            Encodes input text to a list of <see cref="T:Microsoft.ML.Tokenizers.EncodedToken" />s.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="textSpan">The span of the text to encode which will be used if the <paramref name="text"/> is <see langword="null"/>.</param>
            <param name="settings">The settings used to encode the text.</param>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.EnglishRobertaTokenizer.EncodeInternal(System.ReadOnlySpan{System.Char})">
            <summary>
            Encode a text string to a list of tokens.
            </summary>
            <param name="text">The text to encode.</param>
            <returns>The list of tokens generated from the text tokenization.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.EnglishRobertaTokenizer.EncodeToIds(System.String,System.ReadOnlySpan{System.Char},Microsoft.ML.Tokenizers.EncodeSettings)">
            <summary>
            Encodes input text to token Ids.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="textSpan">The span of the text to encode which will be used if the <paramref name="text"/> is <see langword="null"/>.</param>
            <param name="settings">The settings used to encode the text.</param>
            <returns>The encoded results containing the list of encoded Ids.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.EnglishRobertaTokenizer.CountTokens(System.String,System.ReadOnlySpan{System.Char},Microsoft.ML.Tokenizers.EncodeSettings)">
            <summary>
            Get the number of tokens that the input text will be encoded to.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="textSpan">The span of the text to encode which will be used if the <paramref name="text"/> is <see langword="null"/>.</param>
            <param name="settings">The settings used to encode the text.</param>
            <returns>The number of token Ids that the input text will be encoded to.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.EnglishRobertaTokenizer.GetIndexByTokenCount(System.String,System.ReadOnlySpan{System.Char},Microsoft.ML.Tokenizers.EncodeSettings,System.Boolean,System.String@,System.Int32@)">
            <summary>
            Find the index of the maximum encoding capacity without surpassing the token limit.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="textSpan">The span of the text to encode which will be used if the <paramref name="text"/> is <see langword="null"/>.</param>
            <param name="settings">The settings used to encode the text.</param>
            <param name="fromEnd">Indicate whether to find the index from the end of the text.</param>
            <param name="normalizedText">If the tokenizer's normalization is enabled or <paramRef name="settings" /> has <see cref="P:Microsoft.ML.Tokenizers.EncodeSettings.ConsiderNormalization"/> is <see langword="false"/>, this will be set to <paramRef name="text" /> in its normalized form; otherwise, this value will be set to <see langword="null"/>.</param>
            <param name="tokenCount">The token count can be generated which should be smaller than the maximum token count.</param>
            <returns>
            The index of the maximum encoding capacity within the processed text without surpassing the token limit.
            If <paramRef name="fromEnd" /> is <see langword="false"/>, it represents the index immediately following the last character to be included. In cases where no tokens fit, the result will be 0; conversely,
            if all tokens fit, the result will be length of the input text or the <paramref name="normalizedText"/> if the normalization is enabled.
            If <paramRef name="fromEnd" /> is <see langword="true"/>, it represents the index of the first character to be included. In cases where no tokens fit, the result will be the text length; conversely,
            if all tokens fit, the result will be zero.
            </returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.EnglishRobertaTokenizer.MapTokenToId(System.ReadOnlySpan{System.Char})">
            <summary>
            Map the token to encoded Id.
            </summary>
            <param name="token">The token to map to the Id.</param>
            <returns>The mapped Id of the token.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.EnglishRobertaTokenizer.Decode(System.Collections.Generic.IEnumerable{System.Int32})">
            <summary>
            Decode the given ids, back to a String.
            </summary>
            <param name="ids">The list of ids that we want to decode.</param>
            <returns>The decoded string.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.EnglishRobertaTokenizer.Decode(System.Collections.Generic.IEnumerable{System.Int32},System.Span{System.Char},System.Int32@,System.Int32@)">
            <summary>
            Decode the given ids back to text and store the result in the <paramref name="destination"/> span.
            </summary>
            <param name="ids">The list of ids that we want to decode.</param>
            <param name="destination">The span to store the decoded text.</param>
            <param name="idsConsumed">The number of ids consumed during the decoding.</param>
            <param name="charsWritten">The number of characters written to the destination span.</param>
            <returns>The operation status indicates whether all IDs were successfully decoded or if the <paramref name="destination"/> is too small to contain the entire decoded result.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.EnglishRobertaTokenizer.ConvertIdsToOccurrenceRanks(System.Collections.Generic.IReadOnlyList{System.Int32})">
            <summary>
            Convert a list of token Ids to highest occurrence rankings.
            </summary>
            <param name="ids">The Ids list to map to the high occurrence rank.</param>
            <returns>The list of ranks mapped from the list of Ids.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.EnglishRobertaTokenizer.ConvertIdsToOccurrenceValues(System.Collections.Generic.IReadOnlyList{System.Int32})">
            <summary>
            Convert a list of token Ids to highest occurrence values.
            </summary>
            <param name="ids">The Ids list to map to the high occurrence values.</param>
            <returns>The list of occurrence values mapped from the list of Ids.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.EnglishRobertaTokenizer.ConvertOccurrenceRanksToIds(System.Collections.Generic.IReadOnlyList{System.Int32})">
            <summary>
            Convert a list of highest occurrence rankings to token Ids list .
            </summary>
            <param name="ranks">The high occurrence ranks list to map to the Ids list.</param>
            <returns>The list of Ids mapped from the list of ranks.</returns>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.EnglishRobertaTokenizer.PadIndex">
            <summary>
            Gets the index of the pad symbol inside the symbols list.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.EnglishRobertaTokenizer.SymbolsCount">
            <summary>
            Gets the symbols list length.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.EnglishRobertaTokenizer.AddMaskSymbol(System.String)">
            <summary>
            Add the mask symbol to the symbols list.
            </summary>
            <param name="mask">The mask symbol.</param>
            <returns>The index of the mask symbol in the symbols list.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.EnglishRobertaTokenizer.EncodeToTokens(System.Span{System.Char},System.Span{System.Int32})">
            <summary>
            Encode a token into BPE-ed sub-tokens. E.g., "playing" into ["play", "ing"].
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.EnglishRobertaTokenizer.WordToPairs(System.Collections.Generic.IReadOnlyList{System.String},System.Collections.Generic.HashSet{System.ValueTuple{System.String,System.String}})">
            <summary>
            Extract element pairs in an aggregating word. E.g. [p, l, ay] into [(p,l), (l,ay)].
            If word contains 0 or 1 element, an empty HashSet will be returned.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.EnglishRobertaTokenizer.IsSupportedChar(System.Char)">
            <summary>
            Check if the character is supported by the tokenizer's model.
            </summary>
            <param name="ch">The character to check.</param>
            <returns>True if the character is supported, otherwise false.</returns>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.HighestOccurrenceMapping">
            <summary>
            HighestOccurrenceMapping maps the GPT-2 vocabulary Id to highest occurrence value came from dict.txt file
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.HighestOccurrenceMapping.#ctor(System.String,System.String,System.String,System.String,System.String[])">
            <exception cref="T:System.ArgumentNullException">Any of `pad`, `eos`, `unk` and `bos` is `null`.</exception>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.HighestOccurrenceMapping.Item(System.Int32)">
            <exception cref="T:System.ArgumentOutOfRangeException">`idx` is negative.</exception>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.HighestOccurrenceMapping.IndexOf(System.Int32)">
            <exception cref="T:System.ArgumentNullException">`symbol` is `null`.</exception>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.HighestOccurrenceMapping.Load(System.IO.Stream)">
            <summary>
            Loads the mapping from a text file with the format:
                13 850314647
                262 800385005
                11 800251374
                284 432911125
                ...
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.HighestOccurrenceMapping.AddFromStream(System.IO.Stream)">
            <summary>
            Loads a pre-existing vocabulary from a text stream and adds its symbols to this instance.
            </summary>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.LlamaTokenizer">
            <summary>
            LlamaTokenizer is SentencePieceTokenizer which is implemented based on https://github.com/google/sentencepiece.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.LlamaTokenizer.Create(System.IO.Stream,System.Boolean,System.Boolean,System.Collections.Generic.IReadOnlyDictionary{System.String,System.Int32})">
            <summary>
            Create from the given model stream a LlamaTokenizer which is based on SentencePieceTokenizer. The model stream should contain the SentencePiece Bpe model according to
            https://github.com/google/sentencepiece/blob/master/src/sentencepiece_model.proto specification.
            </summary>
            <param name="modelStream">The stream containing the SentencePiece Bpe model.</param>
            <param name="addBeginOfSentence">Indicate emitting the beginning of sentence token during the encoding.</param>
            <param name="addEndOfSentence">Indicate emitting the end of sentence token during the encoding.</param>
            <param name="specialTokens">The additional tokens to add to the vocabulary.</param>
            <remarks>
            When creating the tokenizer, ensure that the vocabulary stream is sourced from a trusted provider.
            </remarks>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.ModelSourceGenerationContext.StringSpanOrdinalKey">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.ModelSourceGenerationContext.Vocabulary">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.ModelSourceGenerationContext.DictionaryStringSpanOrdinalKeyInt32">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.ModelSourceGenerationContext.Int32">
            <summary>
            Defines the source generated JSON serialization contract metadata for a given type.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.ModelSourceGenerationContext.Default">
            <summary>
            The default <see cref="T:System.Text.Json.Serialization.JsonSerializerContext"/> associated with a default <see cref="T:System.Text.Json.JsonSerializerOptions"/> instance.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.ModelSourceGenerationContext.GeneratedSerializerOptions">
            <summary>
            The source-generated options associated with this context.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.ModelSourceGenerationContext.#ctor">
            <inheritdoc/>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.ModelSourceGenerationContext.#ctor(System.Text.Json.JsonSerializerOptions)">
            <inheritdoc/>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.ModelSourceGenerationContext.GetTypeInfo(System.Type)">
            <inheritdoc/>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.Phi2Tokenizer">
            <summary>
            Represent the Byte Pair Encoding model.
            Implement the Phi2 tokenizer described in https://huggingface.co/microsoft/phi-2
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Phi2Tokenizer.#ctor(System.String,System.String,Microsoft.ML.Tokenizers.PreTokenizer,Microsoft.ML.Tokenizers.Normalizer,System.Collections.Generic.IReadOnlyDictionary{System.String,System.Int32},System.Boolean,System.Boolean,System.Boolean,System.String,System.String,System.String)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.ML.Tokenizers.Phi2Tokenizer"/> class.
            </summary>
            <summary>
            Construct tokenizer's model object to use with the English Robert model.
            </summary>
            <param name="vocabularyPath">The JSON file path containing the dictionary of string keys and their ids.</param>
            <param name="mergePath">The file path containing the tokens's pairs list.</param>
            <param name="preTokenizer">The pre-tokenizer to use.</param>
            <param name="normalizer">The normalizer to use.</param>
            <param name="specialTokens">The dictionary mapping special tokens to Ids.</param>
            <param name="addPrefixSpace">Indicate whether to include a leading space before encoding the text.</param>
            <param name="addBeginningOfSentence">Indicate whether to include the beginning of sentence token in the encoding.</param>
            <param name="addEndOfSentence">Indicate whether to include the end of sentence token in the encoding.</param>
            <param name="unknownToken">The unknown token.</param>
            <param name="beginningOfSentenceToken">The beginning of sentence token.</param>
            <param name="endOfSentenceToken">The end of sentence token.</param>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Phi2Tokenizer.#ctor(System.IO.Stream,System.IO.Stream,Microsoft.ML.Tokenizers.PreTokenizer,Microsoft.ML.Tokenizers.Normalizer,System.Collections.Generic.IReadOnlyDictionary{System.String,System.Int32},System.Boolean,System.Boolean,System.Boolean,System.String,System.String,System.String)">
            <summary>
            Construct tokenizer's model object to use with the English Robert model.
            </summary>
            <param name="vocabularyStream">The stream of a JSON file containing the dictionary of string keys and their ids.</param>
            <param name="mergeStream">The stream of a file containing the tokens's pairs list.</param>
            <param name="preTokenizer">The pre-tokenizer to use.</param>
            <param name="normalizer">The normalizer to use.</param>
            <param name="specialTokens">The additional tokens to add to the vocabulary.</param>
            <param name="addPrefixSpace">Indicate whether to include a leading space before encoding the text.</param>
            <param name="addBeginningOfSentence">Indicate whether to include the beginning of sentence token in the encoding.</param>
            <param name="addEndOfSentence">Indicate whether to include the end of sentence token in the encoding.</param>
            <param name="unknownToken">The unknown token.</param>
            <param name="beginningOfSentenceToken">The beginning of sentence token.</param>
            <param name="endOfSentenceToken">The end of sentence token.</param>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Phi2Tokenizer.Create(System.IO.Stream,System.IO.Stream,System.Boolean,System.Boolean,System.Boolean)">
            <summary>
            Create a CodeGen Phi2 tokenizer from the given vocab and merges streams.
            </summary>
            <param name="vocabStream">The stream containing the vocab file.</param>
            <param name="mergesStream">The stream containing the merges file.</param>
            <param name="addPrefixSpace">Indicate whether to add a space before the token.</param>
            <param name="addBeginOfSentence">Indicate emitting the beginning of sentence token during the encoding.</param>
            <param name="addEndOfSentence">Indicate emitting the end of sentence token during the encoding.</param>
            <returns>The CodeGen tokenizer object.</returns>
            <remarks>
            The tokenizer will be created according to the configuration specified in https://huggingface.co/microsoft/phi-2/raw/main/tokenizer.json.
            It is important to provide the similar vocab and merges files to the ones used in the training of the model.
            The vocab and merges files can be downloaded from the following links:
                https://huggingface.co/microsoft/phi-2/resolve/main/vocab.json?download=true
                https://huggingface.co/microsoft/phi-2/resolve/main/merges.txt?download=true
            When creating the tokenizer, ensure that the vocabulary stream is sourced from a trusted provider.
            </remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePieceBpeModel.EncodeInternal(System.ReadOnlySpan{System.Char},System.Boolean,System.Boolean,System.Collections.Generic.List{Microsoft.ML.Tokenizers.EncodedToken})">
            <summary>
            Encode a text to a list of tokens.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="addBeginOfSentence">Indicate emitting the beginning of sentence token during the encoding.</param>
            <param name="addEndOfSentence">Indicate emitting the end of sentence token during the encoding.</param>
            <param name="tokens">A collection to store the encoded tokens.</param>
            <remarks>The input text has to be normalized before calling this method.</remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePieceBpeModel.EncodeToIds(System.ReadOnlySpan{System.Char},System.Boolean,System.Boolean,System.Boolean,System.String@,System.Int32@,System.Int32)">
            <summary>
            Encodes input text to token Ids up to maximum number of tokens.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="addBeginningOfSentence">Indicate emitting the beginning of sentence token during the encoding.</param>
            <param name="addEndOfSentence">Indicate emitting the end of sentence token during the encoding.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <param name="normalizedText">If the tokenizer's normalization is enabled or <paramRef name="considerNormalization" /> is false, this will be set to <paramRef name="text" /> in its normalized form; otherwise, this value will be set to null.</param>
            <param name="charsConsumed">The length of the text that encompasses the maximum encoded tokens.</param>
            <param name="maxTokenCount">The maximum number of tokens to encode.</param>
            <returns>The list of encoded Ids.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePieceBpeModel.EncodeToIds(System.ReadOnlySpan{System.Char},System.Boolean,System.Boolean,System.Collections.Generic.IList{System.Int32},System.Int32@,System.Int32)">
            <summary>
            Encode a text to a list of Ids and add them to the accumulatedIds list.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="addBeginOfSentence">Indicate emitting the beginning of sentence token during the encoding.</param>
            <param name="addEndOfSentence">Indicate emitting the end of sentence token during the encoding.</param>
            <param name="accumulatedIds">The list of accumulated encoded Ids.</param>
            <param name="charsConsumed">The length of the text that encompasses the maximum encoded tokens.</param>
            <param name="maxTokens">The maximum number of tokens to encode.</param>
            <returns>The number of tokens that the input text will be encoded to.</returns>
            <remarks>The input text has to be normalized before calling this method.</remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePieceBpeModel.CountTokens(System.ReadOnlySpan{System.Char},System.Boolean,System.Boolean,System.Int32@,System.Int32)">
            <summary>
            Get the number of tokens that the input text will be encoded to.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="addBeginOfSentence">Indicate emitting the beginning of sentence token during the encoding.</param>
            <param name="addEndOfSentence">Indicate emitting the end of sentence token during the encoding.</param>
            <param name="charsConsumed">The length of the text that encompasses the maximum encoded tokens.</param>
            <param name="maxTokens">The maximum number of tokens to encode.</param>
            <returns>The number of tokens that the input text will be encoded to.</returns>
            <remarks>The input text has to be normalized before calling this method.</remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePieceBpeModel.CountTokensFromEnd(System.ReadOnlySpan{System.Char},System.Boolean,System.Boolean,System.Int32@,System.Int32)">
            <summary>
            Get the number of tokens that the input text will be encoded to.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="addBeginOfSentence">Indicate emitting the beginning of sentence token during the encoding.</param>
            <param name="addEndOfSentence">Indicate emitting the end of sentence token during the encoding.</param>
            <param name="textIndex">Starting from this index to the end of the text will encompasses the maximum encoded tokens.</param>
            <param name="maxTokens">The maximum number of tokens to encode.</param>
            <returns>The number of tokens that the input text will be encoded to.</returns>
            <remarks>The input text has to be normalized before calling this method.</remarks>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.SentencePieceModelType">
            <summary>
            The type of the SentencePiece model.
            </summary>
        </member>
        <member name="F:Microsoft.ML.Tokenizers.SentencePieceModelType.Undefined">
            <summary>
            The model type is not defined.
            </summary>
        </member>
        <member name="F:Microsoft.ML.Tokenizers.SentencePieceModelType.Bpe">
            <summary>
            The model type is Byte Pair Encoding (Bpe) model.
            </summary>
        </member>
        <member name="F:Microsoft.ML.Tokenizers.SentencePieceModelType.Unigram">
            <summary>
            The model type is Unigram model.
            </summary>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.SentencePieceOptions">
            <summary>
            Options for the SentencePiece tokenizer.
            </summary>
            <remarks>
            The options are used to configure the SentencePiece tokenizer. Serialization is not guaranteed for this type.
            </remarks>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceOptions.ModelType">
            <summary>
            The type of the SentencePiece model.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceOptions.ByteFallback">
            <summary>
            Determines whether the model uses a byte fallback strategy to encode unknown tokens as byte sequences.
            </summary>
            <remarks>
            The vocabulary must include a special token for each byte value (0-255) in the format &lt;0xNN&gt;,
            where NN represents the byte's hexadecimal value (e.g., &lt;0x41&gt; for byte value 65).
            </remarks>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceOptions.AddDummyPrefix">
            <summary>
            Indicate emitting the prefix character e.g. U+2581 at the beginning of sentence token during the normalization and encoding.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceOptions.EscapeWhiteSpaces">
            <summary>
            Indicate if the spaces should be replaced with character U+2581 during the normalization and encoding. Default value is `true`.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceOptions.TreatWhitespaceAsSuffix">
            <summary>
            Indicate emitting the character U+2581 at the end of the last sentence token instead beginning of sentence token during the normalization and encoding.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceOptions.RemoveExtraWhiteSpaces">
            <summary>
            Indicate removing extra white spaces from the original string during the normalization.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceOptions.AddBeginningOfSentence">
            <summary>
            Indicate emitting the beginning of sentence token during the encoding. Default value is `true`.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceOptions.AddEndOfSentence">
            <summary>
            Indicate emitting the end of sentence token during the encoding.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceOptions.BeginningOfSentenceToken">
            <summary>
            The beginning of sentence token. Default value is `&lt;s&gt;`.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceOptions.EndOfSentenceToken">
            <summary>
            The end of sentence token. Default value is `&lt;/s&gt;`.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceOptions.UnknownToken">
            <summary>
            The unknown token. Default value is `&lt;unk&gt;`.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceOptions.PrecompiledNormalizationData">
            <summary>
            The data used for string normalization.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceOptions.Vocabulary">
            <summary>
            Represent the vocabulary.
            The list should be sorted by token ID, with entries passed in the order that corresponds to their IDs. In other words,
            the first entry in the list will be mapped to ID 0, the second entry to ID 1, the third to ID 2, and so on.
            Each entry represents a token and its corresponding score.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceOptions.SpecialTokens">
            <summary>
            The special tokens.
            Special tokens remain intact during encoding and are not split into sub-tokens.
            </summary>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.SentencePieceTokenizer">
            <summary>
            SentencePieceBpe is a tokenizer that splits the input into tokens using the SentencePiece Bpe model.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceTokenizer.SpecialTokens">
            <summary>
            The special tokens.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceTokenizer.ByteFallback">
            <summary>
            Specifies whether the model will do a byte fallback when it encounters unknown tokens during the encoding process.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceTokenizer.AddDummyPrefix">
            <summary>
            Indicate emitting the prefix character U+2581 at the beginning of sentence token during the normalization and encoding.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceTokenizer.EscapeWhiteSpaces">
            <summary>
            Indicate if the spaces should be replaced with character U+2581 during the normalization and encoding.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceTokenizer.TreatWhitespaceAsSuffix">
            <summary>
            Indicate emitting the character U+2581 at the end of the last sentence token instead beginning of sentence token during the normalization and encoding.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceTokenizer.AddBeginningOfSentence">
            <summary>
            Indicate emitting the beginning of sentence token during the encoding.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceTokenizer.AddEndOfSentence">
            <summary>
            Indicate emitting the end of sentence token during the encoding.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceTokenizer.BeginningOfSentenceToken">
            <summary>
            The beginning of sentence token.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceTokenizer.EndOfSentenceToken">
            <summary>
            The end of sentence token.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceTokenizer.UnknownToken">
            <summary>
            The unknown token.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceTokenizer.BeginningOfSentenceId">
            <summary>
            The id of the beginning of sentence token.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceTokenizer.EndOfSentenceId">
            <summary>
            The id of the end of sentence token.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceTokenizer.UnknownId">
            <summary>
            The id of the unknown token.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceTokenizer.PreTokenizer">
            <summary>
            Gets the PreTokenizer used by the Tokenizer.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceTokenizer.Normalizer">
            <summary>
            Gets the Normalizer in use by the Tokenizer.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceTokenizer.Vocabulary">
            <summary>
            The vocabulary of the model.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePieceTokenizer.EncodeToTokens(System.String,System.ReadOnlySpan{System.Char},Microsoft.ML.Tokenizers.EncodeSettings)">
            <summary>
            Encodes input text to a list of <see cref="T:Microsoft.ML.Tokenizers.EncodedToken" />s.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="textSpan">The span of the text to encode which will be used if the <paramref name="text"/> is <see langword="null"/>.</param>
            <param name="settings">The settings used to encode the text.</param>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePieceTokenizer.EncodeToTokens(System.String,System.String@,System.Boolean,System.Boolean,System.Boolean,System.Boolean)">
            <summary>
            Encodes input text a list of <see cref="T:Microsoft.ML.Tokenizers.EncodedToken" />s with string value of the token, id, and offset.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="normalizedText">If the tokenizer's normalization is enabled or <paramRef name="considerNormalization" /> is false, this will be set to <paramRef name="text" /> in its normalized form; otherwise, this value will be set to null.</param>
            <param name="addBeginningOfSentence">Indicate emitting the beginning of sentence token during the encoding.</param>
            <param name="addEndOfSentence">Indicate emitting the end of sentence token during the encoding.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <returns>The tokenization result includes a list of <see cref="T:Microsoft.ML.Tokenizers.EncodedToken" />s with string value of the token, id, and offset.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePieceTokenizer.EncodeToTokens(System.ReadOnlySpan{System.Char},System.String@,System.Boolean,System.Boolean,System.Boolean,System.Boolean)">
            <summary>
            Encodes input text a list of <see cref="T:Microsoft.ML.Tokenizers.EncodedToken" />s with string value of the token, id, and offset.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="normalizedText">If the tokenizer's normalization is enabled or <paramRef name="considerNormalization" /> is false, this will be set to <paramRef name="text" /> in its normalized form; otherwise, this value will be set to null.</param>
            <param name="addBeginningOfSentence">Indicate emitting the beginning of sentence token during the encoding.</param>
            <param name="addEndOfSentence">Indicate emitting the end of sentence token during the encoding.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <returns>The tokenization result includes a list of <see cref="T:Microsoft.ML.Tokenizers.EncodedToken" />s with string value of the token, id, and offset.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePieceTokenizer.EncodeToIds(System.String,System.ReadOnlySpan{System.Char},Microsoft.ML.Tokenizers.EncodeSettings)">
            <summary>
            Encodes input text to token Ids.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="textSpan">The span of the text to encode which will be used if the <paramref name="text"/> is <see langword="null"/>.</param>
            <param name="settings">The settings used to encode the text.</param>
            <returns>The encoded results containing the list of encoded Ids.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePieceTokenizer.EncodeToIds(System.String,System.Boolean,System.Boolean,System.Boolean,System.Boolean)">
            <summary>
            Encodes input text to token Ids.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="addBeginningOfSentence">Indicate emitting the beginning of sentence token during the encoding.</param>
            <param name="addEndOfSentence">Indicate emitting the end of sentence token during the encoding.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <returns>The list of encoded Ids.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePieceTokenizer.EncodeToIds(System.ReadOnlySpan{System.Char},System.Boolean,System.Boolean,System.Boolean,System.Boolean)">
            <summary>
            Encodes input text to token Ids.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="addBeginningOfSentence">Indicate emitting the beginning of sentence token during the encoding.</param>
            <param name="addEndOfSentence">Indicate emitting the end of sentence token during the encoding.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <returns>The list of encoded Ids.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePieceTokenizer.EncodeToIds(System.String,System.Boolean,System.Boolean,System.Int32,System.String@,System.Int32@,System.Boolean,System.Boolean)">
            <summary>
            Encodes input text to token Ids up to maximum number of tokens.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="addBeginningOfSentence">Indicate emitting the beginning of sentence token during the encoding.</param>
            <param name="addEndOfSentence">Indicate emitting the end of sentence token during the encoding.</param>
            <param name="maxTokenCount">The maximum number of tokens to encode.</param>
            <param name="normalizedText">If the tokenizer's normalization is enabled or <paramRef name="considerNormalization" /> is false, this will be set to <paramRef name="text" /> in its normalized form; otherwise, this value will be set to null.</param>
            <param name="charsConsumed">The length of the text that encompasses the maximum encoded tokens.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <returns>The list of encoded Ids.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePieceTokenizer.EncodeToIds(System.ReadOnlySpan{System.Char},System.Boolean,System.Boolean,System.Int32,System.String@,System.Int32@,System.Boolean,System.Boolean)">
            <summary>
            Encodes input text to token Ids up to maximum number of tokens.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="addBeginningOfSentence">Indicate emitting the beginning of sentence token during the encoding.</param>
            <param name="addEndOfSentence">Indicate emitting the end of sentence token during the encoding.</param>
            <param name="maxTokenCount">The maximum number of tokens to encode.</param>
            <param name="normalizedText">If the tokenizer's normalization is enabled or <paramRef name="considerNormalization" /> is false, this will be set to <paramRef name="text" /> in its normalized form; otherwise, this value will be set to null.</param>
            <param name="charsConsumed">The length of the text that encompasses the maximum encoded tokens.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <returns>The list of encoded Ids.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePieceTokenizer.CountTokens(System.String,System.ReadOnlySpan{System.Char},Microsoft.ML.Tokenizers.EncodeSettings)">
            <summary>
            Get the number of tokens that the input text will be encoded to.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="textSpan">The span of the text to encode which will be used if the <paramref name="text"/> is <see langword="null"/>.</param>
            <param name="settings">The settings used to encode the text.</param>
            <returns>The number of token Ids that the input text will be encoded to.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePieceTokenizer.CountTokens(System.String,System.Boolean,System.Boolean,System.Boolean,System.Boolean)">
            <summary>
            Get the number of tokens that the input text will be encoded to.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="addBeginningOfSentence">Indicate emitting the beginning of sentence token during the encoding.</param>
            <param name="addEndOfSentence">Indicate emitting the end of sentence token during the encoding.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <returns>The number of token Ids that the input text will be encoded to.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePieceTokenizer.CountTokens(System.ReadOnlySpan{System.Char},System.Boolean,System.Boolean,System.Boolean,System.Boolean)">
            <summary>
            Get the number of tokens that the input text will be encoded to.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="addBeginningOfSentence">Indicate emitting the beginning of sentence token during the encoding.</param>
            <param name="addEndOfSentence">Indicate emitting the end of sentence token during the encoding.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <returns>The number of token Ids that the input text will be encoded to.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePieceTokenizer.CountTokens(System.String,System.Boolean,System.Boolean,System.Boolean,System.Boolean,System.String@,System.Int32@,System.Int32)">
            <summary>
            Get the number of tokens that the input text will be encoded to.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="addBeginningOfSentence">Indicate emitting the beginning of sentence token during the encoding.</param>
            <param name="addEndOfSentence">Indicate emitting the end of sentence token during the encoding.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <param name="normalizedText">If the tokenizer's normalization is enabled or <paramRef name="considerNormalization" /> is false, this will be set to <paramRef name="text" /> in its normalized form; otherwise, this value will be set to null.</param>
            <param name="charsConsumed">The length of the text that encompasses the maximum encoded tokens.</param>
            <param name="maxTokenCount">The maximum number of tokens to encode.</param>
            <returns>The number of tokens that the input text will be encoded to.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePieceTokenizer.CountTokens(System.ReadOnlySpan{System.Char},System.Boolean,System.Boolean,System.Boolean,System.Boolean,System.String@,System.Int32@,System.Int32)">
            <summary>
            Get the number of tokens that the input text will be encoded to.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="addBeginningOfSentence">Indicate emitting the beginning of sentence token during the encoding.</param>
            <param name="addEndOfSentence">Indicate emitting the end of sentence token during the encoding.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <param name="normalizedText">If the tokenizer's normalization is enabled or <paramRef name="considerNormalization" /> is false, this will be set to <paramRef name="text" /> in its normalized form; otherwise, this value will be set to null.</param>
            <param name="charsConsumed">The length of the text that encompasses the maximum encoded tokens.</param>
            <param name="maxTokenCount">The maximum number of tokens to encode.</param>
            <returns>The number of tokens that the input text will be encoded to.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePieceTokenizer.GetIndexByTokenCount(System.String,System.ReadOnlySpan{System.Char},Microsoft.ML.Tokenizers.EncodeSettings,System.Boolean,System.String@,System.Int32@)">
            <summary>
            Find the index of the maximum encoding capacity without surpassing the token limit.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="textSpan">The span of the text to encode which will be used if the <paramref name="text"/> is <see langword="null"/>.</param>
            <param name="settings">The settings used to encode the text.</param>
            <param name="fromEnd">Indicate whether to find the index from the end of the text.</param>
            <param name="normalizedText">If the tokenizer's normalization is enabled or <paramRef name="settings" /> has <see cref="P:Microsoft.ML.Tokenizers.EncodeSettings.ConsiderNormalization"/> is <see langword="false"/>, this will be set to <paramRef name="text" /> in its normalized form; otherwise, this value will be set to <see langword="null"/>.</param>
            <param name="tokenCount">The token count can be generated which should be smaller than the maximum token count.</param>
            <returns>
            The index of the maximum encoding capacity within the processed text without surpassing the token limit.
            If <paramRef name="fromEnd" /> is <see langword="false"/>, it represents the index immediately following the last character to be included. In cases where no tokens fit, the result will be 0; conversely,
            if all tokens fit, the result will be length of the input text or the <paramref name="normalizedText"/> if the normalization is enabled.
            If <paramRef name="fromEnd" /> is <see langword="true"/>, it represents the index of the first character to be included. In cases where no tokens fit, the result will be the text length; conversely,
            if all tokens fit, the result will be zero.
            </returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePieceTokenizer.GetIndexByTokenCount(System.String,System.Boolean,System.Boolean,System.Int32,System.String@,System.Int32@,System.Boolean,System.Boolean)">
            <summary>
            Find the index of the maximum encoding capacity from the start within the text without surpassing the token limit.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="addBeginningOfSentence">Indicate emitting the beginning of sentence token during the encoding.</param>
            <param name="addEndOfSentence">Indicate emitting the end of sentence token during the encoding.</param>
            <param name="maxTokenCount">The maximum token count to limit the encoding capacity.</param>
            <param name="normalizedText">If the tokenizer's normalization is enabled or <paramRef name="considerNormalization" /> is false, this will be set to <paramRef name="text" /> in its normalized form; otherwise, this value will be set to null.</param>
            <param name="tokenCount">The token count can be generated which should be smaller than the maximum token count.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <returns>
            The index of the maximum encoding capacity within the processed text without surpassing the token limit.
            It represents the index immediately following the last character to be included. In cases where no tokens fit, the result will be 0; conversely,
            if all tokens fit, the result will be length of the text or the <paramref name="normalizedText"/> if the normalization is enabled.
            </returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePieceTokenizer.GetIndexByTokenCount(System.ReadOnlySpan{System.Char},System.Boolean,System.Boolean,System.Int32,System.String@,System.Int32@,System.Boolean,System.Boolean)">
            <summary>
            Find the index of the maximum encoding capacity from the start within the text without surpassing the token limit.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="addBeginningOfSentence">Indicate emitting the beginning of sentence token during the encoding.</param>
            <param name="addEndOfSentence">Indicate emitting the end of sentence token during the encoding.</param>
            <param name="maxTokenCount">The maximum token count to limit the encoding capacity.</param>
            <param name="normalizedText">If the tokenizer's normalization is enabled or <paramRef name="considerNormalization" /> is false, this will be set to <paramRef name="text" /> in its normalized form; otherwise, this value will be set to null.</param>
            <param name="tokenCount">The token count can be generated which should be smaller than the maximum token count.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <returns>
            The index of the maximum encoding capacity within the processed text without surpassing the token limit.
            It represents the index immediately following the last character to be included. In cases where no tokens fit, the result will be 0; conversely,
            if all tokens fit, the result will be length of the text or the <paramref name="normalizedText"/> if the normalization is enabled.
            </returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePieceTokenizer.GetIndexByTokenCountFromEnd(System.String,System.Boolean,System.Boolean,System.Int32,System.Boolean,System.String@,System.Int32@)">
            <summary>
            Find the index of the maximum encoding capacity from the end within the text without surpassing the token limit.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="addBeginningOfSentence">Indicate emitting the beginning of sentence token during the encoding.</param>
            <param name="addEndOfSentence">Indicate emitting the end of sentence token during the encoding.</param>
            <param name="maxTokenCount">The maximum token count to limit the encoding capacity.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <param name="normalizedText">If the tokenizer's normalization is enabled or <paramRef name="considerNormalization" /> is false, this will be set to <paramRef name="text" /> in its normalized form; otherwise, this value will be set to null.</param>
            <param name="tokenCount">The token count can be generated which should be smaller than the maximum token count.</param>
            <returns>
            The start index of the maximum encoding capacity within the processed text without surpassing the token limit.
            It represents the index at the first character to be included. In cases where no tokens fit, the result will be length of the <paramref name="normalizedText"/>; conversely, if all tokens fit, the result will be 0.
            </returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePieceTokenizer.GetIndexByTokenCountFromEnd(System.ReadOnlySpan{System.Char},System.Boolean,System.Boolean,System.Int32,System.Boolean,System.String@,System.Int32@)">
            <summary>
            Find the index of the maximum encoding capacity from the end within the text without surpassing the token limit.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="addBeginningOfSentence">Indicate emitting the beginning of sentence token during the encoding.</param>
            <param name="addEndOfSentence">Indicate emitting the end of sentence token during the encoding.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <param name="maxTokenCount">The maximum token count to limit the encoding capacity.</param>
            <param name="normalizedText">If the tokenizer's normalization is enabled or <paramRef name="considerNormalization" /> is false, this will be set to <paramRef name="text" /> in its normalized form; otherwise, this value will be set to null.</param>
            <param name="tokenCount">The token count can be generated which should be smaller than the maximum token count.</param>
            <returns>
            The start index of the maximum encoding capacity within the processed text without surpassing the token limit.
            It represents the index at the first character to be included. In cases where no tokens fit, the result will be length of the <paramref name="normalizedText"/>; conversely, if all tokens fit, the result will be 0.
            </returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePieceTokenizer.Decode(System.Collections.Generic.IEnumerable{System.Int32})">
            <summary>
            Decode the given ids, back to a String.
            </summary>
            <param name="ids">The list of ids that we want to decode.</param>
            <returns>The decoded string.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePieceTokenizer.Decode(System.Collections.Generic.IEnumerable{System.Int32},System.Boolean)">
            <summary>
            Decode the given ids, back to a String.
            </summary>
            <param name="ids">The list of ids that we want to decode.</param>
            <param name="considerSpecialTokens">Indicate whether to consider special tokens during decoding.</param>
            <returns>The decoded string.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePieceTokenizer.Decode(System.Collections.Generic.IEnumerable{System.Int32},System.Span{System.Char},System.Int32@,System.Int32@)">
            <summary>
            Decode the given ids back to text and store the result in the <paramref name="destination"/> span.
            </summary>
            <param name="ids">The list of ids that we want to decode.</param>
            <param name="destination">The span to store the decoded text.</param>
            <param name="idsConsumed">The number of ids consumed during the decoding.</param>
            <param name="charsWritten">The number of characters written to the destination span.</param>
            <returns>The operation status indicates whether all IDs were successfully decoded or if the <paramref name="destination"/> is too small to contain the entire decoded result.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePieceTokenizer.Decode(System.Collections.Generic.IEnumerable{System.Int32},System.Span{System.Char},System.Boolean,System.Int32@,System.Int32@)">
            <summary>
            Decode the given ids back to text and store the result in the <paramref name="destination"/> span.
            </summary>
            <param name="ids">The list of ids that we want to decode.</param>
            <param name="destination">The span to store the decoded text.</param>
            /// <param name="considerSpecialTokens">Indicate whether to consider special tokens during decoding.</param>
            <param name="idsConsumed">The number of ids consumed during the decoding.</param>
            <param name="charsWritten">The number of characters written to the destination span.</param>
            <returns>The operation status indicates whether all IDs were successfully decoded or if the <paramref name="destination"/> is too small to contain the entire decoded result.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePieceTokenizer.Create(System.IO.Stream,System.Boolean,System.Boolean,System.Collections.Generic.IReadOnlyDictionary{System.String,System.Int32})">
            <summary>
            Creates an instance of SentencePieceTokenizer. The model stream should contain a SentencePiece model as specified in the following documentation:
            https://github.com/google/sentencepiece/blob/master/src/sentencepiece_model.proto.
            </summary>
            <param name="modelStream">The stream containing the SentencePiece Bpe or Unigram model.</param>
            <param name="addBeginOfSentence">Indicate emitting the beginning of sentence token during the encoding.</param>
            <param name="addEndOfSentence">Indicate emitting the end of sentence token during the encoding.</param>
            <param name="specialTokens">The additional tokens to add to the vocabulary.</param>
            <remarks>
            When creating the tokenizer, ensure that the vocabulary stream is sourced from a trusted provider.
            </remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePieceTokenizer.Create(Microsoft.ML.Tokenizers.SentencePieceOptions)">
            <summary>
            Creates an instance of SentencePieceTokenizer.
            </summary>
            <param name="options">The options to use for the sentence piece tokenizer.</param>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Symbol.MergeWith(Microsoft.ML.Tokenizers.Symbol@,System.Int32)">
            Merges the current Symbol with the other one.
            In order to update prev/next, we consider Self to be the Symbol on the left,
            and other to be the next one on the right.
        </member>
        <member name="T:Microsoft.ML.Tokenizers.TiktokenTokenizer">
            <summary>
            Represent the rapid Byte Pair Encoding tokenizer.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.TiktokenTokenizer.#ctor(System.String,Microsoft.ML.Tokenizers.PreTokenizer,System.Collections.Generic.IReadOnlyDictionary{System.String,System.Int32},Microsoft.ML.Tokenizers.Normalizer,System.Int32)">
            <summary>
            Create a new Tiktoken tokenizer's object.
            </summary>
            <param name="vocabFilePath">The path to the BPE vocab file.</param>
            <param name="preTokenizer">The pre-tokenizer to use.</param>
            <param name="specialTokens">The dictionary mapping special tokens to Ids.</param>
            <param name="normalizer">The normalizer to use.</param>
            <param name="cacheSize">The size of the cache to use.</param>
            <exception cref="T:System.ArgumentNullException">Thrown when <paramref name="vocabFilePath"/> is null or empty.</exception>
            <exception cref="T:System.InvalidOperationException">Thrown when failed to load the BPE vocab file.</exception>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.TiktokenTokenizer.#ctor(System.IO.Stream,Microsoft.ML.Tokenizers.PreTokenizer,System.Collections.Generic.IReadOnlyDictionary{System.String,System.Int32},Microsoft.ML.Tokenizers.Normalizer,System.Int32)">
            <summary>
            Create a new Tiktoken tokenizer's object.
            </summary>
            <param name="vocabStream">The stream to the BPE vocab file.</param>
            <param name="preTokenizer">The pre-tokenizer to use.</param>
            <param name="specialTokens">The dictionary mapping special tokens to Ids.</param>
            <param name="normalizer">The normalizer to use.</param>
            <param name="cacheSize">The size of the cache to use.</param>
            <exception cref="T:System.ArgumentNullException">Thrown when <paramref name="vocabStream"/> is null or empty.</exception>
            <exception cref="T:System.InvalidOperationException">Thrown when failed to load the BPE vocab file.</exception>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.TiktokenTokenizer.#ctor(System.Collections.Generic.Dictionary{System.ReadOnlyMemory{System.Byte},System.Int32},System.Collections.Generic.Dictionary{System.Int32,System.ReadOnlyMemory{System.Byte}},System.Collections.Generic.Dictionary{Microsoft.ML.Tokenizers.StringSpanOrdinalKey,System.ValueTuple{System.Int32,System.String}},Microsoft.ML.Tokenizers.PreTokenizer,System.Collections.Generic.IReadOnlyDictionary{System.String,System.Int32},Microsoft.ML.Tokenizers.Normalizer,System.Int32)">
            <summary>
            Create a new Tiktoken tokenizer's object.
            </summary>
            <param name="encoder">The dictionary mapping token utf-8 bytes to Ids.</param>
            <param name="decoder">The dictionary mapping Ids to token utf-8 bytes.</param>
            <param name="vocab">The dictionary mapping string tokens to Ids.</param>
            <param name="preTokenizer">The pre-tokenizer to use.</param>
            <param name="specialTokens">The dictionary mapping special tokens to Ids.</param>
            <param name="normalizer">The normalizer to use.</param>
            <param name="cacheSize">The max size of the cache to use.</param>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.TiktokenTokenizer.PreTokenizer">
            <summary>
            Gets the PreTokenizer used by the Tokenizer.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.TiktokenTokenizer.Normalizer">
            <summary>
            Gets the Normalizer in use by the Tokenizer.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.TiktokenTokenizer.LoadTiktokenBpeAsync(System.IO.Stream,System.Boolean,System.Threading.CancellationToken)">
            <summary>
            Load BPE vocab dictionary from a stream.
            </summary>
            <param name="vocabStream">Stream to the BPE vocab file</param>
            <param name="useAsync">Whether to perform I/O synchronously or asynchronously.</param>
            <param name="cancellationToken"><see cref="T:System.Threading.CancellationToken"/> used to request cancellation of the operation.</param>
            <returns>Map of byte[] to integer token id</returns>
            <exception cref="T:System.InvalidOperationException"></exception>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.TiktokenTokenizer.EncodeToTokens(System.String,System.ReadOnlySpan{System.Char},Microsoft.ML.Tokenizers.EncodeSettings)">
            <summary>
            Encodes input text to a list of <see cref="T:Microsoft.ML.Tokenizers.EncodedToken" />s.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="textSpan">The span of the text to encode which will be used if the <paramref name="text"/> is <see langword="null"/>.</param>
            <param name="settings">The settings used to encode the text.</param>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.TiktokenTokenizer.EncodeToTokens(System.ReadOnlySpan{System.Char},System.Collections.Generic.List{Microsoft.ML.Tokenizers.EncodedToken},System.Int32)">
            <summary>
            Encode text to a list of tokens.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="tokens">The list of tokens to populate.</param>
            <param name="offset">The offset to start encoding from.</param>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.TiktokenTokenizer.EncodeToIds(System.String,System.ReadOnlySpan{System.Char},Microsoft.ML.Tokenizers.EncodeSettings)">
            <summary>
            Encodes input text to token Ids.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="textSpan">The span of the text to encode which will be used if the <paramref name="text"/> is <see langword="null"/>.</param>
            <param name="settings">The settings used to encode the text.</param>
            <returns>The encoded results containing the list of encoded Ids.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.TiktokenTokenizer.EncodeToIds(System.ReadOnlySpan{System.Char},System.Collections.Generic.IList{System.Int32},System.Int32@,System.Int32)">
            <summary>
            Encode text to a list of Ids.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="accumulatedIds">The list of accumulated Ids.</param>
            <param name="charsConsumed">The length of the text that encompasses the maximum encoded tokens.</param>
            <param name="maxTokenCount">The maximum number of tokens to encode.</param>
            <returns>The number of tokens that the input text will be encoded to.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.TiktokenTokenizer.CountTokens(System.String,System.ReadOnlySpan{System.Char},Microsoft.ML.Tokenizers.EncodeSettings)">
            <summary>
            Get the number of tokens that the input text will be encoded to.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="textSpan">The span of the text to encode which will be used if the <paramref name="text"/> is <see langword="null"/>.</param>
            <param name="settings">The settings used to encode the text.</param>
            <returns>The number of token Ids that the input text will be encoded to.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.TiktokenTokenizer.CountTokens(System.ReadOnlySpan{System.Char},System.Int32@,System.Int32)">
            <summary>
            Get the number of tokens that the input text will be encoded to.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="charsConsumed">The length of the text that encompasses the maximum encoded tokens.</param>
            <param name="maxTokens">The maximum number of tokens to encode.</param>
            <returns>The number of tokens that the input text will be encoded to.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.TiktokenTokenizer.GetIndexByTokenCount(System.String,System.ReadOnlySpan{System.Char},Microsoft.ML.Tokenizers.EncodeSettings,System.Boolean,System.String@,System.Int32@)">
            <summary>
            Find the index of the maximum encoding capacity without surpassing the token limit.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="textSpan">The span of the text to encode which will be used if the <paramref name="text"/> is <see langword="null"/>.</param>
            <param name="settings">The settings used to encode the text.</param>
            <param name="fromEnd">Indicate whether to find the index from the end of the text.</param>
            <param name="normalizedText">If the tokenizer's normalization is enabled or <paramRef name="settings" /> has <see cref="P:Microsoft.ML.Tokenizers.EncodeSettings.ConsiderNormalization"/> is <see langword="false"/>, this will be set to <paramRef name="text" /> in its normalized form; otherwise, this value will be set to <see langword="null"/>.</param>
            <param name="tokenCount">The token count can be generated which should be smaller than the maximum token count.</param>
            <returns>
            The index of the maximum encoding capacity within the processed text without surpassing the token limit.
            If <paramRef name="fromEnd" /> is <see langword="false"/>, it represents the index immediately following the last character to be included. In cases where no tokens fit, the result will be 0; conversely,
            if all tokens fit, the result will be length of the input text or the <paramref name="normalizedText"/> if the normalization is enabled.
            If <paramRef name="fromEnd" /> is <see langword="true"/>, it represents the index of the first character to be included. In cases where no tokens fit, the result will be the text length; conversely,
            if all tokens fit, the result will be zero.
            </returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.TiktokenTokenizer.CountTokensFromEnd(System.ReadOnlySpan{System.Char},System.Int32@,System.Int32)">
            <summary>
            Get the number of tokens that the input text will be encoded to.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="textIndex">Starting from this index to the end of the text will encompasses the maximum encoded tokens.</param>
            <param name="maxTokens">The maximum number of tokens to encode.</param>
            <returns>The number of tokens that the input text will be encoded to.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.TiktokenTokenizer.Decode(System.Collections.Generic.IEnumerable{System.Int32})">
            <summary>
            Decode the given ids, back to a String.
            </summary>
            <param name="ids">The list of ids that we want to decode.</param>
            <returns>The decoded string.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.TiktokenTokenizer.Decode(System.Collections.Generic.IEnumerable{System.Int32},System.Span{System.Char},System.Int32@,System.Int32@)">
            <summary>
            Decode the given ids back to text and store the result in the <paramref name="destination"/> span.
            </summary>
            <param name="ids">The list of ids that we want to decode.</param>
            <param name="destination">The span to store the decoded text.</param>
            <param name="idsConsumed">The number of ids consumed during the decoding.</param>
            <param name="charsWritten">The number of characters written to the destination span.</param>
            <returns>The operation status indicates whether all IDs were successfully decoded or if the <paramref name="destination"/> is too small to contain the entire decoded result.</returns>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.TiktokenTokenizer.Vocabulary">
            <summary>
            Gets the dictionary mapping tokens to Ids.
            </summary>
            <remarks>This may not contain the full set of vocabulary tokens, use Encoder to get the full set of vocabulary.</remarks>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.TiktokenTokenizer.SpecialTokens">
            <summary>
            Gets the dictionary mapping special tokens to Ids.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.TiktokenTokenizer.Encoder">
            <summary>
            Gets the dictionary mapping token bytes to Ids.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.TiktokenTokenizer.Decoder">
            <summary>
            Gets the dictionary mapping Ids to token utf-8 bytes.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.TiktokenTokenizer.Cl100kBaseRegex">
            <remarks>
            Pattern:<br/>
            <code>'(?i:[sdmt]|ll|ve|re)|(?&gt;[^\\r\\n\\p{L}\\p{N}]?)(?&gt;\\p{L}+)|(?&gt;\\p{N}{1,3})| ?(?&gt;[^\\s\\p{L}\\p{N}]+)(?&gt;[\\r\\n]*)|(?&gt;\\s+)$|\\s*[\\r\\n]|\\s+(?!\\S)|\\s</code><br/>
            Explanation:<br/>
            <code>
            ○ Match with 8 alternative expressions, atomically.<br/>
                ○ Match a sequence of expressions.<br/>
                    ○ Match '\''.<br/>
                    ○ Match with 4 alternative expressions, atomically.<br/>
                        ○ Match a character in the set [DMSTdmst].<br/>
                        ○ Match a character in the set [Ll] exactly 2 times.<br/>
                        ○ Match a sequence of expressions.<br/>
                            ○ Match a character in the set [Vv].<br/>
                            ○ Match a character in the set [Ee].<br/>
                        ○ Match a sequence of expressions.<br/>
                            ○ Match a character in the set [Rr].<br/>
                            ○ Match a character in the set [Ee].<br/>
                ○ Match a sequence of expressions.<br/>
                    ○ Match a character in the set [^\n\r\p{L}\p{N}] atomically, optionally.<br/>
                    ○ Match a character in the set [\p{L}] atomically at least once.<br/>
                ○ Match a character in the set [\p{N}] atomically at least 1 and at most 3 times.<br/>
                ○ Match a sequence of expressions.<br/>
                    ○ Match ' ' atomically, optionally.<br/>
                    ○ Match a character in the set [^\s\p{L}\p{N}] atomically at least once.<br/>
                    ○ Match a character in the set [\n\r] atomically any number of times.<br/>
                ○ Match a sequence of expressions.<br/>
                    ○ Match a whitespace character atomically at least once.<br/>
                    ○ Match if at the end of the string or if before an ending newline.<br/>
                ○ Match a sequence of expressions.<br/>
                    ○ Match a whitespace character greedily any number of times.<br/>
                    ○ Match a character in the set [\n\r].<br/>
                ○ Match a sequence of expressions.<br/>
                    ○ Match a whitespace character greedily at least once.<br/>
                    ○ Zero-width negative lookahead.<br/>
                        ○ Match any character other than a whitespace character.<br/>
                ○ Match a whitespace character.<br/>
            </code>
            </remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.TiktokenTokenizer.P50kBaseRegex">
            <remarks>
            Pattern:<br/>
            <code>'(?:[sdmt]|ll|ve|re)| ?(?&gt;\\p{L}+)| ?(?&gt;\\p{N}+)| ?(?&gt;[^\\s\\p{L}\\p{N}]+)|(?&gt;\\s+)$|\\s+(?!\\S)|\\s</code><br/>
            Explanation:<br/>
            <code>
            ○ Match with 7 alternative expressions, atomically.<br/>
                ○ Match a sequence of expressions.<br/>
                    ○ Match '\''.<br/>
                    ○ Match with 4 alternative expressions, atomically.<br/>
                        ○ Match a character in the set [dmst].<br/>
                        ○ Match the string "ll".<br/>
                        ○ Match the string "ve".<br/>
                        ○ Match the string "re".<br/>
                ○ Match a sequence of expressions.<br/>
                    ○ Match ' ' atomically, optionally.<br/>
                    ○ Match a character in the set [\p{L}] atomically at least once.<br/>
                ○ Match a sequence of expressions.<br/>
                    ○ Match ' ' atomically, optionally.<br/>
                    ○ Match a character in the set [\p{N}] atomically at least once.<br/>
                ○ Match a sequence of expressions.<br/>
                    ○ Match ' ' atomically, optionally.<br/>
                    ○ Match a character in the set [^\s\p{L}\p{N}] atomically at least once.<br/>
                ○ Match a sequence of expressions.<br/>
                    ○ Match a whitespace character atomically at least once.<br/>
                    ○ Match if at the end of the string or if before an ending newline.<br/>
                ○ Match a sequence of expressions.<br/>
                    ○ Match a whitespace character greedily at least once.<br/>
                    ○ Zero-width negative lookahead.<br/>
                        ○ Match any character other than a whitespace character.<br/>
                ○ Match a whitespace character.<br/>
            </code>
            </remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.TiktokenTokenizer.O200kBaseRegex">
            <remarks>
            Pattern:<br/>
            <code>[^\\r\\n\\p{L}\\p{N}]?[\\p{Lu}\\p{Lt}\\p{Lm}\\p{Lo}\\p{M}]*[\\p{Ll}\\p{Lm}\\p{Lo}\\p{M}]+(?i:'s|'t|'re|'ve|'m|'ll|'d)?|[^\\r\\n\\p{L}\\p{N}]?[\\p{Lu}\\p{Lt}\\p{Lm}\\p{Lo}\\p{M}]+[\\p{Ll}\\p{Lm}\\p{Lo}\\p{M}]*(?i:'s|'t|'re|'ve|'m|'ll|'d)?|\\p{N}{1,3}| ?[^\\s\\p{L}\\p{N}]+[\\r\\n/]*|\\s*[\\r\\n]+|\\s+(?!\\S)|\\s+</code><br/>
            Explanation:<br/>
            <code>
            ○ Match with 7 alternative expressions, atomically.<br/>
                ○ Match a sequence of expressions.<br/>
                    ○ Match a character in the set [^\n\r\p{L}\p{N}] greedily, optionally.<br/>
                    ○ Match a character in the set [\p{Lu}\p{Lt}\p{Lm}\p{Lo}\p{M}] greedily any number of times.<br/>
                    ○ Match a character in the set [\p{Ll}\p{Lm}\p{Lo}\p{M}] greedily at least once.<br/>
                    ○ Optional (greedy).<br/>
                        ○ Match '\''.<br/>
                        ○ Match with 6 alternative expressions, atomically.<br/>
                            ○ Match a character in the set [STst].<br/>
                            ○ Match a sequence of expressions.<br/>
                                ○ Match a character in the set [Rr].<br/>
                                ○ Match a character in the set [Ee].<br/>
                            ○ Match a sequence of expressions.<br/>
                                ○ Match a character in the set [Vv].<br/>
                                ○ Match a character in the set [Ee].<br/>
                            ○ Match a character in the set [Mm].<br/>
                            ○ Match a character in the set [Ll] exactly 2 times.<br/>
                            ○ Match a character in the set [Dd].<br/>
                ○ Match a sequence of expressions.<br/>
                    ○ Match a character in the set [^\n\r\p{L}\p{N}] greedily, optionally.<br/>
                    ○ Match a character in the set [\p{Lu}\p{Lt}\p{Lm}\p{Lo}\p{M}] greedily at least once.<br/>
                    ○ Match a character in the set [\p{Ll}\p{Lm}\p{Lo}\p{M}] greedily any number of times.<br/>
                    ○ Optional (greedy).<br/>
                        ○ Match '\''.<br/>
                        ○ Match with 6 alternative expressions, atomically.<br/>
                            ○ Match a character in the set [STst].<br/>
                            ○ Match a sequence of expressions.<br/>
                                ○ Match a character in the set [Rr].<br/>
                                ○ Match a character in the set [Ee].<br/>
                            ○ Match a sequence of expressions.<br/>
                                ○ Match a character in the set [Vv].<br/>
                                ○ Match a character in the set [Ee].<br/>
                            ○ Match a character in the set [Mm].<br/>
                            ○ Match a character in the set [Ll] exactly 2 times.<br/>
                            ○ Match a character in the set [Dd].<br/>
                ○ Match a character in the set [\p{N}] atomically at least 1 and at most 3 times.<br/>
                ○ Match a sequence of expressions.<br/>
                    ○ Match ' ' atomically, optionally.<br/>
                    ○ Match a character in the set [^\s\p{L}\p{N}] greedily at least once.<br/>
                    ○ Match a character in the set [\n\r/] atomically any number of times.<br/>
                ○ Match a sequence of expressions.<br/>
                    ○ Match a whitespace character greedily any number of times.<br/>
                    ○ Match a character in the set [\n\r] atomically at least once.<br/>
                ○ Match a sequence of expressions.<br/>
                    ○ Match a whitespace character greedily at least once.<br/>
                    ○ Zero-width negative lookahead.<br/>
                        ○ Match any character other than a whitespace character.<br/>
                ○ Match a whitespace character atomically at least once.<br/>
            </code>
            </remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.TiktokenTokenizer.Create(System.String,Microsoft.ML.Tokenizers.PreTokenizer,Microsoft.ML.Tokenizers.Normalizer,System.Collections.Generic.IReadOnlyDictionary{System.String,System.Int32},System.Int32)">
            <summary>
            Create a new Tiktoken tokenizer's object.
            </summary>
            <param name="vocabFilePath">The BPE vocab file.</param>
            <param name="preTokenizer">The pre-tokenizer to use.</param>
            <param name="normalizer">The normalizer to use.</param>
            <param name="specialTokens">The dictionary mapping special tokens to Ids.</param>
            <param name="cacheSize">The size of the cache to use.</param>
            <returns>The tokenizer's object.</returns>
            <remarks>
            When creating the tokenizer, ensure that the vocabulary file is sourced from a trusted provider.
            </remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.TiktokenTokenizer.Create(System.IO.Stream,Microsoft.ML.Tokenizers.PreTokenizer,Microsoft.ML.Tokenizers.Normalizer,System.Collections.Generic.IReadOnlyDictionary{System.String,System.Int32},System.Int32)">
            <summary>
            Create a new Tiktoken tokenizer's object.
            </summary>
            <param name="vocabStream">The stream to the BPE vocab file.</param>
            <param name="preTokenizer">The pre-tokenizer to use.</param>
            <param name="normalizer">The normalizer to use.</param>
            <param name="specialTokens">The dictionary mapping special tokens to Ids.</param>
            <param name="cacheSize">The size of the cache to use.</param>
            <returns>The tokenizer's object.</returns>
            <remarks>
            When creating the tokenizer, ensure that the vocabulary stream is sourced from a trusted provider.
            </remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.TiktokenTokenizer.CreateAsync(System.IO.Stream,Microsoft.ML.Tokenizers.PreTokenizer,Microsoft.ML.Tokenizers.Normalizer,System.Collections.Generic.IReadOnlyDictionary{System.String,System.Int32},System.Int32,System.Threading.CancellationToken)">
            <summary>
            Create a new Tiktoken tokenizer's object asynchronously.
            </summary>
            <param name="vocabStream">The stream to the BPE vocab file.</param>
            <param name="preTokenizer">The pre-tokenizer to use.</param>
            <param name="normalizer">The normalizer to use.</param>
            <param name="specialTokens">The dictionary mapping special tokens to Ids.</param>
            <param name="cacheSize">The size of the cache to use.</param>
            <param name="cancellationToken"><see cref="T:System.Threading.CancellationToken"/> used to request cancellation of the operation.</param>
            <returns>The tokenizer's object.</returns>
            <remarks>
            When creating the tokenizer, ensure that the vocabulary stream is sourced from a trusted provider.
            </remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.TiktokenTokenizer.CreateAsync(System.String,Microsoft.ML.Tokenizers.PreTokenizer,Microsoft.ML.Tokenizers.Normalizer,System.Collections.Generic.IReadOnlyDictionary{System.String,System.Int32},System.Int32,System.Threading.CancellationToken)">
            <summary>
            Create a new Tiktoken tokenizer's object asynchronously.
            </summary>
            <param name="vocabFilePath">The BPE vocab file.</param>
            <param name="preTokenizer">The pre-tokenizer to use.</param>
            <param name="normalizer">The normalizer to use.</param>
            <param name="specialTokens">The dictionary mapping special tokens to Ids.</param>
            <param name="cacheSize">The size of the cache to use.</param>
            <param name="cancellationToken"><see cref="T:System.Threading.CancellationToken"/> used to request cancellation of the operation.</param>
            <returns>The tokenizer's object.</returns>
            <remarks>
            When creating the tokenizer, ensure that the vocabulary file is sourced from a trusted provider.
            </remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.TiktokenTokenizer.CreateForModel(System.String,System.IO.Stream,System.Collections.Generic.IReadOnlyDictionary{System.String,System.Int32},System.Int32,Microsoft.ML.Tokenizers.Normalizer)">
            <summary>
            Create a Tiktoken tokenizer based on model name and vocab file.
            </summary>
            <param name="modelName">Model name</param>
            <param name="vocabStream">The stream to the BPE vocab file.</param>
            <param name="extraSpecialTokens">Extra special tokens other than the built-in ones for the model</param>
            <param name="cacheSize">The size of the cache to use.</param>
            <param name="normalizer">To normalize the text before tokenization</param>
            <returns>The tokenizer</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.TiktokenTokenizer.CreateForModelAsync(System.String,System.IO.Stream,System.Collections.Generic.IReadOnlyDictionary{System.String,System.Int32},System.Int32,Microsoft.ML.Tokenizers.Normalizer,System.Threading.CancellationToken)">
            <summary>
            Create a Tiktoken tokenizer based on model name and vocab file.
            </summary>
            <param name="modelName">Model name</param>
            <param name="vocabStream">The stream to the BPE vocab file.</param>
            <param name="extraSpecialTokens">Extra special tokens other than the built-in ones for the model</param>
            <param name="cacheSize">The size of the cache to use.</param>
            <param name="normalizer">To normalize the text before tokenization</param>
            <param name="cancellationToken"><see cref="T:System.Threading.CancellationToken"/> used to request cancellation of the operation.</param>
            <returns>The tokenizer</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.TiktokenTokenizer.CreateForModel(System.String,System.Collections.Generic.IReadOnlyDictionary{System.String,System.Int32},Microsoft.ML.Tokenizers.Normalizer)">
            <summary>
            Create tokenizer based on model name
            </summary>
            <param name="modelName">Model name</param>
            <param name="extraSpecialTokens">Extra special tokens other than the built-in ones for the model</param>
            <param name="normalizer">To normalize the text before tokenization</param>
            <returns>The tokenizer</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.TiktokenTokenizer.CreateForEncoding(System.String,System.Collections.Generic.IReadOnlyDictionary{System.String,System.Int32},Microsoft.ML.Tokenizers.Normalizer)">
            <summary>
            Create tokenizer based on encoding name
            </summary>
            <param name="encodingName">Encoding name</param>
            <param name="extraSpecialTokens">Extra special tokens other than the built-in ones for the encoding</param>
            <param name="normalizer">To normalize the text before tokenization</param>
            <returns>The tokenizer</returns>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.WordPieceOptions">
            <summary>
            Options for the WordPiece tokenizer.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.WordPieceOptions.PreTokenizer">
            <summary>
            Gets or sets the <see cref="P:Microsoft.ML.Tokenizers.WordPieceOptions.PreTokenizer"/> to override the default normalizer, if desired.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.WordPieceOptions.Normalizer">
            <summary>
            Gets or sets the <see cref="P:Microsoft.ML.Tokenizers.WordPieceOptions.Normalizer"/> to override the default normalizer, if desired.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.WordPieceOptions.SpecialTokens">
            <summary>
            Gets or set the special tokens to use.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.WordPieceOptions.UnknownToken">
            <summary>
            Gets or set the unknown token to use.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.WordPieceOptions.ContinuingSubwordPrefix">
            <summary>
            Gets or set the prefix to use for sub-words that are not the first part of a word.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.WordPieceOptions.MaxInputCharsPerWord">
            <summary>
            Gets or set the maximum number of characters to consider for a single word.
            </summary>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.WordPieceTokenizer">
            <summary>
            Represent the WordPiece tokenizer.
            </summary>
            <remarks>
            The WordPiece tokenizer is a sub-word tokenizer that is used in BERT and other transformer models.
            The implementation is based on the Hugging Face WordPiece tokenizer https://huggingface.co/docs/tokenizers/api/models#tokenizers.models.WordPiece.
            </remarks>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.WordPieceTokenizer.UnknownTokenId">
            <summary>
            Gets the unknown token ID.
            A token that is not in the vocabulary cannot be converted to an ID and is set to be this token instead.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.WordPieceTokenizer.ContinuingSubwordPrefix">
            <summary>
            Gets the prefix to use for sub-words that are not the first part of a word.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.WordPieceTokenizer.MaxInputCharsPerWord">
            <summary>
            Gets the maximum number of characters to authorize in a single word.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.WordPieceTokenizer.Create(System.String,Microsoft.ML.Tokenizers.WordPieceOptions)">
            <summary>
            Create a new instance of the <see cref="T:Microsoft.ML.Tokenizers.WordPieceTokenizer"/> class.
            </summary>
            <param name="vocabFilePath">The path to the WordPiece vocab file.</param>
            <param name="options">The options to use for the WordPiece tokenizer.</param>
            <returns>A new instance of the <see cref="T:Microsoft.ML.Tokenizers.WordPieceTokenizer"/> class.</returns>
            <remarks>
            If the <see cref="P:Microsoft.ML.Tokenizers.WordPieceOptions.PreTokenizer"/> is null, the whitespace pre-tokenizer will be used.
            When creating the tokenizer, ensure that the vocabulary file is sourced from a trusted provider.
            </remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.WordPieceTokenizer.Create(System.IO.Stream,Microsoft.ML.Tokenizers.WordPieceOptions)">
            <summary>
            Create a new instance of the <see cref="T:Microsoft.ML.Tokenizers.WordPieceTokenizer"/> class.
            </summary>
            <param name="vocabStream">The path to the WordPiece vocab file.</param>
            <param name="options">The options to use for the WordPiece tokenizer.</param>
            <returns>A new instance of the <see cref="T:Microsoft.ML.Tokenizers.WordPieceTokenizer"/> class.</returns>
            <remarks>
            If the <see cref="P:Microsoft.ML.Tokenizers.WordPieceOptions.PreTokenizer"/> is null, the whitespace pre-tokenizer will be used.
            When creating the tokenizer, ensure that the vocabulary stream is sourced from a trusted provider.
            </remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.WordPieceTokenizer.CreateAsync(System.String,Microsoft.ML.Tokenizers.WordPieceOptions,System.Threading.CancellationToken)">
            <summary>
            Create a new instance of the <see cref="T:Microsoft.ML.Tokenizers.WordPieceTokenizer"/> class asynchronously.
            </summary>
            <param name="vocabFilePath">The path to the WordPiece vocab file.</param>
            <param name="options">The options to use for the WordPiece tokenizer.</param>
            <param name="cancellationToken">The cancellation token.</param>
            <returns>A new instance of the <see cref="T:Microsoft.ML.Tokenizers.WordPieceTokenizer"/> class.</returns>
            <remarks>
            If the <see cref="P:Microsoft.ML.Tokenizers.WordPieceOptions.PreTokenizer"/> is null, the whitespace pre-tokenizer will be used.
            When creating the tokenizer, ensure that the vocabulary file is sourced from a trusted provider.
            </remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.WordPieceTokenizer.CreateAsync(System.IO.Stream,Microsoft.ML.Tokenizers.WordPieceOptions,System.Threading.CancellationToken)">
            <summary>
            Create a new instance of the <see cref="T:Microsoft.ML.Tokenizers.WordPieceTokenizer"/> class asynchronously.
            </summary>
            <param name="vocabStream">The path to the WordPiece vocab file.</param>
            <param name="options">The options to use for the WordPiece tokenizer.</param>
            <param name="cancellationToken">The cancellation token.</param>
            <returns>A new instance of the <see cref="T:Microsoft.ML.Tokenizers.WordPieceTokenizer"/> class.</returns>
            <remarks>
            If the <see cref="P:Microsoft.ML.Tokenizers.WordPieceOptions.PreTokenizer"/> is null, the whitespace pre-tokenizer will be used.
            When creating the tokenizer, ensure that the vocabulary stream is sourced from a trusted provider.
            </remarks>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.WordPieceTokenizer.PreTokenizer">
            <summary>
            Gets the PreTokenizer used by the Tokenizer.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.WordPieceTokenizer.Normalizer">
            <summary>
            Gets the Normalizer in use by the Tokenizer.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.WordPieceTokenizer.UnknownToken">
            <summary>
            Gets the unknown token.
            A token that is not in the vocabulary cannot be converted to an ID and is set to be this token instead.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.WordPieceTokenizer.SpecialTokens">
            <summary>
            Gets the special tokens and their corresponding ids.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.WordPieceTokenizer.SpecialTokensReverse">
            <summary>
            Gets the Ids to tokens mapping for special tokens.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.WordPieceTokenizer.EncodeToTokens(System.String,System.ReadOnlySpan{System.Char},Microsoft.ML.Tokenizers.EncodeSettings)">
            <summary>
            Encodes input text to a list of <see cref="T:Microsoft.ML.Tokenizers.EncodedToken" />s.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="textSpan">The span of the text to encode which will be used if the <paramref name="text"/> is <see langword="null"/>.</param>
            <param name="settings">The settings used to encode the text.</param>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.WordPieceTokenizer.EncodeToTokens(System.ReadOnlySpan{System.Char},System.Collections.Generic.List{Microsoft.ML.Tokenizers.EncodedToken},System.Int32)">
            <summary>
            Encode text to a list of tokens.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="tokens">The list of tokens to populate.</param>
            <param name="offset">The offset to start encoding from.</param>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.WordPieceTokenizer.EncodeToIds(System.String,System.ReadOnlySpan{System.Char},Microsoft.ML.Tokenizers.EncodeSettings)">
            <summary>
            Encodes input text to token Ids.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="textSpan">The span of the text to encode which will be used if the <paramref name="text"/> is <see langword="null"/>.</param>
            <param name="settings">The settings used to encode the text.</param>
            <returns>The encoded results containing the list of encoded Ids.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.WordPieceTokenizer.EncodeToIds(System.ReadOnlySpan{System.Char},System.Collections.Generic.List{System.Int32},System.Int32@,System.Int32)">
            <summary>
            Encode text to a list of Ids.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="accumulatedIds">The list of accumulated Ids.</param>
            <param name="charsConsumed">The length of the text that encompasses the maximum encoded tokens.</param>
            <param name="maxTokenCount">The maximum number of tokens to encode.</param>
            <returns>The number of tokens that the input text will be encoded to.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.WordPieceTokenizer.CountTokens(System.String,System.ReadOnlySpan{System.Char},Microsoft.ML.Tokenizers.EncodeSettings)">
            <summary>
            Get the number of tokens that the input text will be encoded to.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="textSpan">The span of the text to encode which will be used if the <paramref name="text"/> is <see langword="null"/>.</param>
            <param name="settings">The settings used to encode the text.</param>
            <returns>The number of token Ids that the input text will be encoded to.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.WordPieceTokenizer.GetIndexByTokenCount(System.String,System.ReadOnlySpan{System.Char},Microsoft.ML.Tokenizers.EncodeSettings,System.Boolean,System.String@,System.Int32@)">
            <summary>
            Find the index of the maximum encoding capacity without surpassing the token limit.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="textSpan">The span of the text to encode which will be used if the <paramref name="text"/> is <see langword="null"/>.</param>
            <param name="settings">The settings used to encode the text.</param>
            <param name="fromEnd">Indicate whether to find the index from the end of the text.</param>
            <param name="normalizedText">If the tokenizer's normalization is enabled or <paramRef name="settings" /> has <see cref="P:Microsoft.ML.Tokenizers.EncodeSettings.ConsiderNormalization"/> is <see langword="false"/>, this will be set to <paramRef name="text" /> in its normalized form; otherwise, this value will be set to <see langword="null"/>.</param>
            <param name="tokenCount">The token count can be generated which should be smaller than the maximum token count.</param>
            <returns>
            The index of the maximum encoding capacity within the processed text without surpassing the token limit.
            If <paramRef name="fromEnd" /> is <see langword="false"/>, it represents the index immediately following the last character to be included. In cases where no tokens fit, the result will be 0; conversely,
            if all tokens fit, the result will be length of the input text or the <paramref name="normalizedText"/> if the normalization is enabled.
            If <paramRef name="fromEnd" /> is <see langword="true"/>, it represents the index of the first character to be included. In cases where no tokens fit, the result will be the text length; conversely,
            if all tokens fit, the result will be zero.
            </returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.WordPieceTokenizer.Decode(System.Collections.Generic.IEnumerable{System.Int32})">
            <summary>
            Decode the given ids, back to a String.
            </summary>
            <param name="ids">The list of ids that we want to decode.</param>
            <returns>The decoded string.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.WordPieceTokenizer.Decode(System.Collections.Generic.IEnumerable{System.Int32},System.Boolean)">
            <summary>
            Decode the given ids, back to a String.
            </summary>
            <param name="ids">The list of ids that we want to decode.</param>
            <param name="skipSpecialTokens">Indicate whether to skip the special tokens during the decoding.</param>
            <returns>The decoded string.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.WordPieceTokenizer.Decode(System.Collections.Generic.IEnumerable{System.Int32},System.Span{System.Char},System.Int32@,System.Int32@)">
            <summary>
            Decode the given ids back to text and store the result in the <paramref name="destination"/> span.
            </summary>
            <param name="ids">The list of ids that we want to decode.</param>
            <param name="destination">The span to store the decoded text.</param>
            <param name="idsConsumed">The number of ids consumed during the decoding.</param>
            <param name="charsWritten">The number of characters written to the destination span.</param>
            <returns>The operation status indicates whether all IDs were successfully decoded or if the <paramref name="destination"/> is too small to contain the entire decoded result.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.WordPieceTokenizer.Decode(System.Collections.Generic.IEnumerable{System.Int32},System.Span{System.Char},System.Boolean,System.Int32@,System.Int32@)">
            <summary>
            Decode the given ids back to text and store the result in the <paramref name="destination"/> span.
            </summary>
            <param name="ids">The list of ids that we want to decode.</param>
            <param name="destination">The span to store the decoded text.</param>
            <param name="skipSpecialTokens">Indicate whether to skip the special tokens during the decoding.</param>
            <param name="idsConsumed">The number of ids consumed during the decoding.</param>
            <param name="charsWritten">The number of characters written to the destination span.</param>
            <returns>The operation status indicates whether all IDs were successfully decoded or if the <paramref name="destination"/> is too small to contain the entire decoded result.</returns>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.BertNormalizer">
            <summary>
            Normalizer that performs the Bert model normalization.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.BertNormalizer.Normalize(System.String)">
            <summary>
            Normalize the input string.
            </summary>
            <param name="original">The input string to normalize.</param>
            <returns>The normalized string.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.BertNormalizer.Normalize(System.ReadOnlySpan{System.Char})">
            <summary>
            Normalize the input character span.
            </summary>
            <param name="original">The input character span to normalize.</param>
            <returns>The normalized string.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.BertNormalizer.#ctor(System.Boolean,System.Boolean,System.Boolean)">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.ML.Tokenizers.BertNormalizer"/> class.
            </summary>
            <param name="lowerCase">Whether to lowercase the input.</param>
            <param name="individuallyTokenizeCjk">Whether to tokenize CJK characters.</param>
            <param name="removeNonSpacingMarks">Whether to strip accents from the input.</param>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.BertNormalizer.IsCjkChar(System.Int32)">
            <summary>
            Checks whether CP is the codepoint of a CJK character.
            This defines a "chinese character" as anything in the CJK Unicode block:
              https://en.wikipedia.org/wiki/CJK_Unified_Ideographs_(Unicode_block)
            </summary>
            <param name="codePoint">The codepoint to check.</param>
            <remarks>
            The CJK Unicode block is NOT all Japanese and Korean characters,
            despite its name. The modern Korean Hangul alphabet is a different block,
            as is Japanese Hiragana and Katakana. Those alphabets are used to write
            space-separated words, so they are not treated specially and handled
            like the all of the other languages.
            </remarks>
            <returns>True if the codepoint is a CJK character, false otherwise.</returns>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.LowerCaseNormalizer">
            <summary>
            Normalize the string to lowercase form before processing it with the tokenizer.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.LowerCaseNormalizer.#ctor">
            <summary>
            Creates a LowerCaseNormalizer object.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.LowerCaseNormalizer.Instance">
            <summary>
            Gets a singleton instance of the <see cref="T:Microsoft.ML.Tokenizers.LowerCaseNormalizer"/>.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.LowerCaseNormalizer.Normalize(System.String)">
            <summary>
            Lowercase the original string.
            </summary>
            <param name="original">The original string to normalize to lowercase form.</param>
            <returns>The lower-cased normalized string.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.LowerCaseNormalizer.Normalize(System.ReadOnlySpan{System.Char})">
            <summary>
            Lowercase the original string.
            </summary>
            <param name="original">The original string to normalize to lowercase form.</param>
            <returns>The lower-cased normalized string.</returns>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.Normalizer">
            <summary>
            Normalize the string before processing it with the tokenizer.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Normalizer.Normalize(System.String)">
            <summary>
            Process the original string to modify it and obtain a normalized string.
            </summary>
            <param name="original">The original string to normalize.</param>
            <returns>The normalized string.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Normalizer.Normalize(System.ReadOnlySpan{System.Char})">
            <summary>
            Process the original string to modify it and obtain a normalized string.
            </summary>
            <param name="original">The original string to normalize.</param>
            <returns>The normalized string.</returns>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.SentencePieceNormalizer">
            <summary>
            Normalize the string according to SentencePiece normalization.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePieceNormalizer.#ctor(System.Boolean,System.Boolean,System.Boolean,System.Boolean,System.Collections.Generic.IReadOnlyDictionary{System.String,System.Int32})">
            <summary>
            Creates a SentencePieceNormalizer object.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceNormalizer.RemoveExtraWhiteSpaces">
            <summary>
            Indicate removing extra white spaces from the original string during the normalization.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceNormalizer.AddDummyPrefix">
            <summary>
            Indicate emitting the dummy prefix character U+2581 at the beginning of sentence token during the encoding.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceNormalizer.EscapeWhiteSpaces">
            <summary>
            Indicate escaping white spaces by adding the dummy prefix character U+2581.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceNormalizer.TreatWhitespaceAsSuffix">
            <summary>
            Indicate treating white space as suffix.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.SentencePieceNormalizer.SpecialTokens">
            <summary>
            Indicate the added tokens.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePieceNormalizer.Normalize(System.String)">
            <summary>
            Normalize the original string according to SentencePiece normalization.
            </summary>
            <param name="original">The original string to normalize.</param>
            <returns>The normalized string.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.SentencePieceNormalizer.Normalize(System.ReadOnlySpan{System.Char})">
            <summary>
            Normalize the original string according to SentencePiece normalization.
            </summary>
            <param name="original">The original string to normalize.</param>
            <returns>The normalized string.</returns>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.UpperCaseNormalizer">
            <summary>
            Normalize the string to uppercase form before processing it with the tokenizer.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.UpperCaseNormalizer.#ctor">
            <summary>
            Creates a UpperCaseNormalizer object.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.UpperCaseNormalizer.Instance">
            <summary>
            Gets a singleton instance of the <see cref="T:Microsoft.ML.Tokenizers.UpperCaseNormalizer"/>.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.UpperCaseNormalizer.Normalize(System.String)">
            <summary>
            Uppercase the original string.
            </summary>
            <param name="original">The original string to normalize to uppercase form.</param>
            <returns>The upper-cased normalized string.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.UpperCaseNormalizer.Normalize(System.ReadOnlySpan{System.Char})">
            <summary>
            Uppercase the original string.
            </summary>
            <param name="original">The original string to normalize to uppercase form.</param>
            <returns>The upper-cased normalized string.</returns>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.PreTokenizer">
            <summary>
            Base class for all pre-tokenizers classes.
            The PreTokenizer is in charge of doing the pre-segmentation step.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.PreTokenizer.PreTokenize(System.String)">
            <summary>
            Get the offsets and lengths of the tokens relative to the <paramref name="text"/>.
            </summary>
            <param name="text">The string to split into tokens.</param>
            <returns>The offsets and lengths of the tokens, expressed as pairs, are relative to the original string.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.PreTokenizer.PreTokenize(System.ReadOnlySpan{System.Char})">
            <summary>
            Get the offsets and lengths of the tokens relative to the original string.
            </summary>
            <param name="text">The character span to split into tokens.</param>
            <returns>The offsets and lengths of the tokens, expressed as pairs, are relative to the original string.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.PreTokenizer.WhiteSpaceOrPunctuationRegex">
            <remarks>
            Pattern:<br/>
            <code>\\w+|[\\p{P}]</code><br/>
            Explanation:<br/>
            <code>
            ○ Match with 2 alternative expressions, atomically.<br/>
                ○ Match a word character atomically at least once.<br/>
                ○ Match a character in the set [\p{P}].<br/>
            </code>
            </remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.PreTokenizer.CreateWordOrPunctuation(System.Collections.Generic.IReadOnlyDictionary{System.String,System.Int32})">
            <summary>
            Create a new instance of the <see cref="T:Microsoft.ML.Tokenizers.PreTokenizer"/> class which split the text at the whitespace or punctuation characters.
            </summary>
            <param name="specialTokens">The dictionary containing the special tokens and their corresponding ids.</param>
            <returns>The pre-tokenizer that splits the text at the whitespace or punctuation characters.</returns>
            <remarks>
            This pre-tokenizer uses the regex pattern "\w+|[\p{P}]" to split the text into tokens.
            </remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.PreTokenizer.WordOrNonWordRegex">
            <remarks>
            Pattern:<br/>
            <code>\\w+|[^\\w\\s]+</code><br/>
            Explanation:<br/>
            <code>
            ○ Match with 2 alternative expressions, atomically.<br/>
                ○ Match a word character atomically at least once.<br/>
                ○ Match a character in the set [^\w\s] atomically at least once.<br/>
            </code>
            </remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.PreTokenizer.CreateWordOrNonWord(System.Collections.Generic.IReadOnlyDictionary{System.String,System.Int32})">
            <summary>
            Create a new instance of the <see cref="T:Microsoft.ML.Tokenizers.PreTokenizer"/> class which split the text at the word or non-word boundary.
            The word is a set of alphabet, numeric, and underscore characters.
            </summary>
            <param name="specialTokens">The dictionary containing the special tokens and their corresponding ids.</param>
            <returns>The pre-tokenizer that splits the text at the word boundary.</returns>
            <remarks>
            This pre-tokenizer uses the regex pattern "\w+|[^\w\s]+" to split the text into tokens.
            </remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.PreTokenizer.WhiteSpaceRegex">
            <remarks>
            Pattern:<br/>
            <code>\\S+</code><br/>
            Explanation:<br/>
            <code>
            ○ Match any character other than a whitespace character atomically at least once.<br/>
            </code>
            </remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.PreTokenizer.CreateWhiteSpace(System.Collections.Generic.IReadOnlyDictionary{System.String,System.Int32})">
            <summary>
            Create a new instance of the <see cref="T:Microsoft.ML.Tokenizers.PreTokenizer"/> class which split the text at the white spaces.
            </summary>
            <param name="specialTokens">The dictionary containing the special tokens and their corresponding ids.</param>
            <returns>The pre-tokenizer that splits the text at the white spaces.</returns>
            <remarks>
            This pre-tokenizer uses the regex pattern "\S+" to split the text into tokens.
            </remarks>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.RegexPreTokenizer">
            <summary>
            The pre-tokenizer for Tiktoken tokenizer.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.RegexPreTokenizer.#ctor(System.Text.RegularExpressions.Regex,System.Collections.Generic.IReadOnlyDictionary{System.String,System.Int32})">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.ML.Tokenizers.RegexPreTokenizer"/> class.
            </summary>
            <param name="regex">The regex to use for splitting the text into smaller tokens in the pre-tokenization process.</param>
            <param name="specialTokens">The dictionary containing the special tokens and their corresponding ids.</param>
            <exception cref="T:System.ArgumentNullException">When regex is null</exception>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.RegexPreTokenizer.PreTokenize(System.String)">
            <summary>
            Get the offsets and lengths of the tokens relative to the <paramref name="text"/>.
            </summary>
            <param name="text">The string to split into tokens.</param>
            <returns>The offsets and lengths of the tokens, expressed as pairs, are relative to the original string.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.RegexPreTokenizer.PreTokenize(System.ReadOnlySpan{System.Char})">
            <summary>
            Get the offsets and lengths of the tokens relative to the <paramref name="text"/>.
            </summary>
            <param name="text">The string to split into tokens.</param>
            <returns>The offsets and lengths of the tokens, expressed as pairs, are relative to the original string.</returns>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.RobertaPreTokenizer">
            <summary>
            The pre-tokenizer for Roberta English tokenizer.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.RobertaPreTokenizer.Instance">
            <summary>
            Gets a singleton instance of the Roberta pre-tokenizer..
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.RobertaPreTokenizer.PreTokenize(System.String)">
            <summary>
            Get the offsets and lengths of the tokens relative to the <paramref name="text"/>.
            </summary>
            <param name="text">The string to split into tokens.</param>
            <returns>The offsets and lengths of the tokens, expressed as pairs, are relative to the original string.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.RobertaPreTokenizer.PreTokenize(System.ReadOnlySpan{System.Char})">
            <summary>
            Get the offsets and lengths of the tokens relative to the <paramref name="text"/>.
            </summary>
            <param name="text">The string to split into tokens.</param>
            <returns>The offsets and lengths of the tokens, expressed as pairs, are relative to the original string.</returns>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.Tokenizer">
            <summary>
            Provides an abstraction for tokenizers, enabling the encoding of text into tokens and the decoding of token IDs back into text.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tokenizer.#ctor">
            <summary>
            Initializes a new instance of the <see cref="T:Microsoft.ML.Tokenizers.Tokenizer"/> class.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.Tokenizer.PreTokenizer">
            <summary>
            Gets the PreTokenizer used by the Tokenizer.
            </summary>
        </member>
        <member name="P:Microsoft.ML.Tokenizers.Tokenizer.Normalizer">
            <summary>
            Gets the Normalizer in use by the Tokenizer.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tokenizer.EncodeToIds(System.String,System.ReadOnlySpan{System.Char},Microsoft.ML.Tokenizers.EncodeSettings)">
            <summary>
            Encodes input text to token Ids.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="textSpan">The span of the text to encode which will be used if the <paramref name="text"/> is <see langword="null"/>.</param>
            <param name="settings">The settings used to encode the text.</param>
            <returns>The encoded results containing the list of encoded Ids.</returns>
            <remarks>
            Types derived from <see cref="T:Microsoft.ML.Tokenizers.Tokenizer"/> may override this implementation to provide a more efficient implementation.
            By default, it uses <see cref="M:Microsoft.ML.Tokenizers.Tokenizer.EncodeToTokens(System.String,System.ReadOnlySpan{System.Char},Microsoft.ML.Tokenizers.EncodeSettings)"/>.
            </remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tokenizer.EncodeToIds(System.String,System.Boolean,System.Boolean)">
            <summary>
            Encodes input text to token Ids.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <returns>The list of encoded Ids.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tokenizer.EncodeToIds(System.ReadOnlySpan{System.Char},System.Boolean,System.Boolean)">
            <summary>
            Encodes input text to token Ids.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <returns>The list of encoded Ids.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tokenizer.EncodeToIds(System.String,System.Int32,System.String@,System.Int32@,System.Boolean,System.Boolean)">
            <summary>
            Encodes input text to token Ids up to maximum number of tokens.
            <param name="text">The text to encode.</param>
            </summary>
            <param name="maxTokenCount">The maximum number of tokens to encode.</param>
            <param name="normalizedText">If the tokenizer's normalization is enabled or <paramRef name="considerNormalization" /> is <see langword="false"/>, this will be set to <paramRef name="text" /> in its normalized form; otherwise, this value will be set to <see langword="null"/>.</param>
            <param name="charsConsumed">The characters count of the text that encompasses the maximum encoded tokens.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <returns>The list of encoded Ids.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tokenizer.EncodeToIds(System.ReadOnlySpan{System.Char},System.Int32,System.String@,System.Int32@,System.Boolean,System.Boolean)">
            <summary>
            Encodes input text to token Ids up to maximum number of tokens.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="maxTokenCount">The maximum number of tokens to encode.</param>
            <param name="normalizedText">If the tokenizer's normalization is enabled or <paramRef name="considerNormalization" /> is <see langword="false"/>, this will be set to <paramRef name="text" /> in its normalized form; otherwise, this value will be set to <see langword="null"/>.</param>
            <param name="charsConsumed">The characters count of the text that encompasses the maximum encoded tokens.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <returns>The list of encoded Ids.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tokenizer.EncodeToTokens(System.String,System.ReadOnlySpan{System.Char},Microsoft.ML.Tokenizers.EncodeSettings)">
            <summary>
            Encodes input text to a list of <see cref="T:Microsoft.ML.Tokenizers.EncodedToken" />s.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="textSpan">The span of the text to encode which will be used if the <paramref name="text"/> is <see langword="null"/>.</param>
            <param name="settings">The settings used to encode the text.</param>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tokenizer.EncodeToTokens(System.String,System.String@,System.Boolean,System.Boolean)">
            <summary>
            Encodes input text to a list of <see cref="T:Microsoft.ML.Tokenizers.EncodedToken" />s.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="normalizedText">If the tokenizer's normalization is enabled or <paramRef name="considerNormalization" /> is <see langword="false"/>, this will be set to <paramRef name="text" /> in its normalized form; otherwise, this value will be set to <see langword="null"/>.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <returns>The list of encoded <see cref="T:Microsoft.ML.Tokenizers.EncodedToken" />s.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tokenizer.EncodeToTokens(System.ReadOnlySpan{System.Char},System.String@,System.Boolean,System.Boolean)">
            <summary>
            Encodes input text to a list of <see cref="T:Microsoft.ML.Tokenizers.EncodedToken" />s.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="normalizedText">If the tokenizer's normalization is enabled or <paramRef name="considerNormalization" /> is <see langword="false"/>, this will be set to <paramRef name="text" /> in its normalized form; otherwise, this value will be set to <see langword="null"/>.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <returns>The list of encoded <see cref="T:Microsoft.ML.Tokenizers.EncodedToken" />s.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tokenizer.CountTokens(System.String,System.ReadOnlySpan{System.Char},Microsoft.ML.Tokenizers.EncodeSettings)">
            <summary>
            Get the number of tokens that the input text will be encoded to.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="textSpan">The span of the text to encode which will be used if the <paramref name="text"/> is <see langword="null"/>.</param>
            <param name="settings">The settings used to encode the text.</param>
            <returns>The number of token Ids that the input text will be encoded to.</returns>
            <remarks>
            Types derived from <see cref="T:Microsoft.ML.Tokenizers.Tokenizer"/> may override this implementation to provide a more efficient implementation.
            By default, it uses <see cref="M:Microsoft.ML.Tokenizers.Tokenizer.EncodeToTokens(System.String,System.ReadOnlySpan{System.Char},Microsoft.ML.Tokenizers.EncodeSettings)"/>.
            </remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tokenizer.CountTokens(System.String,System.Boolean,System.Boolean)">
            <summary>
            Get the number of tokens that the input text will be encoded to.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <returns>The number of token Ids that the input text will be encoded to.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tokenizer.CountTokens(System.ReadOnlySpan{System.Char},System.Boolean,System.Boolean)">
            <summary>
            Get the number of tokens that the input text will be encoded to.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <returns>The number of token Ids that the input text will be encoded to.</returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tokenizer.GetIndexByTokenCount(System.String,System.ReadOnlySpan{System.Char},Microsoft.ML.Tokenizers.EncodeSettings,System.Boolean,System.String@,System.Int32@)">
            <summary>
            Find the index of the maximum encoding capacity without surpassing the token limit.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="textSpan">The span of the text to encode which will be used if the <paramref name="text"/> is <see langword="null"/>.</param>
            <param name="settings">The settings used to encode the text.</param>
            <param name="fromEnd">Indicate whether to find the index from the end of the text.</param>
            <param name="normalizedText">If the tokenizer's normalization is enabled or <paramRef name="settings" /> has <see cref="P:Microsoft.ML.Tokenizers.EncodeSettings.ConsiderNormalization"/> is <see langword="false"/>, this will be set to <paramRef name="text" /> in its normalized form; otherwise, this value will be set to <see langword="null"/>.</param>
            <param name="tokenCount">The token count can be generated which should be smaller than the maximum token count.</param>
            <returns>
            The index of the maximum encoding capacity within the processed text without surpassing the token limit.
            If <paramRef name="fromEnd" /> is <see langword="false"/>, it represents the index immediately following the last character to be included. In cases where no tokens fit, the result will be 0; conversely,
            if all tokens fit, the result will be length of the input text or the <paramref name="normalizedText"/> if the normalization is enabled.
            If <paramRef name="fromEnd" /> is <see langword="true"/>, it represents the index of the first character to be included. In cases where no tokens fit, the result will be the text length; conversely,
            if all tokens fit, the result will be zero.
            </returns>
            <remarks>
            Types derived from <see cref="T:Microsoft.ML.Tokenizers.Tokenizer"/> may override this implementation to provide a more efficient implementation.
            By default, it uses <see cref="M:Microsoft.ML.Tokenizers.Tokenizer.EncodeToTokens(System.String,System.ReadOnlySpan{System.Char},Microsoft.ML.Tokenizers.EncodeSettings)"/>.
            </remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tokenizer.GetIndexByTokenCount(System.String,System.Int32,System.String@,System.Int32@,System.Boolean,System.Boolean)">
            <summary>
            Find the index of the maximum encoding capacity without surpassing the token limit.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="maxTokenCount">The maximum number of tokens to encode.</param>
            <param name="normalizedText">If the tokenizer's normalization is enabled or <paramRef name="considerNormalization" /> is <see langword="false"/>, this will be set to <paramRef name="text" /> in its normalized form; otherwise, this value will be set to <see langword="null"/>.</param>
            <param name="tokenCount">The token count can be generated which should be smaller than the maximum token count.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <returns>
            The index of the maximum encoding capacity within the processed text without surpassing the token limit.
            It represents the index immediately following the last character to be included. In cases where no tokens fit, the result will be 0; conversely,
            if all tokens fit, the result will be length of the input text or the <paramref name="normalizedText"/> if the normalization is enabled.
            </returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tokenizer.GetIndexByTokenCount(System.ReadOnlySpan{System.Char},System.Int32,System.String@,System.Int32@,System.Boolean,System.Boolean)">
            <summary>
            Find the index of the maximum encoding capacity without surpassing the token limit.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="maxTokenCount">The maximum number of tokens to encode.</param>
            <param name="normalizedText">If the tokenizer's normalization is enabled or <paramRef name="considerPreTokenization" /> is <see langword="false"/>, this will be set to <paramRef name="text" /> in its normalized form; otherwise, this value will be set to <see langword="null"/>.</param>
            <param name="tokenCount">The token count can be generated which should be smaller than the maximum token count.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <returns>
            The index of the maximum encoding capacity within the processed text without surpassing the token limit.
            It represents the index immediately following the last character to be included. In cases where no tokens fit, the result will be 0; conversely,
            if all tokens fit, the result will be length of the input text or the <paramref name="normalizedText"/> if the normalization is enabled.
            </returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tokenizer.GetIndexByTokenCountFromEnd(System.String,System.Int32,System.String@,System.Int32@,System.Boolean,System.Boolean)">
            <summary>
            Find the index of the maximum encoding capacity without surpassing the token limit.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="maxTokenCount">The maximum number of tokens to encode.</param>
            <param name="normalizedText">If the tokenizer's normalization is enabled or <paramRef name="considerPreTokenization" /> is <see langword="false"/>, this will be set to <paramRef name="text" /> in its normalized form; otherwise, this value will be set to <see langword="null"/>.</param>
            <param name="tokenCount">The token count can be generated which should be smaller than the maximum token count.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <returns>
            The index of the maximum encoding capacity within the processed text without surpassing the token limit.
            It represents the index of the first character to be included. In cases where no tokens fit, the result will be the text length; conversely,
            if all tokens fit, the result will be zero.
            </returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tokenizer.GetIndexByTokenCountFromEnd(System.ReadOnlySpan{System.Char},System.Int32,System.String@,System.Int32@,System.Boolean,System.Boolean)">
            <summary>
            Find the index of the maximum encoding capacity without surpassing the token limit.
            </summary>
            <param name="text">The text to encode.</param>
            <param name="maxTokenCount">The maximum number of tokens to encode.</param>
            <param name="normalizedText">If the tokenizer's normalization is enabled or <paramRef name="considerPreTokenization" /> is <see langword="false"/>, this will be set to <paramRef name="text" /> in its normalized form; otherwise, this value will be set to <see langword="null"/>.</param>
            <param name="tokenCount">The token count can be generated which should be smaller than the maximum token count.</param>
            <param name="considerPreTokenization">Indicate whether to consider pre-tokenization before tokenization.</param>
            <param name="considerNormalization">Indicate whether to consider normalization before tokenization.</param>
            <returns>
            The index of the maximum encoding capacity within the processed text without surpassing the token limit.
            It represents the index of the first character to be included. In cases where no tokens fit, the result will be the text length; conversely,
            if all tokens fit, the result will be zero.
            </returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tokenizer.Decode(System.Collections.Generic.IEnumerable{System.Int32})">
            <summary>
            Decode the given ids, back to a String.
            </summary>
            <param name="ids">The list of ids that we want to decode.</param>
            <returns>The decoded string.</returns>
            <exception cref="T:System.ArgumentNullException"><paramref name="ids"/> is null.</exception>
            <exception cref="T:System.InvalidOperationException"><paramref name="ids"/> contains invalid data.</exception>
            <remarks>
            Types derived from <see cref="T:Microsoft.ML.Tokenizers.Tokenizer"/> may override this implementation to provide a more efficient implementation.
            By default, it uses <see cref="M:Microsoft.ML.Tokenizers.Tokenizer.Decode(System.Collections.Generic.IEnumerable{System.Int32},System.Span{System.Char},System.Int32@,System.Int32@)"/>.
            </remarks>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Tokenizer.Decode(System.Collections.Generic.IEnumerable{System.Int32},System.Span{System.Char},System.Int32@,System.Int32@)">
            <summary>
            Decode the given ids back to text and store the result in the <paramref name="destination"/> span.
            </summary>
            <param name="ids">The list of ids that we want to decode.</param>
            <param name="destination">The span to store the decoded text.</param>
            <param name="idsConsumed">The number of ids consumed during the decoding.</param>
            <param name="charsWritten">The number of characters written to the destination span.</param>
            <returns>The operation status indicates whether all IDs were successfully decoded or if the <paramref name="destination"/> is too small to contain the entire decoded result.</returns>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.BytePairEncoder">
            <summary>
            This class implements the byte pair encoding algorithm.
            </summary>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.ByteToUnicodeEncoding">
            <summary>
            Map between utf-8 byte to unicode with avoiding mapping to whitespace/control characters.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.Helpers.EncodeCodePointToUtf8(System.ReadOnlySpan{System.Char},System.Int32,System.Byte[]@,System.Int32@)">
            <summary>
            Encode the next code point in the text to UTF-8.
            </summary>
            <param name="text">The text to encode the first code point from.</param>
            <param name="textIndex">The index of the first code point to encode.</param>
            <param name="destination">The buffer to write the UTF-8 bytes to.</param>
            <param name="bytesIndex">The index in the buffer to write the UTF-8 encoded bytes to.</param>
            <returns>The number of characters consumed from the text.</returns>
        </member>
        <member name="F:Microsoft.ML.Tokenizers.LruCache`1.DefaultCacheSize">
            <summary>
            The default LRU cache size.
            </summary>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.LruCache`1.#ctor(System.Int32)">
            <summary>
            Constructs an <see cref="T:Microsoft.ML.Tokenizers.LruCache`1" /> object.
            </summary>
            <param name="cacheSize">
            The maximum number of mappings that can be cached. This defaults to <see cref="F:Microsoft.ML.Tokenizers.LruCache`1.DefaultCacheSize" />, which is set to <value>8192</value>.
            </param>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.LruCache`1.TryGetValue(System.String,`0@)">
            <summary>
            Retrieves the value associated with the specified key /> object.
            </summary>
            <param name="key">The object to be used as a key.</param>
            <param name="value">An out parameter that is set to the value of the key if key contains a mapping in the cache.</param>
            <returns>
            true if the cache contains a mapping for key, false otherwise.
            </returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.LruCache`1.TryGetValue(System.ReadOnlySpan{System.Char},`0@)">
            <summary>
            Retrieves the value associated with the specified key /> object.
            </summary>
            <param name="key">The object to be used as a key.</param>
            <param name="value">An out parameter that is set to the value of the key if key contains a mapping in the cache.</param>
            <returns>
            true if the cache contains a mapping for key, false otherwise.
            </returns>
        </member>
        <member name="M:Microsoft.ML.Tokenizers.LruCache`1.Add(System.String,`0)">
            <summary>
            Adds or replaces a mapping in the cache.
            </summary>
            <param name="key">The key whose mapped <paramref name="value" /> is to be created or replaced.</param>
            <param name="value">The new value to be mapped to the <paramref name="key" />.</param>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.StringSpanOrdinalKey">
            <summary>Used as a key in a dictionary to enable querying with either a string or a span.</summary>
            <remarks>
            This should only be used with a Ptr/Length for querying. For storing in a dictionary, this should
            always be used with a string.
            </remarks>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.StringSpanOrdinalKeyConverter">
            <summary>
            Custom JSON converter for <see cref="T:Microsoft.ML.Tokenizers.StringSpanOrdinalKey"/>.
            </summary>
        </member>
        <member name="T:Microsoft.ML.Tokenizers.StringSpanOrdinalKeyExtensions">
            <summary>
            Extension methods for <see cref="T:Microsoft.ML.Tokenizers.StringSpanOrdinalKey"/>.
            </summary>
        </member>
        <member name="T:Sentencepiece.SentencepieceModelReflection">
            <summary>Holder for reflection information generated from sentencepiece_model.proto</summary>
        </member>
        <member name="P:Sentencepiece.SentencepieceModelReflection.Descriptor">
            <summary>File descriptor for sentencepiece_model.proto</summary>
        </member>
        <member name="T:Sentencepiece.TrainerSpec">
            <summary>
            TrainerSpec encodes a various parameters for SentencePiece training.
            Next id: 55
            </summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.InputFieldNumber">
            <summary>Field number for the "input" field.</summary>
        </member>
        <!-- Badly formed XML comment ignored for member "P:Sentencepiece.TrainerSpec.Input" -->
        <member name="F:Sentencepiece.TrainerSpec.InputFormatFieldNumber">
            <summary>Field number for the "input_format" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.InputFormat">
            <summary>
            Input corpus format:
            "text": one-sentence-per-line text format (default)
            "tsv":  sentence &lt;tab> freq
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasInputFormat">
            <summary>Gets whether the "input_format" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearInputFormat">
            <summary>Clears the value of the "input_format" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.ModelPrefixFieldNumber">
            <summary>Field number for the "model_prefix" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.ModelPrefix">
            <summary>
            Output model file prefix.
            &lt;model_prefix>.model and &lt;model_prefix>.vocab are generated.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasModelPrefix">
            <summary>Gets whether the "model_prefix" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearModelPrefix">
            <summary>Clears the value of the "model_prefix" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.ModelTypeFieldNumber">
            <summary>Field number for the "model_type" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasModelType">
            <summary>Gets whether the "model_type" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearModelType">
            <summary>Clears the value of the "model_type" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.VocabSizeFieldNumber">
            <summary>Field number for the "vocab_size" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.VocabSize">
            <summary>
            Vocabulary size. 8k is the default size.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasVocabSize">
            <summary>Gets whether the "vocab_size" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearVocabSize">
            <summary>Clears the value of the "vocab_size" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.AcceptLanguageFieldNumber">
            <summary>Field number for the "accept_language" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.AcceptLanguage">
            <summary>
            List of the languages this model can accept.
            Since the model is language-agnostic, this field is used as a reference.
            </summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.SelfTestSampleSizeFieldNumber">
            <summary>Field number for the "self_test_sample_size" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.SelfTestSampleSize">
            <summary>
            Size of self-test samples, which are encoded in the model file.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasSelfTestSampleSize">
            <summary>Gets whether the "self_test_sample_size" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearSelfTestSampleSize">
            <summary>Clears the value of the "self_test_sample_size" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.EnableDifferentialPrivacyFieldNumber">
            <summary>Field number for the "enable_differential_privacy" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.EnableDifferentialPrivacy">
            <summary>
            Whether to use DP version of sentencepiece. Use it with TSV input format
            (requires precomputed word tab counts to work).
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasEnableDifferentialPrivacy">
            <summary>Gets whether the "enable_differential_privacy" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearEnableDifferentialPrivacy">
            <summary>Clears the value of the "enable_differential_privacy" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.DifferentialPrivacyNoiseLevelFieldNumber">
            <summary>Field number for the "differential_privacy_noise_level" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.DifferentialPrivacyNoiseLevel">
            <summary>
            Set these parameters if you need DP version of sentencepiece.
            std of noise to add.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasDifferentialPrivacyNoiseLevel">
            <summary>Gets whether the "differential_privacy_noise_level" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearDifferentialPrivacyNoiseLevel">
            <summary>Clears the value of the "differential_privacy_noise_level" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.DifferentialPrivacyClippingThresholdFieldNumber">
            <summary>Field number for the "differential_privacy_clipping_threshold" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.DifferentialPrivacyClippingThreshold">
            <summary>
            Clipping threshold to apply after adding noise. All the words with
            frequency less than this value are dropped.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasDifferentialPrivacyClippingThreshold">
            <summary>Gets whether the "differential_privacy_clipping_threshold" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearDifferentialPrivacyClippingThreshold">
            <summary>Clears the value of the "differential_privacy_clipping_threshold" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.CharacterCoverageFieldNumber">
            <summary>Field number for the "character_coverage" field.</summary>
        </member>
        <!-- Badly formed XML comment ignored for member "P:Sentencepiece.TrainerSpec.CharacterCoverage" -->
        <member name="P:Sentencepiece.TrainerSpec.HasCharacterCoverage">
            <summary>Gets whether the "character_coverage" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearCharacterCoverage">
            <summary>Clears the value of the "character_coverage" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.InputSentenceSizeFieldNumber">
            <summary>Field number for the "input_sentence_size" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.InputSentenceSize">
            <summary>
            Maximum size of sentences the trainer loads from `input` parameter.
            Trainer simply loads the `input` files in sequence.
            It is better to shuffle the input corpus randomly.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasInputSentenceSize">
            <summary>Gets whether the "input_sentence_size" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearInputSentenceSize">
            <summary>Clears the value of the "input_sentence_size" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.ShuffleInputSentenceFieldNumber">
            <summary>Field number for the "shuffle_input_sentence" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasShuffleInputSentence">
            <summary>Gets whether the "shuffle_input_sentence" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearShuffleInputSentence">
            <summary>Clears the value of the "shuffle_input_sentence" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.MiningSentenceSizeFieldNumber">
            <summary>Field number for the "mining_sentence_size" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.MiningSentenceSize">
            <summary>
            Maximum size of sentences to make seed sentence pieces.
            Extended suffix array is constructed to extract frequent
            sub-strings from the corpus. This uses 20N working space,
            where N is the size of corpus.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasMiningSentenceSize">
            <summary>Gets whether the "mining_sentence_size" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearMiningSentenceSize">
            <summary>Clears the value of the "mining_sentence_size" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.TrainingSentenceSizeFieldNumber">
            <summary>Field number for the "training_sentence_size" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.TrainingSentenceSize">
            <summary>
            Maximum size of sentences to train sentence pieces.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasTrainingSentenceSize">
            <summary>Gets whether the "training_sentence_size" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearTrainingSentenceSize">
            <summary>Clears the value of the "training_sentence_size" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.SeedSentencepieceSizeFieldNumber">
            <summary>Field number for the "seed_sentencepiece_size" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.SeedSentencepieceSize">
            <summary>
            The size of seed sentencepieces.
            `seed_sentencepiece_size` must be larger than `vocab_size`.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasSeedSentencepieceSize">
            <summary>Gets whether the "seed_sentencepiece_size" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearSeedSentencepieceSize">
            <summary>Clears the value of the "seed_sentencepiece_size" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.ShrinkingFactorFieldNumber">
            <summary>Field number for the "shrinking_factor" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.ShrinkingFactor">
            <summary>
            In every EM sub-iterations, keeps top
            `shrinking_factor` * `current sentencepieces size` with respect to
            the loss of the sentence piece. This value should be smaller than 1.0.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasShrinkingFactor">
            <summary>Gets whether the "shrinking_factor" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearShrinkingFactor">
            <summary>Clears the value of the "shrinking_factor" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.MaxSentenceLengthFieldNumber">
            <summary>Field number for the "max_sentence_length" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.MaxSentenceLength">
            <summary>
            The maximum sentence length in byte. The sentences with the length
            larger than `max_sentence_length` is simply ignored.
            Longer input tends to bring the following risks:
             * Overflow during EM training (unigram language model only)
             * Performance drop because of O(n log n) cost in BPE.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasMaxSentenceLength">
            <summary>Gets whether the "max_sentence_length" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearMaxSentenceLength">
            <summary>Clears the value of the "max_sentence_length" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.NumThreadsFieldNumber">
            <summary>Field number for the "num_threads" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.NumThreads">
            <summary>
            Number of threads in the training.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasNumThreads">
            <summary>Gets whether the "num_threads" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearNumThreads">
            <summary>Clears the value of the "num_threads" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.NumSubIterationsFieldNumber">
            <summary>Field number for the "num_sub_iterations" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.NumSubIterations">
            <summary>
            Number of EM sub iterations.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasNumSubIterations">
            <summary>Gets whether the "num_sub_iterations" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearNumSubIterations">
            <summary>Clears the value of the "num_sub_iterations" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.MaxSentencepieceLengthFieldNumber">
            <summary>Field number for the "max_sentencepiece_length" field.</summary>
        </member>
        <!-- Badly formed XML comment ignored for member "P:Sentencepiece.TrainerSpec.MaxSentencepieceLength" -->
        <member name="P:Sentencepiece.TrainerSpec.HasMaxSentencepieceLength">
            <summary>Gets whether the "max_sentencepiece_length" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearMaxSentencepieceLength">
            <summary>Clears the value of the "max_sentencepiece_length" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.SplitByUnicodeScriptFieldNumber">
            <summary>Field number for the "split_by_unicode_script" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.SplitByUnicodeScript">
            <summary>
            Uses Unicode script to split sentence pieces.
            When `split_by_unicode_script` is true, we do not allow sentence piece to
            include multiple Unicode scripts, e.g. "F1" is not a valid piece.
            Exception: CJ characters (Hiragana/Katakana/Han) are all handled
            as one script type, since Japanese word can consist of multiple scripts.
            This exception is always applied regardless of the accept-language
            parameter.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasSplitByUnicodeScript">
            <summary>Gets whether the "split_by_unicode_script" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearSplitByUnicodeScript">
            <summary>Clears the value of the "split_by_unicode_script" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.SplitByNumberFieldNumber">
            <summary>Field number for the "split_by_number" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.SplitByNumber">
            <summary>
            When `split_by_number` is true, put a boundary between number and
            non-number transition. If we want to treat "F1" is one token, set this flag
            to be false.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasSplitByNumber">
            <summary>Gets whether the "split_by_number" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearSplitByNumber">
            <summary>Clears the value of the "split_by_number" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.SplitByWhitespaceFieldNumber">
            <summary>Field number for the "split_by_whitespace" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.SplitByWhitespace">
            <summary>
            Use a white space to split sentence pieces.
            When `split_by_whitespace` is false, we may have the piece containing
            a white space in the middle. e.g., "in_the".
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasSplitByWhitespace">
            <summary>Gets whether the "split_by_whitespace" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearSplitByWhitespace">
            <summary>Clears the value of the "split_by_whitespace" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.TreatWhitespaceAsSuffixFieldNumber">
            <summary>Field number for the "treat_whitespace_as_suffix" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.TreatWhitespaceAsSuffix">
            <summary>
            Adds whitespace symbol (_) as a suffix instead of prefix. e.g., _hello =>
            hello_. When `treat_whitespace_as_suffix` is true,
            NormalizerSpec::add_dummy_prefix will add the dummy whitespace to the end
            of sentence.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasTreatWhitespaceAsSuffix">
            <summary>Gets whether the "treat_whitespace_as_suffix" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearTreatWhitespaceAsSuffix">
            <summary>Clears the value of the "treat_whitespace_as_suffix" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.AllowWhitespaceOnlyPiecesFieldNumber">
            <summary>Field number for the "allow_whitespace_only_pieces" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.AllowWhitespaceOnlyPieces">
            <summary>
            Allows pieces that only contain whitespaces instead of appearing only as
            prefix or suffix of other pieces.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasAllowWhitespaceOnlyPieces">
            <summary>Gets whether the "allow_whitespace_only_pieces" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearAllowWhitespaceOnlyPieces">
            <summary>Clears the value of the "allow_whitespace_only_pieces" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.SplitDigitsFieldNumber">
            <summary>Field number for the "split_digits" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.SplitDigits">
            <summary>
            Split all digits (0-9) into separate pieces.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasSplitDigits">
            <summary>Gets whether the "split_digits" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearSplitDigits">
            <summary>Clears the value of the "split_digits" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.PretokenizationDelimiterFieldNumber">
            <summary>Field number for the "pretokenization_delimiter" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.PretokenizationDelimiter">
            <summary>
            Defines the pre-tokenization delimiter.
            When specified, no pieces crossing this delimiter is not included
            in the vocab. Then the delimiter string is virtually ignored
            during the training. This field can allows constraints on the vocabulary
            selection. Note that this field is available on unigram mode.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasPretokenizationDelimiter">
            <summary>Gets whether the "pretokenization_delimiter" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearPretokenizationDelimiter">
            <summary>Clears the value of the "pretokenization_delimiter" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.ControlSymbolsFieldNumber">
            <summary>Field number for the "control_symbols" field.</summary>
        </member>
        <!-- Badly formed XML comment ignored for member "P:Sentencepiece.TrainerSpec.ControlSymbols" -->
        <member name="F:Sentencepiece.TrainerSpec.UserDefinedSymbolsFieldNumber">
            <summary>Field number for the "user_defined_symbols" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.UserDefinedSymbols">
            <summary>
            Defines user defined symbols.
            These symbols are added with extremely high score
            so they are always treated as one unique symbol in any context.
            Typical usage of user_defined_symbols is placeholder for named entities.
            </summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.RequiredCharsFieldNumber">
            <summary>Field number for the "required_chars" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.RequiredChars">
            <summary>
            Defines required characters. Each UTF8 character in this string is included
            in the character set regardless of character_coverage value. Unlike
            user_defined_symbols, these characters have scores based on the frequency
            on input sentences, and the model can form subwords using characters
            in this field.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasRequiredChars">
            <summary>Gets whether the "required_chars" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearRequiredChars">
            <summary>Clears the value of the "required_chars" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.ByteFallbackFieldNumber">
            <summary>Field number for the "byte_fallback" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.ByteFallback">
            <summary>
            Decomposes unknown pieces into UTF-8 bytes.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasByteFallback">
            <summary>Gets whether the "byte_fallback" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearByteFallback">
            <summary>Clears the value of the "byte_fallback" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.VocabularyOutputPieceScoreFieldNumber">
            <summary>Field number for the "vocabulary_output_piece_score" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.VocabularyOutputPieceScore">
            <summary>
            When creating the vocabulary file, defines whether or not to additionally
            output the score for each piece.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasVocabularyOutputPieceScore">
            <summary>Gets whether the "vocabulary_output_piece_score" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearVocabularyOutputPieceScore">
            <summary>Clears the value of the "vocabulary_output_piece_score" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.HardVocabLimitFieldNumber">
            <summary>Field number for the "hard_vocab_limit" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HardVocabLimit">
            <summary>
            `vocab_size` is treated as hard limit. Crash if
            the model can not produce the vocab of size `vocab_size`,
            When `hard_vocab_limit` is false, vocab_size is treated
            as soft limit. Note that when model_type=char,
            always assumes hard_vocab_limit = false.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasHardVocabLimit">
            <summary>Gets whether the "hard_vocab_limit" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearHardVocabLimit">
            <summary>Clears the value of the "hard_vocab_limit" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.UseAllVocabFieldNumber">
            <summary>Field number for the "use_all_vocab" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.UseAllVocab">
            <summary>
            use all symbols for vocab extraction. This flag is valid
            if model type is either CHAR or WORD
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasUseAllVocab">
            <summary>Gets whether the "use_all_vocab" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearUseAllVocab">
            <summary>Clears the value of the "use_all_vocab" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.UnkIdFieldNumber">
            <summary>Field number for the "unk_id" field.</summary>
        </member>
        <!-- Badly formed XML comment ignored for member "P:Sentencepiece.TrainerSpec.UnkId" -->
        <member name="P:Sentencepiece.TrainerSpec.HasUnkId">
            <summary>Gets whether the "unk_id" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearUnkId">
            <summary>Clears the value of the "unk_id" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.BosIdFieldNumber">
            <summary>Field number for the "bos_id" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.BosId">
            <summary>
            &lt;s>
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasBosId">
            <summary>Gets whether the "bos_id" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearBosId">
            <summary>Clears the value of the "bos_id" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.EosIdFieldNumber">
            <summary>Field number for the "eos_id" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.EosId">
            <summary>
            &lt;/s>
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasEosId">
            <summary>Gets whether the "eos_id" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearEosId">
            <summary>Clears the value of the "eos_id" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.PadIdFieldNumber">
            <summary>Field number for the "pad_id" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.PadId">
            <summary>
            &lt;pad> (padding)
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasPadId">
            <summary>Gets whether the "pad_id" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearPadId">
            <summary>Clears the value of the "pad_id" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.UnkPieceFieldNumber">
            <summary>Field number for the "unk_piece" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasUnkPiece">
            <summary>Gets whether the "unk_piece" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearUnkPiece">
            <summary>Clears the value of the "unk_piece" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.BosPieceFieldNumber">
            <summary>Field number for the "bos_piece" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasBosPiece">
            <summary>Gets whether the "bos_piece" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearBosPiece">
            <summary>Clears the value of the "bos_piece" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.EosPieceFieldNumber">
            <summary>Field number for the "eos_piece" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasEosPiece">
            <summary>Gets whether the "eos_piece" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearEosPiece">
            <summary>Clears the value of the "eos_piece" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.PadPieceFieldNumber">
            <summary>Field number for the "pad_piece" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasPadPiece">
            <summary>Gets whether the "pad_piece" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearPadPiece">
            <summary>Clears the value of the "pad_piece" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.UnkSurfaceFieldNumber">
            <summary>Field number for the "unk_surface" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.UnkSurface">
            <summary>
            Encodes &lt;unk> into U+2047 (DOUBLE QUESTION MARK),
            since this character can be useful both for user and
            developer. We can easily figure out that &lt;unk> is emitted.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasUnkSurface">
            <summary>Gets whether the "unk_surface" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearUnkSurface">
            <summary>Clears the value of the "unk_surface" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.TrainExtremelyLargeCorpusFieldNumber">
            <summary>Field number for the "train_extremely_large_corpus" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.TrainExtremelyLargeCorpus">
            <summary>
            Increase bit depth to allow unigram model training on large
            (>10M sentences) corpora. A Side-effect of enabling this flag
            is increased memory usage.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasTrainExtremelyLargeCorpus">
            <summary>Gets whether the "train_extremely_large_corpus" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearTrainExtremelyLargeCorpus">
            <summary>Clears the value of the "train_extremely_large_corpus" field</summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.SeedSentencepiecesFileFieldNumber">
            <summary>Field number for the "seed_sentencepieces_file" field.</summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.SeedSentencepiecesFile">
            <summary>
            Path to a seed sentencepieces file, with one tab-separated
            seed sentencepiece &lt;tab> frequency per line.
            </summary>
        </member>
        <member name="P:Sentencepiece.TrainerSpec.HasSeedSentencepiecesFile">
            <summary>Gets whether the "seed_sentencepieces_file" field is set</summary>
        </member>
        <member name="M:Sentencepiece.TrainerSpec.ClearSeedSentencepiecesFile">
            <summary>Clears the value of the "seed_sentencepieces_file" field</summary>
        </member>
        <member name="T:Sentencepiece.TrainerSpec.Types">
            <summary>Container for nested types declared in the TrainerSpec message type.</summary>
        </member>
        <member name="T:Sentencepiece.TrainerSpec.Types.ModelType">
            <summary>
            Model type. only have UNIGRAM now.
            </summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.Types.ModelType.Unigram">
            <summary>
            Unigram language model with dynamic algorithm
            </summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.Types.ModelType.Bpe">
            <summary>
            Byte Pair Encoding
            </summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.Types.ModelType.Word">
            <summary>
            Delimitered by whitespace.
            </summary>
        </member>
        <member name="F:Sentencepiece.TrainerSpec.Types.ModelType.Char">
            <summary>
            tokenizes into character sequence
            </summary>
        </member>
        <member name="T:Sentencepiece.NormalizerSpec">
            <summary>
            NormalizerSpec encodes a various parameters for string normalization
            </summary>
        </member>
        <member name="F:Sentencepiece.NormalizerSpec.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="P:Sentencepiece.NormalizerSpec.Name">
            <summary>
            name of normalization rule.
            </summary>
        </member>
        <member name="P:Sentencepiece.NormalizerSpec.HasName">
            <summary>Gets whether the "name" field is set</summary>
        </member>
        <member name="M:Sentencepiece.NormalizerSpec.ClearName">
            <summary>Clears the value of the "name" field</summary>
        </member>
        <member name="F:Sentencepiece.NormalizerSpec.PrecompiledCharsmapFieldNumber">
            <summary>Field number for the "precompiled_charsmap" field.</summary>
        </member>
        <member name="P:Sentencepiece.NormalizerSpec.PrecompiledCharsmap">
            <summary>
            Pre-compiled normalization rule created by
            Builder::GetPrecompiledCharsMap() or Builder::CompileCharsMap() method.
            Usually this field is set by Builder::GetNormalizerSpec() method.
            </summary>
        </member>
        <member name="P:Sentencepiece.NormalizerSpec.HasPrecompiledCharsmap">
            <summary>Gets whether the "precompiled_charsmap" field is set</summary>
        </member>
        <member name="M:Sentencepiece.NormalizerSpec.ClearPrecompiledCharsmap">
            <summary>Clears the value of the "precompiled_charsmap" field</summary>
        </member>
        <member name="F:Sentencepiece.NormalizerSpec.AddDummyPrefixFieldNumber">
            <summary>Field number for the "add_dummy_prefix" field.</summary>
        </member>
        <member name="P:Sentencepiece.NormalizerSpec.AddDummyPrefix">
            <summary>
            Adds dummy whitespace at the beginning of text in order to
            treat "world" in "world" and "hello world" in the same way.
            </summary>
        </member>
        <member name="P:Sentencepiece.NormalizerSpec.HasAddDummyPrefix">
            <summary>Gets whether the "add_dummy_prefix" field is set</summary>
        </member>
        <member name="M:Sentencepiece.NormalizerSpec.ClearAddDummyPrefix">
            <summary>Clears the value of the "add_dummy_prefix" field</summary>
        </member>
        <member name="F:Sentencepiece.NormalizerSpec.RemoveExtraWhitespacesFieldNumber">
            <summary>Field number for the "remove_extra_whitespaces" field.</summary>
        </member>
        <member name="P:Sentencepiece.NormalizerSpec.RemoveExtraWhitespaces">
            <summary>
            Removes leading, trailing, and duplicate internal whitespace.
            </summary>
        </member>
        <member name="P:Sentencepiece.NormalizerSpec.HasRemoveExtraWhitespaces">
            <summary>Gets whether the "remove_extra_whitespaces" field is set</summary>
        </member>
        <member name="M:Sentencepiece.NormalizerSpec.ClearRemoveExtraWhitespaces">
            <summary>Clears the value of the "remove_extra_whitespaces" field</summary>
        </member>
        <member name="F:Sentencepiece.NormalizerSpec.EscapeWhitespacesFieldNumber">
            <summary>Field number for the "escape_whitespaces" field.</summary>
        </member>
        <member name="P:Sentencepiece.NormalizerSpec.EscapeWhitespaces">
            <summary>
            Replaces whitespace with meta symbol.
            This field must be true to train sentence piece model.
            </summary>
        </member>
        <member name="P:Sentencepiece.NormalizerSpec.HasEscapeWhitespaces">
            <summary>Gets whether the "escape_whitespaces" field is set</summary>
        </member>
        <member name="M:Sentencepiece.NormalizerSpec.ClearEscapeWhitespaces">
            <summary>Clears the value of the "escape_whitespaces" field</summary>
        </member>
        <member name="F:Sentencepiece.NormalizerSpec.NormalizationRuleTsvFieldNumber">
            <summary>Field number for the "normalization_rule_tsv" field.</summary>
        </member>
        <member name="P:Sentencepiece.NormalizerSpec.NormalizationRuleTsv">
            <summary>
            Custom normalization rule file in TSV format.
            https://github.com/google/sentencepiece/blob/master/doc/normalization.md
            This field is only used in SentencePieceTrainer::Train() method, which
            compiles the rule into the binary rule stored in `precompiled_charsmap`.
            </summary>
        </member>
        <member name="P:Sentencepiece.NormalizerSpec.HasNormalizationRuleTsv">
            <summary>Gets whether the "normalization_rule_tsv" field is set</summary>
        </member>
        <member name="M:Sentencepiece.NormalizerSpec.ClearNormalizationRuleTsv">
            <summary>Clears the value of the "normalization_rule_tsv" field</summary>
        </member>
        <member name="T:Sentencepiece.SelfTestData">
            <summary>
            Proto to store samples for self-testing.
            </summary>
        </member>
        <member name="F:Sentencepiece.SelfTestData.SamplesFieldNumber">
            <summary>Field number for the "samples" field.</summary>
        </member>
        <member name="T:Sentencepiece.SelfTestData.Types">
            <summary>Container for nested types declared in the SelfTestData message type.</summary>
        </member>
        <member name="F:Sentencepiece.SelfTestData.Types.Sample.InputFieldNumber">
            <summary>Field number for the "input" field.</summary>
        </member>
        <member name="P:Sentencepiece.SelfTestData.Types.Sample.HasInput">
            <summary>Gets whether the "input" field is set</summary>
        </member>
        <member name="M:Sentencepiece.SelfTestData.Types.Sample.ClearInput">
            <summary>Clears the value of the "input" field</summary>
        </member>
        <member name="F:Sentencepiece.SelfTestData.Types.Sample.ExpectedFieldNumber">
            <summary>Field number for the "expected" field.</summary>
        </member>
        <member name="P:Sentencepiece.SelfTestData.Types.Sample.HasExpected">
            <summary>Gets whether the "expected" field is set</summary>
        </member>
        <member name="M:Sentencepiece.SelfTestData.Types.Sample.ClearExpected">
            <summary>Clears the value of the "expected" field</summary>
        </member>
        <member name="T:Sentencepiece.ModelProto">
            <summary>
            ModelProto stores model parameters.
            SentencePieceProcessor is supposed to be self-contained.
            All settings/parameters which may change the behavior must be encoded
            in ModelProto.
            </summary>
        </member>
        <member name="F:Sentencepiece.ModelProto.PiecesFieldNumber">
            <summary>Field number for the "pieces" field.</summary>
        </member>
        <member name="P:Sentencepiece.ModelProto.Pieces">
            <summary>
            Sentence pieces with scores.
            </summary>
        </member>
        <member name="F:Sentencepiece.ModelProto.TrainerSpecFieldNumber">
            <summary>Field number for the "trainer_spec" field.</summary>
        </member>
        <member name="P:Sentencepiece.ModelProto.TrainerSpec">
            <summary>
            Spec used to generate this model file.
            </summary>
        </member>
        <member name="F:Sentencepiece.ModelProto.NormalizerSpecFieldNumber">
            <summary>Field number for the "normalizer_spec" field.</summary>
        </member>
        <member name="P:Sentencepiece.ModelProto.NormalizerSpec">
            <summary>
            Spec for text normalization.
            </summary>
        </member>
        <member name="F:Sentencepiece.ModelProto.SelfTestDataFieldNumber">
            <summary>Field number for the "self_test_data" field.</summary>
        </member>
        <member name="P:Sentencepiece.ModelProto.SelfTestData">
            <summary>
            Stores sample input and its expected segmentation to verify the model.
            </summary>
        </member>
        <member name="F:Sentencepiece.ModelProto.DenormalizerSpecFieldNumber">
            <summary>Field number for the "denormalizer_spec" field.</summary>
        </member>
        <member name="P:Sentencepiece.ModelProto.DenormalizerSpec">
            <summary>
            Spec for text de-normalization.
            </summary>
        </member>
        <member name="T:Sentencepiece.ModelProto.Types">
            <summary>Container for nested types declared in the ModelProto message type.</summary>
        </member>
        <member name="F:Sentencepiece.ModelProto.Types.SentencePiece.PieceFieldNumber">
            <summary>Field number for the "piece" field.</summary>
        </member>
        <member name="P:Sentencepiece.ModelProto.Types.SentencePiece.Piece">
            <summary>
            piece must not be empty.
            </summary>
        </member>
        <member name="P:Sentencepiece.ModelProto.Types.SentencePiece.HasPiece">
            <summary>Gets whether the "piece" field is set</summary>
        </member>
        <member name="M:Sentencepiece.ModelProto.Types.SentencePiece.ClearPiece">
            <summary>Clears the value of the "piece" field</summary>
        </member>
        <member name="F:Sentencepiece.ModelProto.Types.SentencePiece.ScoreFieldNumber">
            <summary>Field number for the "score" field.</summary>
        </member>
        <member name="P:Sentencepiece.ModelProto.Types.SentencePiece.HasScore">
            <summary>Gets whether the "score" field is set</summary>
        </member>
        <member name="M:Sentencepiece.ModelProto.Types.SentencePiece.ClearScore">
            <summary>Clears the value of the "score" field</summary>
        </member>
        <member name="F:Sentencepiece.ModelProto.Types.SentencePiece.TypeFieldNumber">
            <summary>Field number for the "type" field.</summary>
        </member>
        <member name="P:Sentencepiece.ModelProto.Types.SentencePiece.HasType">
            <summary>Gets whether the "type" field is set</summary>
        </member>
        <member name="M:Sentencepiece.ModelProto.Types.SentencePiece.ClearType">
            <summary>Clears the value of the "type" field</summary>
        </member>
        <member name="T:Sentencepiece.ModelProto.Types.SentencePiece.Types">
            <summary>Container for nested types declared in the SentencePiece message type.</summary>
        </member>
        <member name="F:Sentencepiece.ModelProto.Types.SentencePiece.Types.Type.Normal">
            <summary>
            normal symbol
            </summary>
        </member>
        <member name="F:Sentencepiece.ModelProto.Types.SentencePiece.Types.Type.Unknown">
            <summary>
            unknown symbol. only &lt;unk> for now.
            </summary>
        </member>
        <member name="F:Sentencepiece.ModelProto.Types.SentencePiece.Types.Type.Control">
            <summary>
            control symbols. &lt;/s>, &lt;s>, &lt;2ja> etc.
            </summary>
        </member>
        <member name="F:Sentencepiece.ModelProto.Types.SentencePiece.Types.Type.UserDefined">
            <summary>
            user defined symbols.
            </summary>
        </member>
        <member name="F:Sentencepiece.ModelProto.Types.SentencePiece.Types.Type.Byte">
            <summary>
            Typical usage of USER_DEFINED symbol
            is placeholder.
            </summary>
        </member>
        <member name="F:Sentencepiece.ModelProto.Types.SentencePiece.Types.Type.Unused">
            <summary>
            this piece is not used.
            </summary>
        </member>
        <member name="M:System.Text.ValueStringBuilder.GetPinnableReference">
            <summary>
            Get a pinnable reference to the builder.
            Does not ensure there is a null char after <see cref="P:System.Text.ValueStringBuilder.Length"/>
            This overload is pattern matched in the C# 7.3+ compiler so you can omit
            the explicit method call, and write eg "fixed (char* c = builder)"
            </summary>
        </member>
        <member name="M:System.Text.ValueStringBuilder.GetPinnableReference(System.Boolean)">
            <summary>
            Get a pinnable reference to the builder.
            </summary>
            <param name="terminate">Ensures that the builder has a null char after <see cref="P:System.Text.ValueStringBuilder.Length"/></param>
        </member>
        <member name="P:System.Text.ValueStringBuilder.RawChars">
            <summary>Returns the underlying storage of the builder.</summary>
        </member>
        <member name="M:System.Text.ValueStringBuilder.AsSpan(System.Boolean)">
            <summary>
            Returns a span around the contents of the builder.
            </summary>
            <param name="terminate">Ensures that the builder has a null char after <see cref="P:System.Text.ValueStringBuilder.Length"/></param>
        </member>
        <member name="M:System.Text.ValueStringBuilder.RemoveLastChar">
            <summary>
            Remove last character in the builder.
            </summary>
        </member>
        <member name="M:System.Text.ValueStringBuilder.Grow(System.Int32)">
            <summary>
            Resize the internal buffer either by doubling current buffer size or
            by adding <paramref name="additionalCapacityBeyondPos"/> to
            <see cref="F:System.Text.ValueStringBuilder._pos"/> whichever is greater.
            </summary>
            <param name="additionalCapacityBeyondPos">
            Number of chars requested beyond current position.
            </param>
        </member>
        <member name="T:System.Text.RegularExpressions.Generated.Cl100kBaseRegex_0">
            <summary>Custom <see cref="T:System.Text.RegularExpressions.Regex"/>-derived type for the Cl100kBaseRegex method.</summary>
        </member>
        <member name="F:System.Text.RegularExpressions.Generated.Cl100kBaseRegex_0.Instance">
            <summary>Cached, thread-safe singleton instance.</summary>
        </member>
        <member name="M:System.Text.RegularExpressions.Generated.Cl100kBaseRegex_0.#ctor">
            <summary>Initializes the instance.</summary>
        </member>
        <member name="T:System.Text.RegularExpressions.Generated.Cl100kBaseRegex_0.RunnerFactory">
            <summary>Provides a factory for creating <see cref="T:System.Text.RegularExpressions.RegexRunner"/> instances to be used by methods on <see cref="T:System.Text.RegularExpressions.Regex"/>.</summary>
        </member>
        <member name="M:System.Text.RegularExpressions.Generated.Cl100kBaseRegex_0.RunnerFactory.CreateInstance">
            <summary>Creates an instance of a <see cref="T:System.Text.RegularExpressions.RegexRunner"/> used by methods on <see cref="T:System.Text.RegularExpressions.Regex"/>.</summary>
        </member>
        <member name="T:System.Text.RegularExpressions.Generated.Cl100kBaseRegex_0.RunnerFactory.Runner">
            <summary>Provides the runner that contains the custom logic implementing the specified regular expression.</summary>
        </member>
        <member name="M:System.Text.RegularExpressions.Generated.Cl100kBaseRegex_0.RunnerFactory.Runner.Scan(System.ReadOnlySpan{System.Char})">
            <summary>Scan the <paramref name="inputSpan"/> starting from base.runtextstart for the next match.</summary>
            <param name="inputSpan">The text being scanned by the regular expression.</param>
        </member>
        <member name="M:System.Text.RegularExpressions.Generated.Cl100kBaseRegex_0.RunnerFactory.Runner.TryFindNextPossibleStartingPosition(System.ReadOnlySpan{System.Char})">
            <summary>Search <paramref name="inputSpan"/> starting from base.runtextpos for the next location a match could possibly start.</summary>
            <param name="inputSpan">The text being scanned by the regular expression.</param>
            <returns>true if a possible match was found; false if no more matches are possible.</returns>
        </member>
        <member name="M:System.Text.RegularExpressions.Generated.Cl100kBaseRegex_0.RunnerFactory.Runner.TryMatchAtCurrentPosition(System.ReadOnlySpan{System.Char})">
            <summary>Determine whether <paramref name="inputSpan"/> at base.runtextpos is a match for the regular expression.</summary>
            <param name="inputSpan">The text being scanned by the regular expression.</param>
            <returns>true if the regular expression matches at the current position; otherwise, false.</returns>
        </member>
        <member name="T:System.Text.RegularExpressions.Generated.P50kBaseRegex_1">
            <summary>Custom <see cref="T:System.Text.RegularExpressions.Regex"/>-derived type for the P50kBaseRegex method.</summary>
        </member>
        <member name="F:System.Text.RegularExpressions.Generated.P50kBaseRegex_1.Instance">
            <summary>Cached, thread-safe singleton instance.</summary>
        </member>
        <member name="M:System.Text.RegularExpressions.Generated.P50kBaseRegex_1.#ctor">
            <summary>Initializes the instance.</summary>
        </member>
        <member name="T:System.Text.RegularExpressions.Generated.P50kBaseRegex_1.RunnerFactory">
            <summary>Provides a factory for creating <see cref="T:System.Text.RegularExpressions.RegexRunner"/> instances to be used by methods on <see cref="T:System.Text.RegularExpressions.Regex"/>.</summary>
        </member>
        <member name="M:System.Text.RegularExpressions.Generated.P50kBaseRegex_1.RunnerFactory.CreateInstance">
            <summary>Creates an instance of a <see cref="T:System.Text.RegularExpressions.RegexRunner"/> used by methods on <see cref="T:System.Text.RegularExpressions.Regex"/>.</summary>
        </member>
        <member name="T:System.Text.RegularExpressions.Generated.P50kBaseRegex_1.RunnerFactory.Runner">
            <summary>Provides the runner that contains the custom logic implementing the specified regular expression.</summary>
        </member>
        <member name="M:System.Text.RegularExpressions.Generated.P50kBaseRegex_1.RunnerFactory.Runner.Scan(System.ReadOnlySpan{System.Char})">
            <summary>Scan the <paramref name="inputSpan"/> starting from base.runtextstart for the next match.</summary>
            <param name="inputSpan">The text being scanned by the regular expression.</param>
        </member>
        <member name="M:System.Text.RegularExpressions.Generated.P50kBaseRegex_1.RunnerFactory.Runner.TryFindNextPossibleStartingPosition(System.ReadOnlySpan{System.Char})">
            <summary>Search <paramref name="inputSpan"/> starting from base.runtextpos for the next location a match could possibly start.</summary>
            <param name="inputSpan">The text being scanned by the regular expression.</param>
            <returns>true if a possible match was found; false if no more matches are possible.</returns>
        </member>
        <member name="M:System.Text.RegularExpressions.Generated.P50kBaseRegex_1.RunnerFactory.Runner.TryMatchAtCurrentPosition(System.ReadOnlySpan{System.Char})">
            <summary>Determine whether <paramref name="inputSpan"/> at base.runtextpos is a match for the regular expression.</summary>
            <param name="inputSpan">The text being scanned by the regular expression.</param>
            <returns>true if the regular expression matches at the current position; otherwise, false.</returns>
        </member>
        <member name="T:System.Text.RegularExpressions.Generated.O200kBaseRegex_2">
            <summary>Custom <see cref="T:System.Text.RegularExpressions.Regex"/>-derived type for the O200kBaseRegex method.</summary>
        </member>
        <member name="F:System.Text.RegularExpressions.Generated.O200kBaseRegex_2.Instance">
            <summary>Cached, thread-safe singleton instance.</summary>
        </member>
        <member name="M:System.Text.RegularExpressions.Generated.O200kBaseRegex_2.#ctor">
            <summary>Initializes the instance.</summary>
        </member>
        <member name="T:System.Text.RegularExpressions.Generated.O200kBaseRegex_2.RunnerFactory">
            <summary>Provides a factory for creating <see cref="T:System.Text.RegularExpressions.RegexRunner"/> instances to be used by methods on <see cref="T:System.Text.RegularExpressions.Regex"/>.</summary>
        </member>
        <member name="M:System.Text.RegularExpressions.Generated.O200kBaseRegex_2.RunnerFactory.CreateInstance">
            <summary>Creates an instance of a <see cref="T:System.Text.RegularExpressions.RegexRunner"/> used by methods on <see cref="T:System.Text.RegularExpressions.Regex"/>.</summary>
        </member>
        <member name="T:System.Text.RegularExpressions.Generated.O200kBaseRegex_2.RunnerFactory.Runner">
            <summary>Provides the runner that contains the custom logic implementing the specified regular expression.</summary>
        </member>
        <member name="M:System.Text.RegularExpressions.Generated.O200kBaseRegex_2.RunnerFactory.Runner.Scan(System.ReadOnlySpan{System.Char})">
            <summary>Scan the <paramref name="inputSpan"/> starting from base.runtextstart for the next match.</summary>
            <param name="inputSpan">The text being scanned by the regular expression.</param>
        </member>
        <member name="M:System.Text.RegularExpressions.Generated.O200kBaseRegex_2.RunnerFactory.Runner.TryFindNextPossibleStartingPosition(System.ReadOnlySpan{System.Char})">
            <summary>Search <paramref name="inputSpan"/> starting from base.runtextpos for the next location a match could possibly start.</summary>
            <param name="inputSpan">The text being scanned by the regular expression.</param>
            <returns>true if a possible match was found; false if no more matches are possible.</returns>
        </member>
        <member name="M:System.Text.RegularExpressions.Generated.O200kBaseRegex_2.RunnerFactory.Runner.TryMatchAtCurrentPosition(System.ReadOnlySpan{System.Char})">
            <summary>Determine whether <paramref name="inputSpan"/> at base.runtextpos is a match for the regular expression.</summary>
            <param name="inputSpan">The text being scanned by the regular expression.</param>
            <returns>true if the regular expression matches at the current position; otherwise, false.</returns>
        </member>
        <member name="T:System.Text.RegularExpressions.Generated.WhiteSpaceOrPunctuationRegex_3">
            <summary>Custom <see cref="T:System.Text.RegularExpressions.Regex"/>-derived type for the WhiteSpaceOrPunctuationRegex method.</summary>
        </member>
        <member name="F:System.Text.RegularExpressions.Generated.WhiteSpaceOrPunctuationRegex_3.Instance">
            <summary>Cached, thread-safe singleton instance.</summary>
        </member>
        <member name="M:System.Text.RegularExpressions.Generated.WhiteSpaceOrPunctuationRegex_3.#ctor">
            <summary>Initializes the instance.</summary>
        </member>
        <member name="T:System.Text.RegularExpressions.Generated.WhiteSpaceOrPunctuationRegex_3.RunnerFactory">
            <summary>Provides a factory for creating <see cref="T:System.Text.RegularExpressions.RegexRunner"/> instances to be used by methods on <see cref="T:System.Text.RegularExpressions.Regex"/>.</summary>
        </member>
        <member name="M:System.Text.RegularExpressions.Generated.WhiteSpaceOrPunctuationRegex_3.RunnerFactory.CreateInstance">
            <summary>Creates an instance of a <see cref="T:System.Text.RegularExpressions.RegexRunner"/> used by methods on <see cref="T:System.Text.RegularExpressions.Regex"/>.</summary>
        </member>
        <member name="T:System.Text.RegularExpressions.Generated.WhiteSpaceOrPunctuationRegex_3.RunnerFactory.Runner">
            <summary>Provides the runner that contains the custom logic implementing the specified regular expression.</summary>
        </member>
        <member name="M:System.Text.RegularExpressions.Generated.WhiteSpaceOrPunctuationRegex_3.RunnerFactory.Runner.Scan(System.ReadOnlySpan{System.Char})">
            <summary>Scan the <paramref name="inputSpan"/> starting from base.runtextstart for the next match.</summary>
            <param name="inputSpan">The text being scanned by the regular expression.</param>
        </member>
        <member name="M:System.Text.RegularExpressions.Generated.WhiteSpaceOrPunctuationRegex_3.RunnerFactory.Runner.TryFindNextPossibleStartingPosition(System.ReadOnlySpan{System.Char})">
            <summary>Search <paramref name="inputSpan"/> starting from base.runtextpos for the next location a match could possibly start.</summary>
            <param name="inputSpan">The text being scanned by the regular expression.</param>
            <returns>true if a possible match was found; false if no more matches are possible.</returns>
        </member>
        <member name="M:System.Text.RegularExpressions.Generated.WhiteSpaceOrPunctuationRegex_3.RunnerFactory.Runner.TryMatchAtCurrentPosition(System.ReadOnlySpan{System.Char})">
            <summary>Determine whether <paramref name="inputSpan"/> at base.runtextpos is a match for the regular expression.</summary>
            <param name="inputSpan">The text being scanned by the regular expression.</param>
            <returns>true if the regular expression matches at the current position; otherwise, false.</returns>
        </member>
        <member name="T:System.Text.RegularExpressions.Generated.WordOrNonWordRegex_4">
            <summary>Custom <see cref="T:System.Text.RegularExpressions.Regex"/>-derived type for the WordOrNonWordRegex method.</summary>
        </member>
        <member name="F:System.Text.RegularExpressions.Generated.WordOrNonWordRegex_4.Instance">
            <summary>Cached, thread-safe singleton instance.</summary>
        </member>
        <member name="M:System.Text.RegularExpressions.Generated.WordOrNonWordRegex_4.#ctor">
            <summary>Initializes the instance.</summary>
        </member>
        <member name="T:System.Text.RegularExpressions.Generated.WordOrNonWordRegex_4.RunnerFactory">
            <summary>Provides a factory for creating <see cref="T:System.Text.RegularExpressions.RegexRunner"/> instances to be used by methods on <see cref="T:System.Text.RegularExpressions.Regex"/>.</summary>
        </member>
        <member name="M:System.Text.RegularExpressions.Generated.WordOrNonWordRegex_4.RunnerFactory.CreateInstance">
            <summary>Creates an instance of a <see cref="T:System.Text.RegularExpressions.RegexRunner"/> used by methods on <see cref="T:System.Text.RegularExpressions.Regex"/>.</summary>
        </member>
        <member name="T:System.Text.RegularExpressions.Generated.WordOrNonWordRegex_4.RunnerFactory.Runner">
            <summary>Provides the runner that contains the custom logic implementing the specified regular expression.</summary>
        </member>
        <member name="M:System.Text.RegularExpressions.Generated.WordOrNonWordRegex_4.RunnerFactory.Runner.Scan(System.ReadOnlySpan{System.Char})">
            <summary>Scan the <paramref name="inputSpan"/> starting from base.runtextstart for the next match.</summary>
            <param name="inputSpan">The text being scanned by the regular expression.</param>
        </member>
        <member name="M:System.Text.RegularExpressions.Generated.WordOrNonWordRegex_4.RunnerFactory.Runner.TryFindNextPossibleStartingPosition(System.ReadOnlySpan{System.Char})">
            <summary>Search <paramref name="inputSpan"/> starting from base.runtextpos for the next location a match could possibly start.</summary>
            <param name="inputSpan">The text being scanned by the regular expression.</param>
            <returns>true if a possible match was found; false if no more matches are possible.</returns>
        </member>
        <member name="M:System.Text.RegularExpressions.Generated.WordOrNonWordRegex_4.RunnerFactory.Runner.TryMatchAtCurrentPosition(System.ReadOnlySpan{System.Char})">
            <summary>Determine whether <paramref name="inputSpan"/> at base.runtextpos is a match for the regular expression.</summary>
            <param name="inputSpan">The text being scanned by the regular expression.</param>
            <returns>true if the regular expression matches at the current position; otherwise, false.</returns>
        </member>
        <member name="T:System.Text.RegularExpressions.Generated.WhiteSpaceRegex_5">
            <summary>Custom <see cref="T:System.Text.RegularExpressions.Regex"/>-derived type for the WhiteSpaceRegex method.</summary>
        </member>
        <member name="F:System.Text.RegularExpressions.Generated.WhiteSpaceRegex_5.Instance">
            <summary>Cached, thread-safe singleton instance.</summary>
        </member>
        <member name="M:System.Text.RegularExpressions.Generated.WhiteSpaceRegex_5.#ctor">
            <summary>Initializes the instance.</summary>
        </member>
        <member name="T:System.Text.RegularExpressions.Generated.WhiteSpaceRegex_5.RunnerFactory">
            <summary>Provides a factory for creating <see cref="T:System.Text.RegularExpressions.RegexRunner"/> instances to be used by methods on <see cref="T:System.Text.RegularExpressions.Regex"/>.</summary>
        </member>
        <member name="M:System.Text.RegularExpressions.Generated.WhiteSpaceRegex_5.RunnerFactory.CreateInstance">
            <summary>Creates an instance of a <see cref="T:System.Text.RegularExpressions.RegexRunner"/> used by methods on <see cref="T:System.Text.RegularExpressions.Regex"/>.</summary>
        </member>
        <member name="T:System.Text.RegularExpressions.Generated.WhiteSpaceRegex_5.RunnerFactory.Runner">
            <summary>Provides the runner that contains the custom logic implementing the specified regular expression.</summary>
        </member>
        <member name="M:System.Text.RegularExpressions.Generated.WhiteSpaceRegex_5.RunnerFactory.Runner.Scan(System.ReadOnlySpan{System.Char})">
            <summary>Scan the <paramref name="inputSpan"/> starting from base.runtextstart for the next match.</summary>
            <param name="inputSpan">The text being scanned by the regular expression.</param>
        </member>
        <member name="M:System.Text.RegularExpressions.Generated.WhiteSpaceRegex_5.RunnerFactory.Runner.TryFindNextPossibleStartingPosition(System.ReadOnlySpan{System.Char})">
            <summary>Search <paramref name="inputSpan"/> starting from base.runtextpos for the next location a match could possibly start.</summary>
            <param name="inputSpan">The text being scanned by the regular expression.</param>
            <returns>true if a possible match was found; false if no more matches are possible.</returns>
        </member>
        <member name="M:System.Text.RegularExpressions.Generated.WhiteSpaceRegex_5.RunnerFactory.Runner.TryMatchAtCurrentPosition(System.ReadOnlySpan{System.Char})">
            <summary>Determine whether <paramref name="inputSpan"/> at base.runtextpos is a match for the regular expression.</summary>
            <param name="inputSpan">The text being scanned by the regular expression.</param>
            <returns>true if the regular expression matches at the current position; otherwise, false.</returns>
        </member>
        <member name="T:System.Text.RegularExpressions.Generated.Utilities">
            <summary>Helper methods used by generated <see cref="T:System.Text.RegularExpressions.Regex"/>-derived implementations.</summary>
        </member>
        <member name="M:System.Text.RegularExpressions.Generated.Utilities.IndexOfAnyExceptWhiteSpace(System.ReadOnlySpan{System.Char})">
            <summary>Finds the next index of any character that matches any character other than a whitespace character.</summary>
        </member>
        <member name="M:System.Text.RegularExpressions.Generated.Utilities.IndexOfNonAsciiOrAny_A2156A68B3FF2CEFCBABF7078C1AEC356AC590A34A9D31C18E0C21F77ECF6097(System.ReadOnlySpan{System.Char})">
            <summary>Finds the next index of any character that matches a character in the set [\w\p{P}].</summary>
        </member>
        <member name="M:System.Text.RegularExpressions.Generated.Utilities.IsWordChar(System.Char)">
            <summary>Determines whether the character is part of the [\w] set.</summary>
        </member>
        <member name="M:System.Text.RegularExpressions.Generated.Utilities.StackPush(System.Int32[]@,System.Int32@,System.Int32)">
            <summary>Pushes 1 value onto the backtracking stack.</summary>
        </member>
        <member name="F:System.Text.RegularExpressions.Generated.Utilities.s_asciiWhiteSpace">
            <summary>Supports searching for characters in or not in "\t\n\v\f\r ".</summary>
        </member>
        <member name="F:System.Text.RegularExpressions.Generated.Utilities.s_ascii_FFFFFFFF1108007000000040010000D0">
            <summary>Supports searching for characters in or not in "\0\u0001\u0002\u0003\u0004\u0005\u0006\a\b\t\n\v\f\r\u000e\u000f\u0010\u0011\u0012\u0013\u0014\u0015\u0016\u0017\u0018\u0019\u001a\u001b\u001c\u001d\u001e\u001f $+&lt;=&gt;^`|~\u007f".</summary>
        </member>
    </members>
</doc>
