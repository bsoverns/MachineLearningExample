<?xml version="1.0"?>
<doc>
    <assembly>
        <name>TorchSharp</name>
    </assembly>
    <members>
        <member name="T:TorchSharp.AutoGradMode">
            <summary>
            Helper class, relying on IDisposable to implement block-based scoping of autograd settings.
            </summary>
        </member>
        <member name="T:TorchSharp.InferenceMode">
            <summary>
            Helper class, relying on IDisposable to implement block-based scoping of autograd settings.
            </summary>
        </member>
        <member name="M:TorchSharp.InferenceMode.Finalize">
            <summary>
            Finalize the inference mode. Releases the guard.
            </summary>
        </member>
        <member name="T:TorchSharp.AnomalyMode">
            <summary>
            Helper class, relying on IDisposable to implement block-based scoping of anomaly settings.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.autograd.grad(System.Collections.Generic.IList{TorchSharp.torch.Tensor},System.Collections.Generic.IList{TorchSharp.torch.Tensor},System.Collections.Generic.IList{TorchSharp.torch.Tensor},System.Boolean,System.Boolean,System.Boolean)">
            <summary>
            Computes and returns the sum of gradients of outputs with respect to the inputs.
            </summary>
            <param name="outputs">Outputs of the differentiated function.</param>
            <param name="inputs">Inputs w.r.t. which the gradient will be returned (and not accumulated into .grad)..</param>
            <param name="grad_outputs">
            The “vector” in the Jacobian-vector product. Usually gradients w.r.t. each output.
            Null values can be specified for scalar Tensors or ones that don’t require grad.
            If a null value would be acceptable for all grad_tensors, then this argument is optional.
            </param>
            <param name="retain_graph">
            If false, the graph used to compute the grad will be freed.
            Note that in nearly all cases setting this option to true is not needed and often can be worked around in a much more efficient way. Defaults to the value of create_graph.
            </param>
            <param name="create_graph">
             If true, graph of the derivative will be constructed, allowing to compute higher order derivative products.
             </param>
            <param name="allow_unused">
            If false, specifying inputs that were not used when computing outputs (and therefore their grad is always zero) is an error.
            </param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.autograd.backward(System.Collections.Generic.IList{TorchSharp.torch.Tensor},System.Collections.Generic.IList{TorchSharp.torch.Tensor},System.Nullable{System.Boolean},System.Boolean,System.Collections.Generic.IList{TorchSharp.torch.Tensor})">
             <summary>
             Computes the sum of gradients of given tensors with respect to graph leaves.
             </summary>
             <param name="tensors">Tensors of which the derivative will be computed.</param>
             <param name="grad_tensors">
             The “vector” in the Jacobian-vector product, usually gradients w.r.t. each element of corresponding tensors.
             Null values can be specified for scalar Tensors or ones that don’t require grad.
             If a null value would be acceptable for all grad_tensors, then this argument is optional.
             </param>
             <param name="retain_graph">If false, the graph used to compute the grad will be freed.
             Note that in nearly all cases setting this option to true is not needed and often can be worked around in a much more efficient way.
             Defaults to the value of create_graph.</param>
             <param name="create_graph">If true, graph of the derivative will be constructed, allowing to compute higher order derivative products. Defaults to false.</param>
             <param name="inputs">
             Inputs w.r.t. which the gradient be will accumulated into .grad. All other Tensors will be ignored.
             If not provided, the gradient is accumulated into all the leaf Tensors that were used to compute the attr::tensors.
             </param>
             <remarks>
             The graph is differentiated using the chain rule. If any of tensors are non-scalar (i.e. their data has more than one element) and require gradient,
             then the Jacobian-vector product would be computed, in this case the function additionally requires specifying grad_tensors.
            
             It should be a sequence of matching length, that contains the “vector” in the Jacobian-vector product, usually the gradient of the differentiated
             function w.r.t. corresponding tensors (null is an acceptable value for all tensors that don’t need gradient tensors).
            
             This function accumulates gradients in the leaves - you might need to zero the .grad properties or set them to null before calling it.
             </remarks>
        </member>
        <member name="M:TorchSharp.torch.autograd.backward(TorchSharp.torch.Tensor,System.Collections.Generic.IList{TorchSharp.torch.Tensor},System.Nullable{System.Boolean},System.Boolean,System.Collections.Generic.IList{TorchSharp.torch.Tensor})">
             <summary>
             Computes the sum of gradients of given tensors with respect to graph leaves.
             </summary>
             <param name="tensor">Tensor of which the derivative will be computed.</param>
             <param name="grad_tensors">
             The “vector” in the Jacobian-vector product, usually gradients w.r.t. each element of corresponding tensors.
             Null values can be specified for scalar Tensors or ones that don’t require grad.
             If a null value would be acceptable for all grad_tensors, then this argument is optional.
             </param>
             <param name="retain_graph">If false, the graph used to compute the grad will be freed.
             Note that in nearly all cases setting this option to true is not needed and often can be worked around in a much more efficient way.
             Defaults to the value of create_graph.</param>
             <param name="create_graph">If true, graph of the derivative will be constructed, allowing to compute higher order derivative products. Defaults to false.</param>
             <param name="inputs">
             Inputs w.r.t. which the gradient be will accumulated into .grad. All other Tensors will be ignored.
             If not provided, the gradient is accumulated into all the leaf Tensors that were used to compute the attr::tensors.
             </param>
             <remarks>
             The graph is differentiated using the chain rule. If any of tensors are non-scalar (i.e. their data has more than one element) and require gradient,
             then the Jacobian-vector product would be computed, in this case the function additionally requires specifying grad_tensors.
            
             It should be a sequence of matching length, that contains the “vector” in the Jacobian-vector product, usually the gradient of the differentiated
             function w.r.t. corresponding tensors (null is an acceptable value for all tensors that don’t need gradient tensors).
            
             This function accumulates gradients in the leaves - you might need to zero the .grad properties or set them to null before calling it.
             </remarks>
        </member>
        <member name="M:TorchSharp.torch.autograd.backward(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Nullable{System.Boolean},System.Boolean,System.Collections.Generic.IList{TorchSharp.torch.Tensor})">
             <summary>
             Computes the sum of gradients of given tensors with respect to graph leaves.
             </summary>
             <param name="tensor">Tensor of which the derivative will be computed.</param>
             <param name="grad_tensor">
             The “vector” in the Jacobian-vector product, usually gradients w.r.t. each element of corresponding tensors.
             Null values can be specified for scalar Tensors or ones that don’t require grad.
             If a null value would be acceptable for all grad_tensors, then this argument is optional.
             </param>
             <param name="retain_graph">If false, the graph used to compute the grad will be freed.
             Note that in nearly all cases setting this option to true is not needed and often can be worked around in a much more efficient way.
             Defaults to the value of create_graph.</param>
             <param name="create_graph">If true, graph of the derivative will be constructed, allowing to compute higher order derivative products. Defaults to false.</param>
             <param name="inputs">
             Inputs w.r.t. which the gradient be will accumulated into .grad. All other Tensors will be ignored.
             If not provided, the gradient is accumulated into all the leaf Tensors that were used to compute the attr::tensors.
             </param>
             <remarks>
             The graph is differentiated using the chain rule. If any of tensors are non-scalar (i.e. their data has more than one element) and require gradient,
             then the Jacobian-vector product would be computed, in this case the function additionally requires specifying grad_tensors.
            
             It should be a sequence of matching length, that contains the “vector” in the Jacobian-vector product, usually the gradient of the differentiated
             function w.r.t. corresponding tensors (null is an acceptable value for all tensors that don’t need gradient tensors).
            
             This function accumulates gradients in the leaves - you might need to zero the .grad properties or set them to null before calling it.
             </remarks>
        </member>
        <member name="M:TorchSharp.torch.autograd.detect_anomaly(System.Boolean)">
            <summary>
            Context-manager that enable anomaly detection for the autograd engine.
            </summary>
            <param name="check_nan">Flag whether to raise an error when the backward generate “nan”</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.autograd.set_detect_anomaly(System.Boolean,System.Boolean)">
            <summary>
            Context-manager that enable anomaly detection for the autograd engine.
            </summary>
            <param name="mode">Flag whether to enable anomaly detection (true), or disable (false)</param>
            <param name="check_nan">Flag whether to raise an error when the backward generate “nan”</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.autograd.Node`1.ComputeVariableInput(System.Object[])">
            <summary>
            Given a list of arguments passed to the forward function, check which of the inputs are Tensors and which
            are objects of non-tensor types.
            </summary>
            <param name="args">The arguments passed to the Function.forward implementtation</param>
            <returns>A list of only the tensor objects from the args</returns>
        </member>
        <member name="M:TorchSharp.torch.autograd.Node`1.ApplyFunc(System.IntPtr[],System.Int32)">
            <summary>
            This is the function which gets passed back to the unmanaged code, which is used in the autograd graph
            to call the custom backward function and compute the gradients. This function wraps around the Function.backward
            implementation converting between unmanaged and managed objects. 
            </summary>
            <returns>A pointer to an array of tensors with the size</returns>
        </member>
        <member name="M:TorchSharp.torch.autograd.Node`1.DeleteNode">
            <summary>
            This function is also passed as a parameter to the unmanaged object, so that when the unmanaged object
            is destroyed, then we will remove the hard reference we have of this node so that the GC can collect it. 
            </summary>
        </member>
        <member name="M:TorchSharp.torch.autograd.Node`1.DisposeSharedPtr">
            <summary>
            When we create the unmanaged object we need to hold a strong reference to it while we apply the whole process
            of populating it with information, but then once we've attached it to the graph we want to still maintain a reference
            to it so that we can call into it, but not a strong reference so that it will be destroyed. Therefore, we store
            both a shared and a weak pointer to the object, and so once we attach it to a graph, we will dispose the shared ptr.
            </summary>
        </member>
        <member name="T:TorchSharp.torch.autograd.AutogradContext">
            <summary>
            Context to save information during `forward` that can be accessed in
            `backward` in custom autograd operations (see `torch::autograd::Function` for details).
            </summary>
        </member>
        <member name="M:TorchSharp.torch.autograd.AutogradContext.save_for_backward(System.Collections.Generic.List{TorchSharp.torch.Tensor})">
            <summary>
            Saves the list of variables for a future call to `backward`. This
            should be called at most once from inside of `forward`.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.autograd.AutogradContext.save_data(System.String,System.Object)">
            <summary>
            Saves a non tensor object in the data field for a future call to `backward`.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.autograd.AutogradContext.mark_dirty(System.Collections.Generic.List{TorchSharp.torch.Tensor})">
            <summary>
            Marks variables in the list as modified in an in-place operation. This
            should be called at most once from inside of `forward` and all arguments
            should be inputs.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.autograd.AutogradContext.mark_non_differentiable(System.Collections.Generic.List{TorchSharp.torch.Tensor})">
            <summary>
            Marks outputs in the list as not requiring gradients. This should be
            called at most once from inside of `forward` and all arguments should be
            outputs.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.autograd.AutogradContext.set_materialize_grads(System.Boolean)">
            <summary>
            Sets whether undefined output grad tensors should be expanded to tensors
            full of zeros before calling backward function. Default value is true.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.autograd.AutogradContext.get_saved_variables">
            <summary>
            Get the list of variables that were saved in `forward` using
            `save_for_backward()`. Before returning them to the user, a check is made
            to ensure that they were not modified by any in-place operations.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.autograd.AutogradContext.get_data(System.String)">
            <summary>
            Retrieve a non-tensor value stored in the context in the `forward` function.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.autograd.AutogradContext.save_variables">
            <summary>
            Internal function called during the construction of the node on the graph to commit the tensors
            to memory as SavedVariable unmanaged objects. 
            </summary>
        </member>
        <member name="T:TorchSharp.torch.autograd.Function`1">
            <summary>
            To use custom autograd operations, implement a Function subclass implementing tthe
            forward and backward functions:
            `forward` can take as many arguments as you want, passed an object[], and will return either
            a list of tensors or a single tensor (depending which subclass you inherit).
            Use of any direct Variable arguments will be registered in the graph but no vectors/sets or any
            other data structures will be traversed. You can pass null tensors as one of the arguments
            and it will be registered as a variable in the graph if the argument has a
            value. It should take a pointer to `torch::autograd::AutogradContext` as the
            first argument. Tensors can be saved in the `ctx` using `ctx->save_for_backward`
            (see `torch::autograd::AutogradContext::save_for_backward`) and other data
            can be saved using the `ctx->save_data` function (see `torch::autograd::AutogradContext::save_data`)
            in the form of `(string, object)` pairs.
            Variables saved in `forward` can be accessed with `ctx->get_saved_variables` (see
            `torch::autograd::AutogradContext::get_saved_variables`) and other saved
            data can be accessed using `ctx->get_data()`.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.autograd.Function`1.apply_internal(System.Object[])">
            <summary>
            When calling the function, the user should call Function.apply and not the forward function, so that
            the computation graph is built correctly.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.autograd.functional._grad_preprocess(System.Boolean,TorchSharp.torch.Tensor[])">
            <summary>
            Preprocesses the inputs to make sure they require gradient.
            </summary>
            <param name="need_graph">Specifies if we internally want gradients to flow back to the Tensors in the result.</param>
            <param name="inputs">The tensors to preprocess.</param>
            <returns>The same tensors as inputs, but requiring grad.</returns>
        </member>
        <member name="M:TorchSharp.torch.autograd.functional._autograd_grad(TorchSharp.torch.Tensor,System.Boolean,TorchSharp.torch.Tensor[])">
            <summary>
            Wrapper function around torch.autograd.grad.
            </summary>
            <param name="output">The output tensor to compute gradients for.</param>
            <param name="retain_graph">Whether the gradient computation graph should be kept.</param>
            <param name="inputs">The input tensors at which to evaluate the gradients.</param>
            <returns>A collection of gradient tensors for the output with respect to each input.</returns>
        </member>
        <member name="M:TorchSharp.torch.autograd.functional.jacobian(System.Func{TorchSharp.torch.Tensor[],TorchSharp.torch.Tensor[]},TorchSharp.torch.Tensor[])">
             <summary>
             Computes the jacobian of a given function.
             
             Example:
             torch.Tensor x1 = torch.tensor(new double[,] { { 1.0, 3.0 }, { 2.0, 4.0 } }, requires_grad: true);
             torch.Tensor intercepts = torch.tensor(new double[] { 1.0, 5.0 }, requires_grad: true);
             
             torch.Tensor[] jacFunc(torch.Tensor[] inputs)
             {
                 return new torch.Tensor[] { torch.einsum("ij,j->i", inputs[0], inputs[1]) };
             }
            
             var jacobian = torch.autograd.functional.jacobian(jacFunc, x1, intercepts);
            
             jacobian[0] should be:
             [[[1, 5],
               [0, 0]],
              [[0, 0],
               [1, 5]]]
             And jacobian[1]:
             [[1, 3],
              [2, 4]]
              
             </summary>
             <param name="function">The function to compute the jacobian for. It may have multiple inputs and multiple outputs.</param>
             <param name="inputs">The values for the inputs at which to compute the jacobian.</param>
             <returns>A list of tensors, one for each output value of each output. For example, a single output with two elements yields two jacobian tensors.</returns>
        </member>
        <member name="M:TorchSharp.torch.autograd.functional.jacobian(System.Func{TorchSharp.torch.Tensor,TorchSharp.torch.Tensor},TorchSharp.torch.Tensor)">
            <summary>
            Computes the jacobian of a given function with one input and one output.
            </summary>
            <param name="function">The function to compute the jacobian for. It has a single input and single output.</param>
            <param name="inputs">The value for the input at which to compute the jacobian.</param>
            <returns>A single tensor containing the jacobian.</returns>
        </member>
        <member name="M:TorchSharp.torch.autograd.functional.jacobian(System.Func{TorchSharp.torch.Tensor,TorchSharp.torch.Tensor[]},TorchSharp.torch.Tensor)">
            <summary>
            Computes the jacobian of a given function with one input and multiple outputs.
            </summary>
            <param name="function">The function to compute the jacobian for. It has a single input and multiple outputs.</param>
            <param name="inputs">The value for the input at which to compute the jacobian.</param>
            <returns>A list of tensors containing the jacobian for each output.</returns>
        </member>
        <member name="M:TorchSharp.torch.autograd.functional.jacobian(System.Func{TorchSharp.torch.Tensor[],TorchSharp.torch.Tensor},TorchSharp.torch.Tensor[])">
            <summary>
            Computes the jacobian of a given function with multiple inputs and one output.
            </summary>
            <param name="function">The function to compute the jacobian for. It has multiple inputs and single output.</param>
            <param name="inputs">The values for the inputs at which to compute the jacobian.</param>
            <returns>A list of tensors containing the jacobian for the output with respect to each input.</returns>
        </member>
        <member name="T:TorchSharp.torch.utils.data.Dataset">
            <summary>
            Map-style data set
            </summary>
        </member>
        <member name="T:TorchSharp.torch.utils.data.IterableDataset">
            <summary>
            Iterable-style data sets
            </summary>
        </member>
        <member name="T:TorchSharp.torch.utils.data.Dataset`1">
            <summary>
            The base nterface for all Datasets.
            </summary>
        </member>
        <member name="P:TorchSharp.torch.utils.data.Dataset`1.Count">
            <summary>
            Size of dataset
            </summary>
        </member>
        <member name="M:TorchSharp.torch.utils.data.Dataset`1.GetTensor(System.Int64)">
            <summary>
            Get tensor according to index
            </summary>
            <param name="index">Index for tensor</param>
            <returns>Tensors of index. DataLoader will catenate these tensors into batches.</returns>
        </member>
        <member name="M:TorchSharp.torch.utils.data.TensorDataset(TorchSharp.torch.Tensor[])">
             <summary>
             Dataset wrapping tensors.
            
             Each sample will be retrieved by indexing tensors along the first dimension.
             </summary>
             <param name="tensors">Tensors that have the same size of the first dimension.</param>
        </member>
        <member name="T:TorchSharp.torch.utils.tensorboard.GifEncoder.Encoder">
             <summary>
             Class AnimatedGifEncoder - Encodes a GIF file consisting of one or more frames.
            
             No copyright asserted on the source code of this class. May be used for any
             purpose, however, refer to the Unisys LZW patent for restrictions on use of
             the associated LZWEncoder class. Please forward any corrections to
             kweiner@fmsware.com.
            
             @author Kevin Weiner, FM Software
             @version 1.03 November 2003
            
             https://cs.android.com/android/platform/superproject/+/master:external/glide/third_party/gif_encoder/src/main/java/com/bumptech/glide/gifencoder/AnimatedGifEncoder.java
             </summary>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.GifEncoder.Encoder.SetDelay(System.Int32)">
            <summary>
            Sets the delay time between each frame, or changes it
            for subsequent frames (applies to last frame added).
            </summary>
            <param name="ms"> delay time in milliseconds </param>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.GifEncoder.Encoder.SetDispose(System.Int32)">
            <summary>
            Sets the GIF frame disposal code for the last added frame
            and any subsequent frames.  Default is 0 if no transparent
            color has been set, otherwise 2.
            </summary>
            <param name="code"> disposal code. </param>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.GifEncoder.Encoder.SetRepeat(System.Int32)">
            <summary>
            Sets the number of times the set of GIF frames
            should be played.  Default is 1; 0 means play
            indefinitely.  Must be invoked before the first
            image is added.
            </summary>
            <param name="iter"> number of iterations. </param>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.GifEncoder.Encoder.SetTransparent(SkiaSharp.SKColor)">
            <summary>
            Sets the transparent color for the last added frame
            and any subsequent frames.
            Since all colors are subject to modification
            in the quantization process, the color in the final
            palette for each frame closest to the given color
            becomes the transparent color for that frame.
            May be set to null to indicate no transparent color.
            </summary>
            <param name="c"> Color to be treated as transparent on display. </param>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.GifEncoder.Encoder.AddFrame(SkiaSharp.SKBitmap)">
            <summary>
            Adds next GIF frame.  The frame is not written immediately, but is
            actually deferred until the next frame is received so that timing
            data can be inserted.  Invoking <code>finish()</code> flushes all
            frames.  If <code>setSize</code> was not invoked, the size of the
            first image is used for all subsequent frames.
            </summary>
            <param name="im"> BufferedImage containing frame to write. </param>
            <returns> true if successful. </returns>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.GifEncoder.Encoder.Finish">
            <summary>
            Flushes any pending data and closes output file.
            If writing to an OutputStream, the stream is not
            closed.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.GifEncoder.Encoder.SetFrameRate(System.Single)">
            <summary>
            Sets frame rate in frames per second.  Equivalent to
            <code>setDelay(1000/fps)</code>.
            </summary>
            <param name="fps"> fps float frame rate (frames per second) </param>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.GifEncoder.Encoder.SetSize(System.Int32,System.Int32)">
            <summary>
            Sets the GIF frame size.  The default size is the
            size of the first frame added if this method is
            not invoked.
            </summary>
            <param name="w"> frame width </param>
            <param name="h"> frame width </param>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.GifEncoder.Encoder.Start(System.IO.MemoryStream)">
            <summary>
            Initiates GIF file creation on the given stream.  The stream
            is not closed automatically.
            </summary>
            <param name="os"> OutputStream on which GIF images are written. </param>
            <returns> false if initial write failed. </returns>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.GifEncoder.Encoder.Start">
            <summary>
            Initiates writing of a GIF file to a memory stream.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.GifEncoder.Encoder.Output(System.String)">
            <summary>
            Initiates writing of a GIF file with the specified name.
            </summary>
            <param name="file"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.GifEncoder.Encoder.AnalyzePixels">
            <summary>
            Analyzes image colors and creates color map.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.GifEncoder.Encoder.FindClosest(SkiaSharp.SKColor)">
            <summary>
            Returns index of palette color closest to c
            </summary>
            <param name="c"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.GifEncoder.Encoder.GetImagePixels">
            <summary>
            Extracts image pixels into byte array "pixels"
            </summary>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.GifEncoder.Encoder.WriteGraphicCtrlExt">
            <summary>
            Writes Graphic Control Extension
            </summary>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.GifEncoder.Encoder.WriteImageDesc">
            <summary>
            Writes Image Descriptor
            </summary>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.GifEncoder.Encoder.WriteLSD">
            <summary>
            Writes Logical Screen Descriptor
            </summary>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.GifEncoder.Encoder.WriteNetscapeExt">
            <summary>
            Writes Netscape application extension to define repeat count.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.GifEncoder.Encoder.WritePalette">
            <summary>
            Writes color table
            </summary>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.GifEncoder.Encoder.WritePixels">
            <summary>
            Encodes and writes pixel data
            </summary>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.GifEncoder.Encoder.WriteShort(System.Int32)">
            <summary>
            Write 16-bit value to output stream, LSB first
            </summary>
            <param name="value"></param>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.GifEncoder.Encoder.WriteString(System.String)">
            <summary>
            Writes string to output stream
            </summary>
            <param name="s"></param>
        </member>
        <member name="T:TorchSharp.torch.utils.tensorboard.GifEncoder.LZWEncoder">
             <summary>
             Adapted from Jef Poskanzer's Java port by way of J. M. G. Elliott.
             K Weiner 12/00
            
             https://cs.android.com/android/platform/superproject/+/master:external/glide/third_party/gif_encoder/src/main/java/com/bumptech/glide/gifencoder/LZWEncoder.java
             </summary>
        </member>
        <member name="F:TorchSharp.torch.utils.tensorboard.GifEncoder.LZWEncoder.a_count">
            <summary>
            Number of characters so far in this 'packet'
            </summary>
        </member>
        <member name="F:TorchSharp.torch.utils.tensorboard.GifEncoder.LZWEncoder.accum">
            <summary>
            Define the storage for the packet accumulator
            </summary>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.GifEncoder.LZWEncoder.Add(System.Byte,System.IO.Stream)">
            <summary>
            Add a character to the end of the current packet, and if it is 254
            characters, flush the packet to disk.
            </summary>
            <param name="c"></param>
            <param name="outs"></param>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.GifEncoder.LZWEncoder.ClearTable(System.IO.Stream)">
            <summary>
            table clear for block compress
            </summary>
            <param name="outs"></param>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.GifEncoder.LZWEncoder.ResetCodeTable(System.Int32)">
            <summary>
            reset code table
            </summary>
            <param name="hsize"></param>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.GifEncoder.LZWEncoder.Flush(System.IO.Stream)">
            <summary>
            Flush the packet to disk, and reset the accumulator
            </summary>
            <param name="outs"></param>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.GifEncoder.LZWEncoder.NextPixel">
            <summary>
            Return the next pixel from the image
            </summary>
            <returns></returns>
        </member>
        <member name="T:TorchSharp.torch.utils.tensorboard.GifEncoder.NeuQuant">
             <summary>
             NeuQuant Neural-Net Quantization Algorithm
             ------------------------------------------
            
             Copyright (c) 1994 Anthony Dekker
            
             NEUQUANT Neural-Net quantization algorithm by Anthony Dekker, 1994. See
             "Kohonen neural networks for optimal colour quantization" in "Network:
             Computation in Neural Systems" Vol. 5 (1994) pp 351-367. for a discussion of
             the algorithm.
            
             Any party obtaining a copy of these files from the author, directly or
             indirectly, is granted, free of charge, a full and unrestricted irrevocable,
             world-wide, paid up, royalty-free, nonexclusive right and license to deal in
             this software and documentation files (the "Software"), including without
             limitation the rights to use, copy, modify, merge, publish, distribute,
             sublicense, and/or sell copies of the Software, and to permit persons who
             receive copies from any such party to do so, with the only requirement being
             that this copyright notice remain intact.
            
             https://cs.android.com/android/platform/superproject/+/master:external/glide/third_party/gif_encoder/src/main/java/com/bumptech/glide/gifencoder/NeuQuant.java
             </summary>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.GifEncoder.NeuQuant.#ctor(System.Byte[],System.Int32,System.Int32)">
            <summary>
            Initialise network in range (0,0,0) to (255,255,255) and set parameters
            </summary>
            <param name="thepic"></param>
            <param name="len"></param>
            <param name="sample"></param>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.GifEncoder.NeuQuant.Inxbuild">
            <summary>
            Insertion sort of network and building of netindex[0..255] (to do after unbias)
            </summary>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.GifEncoder.NeuQuant.Learn">
            <summary>
            Main Learning Loop
            </summary>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.GifEncoder.NeuQuant.Map(System.Int32,System.Int32,System.Int32)">
            <summary>
            Search for BGR values 0..255 (after net is unbiased) and return colour index
            </summary>
            <param name="b"></param>
            <param name="g"></param>
            <param name="r"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.GifEncoder.NeuQuant.Unbiasnet">
            <summary>
            Unbias network to give byte values 0..255 and record position i to prepare for sort
            </summary>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.GifEncoder.NeuQuant.Alterneigh(System.Int32,System.Int32,System.Int32,System.Int32,System.Int32)">
            <summary>
            Move adjacent neurons by precomputed alpha*(1-((i-j)^2/[r]^2)) in radpower[|i-j|]
            </summary>
            <param name="rad"></param>
            <param name="i"></param>
            <param name="b"></param>
            <param name="g"></param>
            <param name="r"></param>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.GifEncoder.NeuQuant.Altersingle(System.Int32,System.Int32,System.Int32,System.Int32,System.Int32)">
            <summary>
            Move neuron i towards biased (b,g,r) by factor alpha
            </summary>
            <param name="alpha"></param>
            <param name="i"></param>
            <param name="b"></param>
            <param name="g"></param>
            <param name="r"></param>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.GifEncoder.NeuQuant.Contest(System.Int32,System.Int32,System.Int32)">
            <summary>
            Search for biased BGR values
            </summary>
            <param name="b"></param>
            <param name="g"></param>
            <param name="r"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.Summary.histogram(System.String,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Nullable{System.Int64})">
             <summary>
             Outputs a `Summary` protocol buffer with a histogram.
             The generated
             [`Summary`](https://www.tensorflow.org/code/tensorflow/core/framework/summary.proto)
             has one summary value containing a histogram for `values`.
             This op reports an `InvalidArgument` error if any value is not finite.
            
             https://github.com/pytorch/pytorch/blob/1.7/torch/utils/tensorboard/summary.py#L283
             </summary>
             <param name="name"> A name for the generated node. Will also serve as a series name in TensorBoard. </param>
             <param name="values"> A real numeric `Tensor`. Any shape. Values to use to build the histogram. </param>
             <param name="bins"></param>
             <param name="max_bins"></param>
             <returns> A scalar `Tensor` of type `string`. The serialized `Summary` protocol buffer. </returns>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.Summary.histogram(System.String,TorchSharp.torch.Tensor,TorchSharp.HistogramBinSelector,System.Nullable{System.Int64})">
             <summary>
             Outputs a `Summary` protocol buffer with a histogram.
             The generated
             [`Summary`](https://www.tensorflow.org/code/tensorflow/core/framework/summary.proto)
             has one summary value containing a histogram for `values`.
             This op reports an `InvalidArgument` error if any value is not finite.
            
             https://github.com/pytorch/pytorch/blob/1.7/torch/utils/tensorboard/summary.py#L283
             </summary>
             <param name="name"> A name for the generated node. Will also serve as a series name in TensorBoard. </param>
             <param name="values"> A real numeric `Tensor`. Any shape. Values to use to build the histogram. </param>
             <param name="bins"></param>
             <param name="max_bins"></param>
             <returns> A scalar `Tensor` of type `string`. The serialized `Summary` protocol buffer. </returns>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.Summary.make_histogram(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Nullable{System.Int64})">
             <summary>
             Convert values into a histogram proto using logic from histogram.cc.
            
             https://github.com/pytorch/pytorch/blob/1.7/torch/utils/tensorboard/summary.py#L304
             </summary>
             <param name="values"></param>
             <param name="bins"></param>
             <param name="max_bins"></param>
             <returns></returns>
             <exception cref="T:System.ArgumentException"></exception>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.Summary.make_histogram(TorchSharp.torch.Tensor,TorchSharp.HistogramBinSelector,System.Nullable{System.Int64})">
             <summary>
             Convert values into a histogram proto using logic from histogram.cc.
            
             https://github.com/pytorch/pytorch/blob/1.7/torch/utils/tensorboard/summary.py#L304
             </summary>
             <param name="values"></param>
             <param name="bins"></param>
             <param name="max_bins"></param>
             <returns></returns>
             <exception cref="T:System.ArgumentException"></exception>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.Summary.image(System.String,TorchSharp.torch.Tensor,System.Double,System.String)">
            <summary>
            Outputs a `Summary` protocol buffer with images.
            The summary has up to `max_images` summary values containing images. The
            images are built from `tensor` which must be 3-D with shape `[height, width,
            channels]` and where `channels` can be:
            *  1: `tensor` is interpreted as Grayscale.
            *  3: `tensor` is interpreted as RGB.
            *  4: `tensor` is interpreted as RGBA.
            The `name` in the outputted Summary.Value protobufs is generated based on the
            name, with a suffix depending on the max_outputs setting:
            *  If `max_outputs` is 1, the summary value tag is '*name*/image'.
            *  If `max_outputs` is greater than 1, the summary value tags are
               generated sequentially as '*name*/image/0', '*name*/image/1', etc.
            </summary>
            <param name="tag"> A name for the generated node. Will also serve as a series name in TensorBoard. </param>
            <param name="tensor">
            A 3-D `uint8` or `float32` `Tensor` of shape `[height, width,
            channels]` where `channels` is 1, 3, or 4.
            'tensor' can either have values in [0, 1] (float32) or [0, 255] (uint8).
            The image() function will scale the image values to [0, 255] by applying
            a scale factor of either 1 (uint8) or 255 (float32). Out-of-range values
            will be clipped.
            </param>
            <param name="rescale"> Rescale image size </param>
            <param name="dataformats"> Image data format specification of the form CHW, HWC, HW, WH, etc. </param>
            <returns> A scalar `Tensor` of type `string`. The serialized `Summary` protocol buffer. </returns>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.Summary.image(System.String,System.String,System.Double)">
            <summary>
            Outputs a `Summary` protocol buffer with images.
            </summary>
            <param name="tag"> A name for the generated node. Will also serve as a series name in TensorBoard. </param>
            <param name="file_name"> local image filename </param>
            <param name="rescale"> Rescale image size </param>
            <returns> A scalar `Tensor` of type `string`. The serialized `Summary` protocol buffer. </returns>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.Summary.make_image(TorchSharp.torch.Tensor,System.Double)">
            <summary>
            Convert a tensor representation of an image to Image protobuf
            
            https://github.com/pytorch/pytorch/blob/master/torch/utils/tensorboard/summary.py#L481
            </summary>
            <param name="tensor"> HWC(0~255) image tensor </param>
            <param name="rescale"> Rescale image size </param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.Summary.make_image(SkiaSharp.SKBitmap,System.Double)">
            <summary>
            Convert an image to Image protobuf
            
            https://github.com/pytorch/pytorch/blob/master/torch/utils/tensorboard/summary.py#L495
            </summary>
            <param name="img"> Image </param>
            <param name="rescale"> Rescale image size </param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.Summary.video(System.String,TorchSharp.torch.Tensor,System.Int32)">
            <summary>
            https://github.com/pytorch/pytorch/blob/master/torch/utils/tensorboard/summary.py#L509
            </summary>
            <param name="tag"> A name for the generated node. Will also serve as a series name in TensorBoard. </param>
            <param name="tensor"> Video data </param>
            <param name="fps"> Frames per second </param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.Summary.make_video(TorchSharp.torch.Tensor,System.Int32)">
            <summary>
            https://github.com/pytorch/pytorch/blob/master/torch/utils/tensorboard/summary.py#L520
            </summary>
            <param name="tensor"> Video data </param>
            <param name="fps"> Frames per second </param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.Summary.text(System.String,System.String)">
            <summary>
            https://github.com/pytorch/pytorch/blob/master/torch/utils/tensorboard/summary.py#L630
            </summary>
            <param name="tag"> Data identifier </param>
            <param name="text"> String to save </param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.SummaryWriter(System.String,System.String,System.Boolean)">
             <summary>
             Writes entries directly to event files in the log_dir to be consumed by TensorBoard.
             
             The SummaryWriter class provides a high-level API to create an event file in a given directory and add summaries and events to it.The class updates the file contents asynchronously.
            
             This allows a training program to call methods to add data to the file directly from the training loop, without slowing down training.
             </summary>
             <param name="log_dir">
             Save directory location. Default is runs/CURRENT_DATETIME_HOSTNAME, which changes after each run.
             Use hierarchical folder structure to compare between runs easily. e.g. pass in ‘runs/exp1’, ‘runs/exp2’, etc.
             for each new experiment to compare across them
             </param>
             <param name="filename_suffix">Suffix added to all event filenames in the log_dir directory.</param>
             <param name="createRunName">Create a time-based run name, even if log_dir is specified.</param>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.utils.prepare_video(TorchSharp.torch.Tensor)">
             <summary>
             Converts a 5D tensor [batchsize, time(frame), channel(color), height, width]
             into 4D tensor with dimension[time(frame), new_width, new_height, channel].
             A batch of images are spreaded to a grid, which forms a frame.
             e.g. Video with batchsize 16 will have a 4x4 grid.
            
             https://github.com/pytorch/pytorch/blob/master/torch/utils/tensorboard/_utils.py#L110
             </summary>
             <param name="V"></param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.utils.make_grid(TorchSharp.torch.Tensor,System.Int64)">
            <summary>
            https://github.com/pytorch/pytorch/blob/6c30dc6ceed5542351b3be4f8043b28020f93f3a/torch/utils/tensorboard/_utils.py#L69
            </summary>
            <param name="I"></param>
            <param name="ncols"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.utils.tensorboard.utils.convert_to_HWC(TorchSharp.torch.Tensor,System.String)">
            <summary>
            https://github.com/pytorch/pytorch/blob/6c30dc6ceed5542351b3be4f8043b28020f93f3a/torch/utils/tensorboard/_utils.py#L95
            </summary>
            <param name="tensor"> Image data </param>
            <param name="input_format"> Image data format specification of the form NCHW, NHWC, CHW, HWC, HW, WH, etc. </param>
            <returns></returns>
        </member>
        <member name="T:TorchSharp.torch.Device">
            <summary>
            A torch.Device is an object representing the device on which a torch.Tensor is or will be allocated.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Device.#ctor(System.String)">
            <summary>
            Constructor
            </summary>
            <param name="description">A device descriptor 'device[:index]'</param>
        </member>
        <member name="M:TorchSharp.torch.Device.#ctor(System.String,System.Int32)">
            <summary>
            Constructor
            </summary>
            <param name="deviceType">CPU or CUDA</param>
            <param name="index">For CUDA, the device index</param>
        </member>
        <member name="M:TorchSharp.torch.Device.#ctor(TorchSharp.DeviceType,System.Int32)">
            <summary>
            Constructor
            </summary>
            <param name="deviceType">CPU or CUDA</param>
            <param name="index">For CUDA, the device index</param>
        </member>
        <member name="M:TorchSharp.torch.Device.#ctor(System.Int32)">
            <summary>
            Constructor
            </summary>
            <param name="index">The CUDA device index</param>
        </member>
        <member name="M:TorchSharp.torch.Device.ToString">
            <summary>
            Return the device descriptor using the input format.
            </summary>
            <returns></returns>
        </member>
        <member name="P:TorchSharp.torch.CUDA">
            <summary>
            Convenience declaration of a CUDA device accessible everywhere.
            </summary>
        </member>
        <member name="P:TorchSharp.torch.MPS">
            <summary>
            Convenience declaration of a MPS device accessible everywhere.
            </summary>
        </member>
        <member name="F:TorchSharp.torch.CPU">
            <summary>
            Convenience declaration of a CPU device accessible everywhere.
            </summary>
        </member>
        <member name="F:TorchSharp.torch.META">
            <summary>
            Convenience declaration of a META device accessible everywhere.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.device(System.String)">
            <summary>
            Factory for a device object, following the Pytorch API.
            </summary>
            <param name="description">String description of the device, e.g. 'cpu' or 'cuda:0'</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.device(System.String,System.Int32)">
            <summary>
            Factory for a device object, following the Pytorch API.
            </summary>
            <param name="deviceType">The device type, e.g. 'cpu' or 'cuda'</param>
            <param name="index">The device index. Ignored for CPUs</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.device(TorchSharp.DeviceType,System.Int32)">
            <summary>
            Factory for a device object, following the Pytorch API.
            </summary>
            <param name="deviceType">The device type, e.g. DeviceType.CPU or DeviceType.CUDA.</param>
            <param name="index">The device index. Ignored for CPUs</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.device(System.Int32)">
            <summary>
            Factory for a CUDA device object, following the Pytorch API.
            </summary>
            <param name="index">The CUDA device ordinal.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.Bernoulli(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Creates a Bernoulli distribution parameterized by `probs` or `logits` (but not both).
            </summary>
            <param name="probs">The probability of sampling '1'</param>
            <param name="logits">The log-odds of sampling '1'</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.Bernoulli(System.Nullable{System.Single},System.Nullable{System.Single},TorchSharp.torch.Generator)">
            <summary>
            Creates a Bernoulli distribution parameterized by `probs` or `logits` (but not both).
            </summary>
            <param name="probs">The probability of sampling '1'</param>
            <param name="logits">The log-odds of sampling '1'</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.Bernoulli(System.Nullable{System.Double},System.Nullable{System.Double},TorchSharp.torch.Generator)">
            <summary>
            Creates a Bernoulli distribution parameterized by `probs` or `logits` (but not both).
            </summary>
            <param name="probs">The probability of sampling '1'</param>
            <param name="logits">The log-odds of sampling '1'</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.Beta(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Creates a Beta distribution parameterized by concentration1 and concentration0.
            </summary>
            <param name="concentration1">1st concentration parameter of the distribution (often referred to as 'α')</param>
            <param name="concentration0">2nd concentration parameter of the distribution (often referred to as 'β')</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
            <remarks>The order of the arguments is not a mistake -- the original source has them ordered this way.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.distributions.Binomial(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Creates a Binomial distribution parameterized by `probs` or `logits` (but not both).
            `total_count` must be broadcastable with `probs`/`logits`.
            </summary>
            <param name="total_count">Number of Bernoulli trials</param>
            <param name="probs">The probability of sampling '1'</param>
            <param name="logits">The log-odds of sampling '1'</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.Binomial(System.Int32,System.Nullable{System.Single},System.Nullable{System.Single},TorchSharp.torch.Generator)">
            <summary>
            Creates a Binomial distribution parameterized by `probs` or `logits` (but not both).
            </summary>
            <param name="total_count">Number of Bernoulli trials</param>
            <param name="probs">The probability of sampling '1'</param>
            <param name="logits">The log-odds of sampling '1'</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.Binomial(System.Int32,System.Nullable{System.Double},System.Nullable{System.Double},TorchSharp.torch.Generator)">
            <summary>
            Creates a Binomial distribution parameterized by `probs` or `logits` (but not both).
            </summary>
            <param name="total_count">Number of Bernoulli trials</param>
            <param name="probs">The probability of sampling '1'</param>
            <param name="logits">The log-odds of sampling '1'</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.Categorical(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
             <summary>
             Creates a Categorical distribution parameterized by `probs` or `logits` (but not both).
            
             Samples are integers from [0, K-1]` where `K` is probs.size(-1).
             
             If `probs` is 1-dimensional with length- `K`, each element is the relative probability
             of sampling the class at that index.
             
             If `probs` is N-dimensional, the first N-1 dimensions are treated as a batch of
             relative probability vectors.
             </summary>
             <param name="probs">The probability of sampling '1'</param>
             <param name="logits">The log-odds of sampling '1'</param>
             <param name="generator">An optional random number generator object.</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.Categorical(System.Int32,TorchSharp.torch.Generator)">
             <summary>
             Creates an equal-probability categorical distribution parameterized by the number of categories.
            
             </summary>
             <param name="categories">The number of categories.</param>
             <param name="generator">An optional random number generator object.</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.Cauchy(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Samples from a Cauchy (Lorentz) distribution. The distribution of the ratio of
            independent normally distributed random variables with means `0` follows a Cauchy distribution.
            </summary>
            <param name="loc">Mode or median of the distribution.</param>
            <param name="scale">Half width at half maximum.</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.Chi2(TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Creates a Gamma distribution parameterized by a single shape parameter.
            </summary>
            <param name="df">Shape parameter of the distribution</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="T:TorchSharp.torch.distributions.constraints.Constraint">
            <summary>
            Abstract base class for constraints.
            
            A constraint object represents a region over which a variable is valid, e.g. within which a variable can be optimized.
            </summary>
            <remarks>
            // It's not ideal to use a '_' first in a public .NET type name, but that's what Pytorch does for all contraint types.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.distributions.constraints.Constraint.#ctor(System.Boolean,System.Int32)">
            <summary>
            Constructor
            </summary>
            <param name="is_discrete">Whether constrained space is discrete.</param>
            <param name="event_dim">
            Number of rightmost dimensions that together define an event.
            The check() method will remove this many dimensions when computing validity.
            </param>
        </member>
        <member name="M:TorchSharp.torch.distributions.constraints.Constraint.#ctor">
            <summary>
            Constructor
            </summary>
        </member>
        <member name="M:TorchSharp.torch.distributions.constraints.Constraint.check(TorchSharp.torch.Tensor)">
            <summary>
            Returns a byte tensor of sample_shape + batch_shape indicating  whether each event in value satisfies this constraint.
            </summary>
            <param name="value"></param>
            <returns></returns>
        </member>
        <member name="P:TorchSharp.torch.distributions.constraints.Constraint.is_discrete">
            <summary>
            Whether constrained space is discrete.
            </summary>
        </member>
        <member name="P:TorchSharp.torch.distributions.constraints.Constraint.event_dim">
            <summary>
            Number of rightmost dimensions that together define an event.
            The check() method will remove this many dimensions when computing validity.
            </summary>
        </member>
        <member name="T:TorchSharp.torch.distributions.constraints._Dependent">
            <summary>
            Placeholder for variables whose support depends on other variables.
            These variables obey no simple coordinate-wise constraints.
            </summary>
        </member>
        <member name="T:TorchSharp.torch.distributions.constraints._IndependentConstraint">
            <summary>
            Wraps a constraint by aggregating over ``reinterpreted_batch_ndims``-many
            dims in :meth:`check`, so that an event is valid only if all its
            independent entries are valid.
            </summary>
        </member>
        <member name="P:TorchSharp.torch.distributions.constraints._IndependentConstraint.is_discrete">
            <summary>
            Whether constrained space is discrete.
            </summary>
        </member>
        <member name="P:TorchSharp.torch.distributions.constraints._IndependentConstraint.event_dim">
            <summary>
            Number of rightmost dimensions that together define an event.
            The check() method will remove this many dimensions when computing validity.
            </summary>
        </member>
        <member name="T:TorchSharp.torch.distributions.constraints._Boolean">
            <summary>
            Constrain to the two values {0, 1}.
            </summary>
        </member>
        <member name="T:TorchSharp.torch.distributions.constraints._OneHot">
            <summary>
            Constrain to one-hot vectors.
            </summary>
        </member>
        <member name="T:TorchSharp.torch.distributions.constraints._IntegerInterval">
            <summary>
            Constrain to an integer interval [lower_bound, upper_bound].
            </summary>
        </member>
        <member name="T:TorchSharp.torch.distributions.constraints._IntegerLessThan">
            <summary>
            Constrain to an integer interval [-inf, upper_bound].
            </summary>
        </member>
        <member name="T:TorchSharp.torch.distributions.constraints._IntegerGreaterThan">
            <summary>
            Constrain to an integer interval [lower_bound, inf].
            </summary>
        </member>
        <member name="T:TorchSharp.torch.distributions.constraints._Real">
            <summary>
            Trivially constrain to the extended real numbers [-inf, inf].
            </summary>
        </member>
        <member name="T:TorchSharp.torch.distributions.constraints._Interval">
            <summary>
            Constrain to an interval [lower_bound, upper_bound].
            </summary>
        </member>
        <member name="T:TorchSharp.torch.distributions.constraints._HalfOpenInterval">
            <summary>
            Constrain to an interval [lower_bound, upper_bound).
            </summary>
        </member>
        <member name="T:TorchSharp.torch.distributions.constraints._GreaterThan">
            <summary>
            Constrain to an interval (lower_bound, inf].
            </summary>
        </member>
        <member name="T:TorchSharp.torch.distributions.constraints._GreaterThanEq">
            <summary>
            Constrain to an interval [lower_bound, inf].
            </summary>
        </member>
        <member name="T:TorchSharp.torch.distributions.constraints._LessThan">
            <summary>
            Constrain to an integer interval [-inf, upper_bound).
            </summary>
        </member>
        <member name="T:TorchSharp.torch.distributions.constraints._Simplex">
            <summary>
            Constrain to the unit simplex in the innermost (rightmost) dimension.
            Specifically: `x >= 0` and `x.sum(-1) == 1`.
            </summary>
        </member>
        <member name="T:TorchSharp.torch.distributions.constraints._Multinomial">
            <summary>
            Constrain to nonnegative integer values summing to at most an upper bound.
            </summary>
        </member>
        <member name="T:TorchSharp.torch.distributions.constraints._LowerTriangular">
            <summary>
            Constrain to lower-triangular square matrices.
            </summary>
        </member>
        <member name="T:TorchSharp.torch.distributions.constraints._LowerCholesky">
            <summary>
            Constrain to lower-triangular square matrices with positive diagonals.
            </summary>
        </member>
        <member name="T:TorchSharp.torch.distributions.constraints._CorrCholesky">
            <summary>
            Constrain to lower-triangular square matrices with positive diagonals and each
            row vector being of unit length.
            </summary>
        </member>
        <member name="T:TorchSharp.torch.distributions.constraints._Square">
            <summary>
            Constrain to square matrices.
            </summary>
        </member>
        <member name="T:TorchSharp.torch.distributions.constraints._Symmetric">
            <summary>
            Constrain to symmetric square matrices.
            </summary>
        </member>
        <member name="T:TorchSharp.torch.distributions.constraints._PositiveSemiDefinite">
            <summary>
            Constrain to positive-semidefinite matrices.
            </summary>
        </member>
        <member name="T:TorchSharp.torch.distributions.constraints._PositiveDefinite">
            <summary>
            Constrain to positive-definite matrices.
            </summary>
        </member>
        <member name="T:TorchSharp.torch.distributions.constraints._Cat">
            <summary>
            Constraint functor that applies a sequence of constraints cseq at the submatrices at dimension dim,
            each of size lengths[dim], in a way compatible with torch.cat().
            </summary>
        </member>
        <member name="T:TorchSharp.torch.distributions.constraints._Stack">
            <summary>
            Constraint functor that applies a sequence of constraints cseq at the submatrices at dimension dim,
            each of size lengths[dim], in a way compatible with torch.cat().
            </summary>
        </member>
        <member name="M:TorchSharp.torch.distributions.Dirichlet(TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Creates a Dirichlet distribution parameterized by shape `concentration` and `rate`.
            </summary>
            <param name="concentration">Shape parameter of the distribution (often referred to as 'α')</param>
            <param name="generator">An optional random number generator object.</param>
        </member>
        <member name="P:TorchSharp.torch.distributions.Distribution.batch_shape">
            <summary>
            The shape over which parameters are batched.
            </summary>
        </member>
        <member name="P:TorchSharp.torch.distributions.Distribution.event_shape">
            <summary>
            The shape of a single sample (without batching).
            </summary>
        </member>
        <member name="P:TorchSharp.torch.distributions.Distribution.mean">
            <summary>
            The mean of the distribution.
            </summary>
        </member>
        <member name="P:TorchSharp.torch.distributions.Distribution.mode">
            <summary>
            The mode of the distribution.
            </summary>
        </member>
        <member name="P:TorchSharp.torch.distributions.Distribution.variance">
            <summary>
            The variance of the distribution
            </summary>
        </member>
        <member name="P:TorchSharp.torch.distributions.Distribution.stddev">
            <summary>
            The standard deviation of the distribution
            </summary>
        </member>
        <member name="M:TorchSharp.torch.distributions.Distribution.sample(System.Int64[])">
            <summary>
            Generates a sample_shape shaped sample or sample_shape shaped batch of samples if the distribution parameters are batched.
            </summary>
            <param name="sample_shape">A list of dimension sizes</param>
            <returns>A tensor containing the sample.</returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.Distribution.sample(TorchSharp.torch.Size)">
            <summary>
            Generates a sample_shape shaped sample or sample_shape shaped batch of samples if the distribution parameters are batched.
            </summary>
            <param name="sample_shape">A list of dimension sizes</param>
            <returns>A tensor containing the sample.</returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.Distribution.rsample(System.Int64[])">
            <summary>
             Generates a sample_shape shaped reparameterized sample or sample_shape shaped batch of reparameterized samples
             if the distribution parameters are batched.
            </summary>
            <param name="sample_shape">The sample shape.</param>
            <returns>A tensor containing the sample.</returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.Distribution.rsample(TorchSharp.torch.Size)">
            <summary>
             Generates a sample_shape shaped reparameterized sample or sample_shape shaped batch of reparameterized samples
             if the distribution parameters are batched.
            </summary>
            <param name="sample_shape">The sample shape.</param>
            <returns>A tensor containing the sample.</returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.Distribution.log_prob(TorchSharp.torch.Tensor)">
            <summary>
            Returns the log of the probability density/mass function evaluated at `value`.
            </summary>
            <param name="value"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.Distribution.entropy">
            <summary>
            Returns entropy of distribution, batched over batch_shape.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.Distribution.expand(TorchSharp.torch.Size,TorchSharp.torch.distributions.Distribution)">
            <summary>
            Returns a new distribution instance (or populates an existing instance provided by a derived class) with batch dimensions expanded to
            `batch_shape`. This method calls `torch.Tensor.expand()` on the distribution's parameters. As such, this does not allocate new
            memory for the expanded distribution instance.
            </summary>
            <param name="batch_shape">Tthe desired expanded size.</param>
            <param name="instance">new instance provided by subclasses that need to override `.expand`.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.Distribution.cdf(TorchSharp.torch.Tensor)">
            <summary>
            Returns the cumulative density/mass function evaluated at `value`.
            </summary>
            <param name="value"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.Distribution.icdf(TorchSharp.torch.Tensor)">
            <summary>
            Returns the inverse cumulative density/mass function evaluated at `value`.
            </summary>
            <param name="value"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.Distribution.enumerate_support(System.Boolean)">
             <summary>
             Returns tensor containing all values supported by a discrete distribution. The result will enumerate over dimension 0, so the shape
             of the result will be `(cardinality,) + batch_shape + event_shape` (where `event_shape = ()` for univariate distributions).
            
             Note that this enumerates over all batched tensors in lock-step `[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens
             along dim 0, but with the remaining batch dimensions being singleton dimensions, `[[0], [1], ..`
             </summary>
             <param name="expand">Whether to expand the support over the batch dims to match the distribution's `batch_shape`.</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.Distribution.perplexity">
            <summary>
            Returns perplexity of distribution, batched over batch_shape.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.Exponential(TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Creates a Exponential distribution parameterized by `rate`.
            </summary>
            <param name="rate">rate = 1 / scale of the distribution (often referred to as 'β')</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="T:TorchSharp.torch.distributions.ExponentialFamily">
            <summary>
            Base class for all distributions in the exponential family.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.distributions.ExponentialFamily.entropy">
            <summary>
            Returns entropy of distribution, batched over batch_shape.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.distributions.ExpRelaxedCategorical(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Creates a ExpRelaxedCategorical parameterized by `temperature`, and either `probs` or `logits` (but not both).
            Returns the log of a point in the simplex.
            </summary>
            <param name="temperature">Relaxation temperature</param>
            <param name="probs">The probability of sampling '1'</param>
            <param name="logits">The log-odds of sampling '1'</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.ExpRelaxedCategorical(TorchSharp.torch.Tensor,System.Nullable{System.Single},System.Nullable{System.Single},TorchSharp.torch.Generator)">
            <summary>
            Creates a ExpRelaxedCategorical parameterized by `temperature`, and either `probs` or `logits` (but not both).
            Returns the log of a point in the simplex.
            </summary>
            <param name="temperature">Relaxation temperature</param>
            <param name="probs">The probability of sampling '1'</param>
            <param name="logits">The log-odds of sampling '1'</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.ExpRelaxedCategorical(TorchSharp.torch.Tensor,System.Nullable{System.Double},System.Nullable{System.Double},TorchSharp.torch.Generator)">
            <summary>
            Creates a ExpRelaxedCategorical parameterized by `temperature`, and either `probs` or `logits` (but not both).
            Returns the log of a point in the simplex.
            </summary>
            <param name="temperature">Relaxation temperature</param>
            <param name="probs">The probability of sampling '1'</param>
            <param name="logits">The log-odds of sampling '1'</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.FisherSnedecor(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Creates a Fisher-Snedecor distribution parameterized by `df1` and `df2`.
            </summary>
            <param name="df1">Degrees of freedom parameter 1</param>
            <param name="df2">Degrees of freedom parameter 2</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.Gamma(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Creates a Gamma distribution parameterized by shape `concentration` and `rate`.
            </summary>
            <param name="concentration">Shape parameter of the distribution (often referred to as 'α')</param>
            <param name="rate">rate = 1 / scale of the distribution (often referred to as 'β')</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.Geometric(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
             <summary>
             Creates a Geometric distribution parameterized by probs,
             where probs is the probability of success of Bernoulli trials.
            
             It represents the probability that in k+1 Bernoulli trials, the
             first k trials failed, before seeing a success.
             </summary>
             <param name="probs">The probability of sampling '1'. Must be in range (0, 1]</param>
             <param name="logits">The log-odds of sampling '1'</param>
             <param name="generator">An optional random number generator object.</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.Gumbel(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Samples from a Gumbel Distribution.
            </summary>
            <param name="loc">Location parameter of the distribution.</param>
            <param name="scale">Scale parameter of the distribution.</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.HalfCauchy(TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Creates a half-Cauchy distribution parameterized by `scale`
            </summary>
            <param name="scale">Scale parameter of the distribution.</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.HalfNormal(TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Creates a half-normal distribution parameterized by `scale`
            </summary>
            <param name="scale">Scale parameter of the distribution.</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.Independent(TorchSharp.torch.distributions.Distribution,System.Int32,TorchSharp.torch.Generator)">
            <summary>
             Reinterprets some of the batch dims of a distribution as event dims.
             This is mainly useful for changing the shape of the result of `log_prob`.
            </summary>
            <param name="base_distribution">A base distribution.</param>
            <param name="reinterpreted_batch_dims">the number of batch dims to reinterpret as event dims</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.Kumaraswamy(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Samples from a Kumaraswamy distribution.
            </summary>
            <param name="concentration1">1st concentration parameter of the distribution</param>
            <param name="concentration0">2nd concentration parameter of the distribution</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.Laplace(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Creates a Laplace distribution parameterized by :attr:`loc` and :attr:`scale`.
            </summary>
            <param name="loc">Mode or median of the distribution.</param>
            <param name="scale">Standard deviation.</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.Laplace(System.Single,System.Single,TorchSharp.torch.Generator)">
            <summary>
            Creates a Laplace distribution parameterized by :attr:`loc` and :attr:`scale`.
            </summary>
            <param name="loc">Mode or median of the distribution.</param>
            <param name="scale">Standard deviation.</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.Laplace(System.Double,System.Double,TorchSharp.torch.Generator)">
            <summary>
            Creates a Laplace distribution parameterized by :attr:`loc` and :attr:`scale`.
            </summary>
            <param name="loc">Mode or median of the distribution.</param>
            <param name="scale">Standard deviation.</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.LogitRelaxedBernoulli(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Creates a LogitRelaxedBernoulli distribution parameterized by `probs` or 'logits` (but not both),
            which is the logit of a RelaxedBernoulli distribution.
            </summary>
            <param name="temperature">Relaxation temperature</param>
            <param name="probs">The probability of sampling '1'</param>
            <param name="logits">The log-odds of sampling '1'</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.LogitRelaxedBernoulli(TorchSharp.torch.Tensor,System.Nullable{System.Single},System.Nullable{System.Single},TorchSharp.torch.Generator)">
            <summary>
            Creates a LogitRelaxedBernoulli distribution parameterized by `probs` or 'logits` (but not both),
            which is the logit of a RelaxedBernoulli distribution.
            </summary>
            <param name="temperature">Relaxation temperature</param>
            <param name="probs">The probability of sampling '1'</param>
            <param name="logits">The log-odds of sampling '1'</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.LogitRelaxedBernoulli(TorchSharp.torch.Tensor,System.Nullable{System.Double},System.Nullable{System.Double},TorchSharp.torch.Generator)">
            <summary>
            Creates a LogitRelaxedBernoulli distribution parameterized by `probs` or 'logits` (but not both),
            which is the logit of a RelaxedBernoulli distribution.
            </summary>
            <param name="temperature">Relaxation temperature</param>
            <param name="probs">The probability of sampling '1'</param>
            <param name="logits">The log-odds of sampling '1'</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.LogNormal(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Creates a log-normal distribution parameterized by `loc` and `scale`
            </summary>
            <param name="loc">Mode or median of the distribution.</param>
            <param name="scale">Standard deviation.</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.Multinomial(System.Int32,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Creates a Multinomial distribution parameterized by `probs` or `logits` (but not both).
            `total_count` must be broadcastable with `probs`/`logits`.
            </summary>
            <param name="total_count">Number of Bernoulli trials</param>
            <param name="probs">The probability of sampling '1'</param>
            <param name="logits">The log-odds of sampling '1'</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.Multinomial(System.Int32,System.Int32,TorchSharp.torch.Generator)">
            <summary>
            Creates an equal-probability multinomial distribution parameterized by the number of categories.
            `total_count` must be broadcastable with `probs`/`logits`.
            </summary>
            <param name="total_count">Number of Bernoulli trials</param>
            <param name="categories">The number of categories.</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.MultivariateNormal(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Creates a MultivariateNormal distribution parameterized by `probs` or `logits` (but not both).
            `total_count` must be broadcastable with `probs`/`logits`.
            </summary>
            <param name="loc"></param>
            <param name="covariance_matrix"></param>
            <param name="precision_matrix"></param>
            <param name="scale_tril"></param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.NegativeBinomial(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Creates a NegativeBinomial distribution parameterized by `probs` or `logits` (but not both).
            `total_count` must be broadcastable with `probs`/`logits`.
            </summary>
            <param name="total_count">Number of Bernoulli trials</param>
            <param name="probs">The probability of sampling '1'</param>
            <param name="logits">The log-odds of sampling '1'</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.NegativeBinomial(System.Int32,System.Nullable{System.Single},System.Nullable{System.Single},TorchSharp.torch.Generator)">
            <summary>
            Creates a NegativeBinomial distribution parameterized by `probs` or `logits` (but not both).
            </summary>
            <param name="total_count">Number of Bernoulli trials</param>
            <param name="probs">The probability of sampling '1'</param>
            <param name="logits">The log-odds of sampling '1'</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.NegativeBinomial(System.Int32,System.Nullable{System.Double},System.Nullable{System.Double},TorchSharp.torch.Generator)">
            <summary>
            Creates a NegativeBinomial distribution parameterized by `probs` or `logits` (but not both).
            </summary>
            <param name="total_count">Number of Bernoulli trials</param>
            <param name="probs">The probability of sampling '1'</param>
            <param name="logits">The log-odds of sampling '1'</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.Normal(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Samples from a Normal (Gaussian) distribution. The distribution of the ratio of
            independent normally distributed random variables with means `0` follows a Normal distribution.
            </summary>
            <param name="loc">Mode or median of the distribution.</param>
            <param name="scale">Standard deviation.</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.Normal(System.Single,System.Single,TorchSharp.torch.Generator)">
            <summary>
            Samples from a Normal (Gaussian) distribution. The distribution of the ratio of
            independent normally distributed random variables with means `0` follows a Normal distribution.
            </summary>
            <param name="loc">Mode or median of the distribution.</param>
            <param name="scale">Standard deviation.</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.Normal(System.Double,System.Double,TorchSharp.torch.Generator)">
            <summary>
            Samples from a Normal (Gaussian) distribution. The distribution of the ratio of
            independent normally distributed random variables with means `0` follows a Normal distribution.
            </summary>
            <param name="loc">Mode or median of the distribution.</param>
            <param name="scale">Standard deviation.</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.OneHotCategorical(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Creates a Bernoulli distribution parameterized by `probs` or `logits` (but not both).
            </summary>
            <param name="probs">The probability of sampling '1'</param>
            <param name="logits">The log-odds of sampling '1'</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.OneHotCategorical(System.Nullable{System.Single},System.Nullable{System.Single},TorchSharp.torch.Generator)">
            <summary>
            Creates a Bernoulli distribution parameterized by `probs` or `logits` (but not both).
            </summary>
            <param name="probs">The probability of sampling '1'</param>
            <param name="logits">The log-odds of sampling '1'</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.OneHotCategorical(System.Nullable{System.Double},System.Nullable{System.Double},TorchSharp.torch.Generator)">
            <summary>
            Creates a Bernoulli distribution parameterized by `probs` or `logits` (but not both).
            </summary>
            <param name="probs">The probability of sampling '1'</param>
            <param name="logits">The log-odds of sampling '1'</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.Pareto(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Samples from a Pareto Type 1 distribution.
            </summary>
            <param name="scale">Scale parameter of the distribution.</param>
            <param name="alpha">Shape parameter of the distribution</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.Poisson(TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Creates a Poisson distribution parameterized by `rate`.
            </summary>
            <param name="rate">rate = 1 / scale of the distribution (often referred to as 'β')</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.Poisson(System.Single,TorchSharp.torch.Generator)">
            <summary>
            Creates a Poisson distribution parameterized by `rate`.
            </summary>
            <param name="rate">rate = 1 / scale of the distribution (often referred to as 'β')</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.Poisson(System.Double,TorchSharp.torch.Generator)">
            <summary>
            Creates a Poisson distribution parameterized by `rate`.
            </summary>
            <param name="rate">rate = 1 / scale of the distribution (often referred to as 'β')</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.RelaxedBernoulli(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Creates a RelaxedBernoulli distribution, parametrized by `temperature`, and either `probs` or `logits` (but not both).
            This is a relaxed version of the `Bernoulli` distribution, so the values are in (0, 1), and has reparametrizable samples.
            </summary>
            <param name="temperature">Relaxation temperature</param>
            <param name="probs">The probability of sampling '1'</param>
            <param name="logits">The log-odds of sampling '1'</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.RelaxedBernoulli(TorchSharp.torch.Tensor,System.Nullable{System.Single},System.Nullable{System.Single},TorchSharp.torch.Generator)">
            <summary>
            Creates a RelaxedBernoulli distribution, parametrized by `temperature`, and either `probs` or `logits` (but not both).
            This is a relaxed version of the `Bernoulli` distribution, so the values are in (0, 1), and has reparametrizable samples.
            </summary>
            <param name="temperature">Relaxation temperature</param>
            <param name="probs">The probability of sampling '1'</param>
            <param name="logits">The log-odds of sampling '1'</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.RelaxedBernoulli(TorchSharp.torch.Tensor,System.Nullable{System.Double},System.Nullable{System.Double},TorchSharp.torch.Generator)">
            <summary>
            Creates a RelaxedBernoulli distribution, parametrized by `temperature`, and either `probs` or `logits` (but not both).
            This is a relaxed version of the `Bernoulli` distribution, so the values are in (0, 1), and has reparametrizable samples.
            </summary>
            <param name="temperature">Relaxation temperature</param>
            <param name="probs">The probability of sampling '1'</param>
            <param name="logits">The log-odds of sampling '1'</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.RelaxedOneHotCategorical(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Creates a RelaxedOneHotCategorical distribution, parametrized by `temperature`, and either `probs` or `logits` (but not both).
            This is a relaxed version of the `OneHotCategorical` distribution, so its samples are on simplex, and are reparametrizable..
            </summary>
            <param name="temperature">Relaxation temperature</param>
            <param name="probs">The probability of sampling '1'</param>
            <param name="logits">The log-odds of sampling '1'</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.RelaxedOneHotCategorical(TorchSharp.torch.Tensor,System.Nullable{System.Single},System.Nullable{System.Single},TorchSharp.torch.Generator)">
            <summary>
            Creates a RelaxedOneHotCategorical distribution, parametrized by `temperature`, and either `probs` or `logits` (but not both).
            This is a relaxed version of the `OneHotCategorical` distribution, so its samples are on simplex, and are reparametrizable..
            </summary>
            <param name="temperature">Relaxation temperature</param>
            <param name="probs">The probability of sampling '1'</param>
            <param name="logits">The log-odds of sampling '1'</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.RelaxedOneHotCategorical(TorchSharp.torch.Tensor,System.Nullable{System.Double},System.Nullable{System.Double},TorchSharp.torch.Generator)">
            <summary>
            Creates a RelaxedOneHotCategorical distribution, parametrized by `temperature`, and either `probs` or `logits` (but not both).
            This is a relaxed version of the `OneHotCategorical` distribution, so its samples are on simplex, and are reparametrizable..
            </summary>
            <param name="temperature">Relaxation temperature</param>
            <param name="probs">The probability of sampling '1'</param>
            <param name="logits">The log-odds of sampling '1'</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="T:TorchSharp.torch.distributions.transforms.Transform">
             <summary>
             Abstract class for invertable transformations with computable log det jacobians.
            
             They are primarily used in torch.distributions.TransformedDistribution.
             </summary>
             <remarks>
             Derived classes should implement one or both of 'forward()' or 'inverse()'.
             Derived classes that set `bijective=true` should also implement 'log_abs_det_jacobian()'
             </remarks>
        </member>
        <member name="M:TorchSharp.torch.distributions.Uniform(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Generates uniformly distributed random samples from the half-open interval [low, high[.
            </summary>
            <param name="low">Lower bound (inclusive)</param>
            <param name="high">Upper bound (exclusive)</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.distributions.Weibull(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Samples from a two-parameter Weibull distribution.
            </summary>
            <param name="concentration">Concentration parameter of distribution (k/shape).</param>
            <param name="scale">Scale parameter of the distribution.</param>
            <param name="generator">An optional random number generator object.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.fft.fft_(TorchSharp.torch.Tensor,System.Int64,System.Int64,TorchSharp.FFTNormType)">
            <summary>
            Computes the one dimensional discrete Fourier transform of input.
            </summary>
            <param name="input">The input tensor</param>
            <param name="n">Signal length. If given, the input will either be zero-padded or trimmed to this length before computing the FFT.</param>
            <param name="dim">The dimension along which to take the one dimensional FFT.</param>
            <param name="norm">Normalization mode.</param>
            <returns></returns>
            <remarks>The name was changed because it would conflict with its surrounding scope. That's not legal in .NET.</remarks>
        </member>
        <member name="M:TorchSharp.torch.fft.ifft(TorchSharp.torch.Tensor,System.Int64,System.Int64,TorchSharp.FFTNormType)">
            <summary>
            Computes the one dimensional inverse discrete Fourier transform of input.
            </summary>
            <param name="input">The input tensor</param>
            <param name="n">Signal length. If given, the input will either be zero-padded or trimmed to this length before computing the IFFT.</param>
            <param name="dim">The dimension along which to take the one dimensional IFFT.</param>
            <param name="norm">Normalization mode.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.fft.fft2(TorchSharp.torch.Tensor,System.Int64[],System.Int64[],TorchSharp.FFTNormType)">
            <summary>
            Computes the two-dimensional discrete Fourier transform of input.
            </summary>
            <param name="input">The input tensor</param>
            <param name="s">
            Signal size in the transformed dimensions.
            If given, each dimension dim[i] will either be zero-padded or trimmed to the length s[i] before computing the FFT.
            If a length -1 is specified, no padding is done in that dimension.
            </param>
            <param name="dim">Dimensions to be transformed</param>
            <param name="norm">Normalization mode.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.fft.ifft2(TorchSharp.torch.Tensor,System.Int64[],System.Int64[],TorchSharp.FFTNormType)">
            <summary>
            Computes the two-dimensional inverse discrete Fourier transform of input.
            </summary>
            <param name="input">The input tensor</param>
            <param name="s">
            Signal size in the transformed dimensions.
            If given, each dimension dim[i] will either be zero-padded or trimmed to the length s[i] before computing the IFFT.
            If a length -1 is specified, no padding is done in that dimension.
            </param>
            <param name="dim">Dimensions to be transformed</param>
            <param name="norm">Normalization mode.</param>
        </member>
        <member name="M:TorchSharp.torch.fft.fftn(TorchSharp.torch.Tensor,System.Int64[],System.Int64[],TorchSharp.FFTNormType)">
            <summary>
            Computes the N-dimensional discrete Fourier transform of input.
            </summary>
            <param name="input">The input tensor</param>
            <param name="s">
            Signal size in the transformed dimensions.
            If given, each dimension dim[i] will either be zero-padded or trimmed to the length s[i] before computing the IFFT.
            If a length -1 is specified, no padding is done in that dimension.
            </param>
            <param name="dim">Dimensions to be transformed</param>
            <param name="norm">Normalization mode.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.fft.ifftn(TorchSharp.torch.Tensor,System.Int64[],System.Int64[],TorchSharp.FFTNormType)">
            <summary>
            Computes the N-dimensional inverse discrete Fourier transform of input.
            </summary>
            <param name="input">The input tensor</param>
            <param name="s">
            Signal size in the transformed dimensions.
            If given, each dimension dim[i] will either be zero-padded or trimmed to the length s[i] before computing the IFFT.
            If a length -1 is specified, no padding is done in that dimension.
            </param>
            <param name="dim">Dimensions to be transformed</param>
            <param name="norm">Normalization mode.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.fft.irfft(TorchSharp.torch.Tensor,System.Int64,System.Int64,TorchSharp.FFTNormType)">
            <summary>
            Computes the one dimensional inverse Fourier transform of real-valued input.
            </summary>
            <param name="input">The input tensor</param>
            <param name="n">Signal length. If given, the input will either be zero-padded or trimmed to this length before computing the FFT.</param>
            <param name="dim">The dimension along which to take the one dimensional FFT.</param>
            <param name="norm">Normalization mode.</param>
        </member>
        <member name="M:TorchSharp.torch.fft.rfft(TorchSharp.torch.Tensor,System.Int64,System.Int64,TorchSharp.FFTNormType)">
            <summary>
            Computes the one dimensional Fourier transform of real-valued input.
            </summary>
            <param name="input">The input tensor</param>
            <param name="n">Signal length. If given, the input will either be zero-padded or trimmed to this length before computing the FFT.</param>
            <param name="dim">The dimension along which to take the one dimensional FFT.</param>
            <param name="norm">Normalization mode.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.fft.rfft2(TorchSharp.torch.Tensor,System.Int64[],System.Int64[],TorchSharp.FFTNormType)">
            <summary>
            Computes the two-dimensional discrete Fourier transform of real-vaued input.
            </summary>
            <param name="input">The input tensor</param>
            <param name="s">
            Signal size in the transformed dimensions.
            If given, each dimension dim[i] will either be zero-padded or trimmed to the length s[i] before computing the FFT.
            If a length -1 is specified, no padding is done in that dimension.
            </param>
            <param name="dim">Dimensions to be transformed</param>
            <param name="norm">Normalization mode.</param>
        </member>
        <member name="M:TorchSharp.torch.fft.irfft2(TorchSharp.torch.Tensor,System.Int64[],System.Int64[],TorchSharp.FFTNormType)">
            <summary>
            Computes the two-dimensional inverse discrete Fourier transform of real-valued input.
            </summary>
            <param name="input">The input tensor</param>
            <param name="s">
            Signal size in the transformed dimensions.
            If given, each dimension dim[i] will either be zero-padded or trimmed to the length s[i] before computing the IFFT.
            If a length -1 is specified, no padding is done in that dimension.
            </param>
            <param name="dim">Dimensions to be transformed</param>
            <param name="norm">Normalization mode.</param>
        </member>
        <member name="M:TorchSharp.torch.fft.rfftn(TorchSharp.torch.Tensor,System.Int64[],System.Int64[],TorchSharp.FFTNormType)">
            <summary>
            Computes the N-dimensional discrete Fourier transform of real-valued input.
            </summary>
            <param name="input">The input tensor</param>
            <param name="s">
            Signal size in the transformed dimensions.
            If given, each dimension dim[i] will either be zero-padded or trimmed to the length s[i] before computing the IFFT.
            If a length -1 is specified, no padding is done in that dimension.
            </param>
            <param name="dim">Dimensions to be transformed</param>
            <param name="norm">Normalization mode.</param>
        </member>
        <member name="M:TorchSharp.torch.fft.irfftn(TorchSharp.torch.Tensor,System.Int64[],System.Int64[],TorchSharp.FFTNormType)">
            <summary>
            Computes the N-dimensional inverse discrete Fourier transform of real-valued input.
            </summary>
            <param name="input">The input tensor</param>
            <param name="s">
            Signal size in the transformed dimensions.
            If given, each dimension dim[i] will either be zero-padded or trimmed to the length s[i] before computing the IFFT.
            If a length -1 is specified, no padding is done in that dimension.
            </param>
            <param name="dim">Dimensions to be transformed</param>
            <param name="norm">Normalization mode.</param>
        </member>
        <member name="M:TorchSharp.torch.fft.hfft(TorchSharp.torch.Tensor,System.Int64,System.Int64,TorchSharp.FFTNormType)">
            <summary>
            Computes the one dimensional discrete Fourier transform of a Hermitian symmetric input signal.
            </summary>
            <param name="input">The input tensor representing a half-Hermitian signal</param>
            <param name="n">
            Output signal length. This determines the length of the real output.
            If given, the input will either be zero-padded or trimmed to this length before computing the Hermitian FFT.</param>
            <param name="dim">The dimension along which to take the one dimensional Hermitian FFT.</param>
            <param name="norm">Normalization mode.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.fft.ihfft(TorchSharp.torch.Tensor,System.Int64,System.Int64,TorchSharp.FFTNormType)">
            <summary>
            Computes the inverse of hfft().
            </summary>
            <param name="input">The input tensor representing a half-Hermitian signal</param>
            <param name="n">
            Output signal length. This determines the length of the real output.
            If given, the input will either be zero-padded or trimmed to this length before computing the Hermitian FFT.</param>
            <param name="dim">The dimension along which to take the one dimensional Hermitian FFT.</param>
            <param name="norm">Normalization mode.</param>
        </member>
        <member name="M:TorchSharp.torch.fft.fftshift(TorchSharp.torch.Tensor,System.Int64[])">
            <summary>
            Reorders n-dimensional FFT data, as provided by fftn(), to have negative frequency terms first.
            This performs a periodic shift of n-dimensional data such that the origin(0, ..., 0) is moved to the center of the tensor.Specifically, to input.shape[dim] // 2 in each selected dimension.
            </summary>
            <param name="input">The tensor in FFT order</param>
            <param name="dim">The dimensions to rearrange. Only dimensions specified here will be rearranged, any other dimensions will be left in their original order. Default: All dimensions of input.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.fft.ifftshift(TorchSharp.torch.Tensor,System.Int64[])">
            <summary>
            Inverse of fftshift().
            </summary>
            <param name="input">The tensor in FFT order</param>
            <param name="dim">The dimensions to rearrange. Only dimensions specified here will be rearranged, any other dimensions will be left in their original order. Default: All dimensions of input.</param>
        </member>
        <member name="M:TorchSharp.torch.fft.fftfreq(System.Int64,System.Double,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Computes the discrete Fourier Transform sample frequencies for a signal of size n.
            </summary>
            <param name="n">The FFT length</param>
            <param name="d">The sampling length scale. </param>
            <param name="dtype">The desired data type of the returned tensor</param>
            <param name="device">the desired device of the returned tensor</param>
            <param name="requires_grad">If autograd should record operations on the returned tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.fft.rfftfreq(System.Int64,System.Double,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Computes the sample frequencies for rfft() with a signal of size n.
            </summary>
            <param name="n">The FFT length</param>
            <param name="d">The sampling length scale. </param>
            <param name="dtype">The desired data type of the returned tensor</param>
            <param name="device">the desired device of the returned tensor</param>
            <param name="requires_grad">If autograd should record operations on the returned tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.fft.hfft2(TorchSharp.torch.Tensor,System.Int64[],System.Int64[],TorchSharp.FFTNormType)">
             <summary>
             Computes the 2-dimensional discrete Fourier transform of a Hermitian symmetric input signal.
            
             Equivalent to hfftn() but only transforms the last two dimensions by default.
             input is interpreted as a one-sided Hermitian signal in the time domain.
             By the Hermitian property, the Fourier transform will be real-valued.
             </summary>
             <param name="input">The input tensor</param>
             <param name="s">
             Signal size in the transformed dimensions.
             If given, each dimension dim[i] will either be zero-padded or trimmed to the length s[i] before computing the IFFT.
             If a length -1 is specified, no padding is done in that dimension.
             </param>
             <param name="dim">Dimensions to be transformed</param>
             <param name="norm">Normalization mode.</param>
        </member>
        <member name="M:TorchSharp.torch.fft.ihfft2(TorchSharp.torch.Tensor,System.Int64[],System.Int64[],TorchSharp.FFTNormType)">
             <summary>
             Computes the 2-dimensional inverse discrete Fourier transform of a Hermitian symmetric input signal.
            
             Equivalent to hfftn() but only transforms the last two dimensions by default.
             input is interpreted as a one-sided Hermitian signal in the time domain.
             By the Hermitian property, the Fourier transform will be real-valued.
             </summary>
             <param name="input">The input tensor</param>
             <param name="s">
             Signal size in the transformed dimensions.
             If given, each dimension dim[i] will either be zero-padded or trimmed to the length s[i] before computing the IFFT.
             If a length -1 is specified, no padding is done in that dimension.
             </param>
             <param name="dim">Dimensions to be transformed</param>
             <param name="norm">Normalization mode.</param>
        </member>
        <member name="M:TorchSharp.torch.fft.hfftn(TorchSharp.torch.Tensor,System.Int64[],System.Int64[],TorchSharp.FFTNormType)">
             <summary>
             Computes the n-dimensional discrete Fourier transform of a Herimitian symmetric input signal.
            
             input is interpreted as a one-sided Hermitian signal in the time domain.
             By the Hermitian property, the Fourier transform will be real-valued.
             </summary>
             <param name="input">The input tensor</param>
             <param name="s">
             Signal size in the transformed dimensions.
             If given, each dimension dim[i] will either be zero-padded or trimmed to the length s[i] before computing the IFFT.
             If a length -1 is specified, no padding is done in that dimension.
             </param>
             <param name="dim">Dimensions to be transformed</param>
             <param name="norm">Normalization mode.</param>
        </member>
        <member name="M:TorchSharp.torch.fft.ihfftn(TorchSharp.torch.Tensor,System.Int64[],System.Int64[],TorchSharp.FFTNormType)">
             <summary>
             Computes the n-dimensional inverse discrete Fourier transform of a Herimitian symmetric input signal.
            
             input is interpreted as a one-sided Hermitian signal in the time domain.
             By the Hermitian property, the Fourier transform will be real-valued.
             </summary>
             <param name="input">The input tensor</param>
             <param name="s">
             Signal size in the transformed dimensions.
             If given, each dimension dim[i] will either be zero-padded or trimmed to the length s[i] before computing the IFFT.
             If a length -1 is specified, no padding is done in that dimension.
             </param>
             <param name="dim">Dimensions to be transformed</param>
             <param name="norm">Normalization mode.</param>
        </member>
        <member name="T:TorchSharp.torch.Generator">
            <summary>
            Random Number Generator
            </summary>
        </member>
        <member name="P:TorchSharp.torch.Generator.device">
            <summary>
            Gets the current device of the generator.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Generator.get_state">
            <summary>
            Returns the Generator state as a torch.ByteTensor.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Generator.set_state(TorchSharp.torch.Tensor)">
            <summary>
            Sets the Generator state.
            </summary>
            <param name="value">The desired state.</param>
        </member>
        <member name="M:TorchSharp.torch.Generator.seed">
            <summary>
            Gets a non-deterministic random number from std::random_device or the current time and uses it to seed a Generator.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Generator.#ctor(System.UInt64,TorchSharp.torch.Device)">
            <summary>
            Constructor
            </summary>
            <param name="seed">An initial seed to use with the generator.</param>
            <param name="device">The desired device.</param>
        </member>
        <member name="M:TorchSharp.torch.Generator.initial_seed">
            <summary>
            Returns the initial seed for generating random numbers.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.hub.set_create_progress_bar_func(System.Func{System.Boolean,TorchSharp.IProgressBar})">
            <summary>
            Set a function to create a progress bar.
            </summary>
            <param name="func">A progress bar function or null to set default the console progress bar</param>
        </member>
        <member name="M:TorchSharp.torch.hub.CreateProgressBar(System.Boolean)">
            <summary>
            Create a progress bar.
            </summary>
            <param name="hidden">Make a hidden progress bar.</param>
            <returns>A progress bar</returns>
        </member>
        <member name="M:TorchSharp.torch.hub.download_url_to_file(System.String,System.String,System.String,System.Boolean)">
            <summary>
            Download the url to a file 
            </summary>
            <param name="url">The URL to download</param>
            <param name="dst">The file path to download the URL into</param>
            <param name="hash_prefix">If non null, the SHA256 hash of downloaded content must match this prefix</param>
            <param name="progress">whether or not to display a progress bar to stderr</param>
            <exception cref="T:System.IO.InvalidDataException">SHA256 hash doesn't match</exception>
        </member>
        <member name="M:TorchSharp.torch.hub.download_url_to_file_async(System.String,System.String,System.String,System.Boolean,System.Threading.CancellationToken)">
            <summary>
            Download the url to a file 
            </summary>
            <param name="url">The URL to download</param>
            <param name="dst">The file path to download the URL into</param>
            <param name="cancellationToken">A cancellation token</param>
            <param name="hash_prefix">If non null, the SHA256 hash of downloaded content must match this prefix</param>
            <param name="progress">whether or not to display a progress bar to stderr</param>
            <exception cref="T:System.IO.InvalidDataException">SHA256 hash doesn't match</exception>
        </member>
        <member name="T:TorchSharp.torch.jit.CompilationUnit">
             <summary>
             Represents a TorchScript compilation unit, i.e. a Python script file.
             </summary>
             <example>
             var cu = torch.jit.compile(@"
               def relu_script(a, b):
                 return torch.relu(a + b)
             ");
            
             var y = cu.invoke("relu_script", torch.randn(10));
             </example>
             <remarks>
             Currently, scripts are limited to defining functions. Classes will be ignored.
             </remarks>
        </member>
        <member name="M:TorchSharp.torch.jit.CompilationUnit.Dispose">
            <summary>
            Releases the storage.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.jit.CompilationUnit.Dispose(System.Boolean)">
            <summary>
            Implements the .NET Dispose pattern.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.jit.CompilationUnit.invoke(System.String,System.Object[])">
            <summary>
            Invoke a function from the compilation unit.
            </summary>
            <param name="name">The name of the function.</param>
            <param name="objs">Function arguments.</param>
        </member>
        <member name="M:TorchSharp.torch.jit.CompilationUnit.invoke``1(System.String,System.Object[])">
            <summary>
            Invoke a function from the compilation unit.
            </summary>
            <typeparam name="TResult">The return type of the TorchScript function.</typeparam>
            <param name="name">The name of the function.</param>
            <param name="inputs">Function arguments.</param>
        </member>
        <member name="M:TorchSharp.torch.jit.CompilationUnit.invoke``2(System.String,``0[])">
            <summary>
            Invoke a function from the compilation unit.
            </summary>
            <typeparam name="T">The type of all function arguments.</typeparam>
            <typeparam name="TResult">The return type of the TorchScript function.</typeparam>
            <param name="name">The name of the function.</param>
            <param name="inputs">Function arguments.</param>
        </member>
        <member name="M:TorchSharp.torch.jit.compile(System.String)">
            <summary>
            Create a TorchScript compilation unit containing TorchScript-compliant Python from a string.
            </summary>
            <param name="script">A string with Python code expressing a set of TorchScript functions.</param>
            <returns></returns>
        </member>
        <member name="T:TorchSharp.torch.jit.ScriptModule">
            <summary>
            This class represents a TorchScript module.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.jit.ScriptModule.named_modules">
            <summary>
            Returns an enumerable of all modules in the network, yielding both the name of the module as well as the module itself.
            </summary>
            <returns>(string, Module) – Tuple of name and module</returns>
        </member>
        <member name="M:TorchSharp.torch.jit.ScriptModule.named_children">
            <summary>
            Returns an enumerable of immediate children modules, yielding both the name of the module as well as the module itself.
            </summary>
            <returns>(string, Module) – Tuple containing a name and child module</returns>
        </member>
        <member name="M:TorchSharp.torch.jit.ScriptModule.train(System.Boolean)">
            <summary>
            Sets the module in evaluation mode.
            </summary>
            <remarks>
            Any script module that was created using torch.jit.trace() will be unaffected. The behavior of such
            modules will be captured when traced.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.jit.ScriptModule.eval">
            <summary>
            Sets the module in evaluation mode.
            </summary>
            <remarks>
            Any script module that was created using torch.jit.trace() will be unaffected. The behavior of such
            modules will be captured when traced.
            </remarks>
        </member>
        <member name="P:TorchSharp.torch.jit.ScriptModule.training">
            <summary>
            Check whether the module is set to training or evaluation mode.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.jit.ScriptModule._to(TorchSharp.DeviceType,System.Int32,System.Boolean)">
            <summary>
            Moves the parameters and buffers.
            </summary>
            <param name="deviceType">The device type, e.g. 'CPU' or 'CUDA'.</param>
            <param name="deviceIndex">The optional device index.</param>
            <param name="non_blocking">
            When non_blocking is set, it tries to convert/move asynchronously with respect to the host if possible, 
            e.g., moving CPU Tensors with pinned memory to CUDA devices.
            </param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.jit.ScriptModule._to(TorchSharp.torch.ScalarType,System.Boolean)">
            <summary>
            Convert the parameters and buffers.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.jit.ScriptModule.forward(System.Object[])">
             <summary>
             Invoke the 'forward' function of the script with any number of arguments.
             </summary>
             <param name="input">Any number of parameters for the forward function.</param>
             <returns>An object.</returns>
             <remarks>
             Only certain types can currently be passed:
             1. Tensor
             2. Scalar
             3. int/long
             4. double/float
             5. bool
            
             Only certain types can currently be returned:
             1. Tensor / Scalar
             2. Tuple of Tensor / Scalar
             3. Array (Python list) of Tensor / Scalar
            
             For returned types, if the number of values returned in a tuple is greaterh than 5, it is returned as an array, instead.
             If a tuple contains both tensors and scalars, it is returned as an object[].
             </remarks>
        </member>
        <member name="M:TorchSharp.torch.jit.ScriptModule.call(System.Object[])">
             <summary>
             Synonym for `forward`
             </summary>
             <param name="input">Any number of parameters for the forward function.</param>
             <returns>An object.</returns>
             <remarks>
             Only certain types can currently be passed:
             1. Tensor
             2. Scalar
             3. int/long
             4. double/float
             5. bool
            
             Only certain types can currently be returned:
             1. Tensor / Scalar
             2. Tuple of Tensor / Scalar
             3. Array (Python list) of Tensor / Scalar
            
             For returned types, if the number of values returned in a tuple is greaterh than 5, it is returned as an array, instead.
             If a tuple contains both tensors and scalars, it is returned as an object[].
            
             Note: this currently does not support hooking the module.
             </remarks>
        </member>
        <member name="M:TorchSharp.torch.jit.ScriptModule.invoke(System.String,System.Object[])">
             <summary>
             Invoke a function from the script module.
             </summary>
             <param name="name">The name of the function.</param>
             <param name="objs">Function arguments.</param>
             <remarks>
             Only certain types can currently be passed:
             1. Tensor
             2. Scalar
             3. int/long
             4. double/float
             5. bool
             6. 'null' object
             
             Only certain types can currently be returned:
             1. Tensor / Scalar
             2. Tuple of Tensor / Scalar
             3. Array (Python list) of Tensor / Scalar
             4. null object
            
             For returned types, if the number of values returned in a tuple is greaterh than 5, it is returned as an array, instead.
             If a tuple contains both tensors and scalars, it is returned as an object[].
             </remarks>
        </member>
        <member name="M:TorchSharp.torch.jit.ScriptModule.invoke``1(System.String,System.Object[])">
             <summary>
             Invoke a function from the script module.
             </summary>
             <typeparam name="TResult">The return type of the TorchScript function.</typeparam>
             <param name="name">The name of the function.</param>
             <param name="inputs">Function arguments.</param>
             <remarks>
             Only certain types can currently be passed:
             1. Tensor
             2. Scalar
             3. int/long
             4. double/float
             5. bool
            
             Only certain types can currently be returned:
             1. Tensor / Scalar
             2. Tuple of Tensor / Scalar
             3. Array (Python list) of Tensor / Scalar
            
             For returned types, if the number of values returned in a tuple is greaterh than 5, it is returned as an array, instead.
             If a tuple contains both tensors and scalars, it is returned as an object[].
             </remarks>
        </member>
        <member name="M:TorchSharp.torch.jit.ScriptModule.invoke``2(System.String,``0[])">
             <summary>
             Invoke a function from the script module.
             </summary>
             <typeparam name="T">The type of all function arguments.</typeparam>
             <typeparam name="TResult">The return type of the TorchScript function.</typeparam>
             <param name="name">The name of the function.</param>
             <param name="inputs">Function arguments.</param>
             <remarks>
             Only certain types can currently be passed:
             1. Tensor
             2. Scalar
             3. int/long
             4. double/float
             5. bool
            
             Only certain types can currently be returned:
             1. Tensor / Scalar
             2. Tuple of Tensor / Scalar
             3. Array (Python list) of Tensor / Scalar
            
             For returned types, if the number of values returned in a tuple is greaterh than 5, it is returned as an array, instead.
             If a tuple contains both tensors and scalars, it is returned as an object[].
             </remarks>
        </member>
        <member name="T:TorchSharp.torch.jit.HookableScriptModule`2">
            <summary>
            Represents a module that accepts 'hook' to the module logic.
            </summary>
        </member>
        <member name="T:TorchSharp.torch.jit.HookableScriptModule`2.HookRemover">
            <summary>
            Used to remove a specific hook, following the PyTorch API design.
            </summary>
            <remarks>The name and namespace of this class is not the same as in PyTorch, but serves the same purpose.</remarks>
        </member>
        <member name="T:TorchSharp.torch.jit.ScriptModule`1">
            <summary>
            A script module taking any number of tensors as input
            </summary>
            <typeparam name="TResult">The return type of the module.</typeparam>
        </member>
        <member name="M:TorchSharp.torch.jit.ScriptModule`1.call(TorchSharp.torch.Tensor[])">
             <summary>
             Invoke the 'forward' function of the script with one tensor as its argument
             </summary>
             <remarks>
             Only certain types can currently be passed:
             1. Tensor
             2. Scalar
             3. int/long
             4. double/float
             5. bool
            
             Only certain types can currently be returned:
             1. Tensor / Scalar
             2. Tuple of Tensor / Scalar
             3. Array (Python list) of Tensor / Scalar
            
             For returned types, if the number of values returned in a tuple is greaterh than 5, it is returned as an array, instead.
             If a tuple contains both tensors and scalars, it is returned as an object[].
             </remarks>
        </member>
        <member name="T:TorchSharp.torch.jit.ScriptModule`2">
            <summary>
            A script module taking a single argument.
            </summary>
            <typeparam name="T">The argument type.</typeparam>
            <typeparam name="TResult">The return type of the module.</typeparam>
        </member>
        <member name="M:TorchSharp.torch.jit.ScriptModule`2.call(`0)">
             <summary>
             Invoke the 'forward' function of the script with one tensor as its argument
             </summary>
             <remarks>
             Only certain types can currently be passed:
             1. Tensor
             2. Scalar
             3. int/long
             4. double/float
             5. bool
            
             Only certain types can currently be returned:
             1. Tensor / Scalar
             2. Tuple of Tensor / Scalar
             3. Array (Python list) of Tensor / Scalar
            
             For returned types, if the number of values returned in a tuple is greaterh than 5, it is returned as an array, instead.
             If a tuple contains both tensors and scalars, it is returned as an object[].
             </remarks>
        </member>
        <member name="T:TorchSharp.torch.jit.ScriptModule`3">
            <summary>
            A script module taking two arguments.
            </summary>
            <typeparam name="T1">The first argument type.</typeparam>
            <typeparam name="T2">The second argument type.</typeparam>
            <typeparam name="TResult">The return type of the module.</typeparam>
        </member>
        <member name="M:TorchSharp.torch.jit.ScriptModule`3.call(`0,`1)">
             <summary>
             Invoke the 'forward' function of the script with one tensor as its argument
             </summary>
             <remarks>
             Only certain types can currently be passed:
             1. Tensor
             2. Scalar
             3. int/long
             4. double/float
             5. bool
            
             Only certain types can currently be returned:
             1. Tensor / Scalar
             2. Tuple of Tensor / Scalar
             3. Array (Python list) of Tensor / Scalar
            
             For returned types, if the number of values returned in a tuple is greaterh than 5, it is returned as an array, instead.
             If a tuple contains both tensors and scalars, it is returned as an object[].
             </remarks>
        </member>
        <member name="M:TorchSharp.torch.jit.load(System.String,TorchSharp.DeviceType,System.Int64)">
            <summary>
            Load a ScriptModule or ScriptFunction previously saved with torch.jit.save
            </summary>
            <param name="filename">The file name of the module.</param>
            <param name="device_type">The device type, e.g. 'CPU' or 'CUDA'.</param>
            <param name="device_index">The optional device index.</param>
            <returns>A ScriptModule instance, whether the script originated as a module or function.</returns>
            <remarks>
            All previously saved modules, no matter their device, are first loaded onto CPU, and then are moved to the devices they were saved from.If this fails (e.g.because the run time system doesn’t have certain devices), an exception is raised.
            </remarks>
            <exception cref="T:System.IO.FileNotFoundException">Raised if the file is not found.</exception>
        </member>
        <member name="M:TorchSharp.torch.jit.load(System.Byte[],TorchSharp.DeviceType,System.Int64)">
            <summary>
            Load a ScriptModule or ScriptFunction previously saved with torch.jit.save
            </summary>
            <param name="bytes">A byte array holding a serialized module</param>
            <param name="device_type">The device type, e.g. 'CPU' or 'CUDA'.</param>
            <param name="device_index">The optional device index.</param>
            <returns>A ScriptModule instance, whether the script originated as a module or function.</returns>
            <remarks>
            All previously saved modules, no matter their device, are first loaded onto CPU, and then are moved to the devices they were saved from.If this fails (e.g.because the run time system doesn’t have certain devices), an exception is raised.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.jit.load(System.String,TorchSharp.torch.Device)">
            <summary>
            Load a ScriptModule or ScriptFunction previously saved with torch.jit.save
            </summary>
            <param name="filename">The file name of the module.</param>
            <param name="map_location">The device type where the script module should be loaded.</param>
            <returns>A ScriptModule instance, whether the script originated as a module or function.</returns>
            <remarks>
            All previously saved modules, no matter their device, are first loaded onto CPU, and then are moved to the devices they were saved from.If this fails (e.g.because the run time system doesn’t have certain devices), an exception is raised.
            </remarks>
            <exception cref="T:System.IO.FileNotFoundException">Raised if the file is not found.</exception>
        </member>
        <member name="M:TorchSharp.torch.jit.load(System.Byte[],TorchSharp.torch.Device)">
            <summary>
            Load a ScriptModule or ScriptFunction previously saved with torch.jit.save
            </summary>
            <param name="bytes">A byte array holding a serialized module</param>
            <param name="map_location">The device type where the script module should be loaded.</param>
            <returns>A ScriptModule instance, whether the script originated as a module or function.</returns>
            <remarks>
            All previously saved modules, no matter their device, are first loaded onto CPU, and then are moved to the devices they were saved from.If this fails (e.g.because the run time system doesn’t have certain devices), an exception is raised.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.jit.load(System.String,System.String)">
            <summary>
            Load a ScriptModule or ScriptFunction previously saved with torch.jit.save
            </summary>
            <param name="filename">The file name of the module.</param>
            <param name="map_location">The device type where the script module should be loaded.</param>
            <returns>A ScriptModule instance, whether the script originated as a module or function.</returns>
            <remarks>
            All previously saved modules, no matter their device, are first loaded onto CPU, and then are moved to the devices they were saved from.If this fails (e.g.because the run time system doesn’t have certain devices), an exception is raised.
            </remarks>
            <exception cref="T:System.IO.FileNotFoundException">Raised if the file is not found.</exception>
        </member>
        <member name="M:TorchSharp.torch.jit.load(System.Byte[],System.String)">
            <summary>
            Load a ScriptModule or ScriptFunction previously saved with torch.jit.save
            </summary>
            <param name="bytes">A byte array holding a serialized module</param>
            <param name="map_location">The device type where the script module should be loaded.</param>
            <returns>A ScriptModule instance, whether the script originated as a module or function.</returns>
            <remarks>
            All previously saved modules, no matter their device, are first loaded onto CPU, and then are moved to the devices they were saved from.If this fails (e.g.because the run time system doesn’t have certain devices), an exception is raised.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.jit.load``1(System.String,TorchSharp.DeviceType,System.Int64)">
            <summary>
            Load a ScriptModule or ScriptFunction previously saved with torch.jit.save
            </summary>
            <typeparam name="TResult">The return type of the module.</typeparam>
            <param name="filename">The file name of the module.</param>
            <param name="device_type">The device type, e.g. 'CPU' or 'CUDA'.</param>
            <param name="device_index">The optional device index.</param>
            <returns>A ScriptModule instance, whether the script originated as a module or function.</returns>
            <remarks>
            All previously saved modules, no matter their device, are first loaded onto CPU, and then are moved to the devices they were saved from.If this fails (e.g.because the run time system doesn’t have certain devices), an exception is raised.
            </remarks>
            <exception cref="T:System.IO.FileNotFoundException">Raised if the file is not found.</exception>
        </member>
        <member name="M:TorchSharp.torch.jit.load``1(System.Byte[],TorchSharp.DeviceType,System.Int64)">
            <summary>
            Load a ScriptModule or ScriptFunction previously saved with torch.jit.save
            </summary>
            <typeparam name="TResult">The return type of the module.</typeparam>
            <param name="bytes">A byte array holding a serialized module</param>
            <param name="device_type">The device type, e.g. 'CPU' or 'CUDA'.</param>
            <param name="device_index">The optional device index.</param>
            <returns>A ScriptModule instance, whether the script originated as a module or function.</returns>
            <remarks>
            All previously saved modules, no matter their device, are first loaded onto CPU, and then are moved to the devices they were saved from.If this fails (e.g.because the run time system doesn’t have certain devices), an exception is raised.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.jit.load``1(System.String,TorchSharp.torch.Device)">
            <summary>
            Load a ScriptModule or ScriptFunction previously saved with torch.jit.save
            </summary>
            <typeparam name="TResult">The return type of the module.</typeparam>
            <param name="filename">The file name of the module.</param>
            <param name="map_location">The device type where the script module should be loaded.</param>
            <returns>A ScriptModule instance, whether the script originated as a module or function.</returns>
            <remarks>
            All previously saved modules, no matter their device, are first loaded onto CPU, and then are moved to the devices they were saved from.If this fails (e.g.because the run time system doesn’t have certain devices), an exception is raised.
            </remarks>
            <exception cref="T:System.IO.FileNotFoundException">Raised if the file is not found.</exception>
        </member>
        <member name="M:TorchSharp.torch.jit.load``1(System.Byte[],TorchSharp.torch.Device)">
            <summary>
            Load a ScriptModule or ScriptFunction previously saved with torch.jit.save
            </summary>
            <typeparam name="TResult">The return type of the module.</typeparam>
            <param name="bytes">A byte array holding a serialized module</param>
            <param name="map_location">The device type where the script module should be loaded.</param>
            <returns>A ScriptModule instance, whether the script originated as a module or function.</returns>
            <remarks>
            All previously saved modules, no matter their device, are first loaded onto CPU, and then are moved to the devices they were saved from.If this fails (e.g.because the run time system doesn’t have certain devices), an exception is raised.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.jit.load``1(System.String,System.String)">
            <summary>
            Load a ScriptModule or ScriptFunction previously saved with torch.jit.save
            </summary>
            <typeparam name="TResult">The return type of the module.</typeparam>
            <param name="filename">The file name of the module.</param>
            <param name="map_location">The device type where the script module should be loaded.</param>
            <returns>A ScriptModule instance, whether the script originated as a module or function.</returns>
            <remarks>
            All previously saved modules, no matter their device, are first loaded onto CPU, and then are moved to the devices they were saved from.If this fails (e.g.because the run time system doesn’t have certain devices), an exception is raised.
            </remarks>
            <exception cref="T:System.IO.FileNotFoundException">Raised if the file is not found.</exception>
        </member>
        <member name="M:TorchSharp.torch.jit.load``1(System.Byte[],System.String)">
            <summary>
            Load a ScriptModule or ScriptFunction previously saved with torch.jit.save
            </summary>
            <typeparam name="TResult">The return type of the module.</typeparam>
            <param name="bytes">A byte array holding a serialized module</param>
            <param name="map_location">The device type where the script module should be loaded.</param>
            <returns>A ScriptModule instance, whether the script originated as a module or function.</returns>
            <remarks>
            All previously saved modules, no matter their device, are first loaded onto CPU, and then are moved to the devices they were saved from.If this fails (e.g.because the run time system doesn’t have certain devices), an exception is raised.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.jit.load``2(System.String,TorchSharp.DeviceType,System.Int64)">
            <summary>
            Load a ScriptModule or ScriptFunction previously saved with torch.jit.save
            </summary>
            <typeparam name="T1">The argument type.</typeparam>
            <typeparam name="TResult">The return type of the module.</typeparam>
            <param name="filename">The file name of the module.</param>
            <param name="device_type">The device type, e.g. 'CPU' or 'CUDA'.</param>
            <param name="device_index">The optional device index.</param>
            <returns>A ScriptModule instance, whether the script originated as a module or function.</returns>
            <remarks>
            All previously saved modules, no matter their device, are first loaded onto CPU, and then are moved to the devices they were saved from.If this fails (e.g.because the run time system doesn’t have certain devices), an exception is raised.
            </remarks>
            <exception cref="T:System.IO.FileNotFoundException">Raised if the file is not found.</exception>
        </member>
        <member name="M:TorchSharp.torch.jit.load``2(System.Byte[],TorchSharp.DeviceType,System.Int64)">
            <summary>
            Load a ScriptModule or ScriptFunction previously saved with torch.jit.save
            </summary>
            <typeparam name="T1">The argument type.</typeparam>
            <typeparam name="TResult">The return type of the module.</typeparam>
            <param name="bytes">A byte array holding a serialized module</param>
            <param name="device_type">The device type, e.g. 'CPU' or 'CUDA'.</param>
            <param name="device_index">The optional device index.</param>
            <returns>A ScriptModule instance, whether the script originated as a module or function.</returns>
            <remarks>
            All previously saved modules, no matter their device, are first loaded onto CPU, and then are moved to the devices they were saved from.If this fails (e.g.because the run time system doesn’t have certain devices), an exception is raised.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.jit.load``2(System.String,TorchSharp.torch.Device)">
            <summary>
            Load a ScriptModule or ScriptFunction previously saved with torch.jit.save
            </summary>
            <typeparam name="T1">The argument type.</typeparam>
            <typeparam name="TResult">The return type of the module.</typeparam>
            <param name="filename">The file name of the module.</param>
            <param name="map_location">The device type where the script module should be loaded.</param>
            <returns>A ScriptModule instance, whether the script originated as a module or function.</returns>
            <remarks>
            All previously saved modules, no matter their device, are first loaded onto CPU, and then are moved to the devices they were saved from.If this fails (e.g.because the run time system doesn’t have certain devices), an exception is raised.
            </remarks>
            <exception cref="T:System.IO.FileNotFoundException">Raised if the file is not found.</exception>
        </member>
        <member name="M:TorchSharp.torch.jit.load``2(System.Byte[],TorchSharp.torch.Device)">
            <summary>
            Load a ScriptModule or ScriptFunction previously saved with torch.jit.save
            </summary>
            <typeparam name="T1">The argument type.</typeparam>
            <typeparam name="TResult">The return type of the module.</typeparam>
            <param name="bytes">A byte array holding a serialized module</param>
            <param name="map_location">The device type where the script module should be loaded.</param>
            <returns>A ScriptModule instance, whether the script originated as a module or function.</returns>
            <remarks>
            All previously saved modules, no matter their device, are first loaded onto CPU, and then are moved to the devices they were saved from.If this fails (e.g.because the run time system doesn’t have certain devices), an exception is raised.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.jit.load``2(System.String,System.String)">
            <summary>
            Load a ScriptModule or ScriptFunction previously saved with torch.jit.save
            </summary>
            <typeparam name="T1">The argument type.</typeparam>
            <typeparam name="TResult">The return type of the module.</typeparam>
            <param name="filename">The file name of the module.</param>
            <param name="map_location">The device type where the script module should be loaded.</param>
            <returns>A ScriptModule instance, whether the script originated as a module or function.</returns>
            <remarks>
            All previously saved modules, no matter their device, are first loaded onto CPU, and then are moved to the devices they were saved from.If this fails (e.g.because the run time system doesn’t have certain devices), an exception is raised.
            </remarks>
            <exception cref="T:System.IO.FileNotFoundException">Raised if the file is not found.</exception>
        </member>
        <member name="M:TorchSharp.torch.jit.load``2(System.Byte[],System.String)">
            <summary>
            Load a ScriptModule or ScriptFunction previously saved with torch.jit.save
            </summary>
            <typeparam name="T1">The argument type.</typeparam>
            <typeparam name="TResult">The return type of the module.</typeparam>
            <param name="bytes">A byte array holding a serialized module</param>
            <param name="map_location">The device type where the script module should be loaded.</param>
            <returns>A ScriptModule instance, whether the script originated as a module or function.</returns>
            <remarks>
            All previously saved modules, no matter their device, are first loaded onto CPU, and then are moved to the devices they were saved from.If this fails (e.g.because the run time system doesn’t have certain devices), an exception is raised.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.jit.load``3(System.String,TorchSharp.DeviceType,System.Int64)">
            <summary>
            Load a ScriptModule or ScriptFunction previously saved with torch.jit.save
            </summary>
            <typeparam name="T1">The first argument type.</typeparam>
            <typeparam name="T2">The second argument type.</typeparam>
            <typeparam name="TResult">The return type of the module.</typeparam>
            <param name="filename">The file name of the module.</param>
            <param name="device_type">The device type, e.g. 'CPU' or 'CUDA'.</param>
            <param name="device_index">The optional device index.</param>
            <returns>A ScriptModule instance, whether the script originated as a module or function.</returns>
            <remarks>
            All previously saved modules, no matter their device, are first loaded onto CPU, and then are moved to the devices they were saved from.If this fails (e.g.because the run time system doesn’t have certain devices), an exception is raised.
            </remarks>
            <exception cref="T:System.IO.FileNotFoundException">Raised if the file is not found.</exception>
        </member>
        <member name="M:TorchSharp.torch.jit.load``3(System.Byte[],TorchSharp.DeviceType,System.Int64)">
            <summary>
            Load a ScriptModule or ScriptFunction previously saved with torch.jit.save
            </summary>
            <typeparam name="T1">The first argument type.</typeparam>
            <typeparam name="T2">The second argument type.</typeparam>
            <typeparam name="TResult">The return type of the module.</typeparam>
            <param name="bytes">A byte array holding a serialized module</param>
            <param name="device_type">The device type, e.g. 'CPU' or 'CUDA'.</param>
            <param name="device_index">The optional device index.</param>
            <returns>A ScriptModule instance, whether the script originated as a module or function.</returns>
            <remarks>
            All previously saved modules, no matter their device, are first loaded onto CPU, and then are moved to the devices they were saved from.If this fails (e.g.because the run time system doesn’t have certain devices), an exception is raised.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.jit.load``3(System.String,TorchSharp.torch.Device)">
            <summary>
            Load a ScriptModule or ScriptFunction previously saved with torch.jit.save
            </summary>
            <typeparam name="T1">The first argument type.</typeparam>
            <typeparam name="T2">The second argument type.</typeparam>
            <typeparam name="TResult">The return type of the module.</typeparam>
            <param name="filename">The file name of the module.</param>
            <param name="map_location">The device type where the script module should be loaded.</param>
            <returns>A ScriptModule instance, whether the script originated as a module or function.</returns>
            <remarks>
            All previously saved modules, no matter their device, are first loaded onto CPU, and then are moved to the devices they were saved from.If this fails (e.g.because the run time system doesn’t have certain devices), an exception is raised.
            </remarks>
            <exception cref="T:System.IO.FileNotFoundException">Raised if the file is not found.</exception>
        </member>
        <member name="M:TorchSharp.torch.jit.load``3(System.Byte[],TorchSharp.torch.Device)">
            <summary>
            Load a ScriptModule or ScriptFunction previously saved with torch.jit.save
            </summary>
            <typeparam name="T1">The first argument type.</typeparam>
            <typeparam name="T2">The second argument type.</typeparam>
            <typeparam name="TResult">The return type of the module.</typeparam>
            <param name="bytes">A byte array holding a serialized module</param>
            <param name="map_location">The device type where the script module should be loaded.</param>
            <returns>A ScriptModule instance, whether the script originated as a module or function.</returns>
            <remarks>
            All previously saved modules, no matter their device, are first loaded onto CPU, and then are moved to the devices they were saved from.If this fails (e.g.because the run time system doesn’t have certain devices), an exception is raised.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.jit.load``3(System.String,System.String)">
            <summary>
            Load a ScriptModule or ScriptFunction previously saved with torch.jit.save
            </summary>
            <typeparam name="T1">The first argument type.</typeparam>
            <typeparam name="T2">The second argument type.</typeparam>
            <typeparam name="TResult">The return type of the module.</typeparam>
            <param name="filename">The file name of the module.</param>
            <param name="map_location">The device type where the script module should be loaded.</param>
            <returns>A ScriptModule instance, whether the script originated as a module or function.</returns>
            <remarks>
            All previously saved modules, no matter their device, are first loaded onto CPU, and then are moved to the devices they were saved from.If this fails (e.g.because the run time system doesn’t have certain devices), an exception is raised.
            </remarks>
            <exception cref="T:System.IO.FileNotFoundException">Raised if the file is not found.</exception>
        </member>
        <member name="M:TorchSharp.torch.jit.load``3(System.Byte[],System.String)">
            <summary>
            Load a ScriptModule or ScriptFunction previously saved with torch.jit.save
            </summary>
            <typeparam name="T1">The first argument type.</typeparam>
            <typeparam name="T2">The second argument type.</typeparam>
            <typeparam name="TResult">The return type of the module.</typeparam>
            <param name="bytes">A byte array holding a serialized module</param>
            <param name="map_location">The device type where the script module should be loaded.</param>
            <returns>A ScriptModule instance, whether the script originated as a module or function.</returns>
            <remarks>
            All previously saved modules, no matter their device, are first loaded onto CPU, and then are moved to the devices they were saved from.If this fails (e.g.because the run time system doesn’t have certain devices), an exception is raised.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.jit.save(TorchSharp.torch.jit.ScriptModule,System.String)">
             <summary>
             Save an offline version of a previously loaded script module.
            
             The saved module serializes all of the methods, submodules, parameters, and attributes of this module.
             It can be loaded into the C++ API using torch::jit::load(filename) or into the .NET API with torch.jit.load().
             </summary>
             <param name="module">The script module to save.</param>
             <param name="filename">The file name of the module.</param>
        </member>
        <member name="M:TorchSharp.torch.jit.save(TorchSharp.torch.jit.ScriptModule,System.Byte[])">
             <summary>
             Save an offline version of a previously loaded script module.
            
             The saved module serializes all of the methods, submodules, parameters, and attributes of this module.
             It can be loaded into the C++ API using torch::jit::load(filename) or into the .NET API with torch.jit.load().
             </summary>
             <param name="module">The script module to save.</param>
             <param name="bytes">A byte array where the serialized module should be stored.</param>
        </member>
        <member name="M:TorchSharp.torch.jit.TensorType.size">
            <summary>
             Retrieves the sizes of all dimensions of the tensor.
            </summary>
        </member>
        <member name="T:TorchSharp.torch.jit.Type.HType">
            <summary>
               Class wrapping PyTorch's type object reference.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.jit.Type.Dispose">
            <summary>
              Releases the storage.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.jit.Type.Dispose(System.Boolean)">
            <summary>
              Implements the .NET Dispose pattern.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.linalg.cholesky(TorchSharp.torch.Tensor)">
            <summary>
            Computes the Cholesky decomposition of a complex Hermitian or real symmetric positive-definite matrix.
            </summary>
            <param name="input">The input tensor.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.linalg.cholesky_ex(TorchSharp.torch.Tensor,System.Boolean)">
            <summary>
            Computes the Cholesky decomposition of a complex Hermitian or real symmetric positive-definite matrix.
            This function skips the(slow) error checking and error message construction of torch.linalg.cholesky(),
            instead directly returning the LAPACK error codes as part of a named tuple(L, info).
            This makes this function a faster way to check if a matrix is positive-definite, and it provides an opportunity to handle
            decomposition errors more gracefully or performantly than torch.linalg.cholesky() does.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="check_errors">Controls whether to check the content of infos.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.linalg.cond(TorchSharp.torch.Tensor,System.Double)">
            <summary>
            Computes the condition number of a matrix with respect to a matrix norm.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="p">The type of the matrix norm to use in the computations</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.linalg.cond(TorchSharp.torch.Tensor,System.String)">
            <summary>
            Computes the condition number of a matrix with respect to a matrix norm.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="p">The type of the matrix norm to use in the computations</param>
        </member>
        <member name="M:TorchSharp.torch.linalg.cond(TorchSharp.torch.Tensor)">
            <summary>
            Computes the condition number of a matrix with respect to a matrix norm.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.linalg.cross(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Int64)">
            <summary>
            Returns the cross product of vectors in dimension dim of input and other.
            input and other must have the same size, and the size of their dim dimension should be 3.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.linalg.det(TorchSharp.torch.Tensor)">
            <summary>
            Computes the determinant of a square matrix.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.linalg.slogdet(TorchSharp.torch.Tensor)">
            <summary>
            Computes the sign and natural logarithm of the absolute value of the determinant of a square matrix.
            For complex A, it returns the angle and the natural logarithm of the modulus of the determinant, that is, a logarithmic polar decomposition of the determinant.
            </summary>
            <param name="input">The input tensor.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.linalg.diagonal(TorchSharp.torch.Tensor,System.Int32,System.Int32,System.Int32)">
             <summary>
             Returns a partial view of input with the its diagonal elements with respect to dim1 and dim2 appended as a dimension at the end of the shape.
             The argument offset controls which diagonal to consider:
            
                 If offset == 0, it is the main diagonal.
                 If offset &gt; 0, it is above the main diagonal.
                 If offset &lt; 0, it is below the main diagonal.
             </summary>
             <param name="input">The input tensor</param>
             <param name="offset">Which diagonal to consider. Default: 0 (main diagonal).</param>
             <param name="dim1">First dimension with respect to which to take diagonal. Default: -2.</param>
             <param name="dim2">Second dimension with respect to which to take diagonal. Default: -1.</param>
             <remarks>
             Applying torch.diag_embed() to the output of this function with the same arguments yields a diagonal matrix with the diagonal entries of the input.
             However, torch.diag_embed() has different default dimensions, so those need to be explicitly specified.
             </remarks>
        </member>
        <member name="M:TorchSharp.torch.linalg.eig(TorchSharp.torch.Tensor)">
            <summary>
            Computes the eigenvalue decomposition of a square matrix if it exists.
            </summary>
            <param name="input">The input tensor.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.linalg.eigh(TorchSharp.torch.Tensor,System.Char)">
            <summary>
            Computes the eigenvalue decomposition of a complex Hermitian or real symmetric matrix.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="UPLO">Controls whether to use the upper or lower triangular part of A in the computations. </param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.linalg.eigvals(TorchSharp.torch.Tensor)">
            <summary>
            Computes the eigenvalues of a square matrix.
            </summary>
            <param name="input">The input tensor.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.linalg.eigvalsh(TorchSharp.torch.Tensor,System.Char)">
            <summary>
            Computes the eigenvalues of a complex Hermitian or real symmetric matrix.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="UPLO">Controls whether to use the upper or lower triangular part of A in the computations. </param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.linalg.householder_product(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Computes the first n columns of a product of Householder matrices.
            </summary>
            <param name="A">tensor of shape (*, m, n) where * is zero or more batch dimensions.</param>
            <param name="tau">tensor of shape (*, k) where * is zero or more batch dimensions.</param>
        </member>
        <member name="M:TorchSharp.torch.linalg.inv(TorchSharp.torch.Tensor)">
            <summary>
            Computes the inverse of a square matrix if it exists.
            </summary>
            <param name="input">The input tensor.</param>
            <returns></returns>
            <remarks>Throws a RuntimeError if the matrix is not invertible.</remarks>
        </member>
        <member name="M:TorchSharp.torch.linalg.inv_ex(TorchSharp.torch.Tensor,System.Boolean)">
            <summary>
            Computes the inverse of a square matrix if it is invertible.
            Returns a named tuple(inverse, info). inverse contains the result of inverting A and info stores the LAPACK error codes.
            If A is not an invertible matrix, or if it’s a batch of matrices and one or more of them is not an invertible matrix,
            then info stores a positive integer for the corresponding matrix.The positive integer indicates the diagonal element of
            the LU decomposition of the input matrix that is exactly zero. info filled with zeros indicates that the inversion was successful.
            If check_errors = True and info contains positive integers, then a RuntimeError is thrown.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="check_errors">Controls whether to check the content of info. controls whether to check the content of info. </param>
            <returns></returns>
            <remarks>Throws a RuntimeError if the matrix is not invertible.</remarks>
        </member>
        <member name="M:TorchSharp.torch.linalg.lstsq(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Computes a solution to the least squares problem of a system of linear equations.
            </summary>
            <param name="input">lhs tensor of shape (*, m, n) where * is zero or more batch dimensions.</param>
            <param name="other">rhs tensor of shape (*, m, k) where * is zero or more batch dimensions.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.linalg.lu(TorchSharp.torch.Tensor,System.Boolean)">
            <summary>
            Computes the LU decomposition with partial pivoting of a matrix.
            </summary>
            <param name="input">Tensor of shape (*, m, n) where * is zero or more batch dimensions.</param>
            <param name="pivot">Controls whether to compute the LU decomposition with partial pivoting or no pivoting</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.linalg.lu_factor(TorchSharp.torch.Tensor,System.Boolean)">
            <summary>
            Computes a compact representation of the LU factorization with partial pivoting of a matrix.
            </summary>
            <param name="input">Tensor of shape (*, m, n) where * is zero or more batch dimensions.</param>
            <param name="pivot">Controls whether to compute the LU decomposition with partial pivoting or no pivoting</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.linalg.ldl_factor(TorchSharp.torch.Tensor,System.Boolean)">
            <summary>
            Computes a compact representation of the LU factorization with partial pivoting of a matrix.
            </summary>
            <param name="input">Tensor of shape (*, m, n) where * is zero or more batch dimensions.</param>
            <param name="hermitian">Controls whether to consider the input to be Hermitian or symmetric. For real-valued matrices, this switch has no effect.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.linalg.ldl_factor_ex(TorchSharp.torch.Tensor,System.Boolean,System.Boolean)">
            <summary>
            Computes a compact representation of the LU factorization with partial pivoting of a matrix.
            </summary>
            <param name="input">Tensor of shape (*, m, n) where * is zero or more batch dimensions.</param>
            <param name="hermitian">Controls whether to consider the input to be Hermitian or symmetric. For real-valued matrices, this switch has no effect.</param>
            <param name="check_errors">Controls whether to check the content of info and raise an error if it is non-zero.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.linalg.ldl_solve(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Boolean)">
            <summary>
            Computes the solution of a system of linear equations using the LDL factorization.
            </summary>
            <param name="LD">the n times n matrix or the batch of such matrices of size (*, n, n) where * is one or more batch dimensions</param>
            <param name="pivots">the pivots corresponding to the LDL factorization of LD</param>
            <param name="B">Right-hand side tensor of shape (*, n, k)</param>
            <param name="hermitian">Whether to consider the decomposed matrix to be Hermitian or symmetric. For real-valued matrices, this switch has no effect</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.linalg.lstsq(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Double)">
            <summary>
            Computes a solution to the least squares problem of a system of linear equations.
            </summary>
            <param name="input">lhs tensor of shape (*, m, n) where * is zero or more batch dimensions.</param>
            <param name="other">rhs tensor of shape (*, m, k) where * is zero or more batch dimensions.</param>
            <param name="rcond">Used to determine the effective rank of A. If rcond= None, rcond is set to the machine precision of the dtype of A times max(m, n).</param>
        </member>
        <member name="M:TorchSharp.torch.linalg.matrix_exp(TorchSharp.torch.Tensor)">
            <summary>
            Computes the matrix exponential of a square matrix or of each square matrix in a batch.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.linalg.matrix_norm(TorchSharp.torch.Tensor,System.String,System.Int64[],System.Boolean)">
            <summary>
            Computes a matrix norm.
            </summary>
            <param name="input">tensor with two or more dimensions.
            By default its shape is interpreted as (*, m, n) where * is zero or more batch dimensions, but this behavior can be controlled using dims.</param>
            <param name="ord">Order of norm. Default: "fro"</param>
            <param name="dims">Dimensions over which to compute the norm.</param>
            <param name="keepdim">If set to true, the reduced dimensions are retained in the result as dimensions with size one. </param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.linalg.matrix_norm(TorchSharp.torch.Tensor,System.Double,System.Int64[],System.Boolean)">
            <summary>
            Computes a matrix norm.
            </summary>
            <param name="input">tensor with two or more dimensions.
            By default its shape is interpreted as (*, m, n) where * is zero or more batch dimensions, but this behavior can be controlled using dims.</param>
            <param name="ord">Order of norm.</param>
            <param name="dims">Dimensions over which to compute the norm.</param>
            <param name="keepdim">If set to true, the reduced dimensions are retained in the result as dimensions with size one. </param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.linalg.matrix_rank(TorchSharp.torch.Tensor,System.Nullable{System.Double},System.Nullable{System.Double},System.Boolean)">
            <summary>
            Computes the numerical rank of a matrix.
            The matrix rank is computed as the number of singular values(or eigenvalues in absolute value when hermitian = True) that are greater than the specified tol threshold.
            </summary>
            <param name="input">Tensor of shape (*, m, n) where * is zero or more batch dimensions.</param>
            <param name="atol">The absolute tolerance value.</param>
            <param name="rtol">The relative tolerance value.</param>
            <param name="hermitian">Indicates whether A is Hermitian if complex or symmetric if real</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.linalg.matrix_rank(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Boolean)">
            <summary>
            Computes the numerical rank of a matrix.
            The matrix rank is computed as the number of singular values(or eigenvalues in absolute value when hermitian = True) that are greater than the specified tol threshold.
            </summary>
            <param name="input">Tensor of shape (*, m, n) where * is zero or more batch dimensions.</param>
            <param name="atol">The absolute tolerance value.</param>
            <param name="rtol">The relative tolerance value.</param>
            <param name="hermitian">Indicates whether A is Hermitian if complex or symmetric if real</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.linalg.multi_dot(System.Collections.Generic.IList{TorchSharp.torch.Tensor})">
            <summary>
            Efficiently multiplies two or more matrices by reordering the multiplications so that the fewest arithmetic operations are performed.
            </summary>
            <param name="tensors">Two or more tensors to multiply. The first and last tensors may be 1D or 2D. Every other tensor must be 2D.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.linalg.norm(TorchSharp.torch.Tensor,System.String,System.Int64[],System.Boolean)">
            <summary>
            Computes a vector or matrix norm.
            If A is complex valued, it computes the norm of A.abs()
            </summary>
            <param name="input">Tensor of shape (*, n) or (*, m, n) where * is zero or more batch dimensions</param>
            <param name="ord">Order of norm. </param>
            <param name="dims">Dimensions over which to compute the vector or matrix norm.</param>
            <param name="keepdim">If set to true, the reduced dimensions are retained in the result as dimensions with size one.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.linalg.norm(TorchSharp.torch.Tensor,System.Double,System.Int64[],System.Boolean)">
            <summary>
            Computes a vector or matrix norm.
            If A is complex valued, it computes the norm of A.abs()
            </summary>
            <param name="input">Tensor of shape (*, n) or (*, m, n) where * is zero or more batch dimensions</param>
            <param name="ord">Order of norm. </param>
            <param name="dims">Dimensions over which to compute the vector or matrix norm.</param>
            <param name="keepdim">If set to true, the reduced dimensions are retained in the result as dimensions with size one.</param>
        </member>
        <member name="M:TorchSharp.torch.linalg.norm(TorchSharp.torch.Tensor,System.Int32,System.Int64[],System.Boolean)">
            <summary>
            Computes a vector or matrix norm.
            If A is complex valued, it computes the norm of A.abs()
            </summary>
            <param name="input">Tensor of shape (*, n) or (*, m, n) where * is zero or more batch dimensions</param>
            <param name="ord">Order of norm. </param>
            <param name="dims">Dimensions over which to compute the vector or matrix norm.</param>
            <param name="keepdim">If set to true, the reduced dimensions are retained in the result as dimensions with size one.</param>
        </member>
        <member name="M:TorchSharp.torch.linalg.norm(TorchSharp.torch.Tensor,System.Int64[],System.Boolean)">
            <summary>
            Computes a vector or matrix norm.
            If A is complex valued, it computes the norm of A.abs()
            </summary>
            <param name="input">Tensor of shape (*, n) or (*, m, n) where * is zero or more batch dimensions</param>
            <param name="dims">Dimensions over which to compute the vector or matrix norm.</param>
            <param name="keepdim">If set to true, the reduced dimensions are retained in the result as dimensions with size one.</param>
        </member>
        <member name="M:TorchSharp.torch.linalg.pinv(TorchSharp.torch.Tensor,System.Nullable{System.Double},System.Nullable{System.Double},System.Boolean)">
            <summary>
            Computes the numerical rank of a matrix.
            The matrix rank is computed as the number of singular values(or eigenvalues in absolute value when hermitian = True) that are greater than the specified tol threshold.
            </summary>
            <param name="input">Tensor of shape (*, m, n) where * is zero or more batch dimensions.</param>
            <param name="atol">The absolute tolerance value.</param>
            <param name="rtol">The relative tolerance value.</param>
            <param name="hermitian">Indicates whether A is Hermitian if complex or symmetric if real</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.linalg.pinv(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Boolean)">
            <summary>
            Computes the numerical rank of a matrix.
            The matrix rank is computed as the number of singular values(or eigenvalues in absolute value when hermitian = True) that are greater than the specified tol threshold.
            </summary>
            <param name="input">Tensor of shape (*, m, n) where * is zero or more batch dimensions.</param>
            <param name="atol">The absolute tolerance value.</param>
            <param name="rtol">The relative tolerance value.</param>
            <param name="hermitian">Indicates whether A is Hermitian if complex or symmetric if real</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.linalg.qr(TorchSharp.torch.Tensor,TorchSharp.torch.linalg.QRMode)">
            <summary>
            Computes the QR decomposition of a matrix.
            </summary>
            <param name="input">Tensor of shape (*, m, n) where * is zero or more batch dimensions.</param>
            <param name="mode">Controls the shape of the returned tensors. One of ‘Reduced’, ‘Complete’, ‘R’.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.linalg.solve(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Boolean)">
            <summary>
            Computes the solution of a square system of linear equations with a unique solution.
            </summary>
            <param name="A">Tensor of shape (*, n, n) where * is zero or more batch dimensions.</param>
            <param name="B">Right-hand side tensor of shape (*, n) or (*, n, k) or (n,) or (n, k)</param>
            <param name="left">whether to solve the system AX = B or XA = B.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.linalg.solve_ex(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Boolean,System.Boolean)">
            <summary>
            Computes the solution of a square system of linear equations with a unique solution.
            </summary>
            <param name="A">Ttensor of shape (*, n, n) where * is zero or more batch dimensions.</param>
            <param name="B">Right-hand side tensor of shape (*, n) or (*, n, k) or (n,) or (n, k)</param>
            <param name="left">whether to solve the system AX = B or XA = B.</param>
            <param name="check_errors">controls whether to check the content of infos and raise an error if it is non-zero</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.linalg.solve_triangular(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Boolean,System.Boolean,System.Boolean,TorchSharp.torch.Tensor)">
            <summary>
            Computes the solution of a square system of linear equations with a unique solution.
            </summary>
            <param name="A">Tensor of shape (*, n, n) where * is zero or more batch dimensions.</param>
            <param name="B">Right-hand side tensor of shape (*, n) or (*, n, k) or (n,) or (n, k)</param>
            <param name="upper">Whether A is an upper or lower triangular matrix</param>
            <param name="left">Whether to solve the system AX = B or XA = B.</param>
            <param name="unitriangular">If true, the diagonal elements of A are assumed to be all equal to 1.</param>
            <param name="out">Output tensor. B may be passed as out and the result is computed in-place on B.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.linalg.svd(TorchSharp.torch.Tensor,System.Boolean)">
            <summary>
            Computes the singular value decomposition (SVD) of a matrix.
            </summary>
            <param name="input">Tensor of shape (*, m, n) where * is zero or more batch dimensions.</param>
            <param name="fullMatrices">Controls whether to compute the full or reduced SVD, and consequently, the shape of the returned tensors U and Vh.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.linalg.svdvals(TorchSharp.torch.Tensor)">
            <summary>
            Computes the singular values of a matrix.
            </summary>
            <param name="input">The input matrix</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.linalg.tensorinv(TorchSharp.torch.Tensor,System.Int64)">
            <summary>
            Computes the multiplicative inverse of torch.tensordot().
            </summary>
            <param name="input">Tensor to invert. </param>
            <param name="ind">Index at which to compute the inverse of torch.tensordot()</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.linalg.tensorsolve(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Int64[])">
            <summary>
            Computes the solution X to the system torch.tensordot(A, X) = B.
            </summary>
            <param name="A">Tensor to solve for. </param>
            <param name="B">Another tensor, of shape a.shape[B.dim].</param>
            <param name="dims">Dimensions of A to be moved. If None, no dimensions are moved.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.linalg.vector_norm(TorchSharp.torch.Tensor,System.Double,System.Int64[],System.Boolean)">
            <summary>
            Computes a vector norm.
            </summary>
            <param name="input">Tensor, flattened by default, but this behavior can be controlled using dims.</param>
            <param name="ord">Order of norm. Default: 2</param>
            <param name="dims">Dimensions over which to compute the norm.</param>
            <param name="keepdim">If set to true, the reduced dimensions are retained in the result as dimensions with size one. </param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.linalg.vander(TorchSharp.torch.Tensor,System.Nullable{System.Int64})">
            <summary>
            Generates a Vandermonde matrix.
            </summary>
            <param name="input">tensor of shape (*, n) where * is zero or more batch dimensions consisting of vectors.</param>
            <param name="N">Number of columns in the output. Default: x.size(-1)</param>
        </member>
        <member name="M:TorchSharp.torch.linalg.vecdot(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Int64,TorchSharp.torch.Tensor)">
            <summary>
            Computes the dot product of two batches of vectors along a dimension.
            </summary>
            <param name="x">First batch of vectors.</param>
            <param name="y">Second batch of vectors</param>
            <param name="dim">Dimension along which to compute the dot product.</param>
            <param name="out">Optional output tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.linalg.lu_solve(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Boolean,System.Boolean,TorchSharp.torch.Tensor)">
            <summary>
            Computes the solution of a square system of linear equations with a unique solution given an LU decomposition.
            </summary>
            <param name="LU">Tensor of shape (*, n, n) (or (*, k, k) if left= True) where * is zero or more batch dimensions as returned by lu_factor().</param>
            <param name="pivots">Tensor of shape (*, n) (or (*, k) if left= True) where * is zero or more batch dimensions as returned by lu_factor().</param>
            <param name="B">Right-hand side tensor of shape (*, n, k).</param>
            <param name="left">Whether to solve the system AX=B or XA = B. Default: True.</param>
            <param name="adjoint">Whether to solve the adjoint system.</param>
            <param name="out">Optional output tensor.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.CELU(System.Double,System.Boolean)">
            <summary>
            Continuously Differentiable Exponential Linear Unit
            </summary>
            <param name="alpha">The α value for the CELU formulation. Default: 1.0</param>
            <param name="inplace">Do the operation in-place. Default: False</param>
            <returns></returns>
        </member>
        <member name="T:TorchSharp.torch.nn.functional">
            <summary>
            Class maintaing the supported loss functions.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.celu(TorchSharp.torch.Tensor,System.Double,System.Boolean)">
            <summary>
            Continuously Differentiable Exponential Linear Unit
            </summary>
            <param name="x">The input tensor</param>
            <param name="alpha">The α value for the CELU formulation. Default: 1.0</param>
            <param name="inplace">Do the operation in-place. Default: False</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.elu(TorchSharp.torch.Tensor,System.Double,System.Boolean)">
            <summary>
            Exponential Linear Unit
            </summary>
            <param name="x">The input tensor</param>
            <param name="alpha">The α value for the ELU formulation. Default: 1.0</param>
            <param name="inplace">Do the operation in-place. Default: False</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.gelu(TorchSharp.torch.Tensor,System.Boolean)">
            <summary>
            Gaussian Error Linear Units
            </summary>
            <param name="x">The input tensor</param>
            <param name="inplace">Do the operation in-place. Default: False</param>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.gelu(TorchSharp.torch.Tensor)">
            <summary>
            Gaussian Error Linear Units
            </summary>
            <param name="x">The input tensor</param>
            <remarks>The defaulting of 'inplace' to 'false' is implemented as an overload to avoid a breaking change.</remarks>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.glu(TorchSharp.torch.Tensor,System.Int64)">
            <summary>
            The gated linear unit function.
            </summary>
            <param name="input">The input tensor</param>
            <param name="dim">the dimension on which to split the input. Default: -1</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.hardshrink(TorchSharp.torch.Tensor,System.Double)">
            <summary>
            Hardshrink
            </summary>
            <param name="x">The input tensor</param>
            <param name="lambda">The λ value for the Hardshrink formulation. Default: 0.5</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.Hardshrink(TorchSharp.torch.Tensor,System.Double)">
            <summary>
            Hardshrink
            </summary>
            <param name="x">The input tensor</param>
            <param name="lambda">The λ value for the Hardshrink formulation. Default: 0.5</param>
            <remarks>Only here for backward comaptibility.</remarks>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.hardsigmoid(TorchSharp.torch.Tensor,System.Boolean)">
            <summary>
            Hardsigmoid
            </summary>
            <param name="input">The input tensor</param>
            <param name="inplace">Do the operation in-place</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.hardswish(TorchSharp.torch.Tensor,System.Boolean)">
            <summary>
            Applies the Hardswish function, element-wise, as described in the paper:
            `Searching for MobileNetV3 https://arxiv.org/abs/1905.02244`.
            </summary>
            <param name="input">The input tensor</param>
            <param name="inplace">Do the operation in-place</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.hardtanh(TorchSharp.torch.Tensor,System.Double,System.Double,System.Boolean)">
            <summary>
            Hardtanh
            </summary>
            <param name="x">The input tensor</param>
            <param name="min_val">Minimum value of the linear region range.</param>
            <param name="max_val">Maximum value of the linear region range.</param>
            <param name="inplace">Do the operation in-place</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.Hardtanh(TorchSharp.torch.Tensor,System.Double,System.Double,System.Boolean)">
            <summary>
            Hardshrink
            </summary>
            <param name="x">The input tensor</param>
            <param name="min_val">Minimum value of the linear region range.</param>
            <param name="max_val">Maximum value of the linear region range.</param>
            <param name="inplace">Do the operation in-place</param>
            <remarks>Only here for backward comaptibility.</remarks>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.leaky_relu(TorchSharp.torch.Tensor,System.Double,System.Boolean)">
            <summary>
            Continuously Differentiable Exponential Linear Unit
            </summary>
            <param name="input">The input tensor</param>
            <param name="negative_slope">The α value for the LeakyReLU formulation. Default: 1.0</param>
            <param name="inplace">Do the operation in-place. Default: False</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.logsigmoid(TorchSharp.torch.Tensor)">
            <summary>
            LogSigmoid activation
            </summary>
            <param name="x">The input tensor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.mish(TorchSharp.torch.Tensor,System.Boolean)">
            <summary>
            A Self Regularized Non-Monotonic Neural Activation Function.
            </summary>
            <param name="x">The input tensor</param>
            <param name="inplace">Do the operation in-place. Default: False</param>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.Mish(TorchSharp.torch.Tensor)">
            <summary>
            A Self Regularized Non-Monotonic Neural Activation Function.
            </summary>
            <param name="x">The input tensor</param>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.prelu(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Parameterized Rectified Linear Unit
            </summary>
            <param name="input">The input tensor</param>
            <param name="weight">Weight is expected to be a scalar or 1-D tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.relu(TorchSharp.torch.Tensor,System.Boolean)">
            <summary>
            Rectified Linear Unit
            </summary>
            <param name="x">The input tensor</param>
            <param name="inplace">Do the operation in-place. Default: False</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.relu6(TorchSharp.torch.Tensor,System.Boolean)">
             <summary>
             Rectified Linear Unit
            
             This ReLU version caps positive values at 6.
             </summary>
             <param name="x">The input tensor</param>
             <param name="inplace">Do the operation in-place. Default: False</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.rrelu(TorchSharp.torch.Tensor,System.Double,System.Double,System.Boolean)">
            <summary>
            Randomized Rectified Linear Unit
            </summary>
            <param name="x">The input tensor</param>
            <param name="lower">Lower bound of the uniform distribution. Default: 1/8</param>
            <param name="upper">Upper bound of the uniform distribution. Default: 1/3</param>
            <param name="inplace">Do the operation in-place. Default: False</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.selu(TorchSharp.torch.Tensor,System.Boolean)">
            <summary>
            Scaled Exponential Linear Unit
            </summary>
            <param name="x">The input tensor</param>
            <param name="inplace">Do the operation in-place. Default: False</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.sigmoid(TorchSharp.torch.Tensor,System.Boolean)">
            <summary>
            Sigmoid activation
            </summary>
            <param name="x">The input tensor</param>
            <param name="inplace">Do the operation in-place. Default: False</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.sigmoid(TorchSharp.torch.Tensor)">
            <summary>
            Gaussian Error Linear Units
            </summary>
            <param name="x">The input tensor</param>
            <remarks>The defaulting of 'inplace' to 'false' is implemented as an overload to avoid a breaking change.</remarks>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.silu(TorchSharp.torch.Tensor,System.Boolean)">
            <summary>
            Sigmoid-Weighted Linear Unit
            </summary>
            <param name="x">The input tensor</param>
            <param name="inplace">Do the operation in-place. Default: false</param>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.softmax(TorchSharp.torch.Tensor,System.Int64,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Computes the softmax function for the input tensor.
            </summary>
            <param name="input">The input tensor</param>
            <param name="dim">A dimension along which softmax will be computed.</param>
            <param name="dtype">The desired data type of returned tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.softmax2d(TorchSharp.torch.Tensor)">
            <summary>
            Applies Softmax over features to each spatial location
            </summary>
            <param name="x">The input tensor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.softmin(TorchSharp.torch.Tensor,System.Int64)">
            <summary>
            Softmin
            </summary>
            <param name="x">The input tensor</param>
            <param name="dim">A dimension along which Softmin will be computed (so every slice along dim will sum to 1)</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.softplus(TorchSharp.torch.Tensor,System.Double,System.Double)">
            <summary>
            Softplus
            </summary>
            <param name="x">The input tensor</param>
            <param name="beta">The β value for the Softplus formulation.</param>
            <param name="threshold">Values above this revert to a linear function</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.softshrink(TorchSharp.torch.Tensor,System.Double)">
            <summary>
            Softshrink
            </summary>
            <param name="x">The input tensor</param>
            <param name="lambda">The λ value for the Softshrink formulation. Default: 0.5</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.Softshrink(TorchSharp.torch.Tensor,System.Double)">
            <summary>
            Softshrink
            </summary>
            <param name="x">The input tensor</param>
            <param name="lambda">The λ value for the Softshrink formulation. Default: 0.5</param>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.softsign(TorchSharp.torch.Tensor,System.Boolean)">
            <summary>
            Softsign
            </summary>
            <param name="x">The input tensor</param>
            <param name="inplace">Do the operation in-place. Default: False</param>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.Softsign(TorchSharp.torch.Tensor)">
            <summary>
            Softsign
            </summary>
            <param name="x">The input tensor</param>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.tanh(TorchSharp.torch.Tensor,System.Boolean)">
            <summary>
            Tanh activation
            </summary>
            <param name="x">The input tensor</param>
            <param name="inplace">Do the operation in-place. Default: False</param>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.tanhshrink(TorchSharp.torch.Tensor,System.Boolean)">
            <summary>
            Tanhshrink
            </summary>
            <param name="x">The input tensor</param>
            <param name="inplace">Do the operation in-place. Default: False</param>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.Tanhshrink(TorchSharp.torch.Tensor)">
            <summary>
            Tanhshrink
            </summary>
            <param name="x">The input tensor</param>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.threshold(TorchSharp.torch.Tensor,System.Double,System.Double,System.Boolean)">
            <summary>
            Thresholds each element of the input Tensor.
            </summary>
            <param name="x">The input tensor</param>
            <param name="threshold">The value to threshold at</param>
            <param name="value">The value to replace with</param>
            <param name="inplace">Do the operation in-place</param>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.Threshold(TorchSharp.torch.Tensor,System.Double,System.Double,System.Boolean)">
            <summary>
            Thresholds each element of the input Tensor.
            </summary>
            <param name="x">The input tensor</param>
            <param name="threshold">The value to threshold at</param>
            <param name="value">The value to replace with</param>
            <param name="inplace">Do the operation in-place</param>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.alpha_dropout(TorchSharp.torch.Tensor,System.Double,System.Boolean,System.Boolean)">
            <summary>
            Randomly zero out entire channels (a channel is a 2D feature map, e.g., the jj -th channel of the ii -th sample in the batched input is a 2D tensor \text{input}[i, j]input[i,j] ).
            Each channel will be zeroed out independently on every forward call with probability p using samples from a Bernoulli distribution.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.bilinear(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Applies a bilinear transformation to the incoming data
            </summary>
            <param name="input1">Input tensor of shape (N,*,H1)</param>
            <param name="input2">Input tensor of shape (N,*,H2)</param>
            <param name="weight">Weights of shape (Hout,H1, H2)</param>
            <param name="bias">Optional bias of shape (Hout)</param>
            <returns>Tensor of shape (N,*,Hout)</returns>
            <remarks>The '*' sub-shape must be the same among the two inputs.</remarks>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.conv1d(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Nullable{System.Int64},System.Nullable{System.Int64},System.Nullable{System.Int64},System.Int64)">
            <summary>
            Applies a 1D convolution over an input signal composed of several input planes.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="weight">weight matrix of the convolution</param>
            <param name="bias">Optional; bias vector of the convolution</param>
            <param name="stride">Stride of the convolution. Default: (1,)</param>
            <param name="padding">Zero-padding added to both sides of the input. Default: (0,)</param>
            <param name="dilation">Spacing between kernel elements. Default: (1,)</param>
            <param name="groups">Number of blocked connections from input channels to output channels. Default: 1</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.conv1d_padding(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Nullable{System.Int64},TorchSharp.Padding,System.Nullable{System.Int64},System.Int64)">
            <summary>
            Applies a 1D convolution over an input signal composed of several input planes.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="weight">weight matrix of the convolution</param>
            <param name="bias">Optional; bias vector of the convolution</param>
            <param name="stride">Stride of the convolution. Default: (1,)</param>
            <param name="padding">Zero-padding added to both sides of the input. padding=Valid is the same as no padding. padding=Same pads the input so the output has the shape as the input. </param>
            <param name="dilation">Spacing between kernel elements. Default: (1,)</param>
            <param name="groups">Number of blocked connections from input channels to output channels. Default: 1</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.conv2d(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Int64[],System.Int64[],System.Int64[],System.Int64)">
            <summary>
            Applies a 2D convolution over an input image composed of several input planes.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="weight">weight matrix of the convolution</param>
            <param name="bias">Optional; bias vector of the convolution</param>
            <param name="strides">Stride of the convolution. Default: (1,1)</param>
            <param name="padding">Zero-padding added to both sides of the input. Default: (0,0)</param>
            <param name="dilation">Spacing between kernel elements. Default: (1,1)</param>
            <param name="groups">Number of blocked connections from input channels to output channels. Default: 1</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.conv2d_padding(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Int64[],TorchSharp.Padding,System.Int64[],System.Int64)">
            <summary>
            Applies a 2D convolution over an input image composed of several input planes.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="weight">weight matrix of the convolution</param>
            <param name="bias">Optional; bias vector of the convolution</param>
            <param name="strides">Stride of the convolution. Default: (1,1)</param>
            <param name="padding">Zero-padding added to both sides of the input. padding=Valid is the same as no padding. padding=Same pads the input so the output has the shape as the input. </param>
            <param name="dilation">Spacing between kernel elements. Default: (1,1)</param>
            <param name="groups">Number of blocked connections from input channels to output channels. Default: 1</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.conv3d(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Int64[],System.Int64[],System.Int64[],System.Int64)">
            <summary>
            Applies a 3D convolution over an input image composed of several input planes.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="weight">weight matrix of the convolution</param>
            <param name="bias">Optional; bias vector of the convolution</param>
            <param name="strides">Stride of the convolution. Default: (1,1,1)</param>
            <param name="padding">Zero-padding added to both sides of the input. Default: (0,0,0)</param>
            <param name="dilation">Spacing between kernel elements. Default: (1,1,1)</param>
            <param name="groups">Number of blocked connections from input channels to output channels. Default: 1</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.conv3d_padding(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Int64[],TorchSharp.Padding,System.Int64[],System.Int64)">
            <summary>
            Applies a 3D convolution over an input image composed of several input planes.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="weight">weight matrix of the convolution</param>
            <param name="bias">Optional; bias vector of the convolution</param>
            <param name="strides">Stride of the convolution. Default: (1,1,1)</param>
            <param name="padding">Zero-padding added to both sides of the input. padding=Valid is the same as no padding. padding=Same pads the input so the output has the shape as the input. </param>
            <param name="dilation">Spacing between kernel elements. Default: (1,1,1)</param>
            <param name="groups">Number of blocked connections from input channels to output channels. Default: 1</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.conv_transpose1d(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Nullable{System.Int64},System.Nullable{System.Int64},System.Nullable{System.Int64},System.Nullable{System.Int64},System.Int64)">
            <summary>
            Applies a 1D transposed convolution operator over an input signal composed of several input planes, sometimes also called “deconvolution”.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="weight"></param>
            <param name="bias"></param>
            <param name="stride"></param>
            <param name="padding"></param>
            <param name="output_padding"></param>
            <param name="dilation"></param>
            <param name="groups"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.conv_transpose2d(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Int64[],System.Int64[],System.Int64[],System.Int64[],System.Int64)">
            <summary>
            Applies a 2D transposed convolution operator over an input image composed of several input planes, sometimes also called “deconvolution”.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="weight"></param>
            <param name="bias"></param>
            <param name="strides"></param>
            <param name="padding"></param>
            <param name="output_padding"></param>
            <param name="dilation"></param>
            <param name="groups"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.conv_transpose3d(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Int64[],System.Int64[],System.Int64[],System.Int64[],System.Int64)">
            <summary>
            Applies a 3D transposed convolution operator over an input image composed of several input planes, sometimes also called “deconvolution”.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="weight"></param>
            <param name="bias"></param>
            <param name="strides"></param>
            <param name="padding"></param>
            <param name="output_padding"></param>
            <param name="dilation"></param>
            <param name="groups"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.cosine_similarity(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Int64,System.Double)">
            <summary>
            Returns cosine similarity between x1 and x2, computed along dim. Inputs must have same shape.
            </summary>
            <param name="x1">First input.</param>
            <param name="x2">Second input (of size matching x1).</param>
            <param name="dim">Dimension where cosine similarity is computed. Default: 1</param>
            <param name="eps">Small value to avoid division by zero. Default: 1e-8</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.dropout(TorchSharp.torch.Tensor,System.Double,System.Boolean,System.Boolean)">
            <summary>
            During training, randomly zeroes some of the elements of the input tensor with probability p using samples from a Bernoulli distribution.
            Each channel will be zeroed out independently on every forward call.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.dropout1d(TorchSharp.torch.Tensor,System.Double,System.Boolean,System.Boolean)">
            <summary>
            Randomly zero out entire channels (a channel is a 2D feature map, e.g., the jj -th channel of the ii -th sample in the batched input is a 2D tensor).
            Each channel will be zeroed out independently on every forward call with probability p using samples from a Bernoulli distribution.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.dropout2d(TorchSharp.torch.Tensor,System.Double,System.Boolean,System.Boolean)">
            <summary>
            Randomly zero out entire channels (a channel is a 2D feature map, e.g., the jj -th channel of the ii -th sample in the batched input is a 2D tensor).
            Each channel will be zeroed out independently on every forward call with probability p using samples from a Bernoulli distribution.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.dropout3d(TorchSharp.torch.Tensor,System.Double,System.Boolean,System.Boolean)">
            <summary>
            Randomly zero out entire channels (a channel is a 3D feature map, e.g., the jj -th channel of the ii -th sample in the batched input is a 3D tensor \text{input}[i, j]input[i,j] ).
            Each channel will be zeroed out independently on every forward call with probability p using samples from a Bernoulli distribution.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.feature_alpha_dropout(TorchSharp.torch.Tensor,System.Double,System.Boolean,System.Boolean)">
            <summary>
            Randomly masks out entire channels (a channel is a feature map, e.g. the j-th channel of the i-th sample in the batch input is a tensor input[i,j]) of the input tensor.
            Instead of setting activations to zero, as in regular Dropout, the activations are set to the negative saturation value of the SELU activation function.
            Each element will be masked independently on every forward call with probability p using samples from a Bernoulli distribution.The elements to be masked are
            randomized on every forward call, and scaled and shifted to maintain zero mean and unit variance.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.fold(TorchSharp.torch.Tensor,System.Int64,System.Int64,System.Int64,System.Int64,System.Int64)">
            <summary>
            Combines an array of sliding local blocks into a large containing tensor.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="output_size">Describes the spatial shape of the large containing tensor of the sliding local blocks.</param>
            <param name="kernel_size">The size of the sliding blocks</param>
            <param name="dilation">A parameter that controls the stride of elements within the neighborhood.</param>
            <param name="padding">Implicit zero padding to be added on both sides of input.</param>
            <param name="stride">The stride of the sliding blocks in the input spatial dimensions.</param>
            <remarks>Currently, only unbatched (3D) or batched (4D) image-like output tensors are supported.</remarks>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.fold(TorchSharp.torch.Tensor,System.ValueTuple{System.Int64,System.Int64},System.ValueTuple{System.Int64,System.Int64},System.Nullable{System.ValueTuple{System.Int64,System.Int64}},System.Nullable{System.ValueTuple{System.Int64,System.Int64}},System.Nullable{System.ValueTuple{System.Int64,System.Int64}})">
            <summary>
            Combines an array of sliding local blocks into a large containing tensor.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="output_size">Describes the spatial shape of the large containing tensor of the sliding local blocks.</param>
            <param name="kernel_size">The size of the sliding blocks</param>
            <param name="dilation">A parameter that controls the stride of elements within the neighborhood.</param>
            <param name="padding">Implicit zero padding to be added on both sides of input.</param>
            <param name="stride">The stride of the sliding blocks in the input spatial dimensions.</param>
            <remarks>Currently, only unbatched (3D) or batched (4D) image-like output tensors are supported.</remarks>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.linear(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Applies a linear transformation to the incoming data.
            </summary>
            <param name="input">Input tensor of shape (*,Hin)</param>
            <param name="weights">Weights of shape (Hout,Hin) or (Hin)</param>
            <param name="bias">Bias of shape (Hout) or ()</param>
            <returns>A tensor of shape (*,Hout) where '*' is the same as the subshape of the input.</returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.binary_cross_entropy_with_logits(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.nn.Reduction,TorchSharp.torch.Tensor)">
            <summary>
            Function that measures Binary Cross Entropy between target and input logits.
            </summary>
            <param name="input">Tensor of arbitrary shape as unnormalized scores (often referred to as logits).</param>
            <param name="target">Tensor of the same shape as input with values between 0 and 1</param>
            <param name="weight">A manual rescaling weight if provided it’s repeated to match input tensor shape</param>
            <param name="reduction">Specifies the reduction to apply to the output</param>
            <param name="pos_weights">A weight of positive examples. Must be a vector with length equal to the number of classes.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.binary_cross_entropy(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.nn.Reduction)">
            <summary>
            Function that measures the Binary Cross Entropy between the target and input probabilities.
            </summary>
            <param name="input">Tensor of arbitrary shape as probabilities.</param>
            <param name="target">Tensor of the same shape as input with values between 0 and 1</param>
            <param name="weight">A manual rescaling weight if provided it’s repeated to match input tensor shape</param>
            <param name="reduction">Specifies the reduction to apply to the output</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.cross_entropy(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Int64,TorchSharp.torch.nn.Reduction,System.Double)">
            <summary>
            Computes the cross entropy loss between input and target.
            </summary>
            <param name="input">Tensor of arbitrary shape as unnormalized scores (often referred to as logits).</param>
            <param name="target">Ground truth class indices or class probabilities; see Shape section below for supported shapes.</param>
            <param name="weight">A manual rescaling weight if provided it’s repeated to match input tensor shape</param>
            <param name="ignore_index">
            Specifies a target value that is ignored and does not contribute to the input gradient.
            Note that ignore_index is only applicable when the target contains class indices.
            </param>
            <param name="reduction">Specifies the reduction to apply to the output</param>
            <param name="label_smoothing">A float in [0.0, 1.0].
            Specifies the amount of smoothing when computing the loss, where 0.0 means no smoothing.
            The targets become a mixture of the original ground truth and a uniform distribution.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.poisson_nll_loss(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Boolean,System.Boolean,System.Single,TorchSharp.torch.nn.Reduction)">
            <summary>
            Poisson negative log likelihood loss.
            </summary>
            <param name="input">Expectation of underlying Poisson distribution.</param>
            <param name="target">Random sample target.</param>
            <param name="log_input"></param>
            <param name="full">Whether to compute full loss, i.e. to add the Stirling approximation term.</param>
            <param name="eps">Small value to avoid evaluation of log(0)</param>
            <param name="reduction">Specifies the reduction to apply to the output</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.cosine_embedding_loss(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Double,TorchSharp.torch.nn.Reduction)">
             <summary>
            
             </summary>
             <param name="input1">(N,D) or (D), where N is the batch size and D is the embedding dimension.</param>
             <param name="input2">Same shape as input1</param>
             <param name="target">N or ()</param>
             <param name="margin">Should be a number from -1−1 to 11, 00 to 0.50.5 is suggested</param>
             <param name="reduction">Specifies the reduction to apply to the output</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.ctc_loss(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Int64,System.Boolean,TorchSharp.torch.nn.Reduction)">
            <summary>
            Computes the Connectionist Temporal Classification loss.
            </summary>
            <param name="log_probs">The logarithmized probabilities of the outputs.</param>
            <param name="targets"></param>
            <param name="input_lengths">Lengths of the inputs.</param>
            <param name="target_lengths">Lengths of the targets.</param>
            <param name="blank">Blank label.</param>
            <param name="zero_infinity">Whether to zero infinite losses and the associated gradients.</param>
            <param name="reduction">Specifies the reduction to apply to the output</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.hinge_embedding_loss(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Double,TorchSharp.torch.nn.Reduction)">
            <summary>
            Measures the loss given an input tensor x and a labels tensor y (containing 1 or -1).
            </summary>
            <param name="input"></param>
            <param name="target"></param>
            <param name="margin"> Should be a number from -1 to 1, 0 to 0.5 is suggested</param>
            <param name="reduction">Specifies the reduction to apply to the output</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.huber_loss(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Double,TorchSharp.torch.nn.Reduction)">
            <summary>
            Function that uses a squared term if the absolute element-wise error falls below delta and a delta-scaled L1 term otherwise.
            </summary>
            <param name="input"></param>
            <param name="target"></param>
            <param name="delta">Specifies the threshold at which to change between delta-scaled L1 and L2 loss. The value must be positive. Default: 1.0</param>
            <param name="reduction">Specifies the reduction to apply to the output</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.margin_ranking_loss(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Double,TorchSharp.torch.nn.Reduction)">
            <summary>
            Creates a criterion that measures the loss given inputs x1, x2, two 1D mini-batch or 0D Tensors, and a label 1D mini-batch or 0D Tensor y (containing 1 or -1).
            </summary>
            <param name="input1"></param>
            <param name="input2"></param>
            <param name="target"></param>
            <param name="margin">Has a default value of 0.</param>
            <param name="reduction">Specifies the reduction to apply to the output</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.multi_label_margin_loss(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.nn.Reduction)">
            <summary>
            Creates a criterion that optimizes a multi-class multi-classification hinge loss (margin-based loss) between input x (a 2D mini-batch Tensor)
            and output y (which is a 2D Tensor of target class indices).
            </summary>
            <param name="input"></param>
            <param name="target"></param>
            <param name="reduction">Specifies the reduction to apply to the output</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.multilabel_soft_margin_loss(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.nn.Reduction)">
            <summary>
            Creates a criterion that optimizes a multi-label one-versus-all loss based on max-entropy, between input x and target y of size NxC.
            </summary>
            <param name="input"></param>
            <param name="target"></param>
            <param name="weight">A manual rescaling weight if provided it’s repeated to match input tensor shape</param>
            <param name="reduction">Specifies the reduction to apply to the output</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.multi_margin_loss(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Int32,System.Double,TorchSharp.torch.Tensor,TorchSharp.torch.nn.Reduction)">
            <summary>
            Creates a criterion that optimizes a multi-class classification hinge loss.
            </summary>
            <param name="input"></param>
            <param name="target"></param>
            <param name="p">Has a default value of 1. 1 and 2 are the only supported values.</param>
            <param name="margin">Has a default value of 1</param>
            <param name="weight">A manual rescaling weight if provided it’s repeated to match input tensor shape</param>
            <param name="reduction">Specifies the reduction to apply to the output</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.mse_loss(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.nn.Reduction)">
            <summary>
            Measures the element-wise mean squared error.
            </summary>
            <param name="input">Tensor of any shape.</param>
            <param name="target">Tensor of the same shape as 'input'</param>
            <param name="reduction">Specifies the reduction to apply to the output</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.l1_loss(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.nn.Reduction)">
            <summary>
            Function that takes the mean element-wise absolute value difference.
            </summary>
            <param name="input">Tensor of any shape.</param>
            <param name="target">Tensor of the same shape as 'input'</param>
            <param name="reduction">Specifies the reduction to apply to the output</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.nll_loss(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.nn.Reduction)">
            <summary>
            Computes the negative log likelihood loss.
            </summary>
            <param name="input"></param>
            <param name="target"></param>
            <param name="weight">A manual rescaling weight if provided it’s repeated to match input tensor shape</param>
            <param name="reduction">Specifies the reduction to apply to the output</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.gaussian_nll_loss(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Boolean,System.Single,TorchSharp.torch.nn.Reduction)">
            <summary>
            Gaussian negative log likelihood loss.
            </summary>
            <param name="input"></param>
            <param name="target"></param>
            <param name="variance">Tensor of positive variance(s), one for each of the expectations in the input (heteroscedastic), or a single one (homoscedastic).</param>
            <param name="full">Include the constant term in the loss calculation. </param>
            <param name="eps">Value added to var, for stability</param>
            <param name="reduction">Specifies the reduction to apply to the output</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.kl_div(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Boolean,TorchSharp.torch.nn.Reduction)">
            <summary>
            Computes the Kullback-Leibler divergence Loss
            </summary>
            <param name="input"></param>
            <param name="target"></param>
            <param name="log_target">A flag indicating whether target is passed in the log space.</param>
            <param name="reduction">Specifies the reduction to apply to the output</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.smooth_l1_loss(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.nn.Reduction,System.Double)">
            <summary>
            Function that uses a squared term if the absolute element-wise error falls below beta and an L1 term otherwise.
            </summary>
            <param name="input"></param>
            <param name="target"></param>
            <param name="reduction">Specifies the reduction to apply to the output</param>
            <param name="beta">Specifies the threshold at which to change between L1 and L2 loss. The value must be non-negative.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.soft_margin_loss(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.nn.Reduction)">
            <summary>
             Optimizes a two-class classification logistic loss between input tensor x and target tensor y (containing 1 or -1).
            </summary>
            <param name="input"></param>
            <param name="target"></param>
            <param name="reduction">Specifies the reduction to apply to the output</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.triplet_margin_loss(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Double,System.Int64,System.Double,System.Boolean,TorchSharp.torch.nn.Reduction)">
            <summary>
            Creates a criterion that measures the triplet loss given an input tensors x1, x2, x3 and a margin with a value greater than 0.
            This is used for measuring a relative similarity between samples.
            </summary>
            <param name="anchor"></param>
            <param name="positive"></param>
            <param name="negative"></param>
            <param name="margin">
            A nonnegative margin representing the minimum difference between the positive and negative distances required for the loss to be 0.
            Larger margins penalize cases where the negative examples are not distant enough from the anchors, relative to the positives.
            </param>
            <param name="p">The norm degree for pairwise distance. </param>
            <param name="eps"></param>
            <param name="swap">
            If true, and if the positive example is closer to the negative example than the anchor is, swaps the positive example and the anchor in the loss computation.
            The distance swap is described in detail in the paper Learning shallow convolutional feature descriptors with triplet losses by V. Balntas, E. Riba et al.
            </param>
            <param name="reduction">Specifies the reduction to apply to the output</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.triplet_margin_with_distance_loss(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Func{TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor},System.Double,System.Boolean,TorchSharp.torch.nn.Reduction)">
            <summary>
            Creates a criterion that measures the triplet loss given input tensors a, p, and n (representing anchor, positive, and negative examples, respectively),
            and a nonnegative, real-valued function ("distance function") used to compute the relationship between the anchor and positive example ("positive distance")
            and the anchor and negative example ("negative distance").
            </summary>
            <param name="anchor"></param>
            <param name="positive"></param>
            <param name="negative"></param>
            <param name="distance"> A nonnegative, real-valued function that quantifies the closeness of two tensors. If not specified, nn.PairwiseDistance will be used.</param>
            <param name="margin">
            A nonnegative margin representing the minimum difference between the positive and negative distances required for the loss to be 0.
            Larger margins penalize cases where the negative examples are not distant enough from the anchors, relative to the positives.
            </param>
            <param name="swap">
            If true, and if the positive example is closer to the negative example than the anchor is, swaps the positive example and the anchor in the loss computation.
            The distance swap is described in detail in the paper Learning shallow convolutional feature descriptors with triplet losses by V. Balntas, E. Riba et al.
            </param>
            <param name="reduction">Specifies the reduction to apply to the output</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.normalize(TorchSharp.torch.Tensor,System.Double,System.Int64,System.Double)">
            <summary>
            Perform normalization of inputs over specified dimension.
            </summary>
            <param name="input">Input tensor of any shape.</param>
            <param name="p">the exponent value in the norm formulation</param>
            <param name="dim">the dimension to reduce</param>
            <param name="eps">small value to avoid division by zero</param>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.batch_norm(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Boolean,System.Double,System.Double)">
            <summary>
            Applies Batch Normalization for each channel across a batch of data.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.group_norm(TorchSharp.torch.Tensor,System.Int64,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Double)">
            <summary>
            Applies Group Normalization for last certain number of dimensions.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.instance_norm(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Boolean,System.Double,System.Double)">
            <summary>
            Applies Instance Normalization for each channel in each data sample in a batch.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.layer_norm(TorchSharp.torch.Tensor,System.Int64[],TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Double)">
            <summary>
            Applies Layer Normalization for last certain number of dimensions.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.local_response_norm(TorchSharp.torch.Tensor,System.Int64,System.Double,System.Double,System.Double)">
            <summary>
            Applies local response normalization over an input signal.
            The input signal is composed of several input planes, where channels occupy the second dimension.
            Applies normalization across channels.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.one_hot(TorchSharp.torch.Tensor,System.Int64)">
            <summary>
            Takes LongTensor with index values of shape (*) and returns a tensor of shape (*, num_classes) that have zeros
            everywhere except where the index of last dimension matches the corresponding value of the input tensor, in which case it will be 1.
            </summary>
            <param name="x">Category values of any shape</param>
            <param name="num_classes">Total number of classes.
            If set to -1, the number of classes will be inferred as one greater than the largest class value in the input tensor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.pairwise_distance(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Double,System.Double,System.Boolean)">
            <summary>
            Computes the pairwise distance between vectors using the p-norm.
            </summary>
            <param name="input1">(N,D) or (D) where N = batch dimension and D = vector dimension</param>
            <param name="input2">(N, D) or (D), same shape as the Input1</param>
            <param name="p">The norm degree. Default: 2</param>
            <param name="eps">Small value to avoid division by zero.</param>
            <param name="keepdim">Determines whether or not to keep the vector dimension.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.pixel_shuffle(TorchSharp.torch.Tensor,System.Int64)">
            <summary>
            Rearranges elements in a tensor of shape (*, C * r^2, H, W) to a tensor of shape(*, C, H * r, W * r), where r is an upscale factor.
            This is useful for implementing efficient sub-pixel convolution with a stride of 1/r.
            </summary>
            <param name="input">Input tensor</param>
            <param name="upscale_factor">Factor to increase spatial resolution by</param>
            <returns></returns>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.pixel_unshuffle(TorchSharp.torch.Tensor,System.Int64)">
            <summary>
            Reverses the PixelShuffle operation by rearranging elements in a tensor of shape (*, C * r^2, H, W) to a tensor of shape(*, C, H * r, W * r), where r is an downscale factor.
            This is useful for implementing efficient sub-pixel convolution with a stride of 1/r.
            </summary>
            <param name="input">Input tensor</param>
            <param name="downscale_factor">Factor to increase spatial resolution by</param>
            <returns></returns>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.adaptive_avg_pool1d(TorchSharp.torch.Tensor,System.Int64)">
            <summary>
            Applies a 1D adaptive average pooling over an input signal composed of several input planes.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="output_size"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.adaptive_avg_pool2d(TorchSharp.torch.Tensor,System.Int64[])">
            <summary>
            Applies a 2D adaptive average pooling over an input signal composed of several input planes.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="output_size"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.adaptive_avg_pool2d(TorchSharp.torch.Tensor,System.ValueTuple{System.Int64,System.Int64})">
            <summary>
            Applies a 2D adaptive average pooling over an input signal composed of several input planes.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="output_size"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.adaptive_avg_pool2d(TorchSharp.torch.Tensor,System.Int64)">
            <summary>
            Applies a 2D adaptive average pooling over an input signal composed of several input planes.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="output_size"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.adaptive_avg_pool3d(TorchSharp.torch.Tensor,System.Int64[])">
            <summary>
            Applies a 3D adaptive average pooling over an input signal composed of several input planes.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="output_size"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.adaptive_avg_pool3d(TorchSharp.torch.Tensor,System.ValueTuple{System.Int64,System.Int64,System.Int64})">
            <summary>
            Applies a 2D adaptive average pooling over an input signal composed of several input planes.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="output_size"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.adaptive_avg_pool3d(TorchSharp.torch.Tensor,System.Int64)">
            <summary>
            Applies a 2D adaptive average pooling over an input signal composed of several input planes.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="output_size"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.adaptive_max_pool1d(TorchSharp.torch.Tensor,System.Int64)">
            <summary>
            Applies a 1D adaptive max pooling over an input signal composed of several input planes.
            The output size is H, for any input size.The number of output features is equal to the number of input planes.
            </summary>
            <param name="input"></param>
            <param name="output_size">The target output size H.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.adaptive_max_pool1d_with_indices(TorchSharp.torch.Tensor,System.Int64)">
            <summary>
            Applies a 1D adaptive max pooling over an input signal composed of several input planes.
            The output size is H, for any input size.The number of output features is equal to the number of input planes.
            </summary>
            <param name="input"></param>
            <param name="output_size">The target output size H.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.adaptive_max_pool2d(TorchSharp.torch.Tensor,System.Int64[])">
            <summary>
            Applies a 2D adaptive max pooling over an input signal composed of several input planes.
            The output is of size H x W, for any input size.The number of output features is equal to the number of input planes.
            </summary>
            <param name="input"></param>
            <param name="output_size">Applies a 2D adaptive max pooling over an input signal composed of several input planes.
            The output is of size H x W, for any input size.The number of output features is equal to the number of input planes.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.adaptive_max_pool2d_with_indices(TorchSharp.torch.Tensor,System.Int64[])">
            <summary>
            Applies a 2D adaptive max pooling over an input signal composed of several input planes.
            The output is of size H x W, for any input size.The number of output features is equal to the number of input planes.
            </summary>
            <param name="input"></param>
            <param name="output_size">Applies a 2D adaptive max pooling over an input signal composed of several input planes.
            The output is of size H x W, for any input size.The number of output features is equal to the number of input planes.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.adaptive_max_pool3d(TorchSharp.torch.Tensor,System.Int64[])">
            <summary>
            Applies a 3D adaptive max pooling over an input signal composed of several input planes.
            The output is of size D x H x W, for any input size.The number of output features is equal to the number of input planes.
            </summary>
            <param name="input">The input tensor</param>
            <param name="output_size">The target output size of the image of the form D x H x W.
            Can be a tuple (D, H, W) or a single D for a cube D x D x D. D, H and W can be either a int, or null which means the size will be the same as that of the input.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.adaptive_max_pool3d_with_indices(TorchSharp.torch.Tensor,System.Int64[])">
            <summary>
            Applies a 3D adaptive max pooling over an input signal composed of several input planes.
            The output is of size D x H x W, for any input size.The number of output features is equal to the number of input planes.
            </summary>
            <param name="input">The input tensor</param>
            <param name="output_size">The target output size of the image of the form D x H x W.
            Can be a tuple (D, H, W) or a single D for a cube D x D x D. D, H and W can be either a int, or null which means the size will be the same as that of the input.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.avg_pool1d(TorchSharp.torch.Tensor,System.Int64,System.Nullable{System.Int64},System.Nullable{System.Int64},System.Boolean,System.Boolean)">
            <summary>
            Applies a 1D average pooling over an input signal composed of several input planes.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="kernel_size"></param>
            <param name="stride"></param>
            <param name="padding"></param>
            <param name="ceil_mode"></param>
            <param name="count_include_pad"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.avg_pool2d(TorchSharp.torch.Tensor,System.Int64[],System.Int64[],System.Int64[],System.Boolean,System.Boolean,System.Nullable{System.Int64})">
            <summary>
            Applies 2D average-pooling operation in kH × kW regions by step size sH * sW steps. The number of output features is equal to the number of input planes.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="kernel_size"></param>
            <param name="stride"></param>
            <param name="padding"></param>
            <param name="ceil_mode"></param>
            <param name="count_include_pad"></param>
            <param name="divisor_override"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.avg_pool2d(TorchSharp.torch.Tensor,System.Int64,System.Nullable{System.Int64},System.Int64,System.Boolean,System.Boolean,System.Nullable{System.Int64})">
            <summary>
            Applies 2D average-pooling operation in kH × kW regions by step size sH * sW steps. The number of output features is equal to the number of input planes.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="kernel_size"></param>
            <param name="stride"></param>
            <param name="padding"></param>
            <param name="ceil_mode"></param>
            <param name="count_include_pad"></param>
            <param name="divisor_override"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.avg_pool2d(TorchSharp.torch.Tensor,System.ValueTuple{System.Int64,System.Int64},System.Nullable{System.ValueTuple{System.Int64,System.Int64}},System.Nullable{System.ValueTuple{System.Int64,System.Int64}},System.Boolean,System.Boolean,System.Nullable{System.Int64})">
            <summary>
            Applies 2D average-pooling operation in kH × kW regions by step size sH * sW steps. The number of output features is equal to the number of input planes.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="kernel_size"></param>
            <param name="stride"></param>
            <param name="padding"></param>
            <param name="ceil_mode"></param>
            <param name="count_include_pad"></param>
            <param name="divisor_override"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.avg_pool3d(TorchSharp.torch.Tensor,System.Int64[],System.Int64[],System.Int64[],System.Boolean,System.Boolean,System.Nullable{System.Int64})">
            <summary>
            Applies 3D average-pooling operation in kT x kH x kW regions by step size sT x sH x sW steps.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="kernel_size"></param>
            <param name="stride"></param>
            <param name="padding"></param>
            <param name="ceil_mode"></param>
            <param name="count_include_pad"></param>
            <param name="divisor_override"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.fractional_max_pool2d(TorchSharp.torch.Tensor,System.Int64,System.Nullable{System.Int64},System.Nullable{System.Double})">
             <summary>
             Applies a 2D fractional max pooling over an input signal composed of several input planes.
            
             Fractional MaxPooling is described in detail in the paper Fractional MaxPooling by Ben Graham,
             see: https://arxiv.org/abs/1412.6071
             </summary>
             <param name="input">The input tensor</param>
             <param name="kernel_size">The size of the sliding window, must be > 0.</param>
             <param name="output_size">The target output size of the image of the form oH x oW. Can be a tuple (oH, oW) or a single number oH for a square image oH x oH</param>
             <param name="output_ratio">If one wants to have an output size as a ratio of the input size, this option can be given. This has to be a number or tuple in the range (0, 1)</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.fractional_max_pool2d(TorchSharp.torch.Tensor,System.ValueTuple{System.Int64,System.Int64},System.Nullable{System.ValueTuple{System.Int64,System.Int64}},System.Nullable{System.ValueTuple{System.Double,System.Double}})">
             <summary>
             Applies a 2D fractional max pooling over an input signal composed of several input planes.
            
             Fractional MaxPooling is described in detail in the paper Fractional MaxPooling by Ben Graham,
             see: https://arxiv.org/abs/1412.6071
             </summary>
             <param name="input">The input tensor</param>
             <param name="kernel_size">The size of the sliding window, must be > 0.</param>
             <param name="output_size">The target output size of the image of the form oH x oW. Can be a tuple (oH, oW) or a single number oH for a square image oH x oH</param>
             <param name="output_ratio">If one wants to have an output size as a ratio of the input size, this option can be given. This has to be a number or tuple in the range (0, 1)</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.fractional_max_pool2d(TorchSharp.torch.Tensor,System.Int64[],System.Int64[],System.Double[])">
             <summary>
             Applies a 2D fractional max pooling over an input signal composed of several input planes.
            
             Fractional MaxPooling is described in detail in the paper Fractional MaxPooling by Ben Graham,
             see: https://arxiv.org/abs/1412.6071
             </summary>
             <param name="input">The input tensor</param>
             <param name="kernel_size">The size of the sliding window, must be > 0.</param>
             <param name="output_size">The target output size of the image of the form oH x oW. Can be a tuple (oH, oW) or a single number oH for a square image oH x oH</param>
             <param name="output_ratio">If one wants to have an output size as a ratio of the input size, this option can be given. This has to be a number or tuple in the range (0, 1)</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.fractional_max_pool2d_with_indices(TorchSharp.torch.Tensor,System.Int64,System.Nullable{System.Int64},System.Nullable{System.Double})">
             <summary>
             Applies a 2D fractional max pooling over an input signal composed of several input planes.
            
             Fractional MaxPooling is described in detail in the paper Fractional MaxPooling by Ben Graham,
             see: https://arxiv.org/abs/1412.6071
             </summary>
             <param name="input">The input tensor</param>
             <param name="kernel_size">The size of the sliding window, must be > 0.</param>
             <param name="output_size">The target output size of the image of the form oH x oW. Can be a tuple (oH, oW) or a single number oH for a square image oH x oH</param>
             <param name="output_ratio">If one wants to have an output size as a ratio of the input size, this option can be given. This has to be a number or tuple in the range (0, 1)</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.fractional_max_pool2d_with_indices(TorchSharp.torch.Tensor,System.ValueTuple{System.Int64,System.Int64},System.Nullable{System.ValueTuple{System.Int64,System.Int64}},System.Nullable{System.ValueTuple{System.Double,System.Double}})">
             <summary>
             Applies a 2D fractional max pooling over an input signal composed of several input planes.
            
             Fractional MaxPooling is described in detail in the paper Fractional MaxPooling by Ben Graham,
             see: https://arxiv.org/abs/1412.6071
             </summary>
             <param name="input">The input tensor</param>
             <param name="kernel_size">The size of the sliding window, must be > 0.</param>
             <param name="output_size">The target output size of the image of the form oH x oW. Can be a tuple (oH, oW) or a single number oH for a square image oH x oH</param>
             <param name="output_ratio">If one wants to have an output size as a ratio of the input size, this option can be given. This has to be a number or tuple in the range (0, 1)</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.fractional_max_pool2d_with_indices(TorchSharp.torch.Tensor,System.Int64[],System.Int64[],System.Double[])">
             <summary>
             Applies a 2D fractional max pooling over an input signal composed of several input planes.
            
             Fractional MaxPooling is described in detail in the paper Fractional MaxPooling by Ben Graham,
             see: https://arxiv.org/abs/1412.6071
             </summary>
             <param name="input">The input tensor</param>
             <param name="kernel_size">The size of the sliding window, must be > 0.</param>
             <param name="output_size">The target output size of the image of the form oH x oW. Can be a tuple (oH, oW) or a single number oH for a square image oH x oH</param>
             <param name="output_ratio">If one wants to have an output size as a ratio of the input size, this option can be given. This has to be a number or tuple in the range (0, 1)</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.fractional_max_pool3d(TorchSharp.torch.Tensor,System.Int64,System.Nullable{System.Int64},System.Nullable{System.Double})">
             <summary>
             Applies a 3d fractional max pooling over an input signal composed of several input planes.
            
             Fractional MaxPooling is described in detail in the paper Fractional MaxPooling by Ben Graham,
             see: https://arxiv.org/abs/1412.6071
             </summary>
             <param name="input">The input tensor</param>
             <param name="kernel_size">The size of the sliding window, must be > 0.</param>
             <param name="output_size">The target output size of the image of the form oH x oW. Can be a tuple (oH, oW) or a single number oH for a square image oH x oH</param>
             <param name="output_ratio">If one wants to have an output size as a ratio of the input size, this option can be given. This has to be a number or tuple in the range (0, 1)</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.fractional_max_pool3d(TorchSharp.torch.Tensor,System.ValueTuple{System.Int64,System.Int64,System.Int64},System.Nullable{System.ValueTuple{System.Int64,System.Int64,System.Int64}},System.Nullable{System.ValueTuple{System.Double,System.Double,System.Double}})">
             <summary>
             Applies a 3d fractional max pooling over an input signal composed of several input planes.
            
             Fractional MaxPooling is described in detail in the paper Fractional MaxPooling by Ben Graham,
             see: https://arxiv.org/abs/1412.6071
             </summary>
             <param name="input">The input tensor</param>
             <param name="kernel_size">The size of the sliding window, must be > 0.</param>
             <param name="output_size">The target output size of the image of the form oH x oW. Can be a tuple (oH, oW) or a single number oH for a square image oH x oH</param>
             <param name="output_ratio">If one wants to have an output size as a ratio of the input size, this option can be given. This has to be a number or tuple in the range (0, 1)</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.fractional_max_pool3d(TorchSharp.torch.Tensor,System.Int64[],System.Int64[],System.Double[])">
             <summary>
             Applies a 3d fractional max pooling over an input signal composed of several input planes.
            
             Fractional MaxPooling is described in detail in the paper Fractional MaxPooling by Ben Graham,
             see: https://arxiv.org/abs/1412.6071
             </summary>
             <param name="input">The input tensor</param>
             <param name="kernel_size">The size of the sliding window, must be > 0.</param>
             <param name="output_size">The target output size of the image of the form oH x oW. Can be a tuple (oH, oW) or a single number oH for a square image oH x oH</param>
             <param name="output_ratio">If one wants to have an output size as a ratio of the input size, this option can be given. This has to be a number or tuple in the range (0, 1)</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.fractional_max_pool3d_with_indices(TorchSharp.torch.Tensor,System.Int64,System.Nullable{System.Int64},System.Nullable{System.Double})">
             <summary>
             Applies a 3d fractional max pooling over an input signal composed of several input planes.
            
             Fractional MaxPooling is described in detail in the paper Fractional MaxPooling by Ben Graham,
             see: https://arxiv.org/abs/1412.6071
             </summary>
             <param name="input">The input tensor</param>
             <param name="kernel_size">The size of the sliding window, must be > 0.</param>
             <param name="output_size">The target output size of the image of the form oH x oW. Can be a tuple (oH, oW) or a single number oH for a square image oH x oH</param>
             <param name="output_ratio">If one wants to have an output size as a ratio of the input size, this option can be given. This has to be a number or tuple in the range (0, 1)</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.fractional_max_pool3d_with_indices(TorchSharp.torch.Tensor,System.ValueTuple{System.Int64,System.Int64,System.Int64},System.Nullable{System.ValueTuple{System.Int64,System.Int64,System.Int64}},System.Nullable{System.ValueTuple{System.Double,System.Double,System.Double}})">
             <summary>
             Applies a 3d fractional max pooling over an input signal composed of several input planes.
            
             Fractional MaxPooling is described in detail in the paper Fractional MaxPooling by Ben Graham,
             see: https://arxiv.org/abs/1412.6071
             </summary>
             <param name="input">The input tensor</param>
             <param name="kernel_size">The size of the sliding window, must be > 0.</param>
             <param name="output_size">The target output size of the image of the form oH x oW. Can be a tuple (oH, oW) or a single number oH for a square image oH x oH</param>
             <param name="output_ratio">If one wants to have an output size as a ratio of the input size, this option can be given. This has to be a number or tuple in the range (0, 1)</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.fractional_max_pool3d_with_indices(TorchSharp.torch.Tensor,System.Int64[],System.Int64[],System.Double[])">
             <summary>
             Applies a 3d fractional max pooling over an input signal composed of several input planes.
            
             Fractional MaxPooling is described in detail in the paper Fractional MaxPooling by Ben Graham,
             see: https://arxiv.org/abs/1412.6071
             </summary>
             <param name="input">The input tensor</param>
             <param name="kernel_size">The size of the sliding window, must be > 0.</param>
             <param name="output_size">The target output size of the image of the form oH x oW. Can be a tuple (oH, oW) or a single number oH for a square image oH x oH</param>
             <param name="output_ratio">If one wants to have an output size as a ratio of the input size, this option can be given. This has to be a number or tuple in the range (0, 1)</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.lp_pool1d(TorchSharp.torch.Tensor,System.Double,System.Int64,System.Nullable{System.Int64},System.Boolean)">
            <summary>
            Applies a 1D power-average pooling over an input signal composed of several input planes.
            </summary>
            <param name="input">The input tensor</param>
            <param name="norm_type">The LP norm (exponent)</param>
            <param name="kernel_size">The size of the window</param>
            <param name="stride">The stride of the window. Default value is kernel_size</param>
            <param name="ceil_mode">Use ceil instead of floor to compute the output shape</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.lp_pool2d(TorchSharp.torch.Tensor,System.Double,System.Int64[],System.Int64[],System.Boolean)">
            <summary>
            Applies a 2D power-average pooling over an input signal composed of several input planes.
            </summary>
            <param name="input">The input tensor</param>
            <param name="norm_type">The LP norm (exponent)</param>
            <param name="kernel_size">The size of the window</param>
            <param name="stride">The stride of the window. Default value is kernel_size</param>
            <param name="ceil_mode">Use ceil instead of floor to compute the output shape</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.lp_pool2d(TorchSharp.torch.Tensor,System.Double,System.Int64,System.Nullable{System.Int64},System.Boolean)">
            <summary>
            Applies a 2D power-average pooling over an input signal composed of several input planes.
            </summary>
            <param name="input">The input tensor</param>
            <param name="norm_type">The LP norm (exponent)</param>
            <param name="kernel_size">The size of the window</param>
            <param name="stride">The stride of the window.</param>
            <param name="ceil_mode">Use ceil instead of floor to compute the output shape</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.max_pool1d(TorchSharp.torch.Tensor,System.Int64,System.Nullable{System.Int64},System.Nullable{System.Int64},System.Nullable{System.Int64},System.Boolean)">
            <summary>
            Applies a 1D max pooling over an input signal composed of several input planes.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="kernel_size"></param>
            <param name="stride"></param>
            <param name="padding"></param>
            <param name="dilation"></param>
            <param name="ceil_mode"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.max_pool1d_with_indices(TorchSharp.torch.Tensor,System.Int64,System.Nullable{System.Int64},System.Nullable{System.Int64},System.Nullable{System.Int64},System.Boolean)">
            <summary>
            Applies a 1D max pooling over an input signal composed of several input planes.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="kernel_size"></param>
            <param name="stride"></param>
            <param name="padding"></param>
            <param name="dilation"></param>
            <param name="ceil_mode"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.max_pool2d(TorchSharp.torch.Tensor,System.Int64[],System.Int64[],System.Int64[],System.Int64[],System.Boolean)">
            <summary>
            Applies a 2D max pooling over an input signal composed of several input planes.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="kernel_size"></param>
            <param name="strides"></param>
            <param name="padding"></param>
            <param name="dilation"></param>
            <param name="ceil_mode"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.max_pool2d(TorchSharp.torch.Tensor,System.Int64,System.Nullable{System.Int64},System.Nullable{System.Int64},System.Nullable{System.Int64},System.Boolean)">
            <summary>
            Applies a 2D max pooling over an input signal composed of several input planes.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="kernel_size"></param>
            <param name="stride"></param>
            <param name="padding"></param>
            <param name="dilation"></param>
            <param name="ceil_mode"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.max_pool2d(TorchSharp.torch.Tensor,System.ValueTuple{System.Int64,System.Int64},System.Nullable{System.ValueTuple{System.Int64,System.Int64}},System.Nullable{System.ValueTuple{System.Int64,System.Int64}},System.Nullable{System.ValueTuple{System.Int64,System.Int64}},System.Boolean)">
            <summary>
            Applies a 2D max pooling over an input signal composed of several input planes.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="kernel_size"></param>
            <param name="stride"></param>
            <param name="padding"></param>
            <param name="dilation"></param>
            <param name="ceil_mode"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.max_pool2d_with_indices(TorchSharp.torch.Tensor,System.Int64[],System.Int64[],System.Int64[],System.Int64[],System.Boolean)">
            <summary>
            Applies a 2D max pooling over an input signal composed of several input planes.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="kernel_size"></param>
            <param name="strides"></param>
            <param name="padding"></param>
            <param name="dilation"></param>
            <param name="ceil_mode"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.max_pool3d(TorchSharp.torch.Tensor,System.Int64[],System.Int64[],System.Int64[],System.Int64[],System.Boolean)">
            <summary>
            Applies a 3D max pooling over an input signal composed of several input planes.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="kernel_size"></param>
            <param name="strides"></param>
            <param name="padding"></param>
            <param name="dilation"></param>
            <param name="ceil_mode"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.max_pool3d_with_indices(TorchSharp.torch.Tensor,System.Int64[],System.Int64[],System.Int64[],System.Int64[],System.Boolean)">
            <summary>
            Applies a 3D max pooling over an input signal composed of several input planes.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="kernel_size"></param>
            <param name="strides"></param>
            <param name="padding"></param>
            <param name="dilation"></param>
            <param name="ceil_mode"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.max_unpool1d(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Int64,System.Nullable{System.Int64},System.Nullable{System.Int64},System.Int64[])">
            <summary>
            Applies a 1D max pooling over an input signal composed of several input planes.
            </summary>
            <param name="input">the input Tensor to invert</param>
            <param name="indices">the indices given out by :class:`~torch.nn.MaxPool1d`</param>
            <param name="kernel_size">The size of the sliding window, must be > 0.</param>
            <param name="stride">The stride of the sliding window, must be > 0. Default value is kernel_size.</param>
            <param name="padding">Implicit negative infinity padding to be added on both sides, must be >= 0 and less than or equal to kernel_size / 2</param>
            <param name="output_size">(optional): The targeted output size</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.max_unpool2d(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Int64[],System.Int64[],System.Int64[],System.Int64[])">
            <summary>
            Computes a partial inverse of MaxPool2d.
            </summary>
            <param name="input">the input Tensor to invert</param>
            <param name="indices">the indices given out by :class:`~torch.nn.MaxPool2d`</param>
            <param name="kernel_size">The size of the sliding window, must be > 0.</param>
            <param name="stride">The stride of the sliding window, must be > 0. Default value is kernel_size.</param>
            <param name="padding">Implicit negative infinity padding to be added on both sides, must be >= 0 and less than or equal to kernel_size / 2</param>
            <param name="output_size">(optional): The targeted output size</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.max_unpool3d(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Int64[],System.Int64[],System.Int64[],System.Int64[])">
            <summary>
            Computes a partial inverse of MaxPool3d.
            </summary>
            <param name="input">the input Tensor to invert</param>
            <param name="indices">the indices given out by :class:`~torch.nn.MaxPool3d`</param>
            <param name="kernel_size">The size of the sliding window, must be > 0.</param>
            <param name="stride">The stride of the sliding window, must be > 0. Default value is kernel_size.</param>
            <param name="padding">Implicit negative infinity padding to be added on both sides, must be >= 0 and less than or equal to kernel_size / 2</param>
            <param name="output_size">(optional): The targeted output size</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.scaled_dot_product_attention(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Double,System.Boolean)">
            <summary>
            Computes scaled dot product attention on query, key and value tensors, using an optional attention mask if passed, and applying dropout if a probability greater than 0.0 is specified.
            </summary>
            <param name="query">Query tensor, shaped (N, ..., L, E)</param>
            <param name="key">Key tensor, shaped (N, ..., S, E)</param>
            <param name="value">Value tensor, shaped (N, ..., S, Ev)</param>
            <param name="attn_mask">
            Attention mask, shaped (N, ..., L, S).
            Two types of masks are supported:
            A boolean mask where a value of True indicates that the element should take part in attention.
            A float mask of the same type as query, key, value that is added to the attention score.
            </param>
            <param name="p">Dropout probability</param>
            <param name="is_casual">If true, assumes causal attention masking and errors if both attn_mask and is_causal are set.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.unfold(TorchSharp.torch.Tensor,System.Int64,System.Int64,System.Int64,System.Int64)">
            <summary>
            Extracts sliding local blocks from a batched input tensor.
            </summary>
            <param name="input">The input tensor. Must be 4-D (batched images).</param>
            <param name="kernel_size">The size of the sliding blocks</param>
            <param name="dilation">A parameter that controls the stride of elements within the neighborhood.</param>
            <param name="padding">Implicit zero padding to be added on both sides of input.</param>
            <param name="stride">The stride of the sliding blocks in the input spatial dimensions.</param>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.unfold(TorchSharp.torch.Tensor,System.ValueTuple{System.Int64,System.Int64},System.Nullable{System.ValueTuple{System.Int64,System.Int64}},System.Nullable{System.ValueTuple{System.Int64,System.Int64}},System.Nullable{System.ValueTuple{System.Int64,System.Int64}})">
            <summary>
            Extracts sliding local blocks from a batched input tensor.
            </summary>
            <param name="input">The input tensor. Must be 4-D (batched images).</param>
            <param name="kernel_size">The size of the sliding blocks</param>
            <param name="dilation">A parameter that controls the stride of elements within the neighborhood.</param>
            <param name="padding">Implicit zero padding to be added on both sides of input.</param>
            <param name="stride">The stride of the sliding blocks in the input spatial dimensions.</param>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.upsample(TorchSharp.torch.Tensor,System.Int64[],System.Double[],TorchSharp.torch.UpsampleMode,System.Boolean)">
            <summary>
            Upsamples a given multi-channel 1D (temporal), 2D (spatial) or 3D (volumetric) data.
            The input data is assumed to be of the form minibatch x channels x[optional depth] x[optional height] x width.
            Hence, for spatial inputs, we expect a 4D Tensor and for volumetric inputs, we expect a 5D Tensor.
            </summary>
            <param name="input">Input tensor</param>
            <param name="size">Output spatial sizes</param>
            <param name="scale_factor">Multiplier for spatial size. Has to match input size</param>
            <param name="mode">The upsampling algorithm: one of 'nearest', 'linear', 'bilinear', 'bicubic' and 'trilinear'. Default: 'nearest'</param>
            <param name="align_corners">If true, the corner pixels of the input and output tensors are aligned, and thus preserving the values at those pixels.
            This only has effect when mode is 'linear', 'bilinear', or 'trilinear'. Default: false</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.upsample_nearest1d(TorchSharp.torch.Tensor,System.Nullable{System.Int64},System.Nullable{System.Double})">
            <summary>
            Upsamples the input, using nearest neighbours’ pixel values.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="outputSize"></param>
            <param name="scaleFactor"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.upsample_nearest2d(TorchSharp.torch.Tensor,System.Int64[],System.Double[])">
            <summary>
            Upsamples the input, using nearest neighbours’ pixel values.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="outputSizes"></param>
            <param name="scaleFactors"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.upsample_nearest3d(TorchSharp.torch.Tensor,System.Int64[],System.Double[])">
            <summary>
            Upsamples the input, using nearest neighbours’ pixel values.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="outputSizes"></param>
            <param name="scaleFactors"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.pad(TorchSharp.torch.Tensor,System.Int64[],TorchSharp.PaddingModes,System.Double)">
            <summary>
            Pads tensor.
            </summary>
            <param name="input">N-dimensional tensor</param>
            <param name="pad">m-elements tuple, where m/2 ≤ input dimensions and m is even</param>
            <param name="mode">'constant', 'reflect', 'replicate' or 'circular'. Default: 'constant'</param>
            <param name="value">Fill value for 'constant' padding. Default: 0</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.pad(TorchSharp.torch.Tensor,System.ReadOnlySpan{System.Int64},TorchSharp.PaddingModes,System.Double)">
            <summary>
            Pads tensor.
            </summary>
            <param name="input">N-dimensional tensor</param>
            <param name="pad">m-elements tuple, where m/2 ≤ input dimensions and m is even</param>
            <param name="mode">'constant', 'reflect', 'replicate' or 'circular'. Default: 'constant'</param>
            <param name="value">Fill value for 'constant' padding. Default: 0</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.pad(TorchSharp.torch.Tensor,System.ValueTuple{System.Int64,System.Int64},TorchSharp.PaddingModes,System.Double)">
            <summary>
            Pads tensor.
            </summary>
            <param name="input">N-dimensional tensor</param>
            <param name="pad">m-elements tuple, where m/2 ≤ input dimensions and m is even</param>
            <param name="mode">'constant', 'reflect', 'replicate' or 'circular'. Default: 'constant'</param>
            <param name="value">Fill value for 'constant' padding. Default: 0</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.pad(TorchSharp.torch.Tensor,System.ValueTuple{System.Int64,System.Int64,System.Int64,System.Int64},TorchSharp.PaddingModes,System.Double)">
            <summary>
            Pads tensor.
            </summary>
            <param name="input">N-dimensional tensor</param>
            <param name="pad">m-elements tuple, where m/2 ≤ input dimensions and m is even</param>
            <param name="mode">'constant', 'reflect', 'replicate' or 'circular'. Default: 'constant'</param>
            <param name="value">Fill value for 'constant' padding. Default: 0</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.pad(TorchSharp.torch.Tensor,System.Int64,TorchSharp.PaddingModes,System.Double)">
            <summary>
            Pads tensor.
            </summary>
            <param name="input">N-dimensional tensor</param>
            <param name="pad">A single padding size, used for all edges.</param>
            <param name="mode">'constant', 'reflect', 'replicate' or 'circular'. Default: 'constant'</param>
            <param name="value">Fill value for 'constant' padding. Default: 0</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.grid_sample(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.GridSampleMode,TorchSharp.torch.GridSamplePaddingMode,System.Nullable{System.Boolean})">
            <summary>
            Given an input and a flow-field grid, computes the output using input values and pixel locations from grid.
            </summary>
            <param name="input">Tensor of 4D or 5D</param>
            <param name="grid">Flow-field tensor.</param>
            <param name="mode">Interpolation mode to calculate output values 'bilinear' | 'nearest' | 'bicubic'.</param>
            <param name="padding_mode">Padding mode for outside grid values 'zeros' | 'border' | 'reflection'. Default: 'zeros'</param>
            <param name="align_corners">Geometrically, we consider the pixels of the input as squares rather than points.
            If set to true, the extrema (-1 and 1) are considered as referring to the center points of the input’s corner pixels.
            If set to false, they are instead considered as referring to the corner points of the input’s corner pixels, making the sampling more resolution agnostic.</param>
            <returns></returns>
            <remarks>
            Currently, only spatial (4-D) and volumetric (5-D) input are supported.
            Note: mode='bicubic' supports only 4-D input.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.affine_grid(TorchSharp.torch.Tensor,System.Int64[],System.Boolean)">
            <summary>
            Generates a 2D or 3D flow field (sampling grid), given a batch of affine matrices theta.
            </summary>
            <param name="theta">Input batch of affine matrices with shape (N, 2, 3 ) for 2D or (N, 3, 4 ) for 3D</param>
            <param name="size">The target output image size</param>
            <param name="align_corners">if true, consider -1 and 1 to refer to the centers of the corner pixels rather than the image corners.
            Refer to grid_sample() for a more complete description.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.interpolate(TorchSharp.torch.Tensor,System.Int64[],System.Double[],TorchSharp.torch.InterpolationMode,System.Nullable{System.Boolean},System.Boolean)">
             <summary>
            
             </summary>
             <param name="x">The input tensor</param>
             <param name="size">Output spatial size</param>
             <param name="scale_factor">Multiplier for spatial size. Has to match input size if it is a tuple.</param>
             <param name="mode">The algorithm used for upsampling: 'nearest' | 'linear' | 'bilinear' | 'bicubic' | 'trilinear' | 'area'</param>
             <param name="align_corners">Geometrically, we consider the pixels of the input and output as squares rather than points.
             If set to true, the input and output tensors are aligned by the center points of their corner pixels, preserving the values at the corner pixels.
             If set to false, the input and output tensors are aligned by the corner points of their corner pixels, and the interpolation uses edge value padding for out-of-boundary values, making this operation independent of input size when scale_factor is kept the same.</param>
             <param name="recompute_scale_factor">
             Recompute the scale_factor for use in the interpolation calculation.
             When scale_factor is passed as a parameter, it is used to compute the output_size.
             If recompute_scale_factor is False or not specified, the passed-in scale_factor will be used in the interpolation computation.
             Otherwise, a new scale_factor will be computed based on the output and input sizes for use in the interpolation computation
             (i.e. the computation will be identical to if the computed output_size were passed-in explicitly).
             </param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.upsample_bilinear(TorchSharp.torch.Tensor,System.Int64[],System.Double[],System.Boolean)">
            <summary>
            Upsamples a given multi-channel 1D (temporal), 2D (spatial) or 3D (volumetric) data.
            The input data is assumed to be of the form minibatch x channels x[optional depth] x[optional height] x width.
            Hence, for spatial inputs, we expect a 4D Tensor and for volumetric inputs, we expect a 5D Tensor.
            </summary>
            <param name="x">Input tensor</param>
            <param name="size">Output spatial sizes</param>
            <param name="scale_factor">Multiplier for spatial size. Has to match input size</param>
            <param name="align_corners">If true, the corner pixels of the input and output tensors are aligned, and thus preserving the values at those pixels.
            This only has effect when mode is 'linear', 'bilinear', or 'trilinear'. Default: false</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.functional.upsample_nearest(TorchSharp.torch.Tensor,System.Int64[],System.Double[],System.Boolean)">
            <summary>
            Upsamples a given multi-channel 1D (temporal), 2D (spatial) or 3D (volumetric) data.
            The input data is assumed to be of the form minibatch x channels x[optional depth] x[optional height] x width.
            Hence, for spatial inputs, we expect a 4D Tensor and for volumetric inputs, we expect a 5D Tensor.
            </summary>
            <param name="x">Input tensor</param>
            <param name="size">Output spatial sizes</param>
            <param name="scale_factor">Multiplier for spatial size. Has to match input size</param>
            <param name="align_corners">If true, the corner pixels of the input and output tensors are aligned, and thus preserving the values at those pixels.
            This only has effect when mode is 'linear', 'bilinear', or 'trilinear'. Default: false</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.ELU(System.Double,System.Boolean)">
            <summary>
            Exponential Linear Unit
            </summary>
            <param name="alpha">The α value for the ELU formulation. Default: 1.0</param>
            <param name="inplace">Do the operation in-place. Default: False</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.GELU">
            <summary>
            Gaussian Error Linear Units
            </summary>
        </member>
        <member name="M:TorchSharp.torch.nn.GELU(System.Boolean)">
            <summary>
            Gaussian Error Linear Units
            </summary>
            <param name="inplace">Do the operation in-place. Default: False</param>
        </member>
        <member name="M:TorchSharp.torch.nn.GLU(System.Int64)">
            <summary>
            Gated Linear Unit
            </summary>
            <param name="dim">the dimension on which to split the input. Default: -1</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Hardshrink(System.Double)">
            <summary>
            Hardshrink
            </summary>
            <param name="lambda"> the λ value for the Hardshrink formulation. Default: 0.5</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Hardsigmoid(System.Boolean)">
            <summary>
            Hardsigmoid
            </summary>
            <param name="inplace">Do the operation in-place</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Hardswish(System.Boolean)">
            <summary>
            Applies the Hardswish function, element-wise, as described in the paper:
            `Searching for MobileNetV3 https://arxiv.org/abs/1905.02244`.
            </summary>
            <param name="inplace">Do the operation in-place</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Hardtanh(System.Double,System.Double,System.Boolean)">
            <summary>
            Hardtanh
            </summary>
            <param name="min_val">Minimum value of the linear region range.</param>
            <param name="max_val">Maximum value of the linear region range.</param>
            <param name="inplace">Do the operation in-place</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.LeakyReLU(System.Double,System.Boolean)">
            <summary>
            Continuously Differentiable Exponential Linear Unit
            </summary>
            <param name="negative_slope">The α value for the LeakyReLU formulation.</param>
            <param name="inplace">Do the operation in-place.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.LogSigmoid">
            <summary>
            LogSigmoid activation
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Mish">
            <summary>
            A Self Regularized Non-Monotonic Neural Activation Function.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.nn.Mish(System.Boolean)">
            <summary>
            A Self Regularized Non-Monotonic Neural Activation Function.
            </summary>
            <param name="inplace">Do the operation in-place. Default: False</param>
        </member>
        <member name="M:TorchSharp.torch.nn.PReLU(System.Int64,System.Double,TorchSharp.torch.Device,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Parameterized Rectified Linear Unit
            </summary>
            <param name="num_parameters">
            Number of 'a' to learn.
            Although it takes an int as input, there is only two values are legitimate: 1, or the number of channels at input.
            </param>
            <param name="init">The initial value of 'a'.</param>
            <param name="device">The desired device of the parameters and buffers in this module</param>
            <param name="dtype">The desired floating point or complex dtype of the parameters and buffers in this module</param>
        </member>
        <member name="M:TorchSharp.torch.nn.ReLU(System.Boolean)">
            <summary>
            Rectified Linear Unit
            </summary>
            <param name="inplace">Do the operation in-place. Default: False</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.ReLU6(System.Boolean)">
             <summary>
             Rectified Linear Unit
            
             This ReLU version caps positive values at 6.
             </summary>
             <param name="inplace">Do the operation in-place. Default: False</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.RReLU(System.Double,System.Double,System.Boolean)">
            <summary>
            Randomized Rectified Linear Unit
            </summary>
            <param name="lower">Lower bound of the uniform distribution. Default: 1/8</param>
            <param name="upper">Upper bound of the uniform distribution. Default: 1/3</param>
            <param name="inplace">Do the operation in-place. Default: False</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.SELU(System.Boolean)">
            <summary>
            Scaled Exponential Linear Unit
            </summary>
            <param name="inplace">Do the operation in-place. Default: False</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Sigmoid">
            <summary>
            Sigmoid activation
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Sigmoid(System.Boolean)">
            <summary>
            Sigmoid activation
            </summary>
            <param name="inplace">Do the operation in-place. Default: False</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.SiLU">
            <summary>
            Sigmoid-Weighted Linear Unit
            </summary>
        </member>
        <member name="M:TorchSharp.torch.nn.SiLU(System.Boolean)">
            <summary>
            Sigmoid-Weighted Linear Unit
            </summary>
        </member>
        <member name="M:TorchSharp.torch.nn.Softmax(System.Int64)">
            <summary>
            Softmax
            </summary>
            <param name="dim">A dimension along which Softmax will be computed (so every slice along dim will sum to 1)</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Softmax2d">
            <summary>
            Applies Softmax over features to each spatial location
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Softmin(System.Int64)">
            <summary>
            Softmin
            </summary>
            <param name="dim">A dimension along which Softmin will be computed (so every slice along dim will sum to 1)</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Softplus(System.Double,System.Double)">
            <summary>
            Softplus
            </summary>
            <param name="beta">The β value for the Softplus formulation.</param>
            <param name="threshold">Values above this revert to a linear function</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Softshrink(System.Double)">
            <summary>
            Softshrink
            </summary>
            <param name="lambda"> the λ value for the Softshrink formulation. Default: 0.5</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Softsign">
            <summary>
            Softsign
            </summary>
        </member>
        <member name="M:TorchSharp.torch.nn.Softsign(System.Boolean)">
            <summary>
            Softsign
            </summary>
            <param name="inplace">Do the operation in-place. Default: False</param>
        </member>
        <member name="M:TorchSharp.torch.nn.Tanh">
            <summary>
            Tanh activation
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Tanh(System.Boolean)">
            <summary>
            Tanh activation
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Tanhshrink">
            <summary>
            Tanhshrink
            </summary>
        </member>
        <member name="M:TorchSharp.torch.nn.Tanhshrink(System.Boolean)">
            <summary>
            Tanhshrink
            </summary>
            <param name="inplace">Do the operation in-place. Default: False</param>
        </member>
        <member name="M:TorchSharp.torch.nn.Threshold(System.Double,System.Double,System.Boolean)">
            <summary>
            Threshold
            </summary>
            <param name="threshold">The value to threshold at</param>
            <param name="value">The value to replace with</param>
            <param name="inplace">Do the operation in-place</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.AlphaDropout(System.Double,System.Boolean)">
            <summary>
            Randomly zero out entire channels (a channel is a 2D feature map, e.g., the jj -th channel of the ii -th sample in the batched input is a 2D tensor \text{input}[i, j]input[i,j] ).
            Each channel will be zeroed out independently on every forward call with probability p using samples from a Bernoulli distribution.
            </summary>
            <param name="p">Probability of an element to be zeroed. Default: 0.5</param>
            <param name="inplace">If set to true, will do this operation in-place. Default: false</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Bilinear(System.Int64,System.Int64,System.Int64,System.Boolean,TorchSharp.torch.Device,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Applies a bilinear transformation to the incoming data
            </summary>
            <param name="in1_features">size of each first input sample</param>
            <param name="in2_features">size of each second input sample</param>
            <param name="out_features">size of each output sample</param>
            <param name="hasBias">If set to false, the layer will not learn an additive bias</param>
            <param name="device">The desired device of the parameters and buffers in this module</param>
            <param name="dtype">The desired floating point or complex dtype of the parameters and buffers in this module</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Conv1d(System.Int64,System.Int64,System.Int64,System.Int64,System.Int64,System.Int64,TorchSharp.PaddingModes,System.Int64,System.Boolean,TorchSharp.torch.Device,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Applies a 1D convolution over an input signal composed of several input planes.
            </summary>
            <param name="in_channels">Number of channels in the input image</param>
            <param name="out_channels">Number of channels produced by the convolution</param>
            <param name="kernel_size">Size of the convolving kernel</param>
            <param name="stride">Stride of the convolution. Default: 1</param>
            <param name="padding">Zero-padding added to both sides of the input. Default: 0</param>
            <param name="dilation">Spacing between kernel elements. Default: 1</param>
            <param name="padding_mode">'zeros', 'reflect', 'replicate' or 'circular'. Default: 'zeros'</param>
            <param name="groups">Number of blocked connections from input channels to output channels. Default: 1</param>
            <param name="bias">If true, adds a learnable bias to the output. Default: true</param>
            <param name="device">The desired device of the parameters and buffers in this module</param>
            <param name="dtype">The desired floating point or complex dtype of the parameters and buffers in this module</param>
            <returns>Tensor of shape (N,C_out,L_out)</returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Conv1d(System.Int64,System.Int64,System.Int64,TorchSharp.Padding,System.Int64,System.Int64,TorchSharp.PaddingModes,System.Int64,System.Boolean,TorchSharp.torch.Device,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Applies a 1D convolution over an input signal composed of several input planes.
            </summary>
            <param name="in_channels">Number of channels in the input image</param>
            <param name="out_channels">Number of channels produced by the convolution</param>
            <param name="kernel_size">Size of the convolving kernel</param>
            <param name="stride">Stride of the convolution. Default: 1</param>
            <param name="padding">Zero-padding added to both sides of the input. padding=Valid is the same as no padding. padding=Same pads the input so the output has the shape as the input. </param>
            <param name="dilation">Spacing between kernel elements. Default: 1</param>
            <param name="padding_mode">'zeros', 'reflect', 'replicate' or 'circular'. Default: 'zeros'</param>
            <param name="groups">Number of blocked connections from input channels to output channels. Default: 1</param>
            <param name="bias">If true, adds a learnable bias to the output. Default: true</param>
            <param name="device">The desired device of the parameters and buffers in this module</param>
            <param name="dtype">The desired floating point or complex dtype of the parameters and buffers in this module</param>
            <returns>Tensor of shape (N,C_out,L_out)</returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Conv2d(System.Int64,System.Int64,System.Int64,System.Int64,System.Int64,System.Int64,TorchSharp.PaddingModes,System.Int64,System.Boolean,TorchSharp.torch.Device,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Applies a 2D convolution over an input signal composed of several input planes
            </summary>
            <param name="in_channels">Number of channels in the input image</param>
            <param name="out_channels">Number of channels produced by the convolution</param>
            <param name="kernel_size">Size of the convolving kernel</param>
            <param name="stride">Stride of the convolution. Default: 1</param>
            <param name="padding">Zero-padding added to both sides of the input. Default: 0</param>
            <param name="dilation">Spacing between kernel elements. Default: 1</param>
            <param name="padding_mode">'zeros', 'reflect', 'replicate' or 'circular'. Default: 'zeros'</param>
            <param name="groups">Number of blocked connections from input channels to output channels. Default: 1</param>
            <param name="bias">If true, adds a learnable bias to the output. Default: true</param>
            <param name="device">The desired device of the parameters and buffers in this module</param>
            <param name="dtype">The desired floating point or complex dtype of the parameters and buffers in this module</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Conv2d(System.Int64,System.Int64,System.ValueTuple{System.Int64,System.Int64},System.Nullable{System.ValueTuple{System.Int64,System.Int64}},System.Nullable{System.ValueTuple{System.Int64,System.Int64}},System.Nullable{System.ValueTuple{System.Int64,System.Int64}},TorchSharp.PaddingModes,System.Int64,System.Boolean,TorchSharp.torch.Device,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Applies a 2D convolution over an input signal composed of several input planes
            </summary>
            <param name="in_channels">Number of channels in the input image</param>
            <param name="out_channels">Number of channels produced by the convolution</param>
            <param name="kernel_size">Size of the convolving kernel</param>
            <param name="stride">Stride of the convolution. Default: (1,1)</param>
            <param name="padding">Zero-padding added to both sides of the input. Default: (0,0)</param>
            <param name="dilation">Spacing between kernel elements. Default: (1,1)</param>
            <param name="padding_mode">'zeros', 'reflect', 'replicate' or 'circular'. Default: 'zeros'</param>
            <param name="groups">Number of blocked connections from input channels to output channels. Default: 1</param>
            <param name="bias">If true, adds a learnable bias to the output. Default: true</param>
            <param name="device">The desired device of the parameters and buffers in this module</param>
            <param name="dtype">The desired floating point or complex dtype of the parameters and buffers in this module</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Conv2d(System.Int64,System.Int64,System.Int64,TorchSharp.Padding,System.Int64,System.Int64,TorchSharp.PaddingModes,System.Int64,System.Boolean,TorchSharp.torch.Device,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Applies a 2D convolution over an input signal composed of several input planes
            </summary>
            <param name="in_channels">Number of channels in the input image</param>
            <param name="out_channels">Number of channels produced by the convolution</param>
            <param name="kernel_size">Size of the convolving kernel</param>
            <param name="stride">Stride of the convolution. Default: 1</param>
            <param name="padding">Zero-padding added to both sides of the input. padding=Valid is the same as no padding. padding=Same pads the input so the output has the shape as the input. </param>
            <param name="dilation">Spacing between kernel elements. Default: 1</param>
            <param name="padding_mode">'zeros', 'reflect', 'replicate' or 'circular'. Default: 'zeros'</param>
            <param name="groups">Number of blocked connections from input channels to output channels. Default: 1</param>
            <param name="bias">If true, adds a learnable bias to the output. Default: true</param>
            <param name="device">The desired device of the parameters and buffers in this module</param>
            <param name="dtype">The desired floating point or complex dtype of the parameters and buffers in this module</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Conv2d(System.Int64,System.Int64,System.ValueTuple{System.Int64,System.Int64},TorchSharp.Padding,System.Nullable{System.ValueTuple{System.Int64,System.Int64}},System.Nullable{System.ValueTuple{System.Int64,System.Int64}},TorchSharp.PaddingModes,System.Int64,System.Boolean,TorchSharp.torch.Device,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Applies a 2D convolution over an input signal composed of several input planes
            </summary>
            <param name="in_channels">Number of channels in the input image</param>
            <param name="out_channels">Number of channels produced by the convolution</param>
            <param name="kernel_size">Size of the convolving kernel</param>
            <param name="padding">Zero-padding added to both sides of the input. padding=Valid is the same as no padding. padding=Same pads the input so the output has the shape as the input. </param>
            <param name="stride">Stride of the convolution. Default: (1,1)</param>
            <param name="dilation">Spacing between kernel elements. Default: (1,1)</param>
            <param name="padding_mode">'zeros', 'reflect', 'replicate' or 'circular'. Default: 'zeros'</param>
            <param name="groups">Number of blocked connections from input channels to output channels. Default: 1</param>
            <param name="bias">If true, adds a learnable bias to the output. Default: true</param>
            <param name="device">The desired device of the parameters and buffers in this module</param>
            <param name="dtype">The desired floating point or complex dtype of the parameters and buffers in this module</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Conv3d(System.Int64,System.Int64,System.Int64,System.Int64,System.Int64,System.Int64,TorchSharp.PaddingModes,System.Int64,System.Boolean,TorchSharp.torch.Device,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Applies a 3D convolution over an input signal composed of several input planes
            </summary>
            <param name="in_channels">Number of channels in the input image</param>
            <param name="out_channels">Number of channels produced by the convolution</param>
            <param name="kernel_size">Size of the convolving kernel</param>
            <param name="stride">Stride of the convolution. Default: 1</param>
            <param name="padding">Zero-padding added to both sides of the input. Default: 0</param>
            <param name="dilation">Spacing between kernel elements. Default: 1</param>
            <param name="padding_mode">'zeros', 'reflect', 'replicate' or 'circular'. Default: 'zeros'</param>
            <param name="groups">Number of blocked connections from input channels to output channels. Default: 1</param>
            <param name="bias">If true, adds a learnable bias to the output. Default: true</param>
            <param name="device">The desired device of the parameters and buffers in this module</param>
            <param name="dtype">The desired floating point or complex dtype of the parameters and buffers in this module</param>
        </member>
        <member name="M:TorchSharp.torch.nn.Conv3d(System.Int64,System.Int64,System.ValueTuple{System.Int64,System.Int64,System.Int64},System.Nullable{System.ValueTuple{System.Int64,System.Int64,System.Int64}},System.Nullable{System.ValueTuple{System.Int64,System.Int64,System.Int64}},System.Nullable{System.ValueTuple{System.Int64,System.Int64,System.Int64}},TorchSharp.PaddingModes,System.Int64,System.Boolean,TorchSharp.torch.Device,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Applies a 3D convolution over an input signal composed of several input planes
            </summary>
            <param name="in_channels">Number of channels in the input image</param>
            <param name="out_channels">Number of channels produced by the convolution</param>
            <param name="kernel_size">Size of the convolving kernel</param>
            <param name="stride">Stride of the convolution. Default: (1,1,1)</param>
            <param name="padding">Zero-padding added to both sides of the input. Default: (0,0,0)</param>
            <param name="dilation">Spacing between kernel elements. Default: (1,1,1)</param>
            <param name="padding_mode">'zeros', 'reflect', 'replicate' or 'circular'. Default: 'zeros'</param>
            <param name="groups">Number of blocked connections from input channels to output channels. Default: 1</param>
            <param name="bias">If true, adds a learnable bias to the output. Default: true</param>
            <param name="device">The desired device of the parameters and buffers in this module</param>
            <param name="dtype">The desired floating point or complex dtype of the parameters and buffers in this module</param>
        </member>
        <member name="M:TorchSharp.torch.nn.Conv3d(System.Int64,System.Int64,System.Int64,TorchSharp.Padding,System.Int64,System.Int64,TorchSharp.PaddingModes,System.Int64,System.Boolean,TorchSharp.torch.Device,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Applies a 3D convolution over an input signal composed of several input planes
            </summary>
            <param name="in_channels">Number of channels in the input image</param>
            <param name="out_channels">Number of channels produced by the convolution</param>
            <param name="kernel_size">Size of the convolving kernel</param>
            <param name="stride">Stride of the convolution. Default: 1</param>
            <param name="padding">Zero-padding added to both sides of the input. padding=Valid is the same as no padding. padding=Same pads the input so the output has the shape as the input. </param>
            <param name="dilation">Spacing between kernel elements. Default: 1</param>
            <param name="padding_mode">'zeros', 'reflect', 'replicate' or 'circular'. Default: 'zeros'</param>
            <param name="groups">Number of blocked connections from input channels to output channels. Default: 1</param>
            <param name="bias">If true, adds a learnable bias to the output. Default: true</param>
            <param name="device">The desired device of the parameters and buffers in this module</param>
            <param name="dtype">The desired floating point or complex dtype of the parameters and buffers in this module</param>
        </member>
        <member name="M:TorchSharp.torch.nn.Conv3d(System.Int64,System.Int64,System.ValueTuple{System.Int64,System.Int64,System.Int64},TorchSharp.Padding,System.Nullable{System.ValueTuple{System.Int64,System.Int64,System.Int64}},System.Nullable{System.ValueTuple{System.Int64,System.Int64,System.Int64}},TorchSharp.PaddingModes,System.Int64,System.Boolean,TorchSharp.torch.Device,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Applies a 3D convolution over an input signal composed of several input planes
            </summary>
            <param name="in_channels">Number of channels in the input image</param>
            <param name="out_channels">Number of channels produced by the convolution</param>
            <param name="kernel_size">Size of the convolving kernel</param>
            <param name="stride">Stride of the convolution. Default: (1,1,1)</param>
            <param name="padding">Zero-padding added to both sides of the input. padding=Valid is the same as no padding. padding=Same pads the input so the output has the shape as the input. </param>
            <param name="dilation">Spacing between kernel elements. Default: (1,1,1)</param>
            <param name="padding_mode">'zeros', 'reflect', 'replicate' or 'circular'. Default: 'zeros'</param>
            <param name="groups">Number of blocked connections from input channels to output channels. Default: 1</param>
            <param name="bias">If true, adds a learnable bias to the output. Default: true</param>
            <param name="device">The desired device of the parameters and buffers in this module</param>
            <param name="dtype">The desired floating point or complex dtype of the parameters and buffers in this module</param>
        </member>
        <member name="M:TorchSharp.torch.nn.ConvTranspose1d(System.Int64,System.Int64,System.Int64,System.Int64,System.Int64,System.Int64,System.Int64,TorchSharp.PaddingModes,System.Int64,System.Boolean,TorchSharp.torch.Device,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Applies a 1D convolution over an input signal composed of several input planes.
            </summary>
            <param name="in_channels">Number of channels in the input image</param>
            <param name="out_channels">Number of channels produced by the convolution</param>
            <param name="kernel_size">Size of the convolving kernel</param>
            <param name="stride">Stride of the convolution. Default: 1</param>
            <param name="padding">Zero-padding added to both sides of the input. Default: 0</param>
            <param name="output_padding">Additional size added to one side of the output shape. Default: 0</param>
            <param name="dilation">Spacing between kernel elements. Default: 1</param>
            <param name="padding_mode">'zeros', 'reflect', 'replicate' or 'circular'. Default: 'zeros'</param>
            <param name="groups">Number of blocked connections from input channels to output channels. Default: 1</param>
            <param name="bias">If true, adds a learnable bias to the output. Default: true</param>
            <param name="device">The desired device of the parameters and buffers in this module</param>
            <param name="dtype">The desired floating point or complex dtype of the parameters and buffers in this module</param>
            <returns>Tensor of shape (N,C_out,L_out)</returns>
        </member>
        <member name="M:TorchSharp.torch.nn.ConvTranspose2d(System.Int64,System.Int64,System.Int64,System.Int64,System.Int64,System.Int64,System.Int64,TorchSharp.PaddingModes,System.Int64,System.Boolean,TorchSharp.torch.Device,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Applies a 2D transposed convolution over an input signal composed of several input planes.
            </summary>
            <param name="in_channels">Number of channels in the input image</param>
            <param name="out_channels">Number of channels produced by the convolution</param>
            <param name="kernel_size">Size of the convolving kernel</param>
            <param name="stride">Stride of the convolution. Default: 1</param>
            <param name="padding">Zero-padding added to both sides of the input. Default: 0</param>
            <param name="output_padding">Additional size added to one side of the output shape. Default: 0</param>
            <param name="dilation">Spacing between kernel elements. Default: 1</param>
            <param name="padding_mode">'zeros', 'reflect', 'replicate' or 'circular'. Default: 'zeros'</param>
            <param name="groups">Number of blocked connections from input channels to output channels. Default: 1</param>
            <param name="bias">If true, adds a learnable bias to the output. Default: true</param>
            <param name="device">The desired device of the parameters and buffers in this module</param>
            <param name="dtype">The desired floating point or complex dtype of the parameters and buffers in this module</param>
            <returns>Tensor of shape (N,C_out,L_out)</returns>
        </member>
        <member name="M:TorchSharp.torch.nn.ConvTranspose2d(System.Int64,System.Int64,System.ValueTuple{System.Int64,System.Int64},System.Nullable{System.ValueTuple{System.Int64,System.Int64}},System.Nullable{System.ValueTuple{System.Int64,System.Int64}},System.Nullable{System.ValueTuple{System.Int64,System.Int64}},System.Nullable{System.ValueTuple{System.Int64,System.Int64}},TorchSharp.PaddingModes,System.Int64,System.Boolean,TorchSharp.torch.Device,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Applies a 2D transposed convolution over an input signal composed of several input planes
            </summary>
            <param name="in_channels">Number of channels in the input image</param>
            <param name="out_channels">Number of channels produced by the convolution</param>
            <param name="kernel_size">Size of the convolving kernel</param>
            <param name="stride">Stride of the convolution. Default: (1,1)</param>
            <param name="padding">Zero-padding added to both sides of the input. Default: (0,0)</param>
            <param name="output_padding">Additional size added to one side of the output shape. Default: 0</param>
            <param name="dilation">Spacing between kernel elements. Default: (1,1)</param>
            <param name="padding_mode">'zeros', 'reflect', 'replicate' or 'circular'. Default: 'zeros'</param>
            <param name="groups">Number of blocked connections from input channels to output channels. Default: 1</param>
            <param name="bias">If true, adds a learnable bias to the output. Default: true</param>
            <param name="device">The desired device of the parameters and buffers in this module</param>
            <param name="dtype">The desired floating point or complex dtype of the parameters and buffers in this module</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.ConvTranspose3d(System.Int64,System.Int64,System.Int64,System.Int64,System.Int64,System.Int64,System.Int64,TorchSharp.PaddingModes,System.Int64,System.Boolean,TorchSharp.torch.Device,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Applies a 3D transposed convolution over an input signal composed of several input planes.
            </summary>
            <param name="in_channels">Number of channels in the input image</param>
            <param name="out_channels">Number of channels produced by the convolution</param>
            <param name="kernel_size">Size of the convolving kernel</param>
            <param name="stride">Stride of the convolution. Default: 1</param>
            <param name="padding">Zero-padding added to both sides of the input. Default: 0</param>
            <param name="output_padding">Additional size added to one side of the output shape. Default: 0</param>
            <param name="dilation">Spacing between kernel elements. Default: 1</param>
            <param name="padding_mode">'zeros', 'reflect', 'replicate' or 'circular'. Default: 'zeros'</param>
            <param name="groups">Number of blocked connections from input channels to output channels. Default: 1</param>
            <param name="bias">If true, adds a learnable bias to the output. Default: true</param>
            <param name="device">The desired device of the parameters and buffers in this module</param>
            <param name="dtype">The desired floating point or complex dtype of the parameters and buffers in this module</param>
            <returns>Tensor of shape (N,C_out,L_out)</returns>
        </member>
        <member name="M:TorchSharp.torch.nn.ConvTranspose3d(System.Int64,System.Int64,System.ValueTuple{System.Int64,System.Int64,System.Int64},System.Nullable{System.ValueTuple{System.Int64,System.Int64,System.Int64}},System.Nullable{System.ValueTuple{System.Int64,System.Int64,System.Int64}},System.Nullable{System.ValueTuple{System.Int64,System.Int64,System.Int64}},System.Nullable{System.ValueTuple{System.Int64,System.Int64,System.Int64}},TorchSharp.PaddingModes,System.Int64,System.Boolean,TorchSharp.torch.Device,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Applies a 3D transposed convolution over an input signal composed of several input planes
            </summary>
            <param name="in_channels">Number of channels in the input image</param>
            <param name="out_channels">Number of channels produced by the convolution</param>
            <param name="kernel_size">Size of the convolving kernel</param>
            <param name="stride">Stride of the convolution. Default: (1,1,1)</param>
            <param name="padding">Zero-padding added to both sides of the input. Default: (0,0,0)</param>
            <param name="output_padding">Additional size added to one side of the output shape. Default: 0</param>
            <param name="dilation">Spacing between kernel elements. Default: (1,1,1)</param>
            <param name="padding_mode">'zeros', 'reflect', 'replicate' or 'circular'. Default: 'zeros'</param>
            <param name="groups">Number of blocked connections from input channels to output channels. Default: 1</param>
            <param name="bias">If true, adds a learnable bias to the output. Default: true</param>
            <param name="device">The desired device of the parameters and buffers in this module</param>
            <param name="dtype">The desired floating point or complex dtype of the parameters and buffers in this module</param>
        </member>
        <member name="M:TorchSharp.torch.nn.CosineSimilarity(System.Int64,System.Double)">
            <summary>
            Returns cosine similarity between x1 and x2, computed along dim. Inputs must have same shape.
            </summary>
            <param name="dim">Dimension where cosine similarity is computed. Default: 1</param>
            <param name="eps">Small value to avoid division by zero. Default: 1e-8</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Dropout(System.Double,System.Boolean)">
            <summary>
            During training, randomly zeroes some of the elements of the input tensor with probability p using samples from a Bernoulli distribution.
            Each channel will be zeroed out independently on every forward call.
            </summary>
            <param name="p">Probability of an element to be zeroed. Default: 0.5</param>
            <param name="inplace">If set to true, will do this operation in-place. Default: false</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Dropout1d(System.Double,System.Boolean)">
            <summary>
            Randomly zero out entire channels (a channel is a 2D feature map, e.g., the jj -th channel of the ii -th sample in the batched input is a 2D tensor).
            Each channel will be zeroed out independently on every forward call with probability p using samples from a Bernoulli distribution.
            </summary>
            <param name="p">Probability of an element to be zeroed. Default: 0.5</param>
            <param name="inplace">If set to true, will do this operation in-place. Default: false</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Dropout2d(System.Double,System.Boolean)">
            <summary>
            Randomly zero out entire channels (a channel is a 2D feature map, e.g., the jj -th channel of the ii -th sample in the batched input is a 2D tensor).
            Each channel will be zeroed out independently on every forward call with probability p using samples from a Bernoulli distribution.
            </summary>
            <param name="p">Probability of an element to be zeroed. Default: 0.5</param>
            <param name="inplace">If set to true, will do this operation in-place. Default: false</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Dropout3d(System.Double,System.Boolean)">
            <summary>
            Randomly zero out entire channels (a channel is a 3D feature map, e.g., the jj -th channel of the ii -th sample in the batched input is a 3D tensor \text{input}[i, j]input[i,j] ).
            Each channel will be zeroed out independently on every forward call with probability p using samples from a Bernoulli distribution.
            </summary>
            <param name="p">Probability of an element to be zeroed. Default: 0.5</param>
            <param name="inplace">If set to true, will do this operation in-place. Default: false</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Embedding(System.Int64,System.Int64,System.Nullable{System.Int64},System.Nullable{System.Double},System.Double,System.Boolean,System.Boolean,TorchSharp.torch.Device,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            A simple lookup table that stores embeddings of a fixed dictionary and size.
            This module is often used to store word embeddings and retrieve them using indices. The input to the module is a list of indices, and the output is the corresponding word embeddings.
            </summary>
            <param name="num_embeddings">Size of the dictionary of embeddings, the vocabulary size.</param>
            <param name="embedding_dims">The size of each embedding vector</param>
            <param name="padding_idx">If given, pads the output with the embedding vector at padding_idx (initialized to zeros) whenever it encounters the index.</param>
            <param name="max_norm">If given, each embedding vector with norm larger than max_norm is renormalized to have norm max_norm.</param>
            <param name="norm_type">The p of the p-norm to compute for the max_norm option. Default 2.</param>
            <param name="scale_grad_by_freq">If given, this will scale gradients by the inverse of frequency of the words in the mini-batch. Default: false.</param>
            <param name="sparse">If true, gradient w.r.t. weight matrix will be a sparse tensor. Default: false</param>
            <param name="device">The desired device of the parameters and buffers in this module</param>
            <param name="dtype">The desired floating point or complex dtype of the parameters and buffers in this module</param>
            <returns></returns>
            <remarks>Keep in mind that only a limited number of optimizers support sparse gradients: currently it’s optim.SGD (CUDA and CPU), optim.SparseAdam (CUDA and CPU) and optim.Adagrad (CPU)</remarks>
        </member>
        <member name="M:TorchSharp.torch.nn.Embedding_from_pretrained(TorchSharp.torch.Tensor,System.Boolean,System.Nullable{System.Int64},System.Nullable{System.Double},System.Double,System.Boolean,System.Boolean,TorchSharp.torch.Device,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            A simple lookup table that stores embeddings of a fixed dictionary and size.
            This module is often used to store word embeddings and retrieve them using indices. The input to the module is a list of indices, and the output is the corresponding word embeddings.
            </summary>
            <param name="embeddings">FloatTensor containing weights for the Embedding in two dimensions. First dimension is being passed to Embedding as num_embeddings, second as embedding_dim.</param>
            <param name="freeze">If true (the default), the tensor does not get updated in the learning</param>
            <param name="padding_idx">If given, pads the output with the embedding vector at padding_idx (initialized to zeros) whenever it encounters the index.</param>
            <param name="max_norm">If given, each embedding vector with norm larger than max_norm is renormalized to have norm max_norm.</param>
            <param name="norm_type">The p of the p-norm to compute for the max_norm option. Default 2.</param>
            <param name="scale_grad_by_freq">If given, this will scale gradients by the inverse of frequency of the words in the mini-batch. Default: false.</param>
            <param name="sparse">If true, gradient w.r.t. weight matrix will be a sparse tensor. Default: false</param>
            <param name="device">The desired device of the parameters and buffers in this module</param>
            <param name="dtype">The desired floating point or complex dtype of the parameters and buffers in this module</param>
            <returns></returns>
            <remarks>Keep in mind that only a limited number of optimizers support sparse gradients: currently it’s optim.SGD (CUDA and CPU), optim.SparseAdam (CUDA and CPU) and optim.Adagrad (CPU)</remarks>
        </member>
        <member name="M:TorchSharp.torch.nn.EmbeddingBag(System.Int64,System.Int64,System.Nullable{System.Double},System.Double,System.Boolean,TorchSharp.EmbeddingBagMode,System.Boolean,System.Boolean,System.Int64,TorchSharp.torch.Device,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            A simple lookup table that stores embeddings of a fixed dictionary and size.
            This module is often used to store word embeddings and retrieve them using indices. The input to the module is a list of indices, and the output is the corresponding word embeddings.
            </summary>
            <param name="num_embeddings">Size of the dictionary of embeddings, the vocabulary size.</param>
            <param name="embedding_dims">The size of each embedding vector</param>
            <param name="max_norm">If given, each embedding vector with norm larger than max_norm is renormalized to have norm max_norm.</param>
            <param name="norm_type">The p of the p-norm to compute for the max_norm option. Default 2.</param>
            <param name="scale_grad_by_freq">If given, this will scale gradients by the inverse of frequency of the words in the mini-batch. Default: false.</param>
            <param name="mode">"sum", "mean" or "max". Specifies the way to reduce the bag.
            "sum" computes the weighted sum, taking per_sample_weights into consideration.
            "mean" computes the average of the values in the bag, "max" computes the max value over each bag. Default: "mean"</param>
            <param name="sparse">If true, gradient w.r.t. weight matrix will be a sparse tensor. Default: false</param>
            <param name="include_last_offset">If true, offsets has one additional element, where the last element is equivalent to the size of indices. This matches the CSR format.</param>
            <param name="padding_index"> If specified, the entries at padding_idx do not contribute to the gradient; therefore, the embedding vector at padding_idx is not updated during training, i.e. it remains as a fixed “pad”. For a newly constructed EmbeddingBag, the embedding vector at padding_idx will default to all zeros, but can be updated to another value to be used as the padding vector. Note that the embedding vector at padding_idx is excluded from the reduction.</param>
            <param name="device">The desired device of the parameters and buffers in this module</param>
            <param name="dtype">The desired floating point or complex dtype of the parameters and buffers in this module</param>
            <returns></returns>
            <remarks>Keep in mind that only a limited number of optimizers support sparse gradients: currently it’s optim.SGD (CUDA and CPU), optim.SparseAdam (CUDA and CPU) and optim.Adagrad (CPU)</remarks>
        </member>
        <member name="M:TorchSharp.torch.nn.EmbeddingBag_from_pretrained(TorchSharp.torch.Tensor,System.Boolean,System.Nullable{System.Double},System.Double,System.Boolean,TorchSharp.EmbeddingBagMode,System.Boolean,System.Boolean,System.Int64,TorchSharp.torch.Device,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            A simple lookup table that stores embeddings of a fixed dictionary and size.
            This module is often used to store word embeddings and retrieve them using indices. The input to the module is a list of indices, and the output is the corresponding word embeddings.
            </summary>
            <param name="embeddings">FloatTensor containing weights for the EmbeddingBag in two dimensions. First dimension is being passed to EmbeddingBag as num_embeddings, second as embedding_dim.</param>
            <param name="freeze">If true (the default), the tensor does not get updated in the learning</param>
            <param name="max_norm">If given, each embedding vector with norm larger than max_norm is renormalized to have norm max_norm.</param>
            <param name="norm_type">The p of the p-norm to compute for the max_norm option. Default 2.</param>
            <param name="scale_grad_by_freq">If given, this will scale gradients by the inverse of frequency of the words in the mini-batch. Default: false.</param>
            <param name="mode"></param>
            <param name="sparse">If true, gradient w.r.t. weight matrix will be a sparse tensor. Default: false</param>
            <param name="include_last_offset">If true, offsets has one additional element, where the last element is equivalent to the size of indices. This matches the CSR format.</param>
            <param name="padding_index"> If specified, the entries at padding_idx do not contribute to the gradient; therefore, the embedding vector at padding_idx is not updated during training, i.e. it remains as a fixed “pad”. For a newly constructed EmbeddingBag, the embedding vector at padding_idx will default to all zeros, but can be updated to another value to be used as the padding vector. Note that the embedding vector at padding_idx is excluded from the reduction.</param>
            <param name="device">The desired device of the parameters and buffers in this module</param>
            <param name="dtype">The desired floating point or complex dtype of the parameters and buffers in this module</param>
            <returns></returns>
            <remarks>Keep in mind that only a limited number of optimizers support sparse gradients: currently it’s optim.SGD (CUDA and CPU), optim.SparseAdam (CUDA and CPU) and optim.Adagrad (CPU)</remarks>
        </member>
        <member name="M:TorchSharp.torch.nn.FeatureAlphaDropout(System.Double,System.Boolean)">
            <summary>
            Randomly masks out entire channels (a channel is a feature map, e.g. the j-th channel of the i-th sample in the batch input is a tensor input[i,j]) of the input tensor.
            Instead of setting activations to zero, as in regular Dropout, the activations are set to the negative saturation value of the SELU activation function.
            Each element will be masked independently on every forward call with probability p using samples from a Bernoulli distribution.The elements to be masked are
            randomized on every forward call, and scaled and shifted to maintain zero mean and unit variance.
            </summary>
            <param name="p">Dropout probability of a channel to be zeroed. Default: 0.5</param>
            <param name="inplace">If set to true, will do this operation in-place. Default: false</param>
        </member>
        <member name="M:TorchSharp.torch.nn.FeatureAlphaDropout(System.Double)">
            <summary>
            Randomly masks out entire channels (a channel is a feature map, e.g. the j-th channel of the i-th sample in the batch input is a tensor input[i,j]) of the input tensor.
            Instead of setting activations to zero, as in regular Dropout, the activations are set to the negative saturation value of the SELU activation function.
            Each element will be masked independently on every forward call with probability p using samples from a Bernoulli distribution.The elements to be masked are
            randomized on every forward call, and scaled and shifted to maintain zero mean and unit variance.
            </summary>
            <param name="p">Dropout probability of a channel to be zeroed. Default: 0.5</param>
        </member>
        <member name="M:TorchSharp.torch.nn.Flatten(System.Int64,System.Int64)">
            <summary>
            Flattens a contiguous range of dims into a tensor. For use with Sequential.
            </summary>
            <param name="start_dim">First dim to flatten (default = 1).</param>
            <param name="end_dim">Last dim to flatten (default = -1).</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Fold(System.Int64,System.Int64,System.Int64,System.Int64,System.Int64)">
            <summary>
            Combines an array of sliding local blocks into a large containing tensor.
            </summary>
            <param name="output_size">Describes the spatial shape of the large containing tensor of the sliding local blocks.</param>
            <param name="kernel_size">The size of the sliding blocks</param>
            <param name="dilation">A parameter that controls the stride of elements within the neighborhood.</param>
            <param name="padding">Implicit zero padding to be added on both sides of input.</param>
            <param name="stride">The stride of the sliding blocks in the input spatial dimensions.</param>
            <remarks>Currently, only unbatched (3D) or batched (4D) image-like output tensors are supported.</remarks>
        </member>
        <member name="M:TorchSharp.torch.nn.Fold(System.ValueTuple{System.Int64,System.Int64},System.ValueTuple{System.Int64,System.Int64},System.Nullable{System.ValueTuple{System.Int64,System.Int64}},System.Nullable{System.ValueTuple{System.Int64,System.Int64}},System.Nullable{System.ValueTuple{System.Int64,System.Int64}})">
            <summary>
            Combines an array of sliding local blocks into a large containing tensor.
            </summary>
            <param name="output_size">Describes the spatial shape of the large containing tensor of the sliding local blocks.</param>
            <param name="kernel_size">The size of the sliding blocks</param>
            <param name="dilation">A parameter that controls the stride of elements within the neighborhood.</param>
            <param name="padding">Implicit zero padding to be added on both sides of input.</param>
            <param name="stride">The stride of the sliding blocks in the input spatial dimensions.</param>
            <remarks>Currently, only unbatched (3D) or batched (4D) image-like output tensors are supported.</remarks>
        </member>
        <member name="M:TorchSharp.torch.nn.Identity">
            <summary>
            A placeholder identity operator.
            </summary>
            <returns>The same tensor as is input.</returns>
        </member>
        <member name="M:TorchSharp.torch.nn.init.calculate_gain(TorchSharp.torch.nn.init.NonlinearityType,System.Double)">
            <summary>
            Return the recommended gain value for the given nonlinearity function.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.nn.init.ones_(TorchSharp.torch.Tensor)">
            <summary>
            Fills the input Tensor with the value 1
            </summary>
        </member>
        <member name="M:TorchSharp.torch.nn.init.zeros_(TorchSharp.torch.Tensor)">
            <summary>
            Fills the input Tensor with the value 0
            </summary>
        </member>
        <member name="M:TorchSharp.torch.nn.init.dirac_(TorchSharp.torch.Tensor)">
            <summary>
            Fills the {3, 4, 5}-dimensional input Tensor with the Dirac delta function.
            Preserves the identity of the inputs in Convolutional layers, where as many input channels are preserved as possible.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.nn.init.eye_(TorchSharp.torch.Tensor)">
            <summary>
            Fills the 2-dimensional input Tensor with the identity matrix.
            Preserves the identity of the inputs in Linear layers, where as many inputs are preserved as possible.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.nn.init.constant_(TorchSharp.torch.Tensor,TorchSharp.Scalar)">
            <summary>
            Fills the input Tensor with the value 'val'
            </summary>
        </member>
        <member name="M:TorchSharp.torch.nn.init.uniform_(TorchSharp.torch.Tensor,System.Double,System.Double,TorchSharp.torch.Generator)">
            <summary>
            Fills the input Tensor with values drawn from the uniform distribution
            </summary>
        </member>
        <member name="M:TorchSharp.torch.nn.init.normal_(TorchSharp.torch.Tensor,System.Double,System.Double,TorchSharp.torch.Generator)">
            <summary>
            Fills the input Tensor with values drawn from the normal distribution
            </summary>
        </member>
        <member name="M:TorchSharp.torch.nn.init.trunc_normal_(TorchSharp.torch.Tensor,System.Double,System.Double,System.Double,System.Double,TorchSharp.torch.Generator)">
            <summary>
            Fills the input Tensor with values drawn from a truncated normal distribution.
            </summary>
            <param name="tensor">Input tensor</param>
            <param name="mean">The mean of the normal distribution</param>
            <param name="std">The standard deviation of the normal distribution</param>
            <param name="a">The minimum cutoff value</param>
            <param name="b">The maximum cutoff value</param>
            <param name="generator">An optional random number generator.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.init.orthogonal_(TorchSharp.torch.Tensor,System.Double)">
            <summary>
            Fills the input Tensor with a (semi) orthogonal matrix, as described in 'Exact solutions to the nonlinear dynamics of learning in deep linear neural networks'
            </summary>
        </member>
        <member name="M:TorchSharp.torch.nn.init.sparse_(TorchSharp.torch.Tensor,System.Double,System.Double)">
            <summary>
            Fills the 2D input Tensor as a sparse matrix, where the non-zero elements will be drawn from the normal distribution N(0,std)
            </summary>
        </member>
        <member name="M:TorchSharp.torch.nn.init.kaiming_uniform_(TorchSharp.torch.Tensor,System.Double,TorchSharp.torch.nn.init.FanInOut,TorchSharp.torch.nn.init.NonlinearityType)">
            <summary>
            Fills the input Tensor with values according to the method described in 'Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification'
            </summary>
        </member>
        <member name="M:TorchSharp.torch.nn.init.kaiming_normal_(TorchSharp.torch.Tensor,System.Double,TorchSharp.torch.nn.init.FanInOut,TorchSharp.torch.nn.init.NonlinearityType)">
            <summary>
            Fills the input Tensor with values according to the method described in 'Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification'
            </summary>
        </member>
        <member name="M:TorchSharp.torch.nn.init.xavier_uniform_(TorchSharp.torch.Tensor,System.Double)">
            <summary>
            Fills the input Tensor with values according to the method described in 'Understanding the difficulty of training deep feedforward neural networks'
            </summary>
        </member>
        <member name="M:TorchSharp.torch.nn.init.glorot_uniform_(TorchSharp.torch.Tensor,System.Double)">
            <summary>
            Fills the input Tensor with values according to the method described in 'Understanding the difficulty of training deep feedforward neural networks'
            </summary>
        </member>
        <member name="M:TorchSharp.torch.nn.init.xavier_normal_(TorchSharp.torch.Tensor,System.Double)">
            <summary>
            Fills the input Tensor with values according to the method described in 'Understanding the difficulty of training deep feedforward neural networks'
            </summary>
        </member>
        <member name="M:TorchSharp.torch.nn.init.glorot_normal_(TorchSharp.torch.Tensor,System.Double)">
            <summary>
            Fills the input Tensor with values according to the method described in 'Understanding the difficulty of training deep feedforward neural networks'
            </summary>
        </member>
        <member name="M:TorchSharp.torch.nn.Linear(System.Int64,System.Int64,System.Boolean,TorchSharp.torch.Device,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Create a Linear module initialized with random weights and bias.
            </summary>
            <param name="inputSize">Size of each input sample</param>
            <param name="outputSize">Size of each output sample</param>
            <param name="hasBias">If set to false, the layer will not learn an additive bias.</param>
            <param name="device">The desired device of the parameters and buffers in this module</param>
            <param name="dtype">The desired floating point or complex dtype of the parameters and buffers in this module</param>
        </member>
        <member name="M:TorchSharp.torch.nn.Linear(TorchSharp.Modules.Parameter,TorchSharp.Modules.Parameter)">
            <summary>
            Create a Linear module with the given weights and bias.
            </summary>
            <param name="weight">The linear weight attribute.</param>
            <param name="bias">The additive linear bias. Optional.</param>
        </member>
        <member name="M:TorchSharp.torch.nn.CrossEntropyLoss(TorchSharp.torch.Tensor,System.Nullable{System.Int64},TorchSharp.torch.nn.Reduction)">
            <summary>
            This criterion combines log_softmax and nll_loss in a single function.
            </summary>
            <param name="weight">A manual rescaling weight if provided it’s repeated to match input tensor shape</param>
            <param name="ignore_index">Specifies a target value that is ignored and does not contribute to the input gradient.</param>
            <param name="reduction">Specifies the reduction to apply to the output</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.BCELoss(TorchSharp.torch.Tensor,TorchSharp.torch.nn.Reduction)">
            <summary>
            Measures the Binary Cross Entropy between the target and the output.
            </summary>
            <param name="weight">A manual rescaling weight if provided it’s repeated to match input tensor shape</param>
            <param name="reduction">Specifies the reduction to apply to the output</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.BCEWithLogitsLoss(TorchSharp.torch.Tensor,TorchSharp.torch.nn.Reduction,TorchSharp.torch.Tensor)">
            <summary>
            Measures Binary Cross Entropy between target and output logits.
            </summary>
            <param name="weight">A manual rescaling weight if provided it’s repeated to match input tensor shape</param>
            <param name="reduction">Specifies the reduction to apply to the output</param>
            <param name="pos_weights">A weight of positive examples. Must be a vector with length equal to the number of classes.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.CosineEmbeddingLoss(System.Double,TorchSharp.torch.nn.Reduction)">
             <summary>
             Measures the loss given two input tensor and a lable tensor with values 1 or -1.
            
             See: https://pytorch.org/docs/stable/generated/torch.nn.CosineEmbeddingLoss.html#torch.nn.CosineEmbeddingLoss
             </summary>
             <param name="margin"> Should be a number from -1 to 1, 0 to 0.5 is suggested</param>
             <param name="reduction">Specifies the reduction to apply to the output</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.CTCLoss(System.Int64,System.Boolean,TorchSharp.torch.nn.Reduction)">
             <summary>
             The Connectionist Temporal Classification loss.
            
             Calculates loss between a continuous (unsegmented) time series and a target sequence.
             CTCLoss sums over the probability of possible alignments of input to target, producing a
             loss value which is differentiable with respect to each input node. The alignment of input to
             target is assumed to be “many-to-one”, which limits the length of the target sequence such that
             it must be less than the input length.
             </summary>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.HingeEmbeddingLoss(System.Double,TorchSharp.torch.nn.Reduction)">
             <summary>
             Measures the loss given an input tensor x and a labels tensor y (containing 1 or -1).
            
             See: https://pytorch.org/docs/stable/generated/torch.nn.HingeEmbeddingLoss.html#torch.nn.HingeEmbeddingLoss
             </summary>
             <param name="margin"> Should be a number from -1 to 1, 0 to 0.5 is suggested</param>
             <param name="reduction">Specifies the reduction to apply to the output</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.HuberLoss(System.Double,TorchSharp.torch.nn.Reduction)">
             <summary>
             Creates a criterion that uses a squared term if the absolute element-wise error falls below delta and a delta-scaled L1 term otherwise.
            
             See: https://pytorch.org/docs/stable/generated/torch.nn.HuberLoss.html#torch.nn.HuberLoss
             </summary>
             <param name="delta">Specifies the threshold at which to change between delta-scaled L1 and L2 loss. The value must be positive. Default: 1.0</param>
             <param name="reduction">Specifies the reduction to apply to the output</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.MarginRankingLoss(System.Double,TorchSharp.torch.nn.Reduction)">
             <summary>
             Creates a criterion that measures the loss given inputs x1, x2, two 1D mini-batch or 0D Tensors, and a label 1D mini-batch or 0D Tensor y (containing 1 or -1).
            
             See: https://pytorch.org/docs/stable/generated/torch.nn.MarginRankingLoss.html#torch.nn.MarginRankingLoss
             </summary>
             <param name="margin">Has a default value of 0.</param>
             <param name="reduction">Specifies the reduction to apply to the output</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.MultiLabelSoftMarginLoss(TorchSharp.torch.Tensor,TorchSharp.torch.nn.Reduction)">
             <summary>
             Creates a criterion that optimizes a multi-label one-versus-all loss based on max-entropy, between input x and target y of size NxC.
            
             See: https://pytorch.org/docs/stable/generated/torch.nn.MultiLabelSoftMarginLoss.html#torch.nn.MultiLabelSoftMarginLoss
             </summary>
             <param name="weight">A manual rescaling weight given to each class. If given, it has to be a Tensor of size C. Otherwise, it is treated as if having all ones.</param>
             <param name="reduction">Specifies the reduction to apply to the output</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.MultiMarginLoss(System.Int32,System.Double,TorchSharp.torch.Tensor,TorchSharp.torch.nn.Reduction)">
             <summary>
             Creates a criterion that optimizes a multi-class classification hinge loss.
            
             See: https://pytorch.org/docs/stable/generated/torch.nn.MultiMarginLoss.html#torch.nn.MultiMarginLoss
             </summary>
             <param name="p">Has a default value of 1. 1 and 2 are the only supported values.</param>
             <param name="margin">Has a default value of 1</param>
             <param name="weight">A manual rescaling weight given to each class. If given, it has to be a Tensor of size C. Otherwise, it is treated as if having all ones.</param>
             <param name="reduction">Specifies the reduction to apply to the output</param>
        </member>
        <member name="M:TorchSharp.torch.nn.MSELoss(TorchSharp.torch.nn.Reduction)">
            <summary>
            Measures the element-wise mean squared error.
            </summary>
            <param name="reduction">Specifies the reduction to apply to the output</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.L1Loss(TorchSharp.torch.nn.Reduction)">
            <summary>
            Function that takes the mean element-wise absolute value difference.
            </summary>
            <param name="reduction">Specifies the reduction to apply to the output</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.NLLLoss(TorchSharp.torch.Tensor,TorchSharp.torch.nn.Reduction)">
            <summary>
            The negative log likelihood loss.
            </summary>
            <param name="weight">A manual rescaling weight if provided it’s repeated to match input tensor shape</param>
            <param name="reduction">Specifies the reduction to apply to the output</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.PoissonNLLLoss(System.Boolean,System.Boolean,System.Single,TorchSharp.torch.nn.Reduction)">
            <summary>
            Poisson negative log likelihood loss.
            </summary>
            <param name="log_input"></param>
            <param name="full">Whether to compute full loss, i. e. to add the Stirling approximation term.</param>
            <param name="eps">Small value to avoid evaluation of log(0)</param>
            <param name="reduction">Specifies the reduction to apply to the output</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.KLDivLoss(System.Boolean,TorchSharp.torch.nn.Reduction)">
            <summary>
            The Kullback-Leibler divergence Loss
            </summary>
            <param name="log_target">A flag indicating whether target is passed in the log space.</param>
            <param name="reduction">Specifies the reduction to apply to the output</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.SoftMarginLoss(TorchSharp.torch.nn.Reduction)">
            <summary>
            Optimizes a two-class classification logistic loss between input tensor xx and target tensor yy (containing 1 or -1).
            </summary>
            <param name="reduction">Specifies the reduction to apply to the output</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.TripletMarginLoss(System.Double,System.Int64,System.Double,System.Boolean,TorchSharp.torch.nn.Reduction)">
             <summary>
             Creates a criterion that measures the triplet loss given an input tensors x1, x2, x3 and a margin with a value greater than 0.
             This is used for measuring a relative similarity between samples.
            
             See: https://pytorch.org/docs/stable/generated/torch.nn.TripletMarginLoss.html#torch.nn.TripletMarginLoss
             </summary>
             <param name="margin">
             A nonnegative margin representing the minimum difference between the positive and negative distances required for the loss to be 0.
             Larger margins penalize cases where the negative examples are not distant enough from the anchors, relative to the positives.
             </param>
             <param name="p">The norm degree for pairwise distance. </param>
             <param name="eps"></param>
             <param name="swap">
             If true, and if the positive example is closer to the negative example than the anchor is, swaps the positive example and the anchor in the loss computation.
             The distance swap is described in detail in the paper Learning shallow convolutional feature descriptors with triplet losses by V. Balntas, E. Riba et al.
             </param>
             <param name="reduction">Specifies the reduction to apply to the output</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.TripletMarginWithDistanceLoss(System.Func{TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor},System.Double,System.Boolean,TorchSharp.torch.nn.Reduction)">
            <summary>
            Creates a criterion that measures the triplet loss given input tensors a, p, and n (representing anchor, positive, and negative examples, respectively),
            and a nonnegative, real-valued function ("distance function") used to compute the relationship between the anchor and positive example ("positive distance")
            and the anchor and negative example ("negative distance").
            </summary>
            <param name="distance"> A nonnegative, real-valued function that quantifies the closeness of two tensors. If not specified, nn.PairwiseDistance will be used.</param>
            <param name="margin">
            A nonnegative margin representing the minimum difference between the positive and negative distances required for the loss to be 0.
            Larger margins penalize cases where the negative examples are not distant enough from the anchors, relative to the positives.
            </param>
            <param name="swap">
            If true, and if the positive example is closer to the negative example than the anchor is, swaps the positive example and the anchor in the loss computation.
            The distance swap is described in detail in the paper Learning shallow convolutional feature descriptors with triplet losses by V. Balntas, E. Riba et al.
            </param>
            <param name="reduction">Specifies the reduction to apply to the output</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.GaussianNLLLoss(System.Boolean,System.Single,TorchSharp.torch.nn.Reduction)">
            <summary>
            Gaussian negative log likelihood loss.
            </summary>
            <param name="full">Include the constant term in the loss calculation</param>
            <param name="eps">Value used to clamp var (see note below), for stability.</param>
            <param name="reduction">Specifies the reduction to apply to the output</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.MultiLabelMarginLoss(TorchSharp.torch.nn.Reduction)">
            <summary>
            Creates a criterion that optimizes a multi-class multi-classification hinge loss (margin-based loss) between input x (a 2D mini-batch Tensor)
            and output y (which is a 2D Tensor of target class indices).
            </summary>
            <param name="reduction">Specifies the reduction to apply to the output</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.SmoothL1Loss(TorchSharp.torch.nn.Reduction,System.Double)">
            <summary>
            Function that uses a squared term if the absolute element-wise error falls below beta and an L1 term otherwise.
            </summary>
            <param name="beta">Specifies the threshold at which to change between L1 and L2 loss. The value must be non-negative. Default: 1.0</param>
            <param name="reduction">Specifies the reduction to apply to the output</param>
            <returns></returns>
        </member>
        <member name="T:TorchSharp.torch.nn.Module">
            <summary>
            Base class for all neural network modules.
            Your models should subclass this class.
            </summary>
            <remarks>
            Modules can also contain other Modules, allowing to nest them in a tree structure.
            You can assign the submodules as regular fields of the derived Module class. Submodules assigned
            to fields will be registered, and will have their parameters converted and moved when you call to(),
            and saved to disk when calling save().
            </remarks>
        </member>
        <member name="T:TorchSharp.torch.nn.Module.HType">
            <summary>
            Class wrapping PyTorch's module object reference.
            </summary>
        </member>
        <member name="F:TorchSharp.torch.nn.Module.boxedModule">
            Stores the AnyModule corresponding to this module.
        </member>
        <member name="M:TorchSharp.torch.nn.Module.Dispose">
            <summary>
            Releases the storage.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.nn.Module.Dispose(System.Boolean)">
            <summary>
            Implements the .NET Dispose pattern.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.nn.Module._to(TorchSharp.torch.Device,TorchSharp.torch.ScalarType,System.Boolean)">
            <summary>
            Moves and converts the parameters and buffers.
            </summary>
            <param name="device">The target device.</param>
            <param name="dtype">The target element type.</param>
            <param name="non_blocking">
            When non_blocking is set, it tries to convert/move asynchronously with respect to the host if possible,
            e.g., moving CPU Tensors with pinned memory to CUDA devices.
            </param>
        </member>
        <member name="M:TorchSharp.torch.nn.Module._to(TorchSharp.DeviceType,System.Int32,System.Boolean)">
            <summary>
            Moves the parameters and buffers.
            </summary>
            <param name="deviceType">The device type, e.g. 'CPU' or 'CUDA'.</param>
            <param name="deviceIndex">The optional device index.</param>
            <param name="non_blocking">
            When non_blocking is set, it tries to convert/move asynchronously with respect to the host if possible,
            e.g., moving CPU Tensors with pinned memory to CUDA devices.
            </param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Module._to(TorchSharp.torch.ScalarType,System.Boolean)">
            <summary>
            Convert the parameters and buffers.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Module._to(TorchSharp.torch.Tensor,System.Boolean)">
            <summary>
            Moves and converts the parameters and buffers.
            </summary>
            <param name="other">The tensor serving as a template.</param>
            <param name="non_blocking">
            When non_blocking is set, it tries to convert/move asynchronously with respect to the host if possible,
            e.g., moving CPU Tensors with pinned memory to CUDA devices.
            </param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Module.apply(System.Action{TorchSharp.torch.nn.Module})">
            <summary>
            Applies a function recursively to every submodule as well as this.
            </summary>
            <param name="fn">Function to be applied to each submodule</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Module.train(System.Boolean)">
            <summary>
            Sets the module in training mode.
            </summary>
            <remarks>
            This has any effect only on certain modules.See documentations of particular modules for details of their behaviors in training/evaluation mode, if they are affected, e.g.Dropout, BatchNorm, etc.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.nn.Module.eval">
            <summary>
            Sets the module in evaluation mode.
            </summary>
            <remarks>
            This has any effect only on certain modules.See documentations of particular modules for details of their behaviors in training/evaluation mode, if they are affected, e.g.Dropout, BatchNorm, etc.
            </remarks>
        </member>
        <member name="P:TorchSharp.torch.nn.Module.training">
            <summary>
            Check whether the module is set to training or evaluation mode.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.nn.Module.named_buffers(System.Boolean,System.Boolean)">
            <summary>
            Returns an enumerable of module buffers, yielding both the name of the buffer as well as the buffer itself.
            </summary>
            <param name="recurse">If true, then yields buffers of this module and all submodules. Otherwise, yields only buffers that are direct members of this module.</param>
            <param name="include_nonpersistent">Include buffers that are not persistent.</param>
            <returns>(string, torch.Tensor) – Tuple containing the name and buffer</returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Module.buffers(System.Boolean,System.Boolean)">
            <summary>
            Returns an enumerable of buffers.
            </summary>
            <param name="recurse">If true, then yields buffers of this module and all submodules. Otherwise, yields only buffers that are direct members of this module.</param>
            <param name="include_nonpersistent">Include buffers that are not persistent.</param>
        </member>
        <member name="M:TorchSharp.torch.nn.Module.named_children">
            <summary>
            Returns an enumerable of immediate children modules, yielding both the name of the module as well as the module itself.
            </summary>
            <returns>(string, Module) – Tuple containing a name and child module</returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Module.named_modules">
            <summary>
            Returns an enumerable of all modules in the network, yielding both the name of the module as well as the module itself.
            </summary>
            <returns>(string, Module) – Tuple of name and module</returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Module.modules">
            <summary>
            Returns an enumerable of modules.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.nn.Module.children">
            <summary>
            Returns an enumerable of immediate modules.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.nn.Module.state_dict(System.Collections.Generic.Dictionary{System.String,TorchSharp.torch.Tensor},System.String)">
             <summary>
             Returns a dictionary containing a whole state of the module.
            
             Both parameters and persistent buffers(e.g.running averages) are included.Keys are corresponding parameter and buffer names.
             Parameters and buffers set to null are not included.
             </summary>
             <param name="destination">An optional dictionary where the state should be accumulated.</param>
             <param name="prefix">A prefix string to use when entering the name of entries into the dictionary.</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Module.load_state_dict(System.Collections.Generic.Dictionary{System.String,TorchSharp.torch.Tensor},System.Boolean,System.Collections.Generic.IList{System.String})">
             <summary>
             Copies parameters and buffers from state_dict into this module and its descendants.
            
             If strict is True, then the keys of state_dict must exactly match the keys returned by this module’s state_dict() function.
             </summary>
             <param name="source">A dict containing parameters and persistent buffers.</param>
             <param name="strict">Whether to strictly enforce that the keys in state_dict match the keys returned by this module’s state_dict() function.</param>
             <param name="skip">A list of keys not to consider when loading the dictionary.</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Module.named_parameters(System.Boolean)">
            <summary>
            Returns an enumerable of module parameters, yielding both the name of the parameter as well as the parameter itself.
            </summary>
            <param name="recurse">If true, then yields parameters of this module and all submodules. Otherwise, yields only parameters that are direct members of this module.</param>
            <returns>(string, Parameter) – Tuple containing the name and parameter</returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Module.parameters(System.Boolean)">
            <summary>
            Returns an enumerable of module parameters.
            </summary>
            <param name="recurse">If true, then yields parameters of this module and all submodules. Otherwise, yields only parameters that are direct members of this module.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Module.get_buffer(System.String)">
            <summary>
            Returns the buffer given by target if it exists, otherwise throws an error.
            </summary>
            <param name="target">The fully-qualified string name of the buffer to look for.</param>
            <returns>The tensor referenced by target</returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Module.get_parameter(System.String)">
            <summary>
            Returns the parameter given by target if it exists, otherwise throws an error.
            </summary>
            <param name="target">The fully-qualified string name of the Parameter to look for.</param>
            <returns>The Parameter referenced by target</returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Module.register_buffer(System.String,TorchSharp.torch.Tensor,System.Boolean)">
             <summary>
             Adds a buffer to the module.
            
             This is typically used to register a buffer that should not to be considered a model parameter.For example, BatchNorm’s running_mean is not a parameter,
             but is part of the module’s state.Buffers, by default, are persistent and will be saved alongside parameters.
             </summary>
             <param name="name">Name of the buffer. The buffer can be accessed from this module using the given name</param>
             <param name="tensor">
             Buffer to be registered. If null, then operations that run on buffers, such as cuda(), are ignored.
             If null, the buffer is not included in the module’s state_dict.
             </param>
             <param name="persistent">Whether the buffer is part of this module’s state_dict.</param>
             <exception cref="T:System.ArgumentNullException"></exception>
             <exception cref="T:System.InvalidOperationException"></exception>
        </member>
        <member name="M:TorchSharp.torch.nn.Module.register_parameter(System.String,TorchSharp.Modules.Parameter)">
            <summary>
            Adds a parameter to the module.
            </summary>
            <param name="name">Name of the parameter. The parameter can be accessed from this module using the given name</param>
            <param name="param">
            Buffer to be registered.
            If null, then operations that run on buffers, such as cuda(), are ignored.
            If null, the buffer is not included in the module’s state_dict.</param>
            <exception cref="T:System.ArgumentNullException"></exception>
            <exception cref="T:System.InvalidOperationException"></exception>
        </member>
        <member name="M:TorchSharp.torch.nn.Module.add_module(System.String,TorchSharp.torch.nn.Module)">
            <summary>
            Alias for register_module()
            </summary>
            <param name="name">
            name of the child module.
            The child module can be accessed from this module using the given name
            </param>
            <param name="module">child module to be added to the module.</param>
            <exception cref="T:System.ArgumentException"></exception>
            <exception cref="T:System.InvalidOperationException"></exception>
        </member>
        <member name="M:TorchSharp.torch.nn.Module.register_module(System.String,TorchSharp.torch.nn.Module)">
            <summary>
            Register a submodule.
            </summary>
            <param name="name">Name of the submodule.</param>
            <param name="submodule">The module to register.</param>
            <exception cref="T:System.ArgumentException"></exception>
            <exception cref="T:System.InvalidOperationException"></exception>
        </member>
        <member name="M:TorchSharp.torch.nn.Module.save(System.String,System.Collections.Generic.IList{System.String})">
            <summary>
            Save the parameters and buffers of the module to a disk location.
            </summary>
            <param name="location">The file path.</param>
            <param name="skip">A list of keys not to consider when saving the weights.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Module.save(System.IO.BinaryWriter,System.Collections.Generic.IList{System.String})">
            <summary>
            Save the parameters and buffers of the module to a disk location.
            </summary>
            <param name="writer">A binary writer instance.</param>
            <param name="skip">A list of keys not to consider when saving the weights.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Module.save(System.IO.Stream,System.Collections.Generic.IList{System.String})">
            <summary>
            Save the parameters and buffers of the module to a disk location.
            </summary>
            <param name="stream">A writable stream instance.</param>
            <param name="skip">A list of keys not to consider when saving the weights.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Module.save_state_dict(System.IO.BinaryWriter,System.Collections.Generic.Dictionary{System.String,TorchSharp.torch.Tensor},System.Collections.Generic.IList{System.String})">
             <summary>
            
             </summary>
             <param name="writer">A binary writer instance.</param>
             <param name="skip">A list of keys not to consider when saving the weights.</param>
             <param name="sd">A dictionary containing all the buffers and parameters of the module.</param>
        </member>
        <member name="M:TorchSharp.torch.nn.Module.load(System.String,System.Boolean,System.Collections.Generic.IList{System.String},System.Collections.Generic.Dictionary{System.String,System.Boolean})">
            <summary>
            Load the parameters and buffers
            </summary>
            <param name="location">The file path.</param>
            <param name="strict">
            If true, will only load a module if it exactly corresponds to the current module's state.
            If false, will load the parameters and buffers that it finds in the saved file,
            leaving everything else alone.
            </param>
            <param name="skip">A list of keys not to consider when loading the dictionary.</param>
            <param name="loadedParameters">A dictionary to populate with the list of parameters loaded and whether they were matched/skipped. Useful when loading in non-strict mode.</param>
            <returns>The module, with parameters and buffers loaded.</returns>
            <remarks>
            Using a skip list only prevents tensors in the target module from being modified, it
            does not alter any logic related to checking for matching tensor element types or entries.
            It may be necessary to also pass 'strict=false' to avoid exceptions.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.nn.Module.load(System.IO.BinaryReader,System.Boolean,System.Collections.Generic.IList{System.String},System.Collections.Generic.Dictionary{System.String,System.Boolean})">
            <summary>
            Load the parameters and buffers
            </summary>
            <param name="reader">A binary reader instance.</param>
            <param name="strict">
            If true, will only load a module if it exactly corresponds to the current module's state.
            If false, will load the parameters and buffers that it finds in the saved file,
            leaving everything else alone.
            </param>
            <param name="skip">A list of keys not to consider when loading the dictionary.</param>
            <param name="loadedParameters">A dictionary to populate with the list of parameters loaded and whether they were matched/skipped. Useful when loading in non-strict mode.</param>
            <returns>The module, with parameters and buffers loaded.</returns>
            <remarks>
            Using a skip list only prevents tensors in the target module from being modified, it
            does not alter any logic related to checking for matching tensor element types or entries.
            It may be necessary to also pass 'strict=false' to avoid exceptions.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.nn.Module.load(System.IO.Stream,System.Boolean,System.Collections.Generic.IList{System.String},System.Collections.Generic.Dictionary{System.String,System.Boolean})">
            <summary>
            Load the parameters and buffers
            </summary>
            <param name="stream">A readable stream instance.</param>
            <param name="strict">
            If true, will only load a module if it exactly corresponds to the current module's state.
            If false, will load the parameters and buffers that it finds in the saved file,
            leaving everything else alone.
            </param>
            <param name="skip">A list of keys not to consider when loading the dictionary.</param>
            <param name="loadedParameters">A dictionary to populate with the list of parameters loaded and whether they were matched/skipped. Useful when loading in non-strict mode.</param>
            <returns>The module, with parameters and buffers loaded.</returns>
            <remarks>
            Using a skip list only prevents tensors in the target module from being modified, it
            does not alter any logic related to checking for matching tensor element types or entries.
            It may be necessary to also pass 'strict=false' to avoid exceptions.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.nn.Module.Create``1(System.String)">
            <summary>
            Create a module and load its weights from disk.
            </summary>
            <typeparam name="T"></typeparam>
            <param name="path"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Module.#ctor(System.String)">
            <summary>
            Constructor for custom modules, i.e. those defined outside of TorchSharp.
            </summary>
            <param name="name">The name of the module. Useful for debugging purposes, mostly.</param>
        </member>
        <member name="F:TorchSharp.torch.nn.Module._forwardNative">
            Keeps the callback delegate alive
        </member>
        <member name="M:TorchSharp.torch.nn.BoxedModule.Dispose">
            <summary>
              Releases the storage.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.nn.BoxedModule.Dispose(System.Boolean)">
            <summary>
              Implements the .NET Dispose pattern.
            </summary>
        </member>
        <member name="T:TorchSharp.torch.nn.IModule`2">
            <summary>
            Interface for concrete modules with a forward() that takes a single argument.
            </summary>
            <typeparam name="T">The argument type of the module's forward() function.</typeparam>
            <typeparam name="TResult">The return type of the module's forward() function.</typeparam>
        </member>
        <member name="T:TorchSharp.torch.nn.IModule`3">
            <summary>
            Interface for concrete modules with a forward() that takes two arguments.
            </summary>
            <typeparam name="T1">The first argument type of the module's forward() function.</typeparam>
            <typeparam name="T2">The second argument type of the module's forward() function.</typeparam>
            <typeparam name="TResult">The return type of the module's forward() function.</typeparam>
        </member>
        <member name="T:TorchSharp.torch.nn.IModule`4">
            <summary>
            Interface for concrete modules with a forward() that takes three arguments.
            </summary>
            <typeparam name="T1">The first argument type of the module's forward() function.</typeparam>
            <typeparam name="T2">The second argument type of the module's forward() function.</typeparam>
            <typeparam name="T3">The third argument type of the module's forward() function.</typeparam>
            <typeparam name="TResult">The return type of the module's forward() function.</typeparam>
        </member>
        <member name="T:TorchSharp.torch.nn.IModule`5">
            <summary>
            Interface for concrete modules with a forward() that takes four arguments.
            </summary>
            <typeparam name="T1">The first argument type of the module's forward() function.</typeparam>
            <typeparam name="T2">The second argument type of the module's forward() function.</typeparam>
            <typeparam name="T3">The third argument type of the module's forward() function.</typeparam>
            <typeparam name="T4">The fourth argument type of the module's forward() function.</typeparam>
            <typeparam name="TResult">The return type of the module's forward() function.</typeparam>
        </member>
        <member name="T:TorchSharp.torch.nn.IModule`6">
            <summary>
            Interface for concrete modules with a forward() that takes five arguments.
            </summary>
            <typeparam name="T1">The first argument type of the module's forward() function.</typeparam>
            <typeparam name="T2">The second argument type of the module's forward() function.</typeparam>
            <typeparam name="T3">The third argument type of the module's forward() function.</typeparam>
            <typeparam name="T4">The fourth argument type of the module's forward() function.</typeparam>
            <typeparam name="T5">The fifth argument type of the module's forward() function.</typeparam>
            <typeparam name="TResult">The return type of the module's forward() function.</typeparam>
        </member>
        <member name="T:TorchSharp.torch.nn.IModule`7">
            <summary>
            Interface for concrete modules with a forward() that takes six arguments.
            </summary>
            <typeparam name="T1">The first argument type of the module's forward() function.</typeparam>
            <typeparam name="T2">The second argument type of the module's forward() function.</typeparam>
            <typeparam name="T3">The third argument type of the module's forward() function.</typeparam>
            <typeparam name="T4">The fourth argument type of the module's forward() function.</typeparam>
            <typeparam name="T5">The fifth argument type of the module's forward() function.</typeparam>
            <typeparam name="T6">The sixth argument type of the module's forward() function.</typeparam>
            <typeparam name="TResult">The return type of the module's forward() function.</typeparam>
        </member>
        <member name="T:TorchSharp.torch.nn.HookableModule`2">
            <summary>
            Represents a module that accepts 'hook' to the module logic.
            </summary>
        </member>
        <member name="T:TorchSharp.torch.nn.HookableModule`2.HookRemover">
            <summary>
            Used to remove a specific hook, following the PyTorch API design.
            </summary>
            <remarks>The name and namespace of this class is not the same as in PyTorch, but serves the same purpose.</remarks>
        </member>
        <member name="T:TorchSharp.torch.nn.Module`2">
            <summary>
            Base class for concrete modules with a forward() that takes a single argument.
            </summary>
            <typeparam name="T">The argument type of the module's forward() function.</typeparam>
            <typeparam name="TResult">The return type of the module's forward() function.</typeparam>
        </member>
        <member name="M:TorchSharp.torch.nn.Module`2.forward(`0)">
            <summary>
            Invoke the logic of the module.
            </summary>
            <remarks>`forward` will not invoke any registered hooks for the module.</remarks>
        </member>
        <member name="M:TorchSharp.torch.nn.Module`2.call(`0)">
            <summary>
            Invoke the logic of the module.
            </summary>
            <remarks>`call` will invoke any registered hooks for the module.</remarks>
        </member>
        <member name="T:TorchSharp.torch.nn.Module`3">
            <summary>
            Base class for concrete modules with a forward() that takes two arguments.
            </summary>
            <typeparam name="T1">The first argument type of the module's forward() function.</typeparam>
            <typeparam name="T2">The second argument type of the module's forward() function.</typeparam>
            <typeparam name="TResult">The return type of the module's forward() function.</typeparam>
        </member>
        <member name="M:TorchSharp.torch.nn.Module`3.forward(`0,`1)">
            <summary>
            Invoke the logic of the module.
            </summary>
            <remarks>`forward` will not invoke any registered hooks for the module.</remarks>
        </member>
        <member name="M:TorchSharp.torch.nn.Module`3.call(`0,`1)">
            <summary>
            Invoke the logic of the module.
            </summary>
            <remarks>`call` will invoke any registered hooks for the module.</remarks>
        </member>
        <member name="T:TorchSharp.torch.nn.Module`4">
            <summary>
            Base class for concrete modules with a forward() that takes three arguments.
            </summary>
            <typeparam name="T1">The first argument type of the module's forward() function.</typeparam>
            <typeparam name="T2">The second argument type of the module's forward() function.</typeparam>
            <typeparam name="T3">The third argument type of the module's forward() function.</typeparam>
            <typeparam name="TResult">The return type of the module's forward() function.</typeparam>
        </member>
        <member name="M:TorchSharp.torch.nn.Module`4.forward(`0,`1,`2)">
            <summary>
            Invoke the logic of the module.
            </summary>
            <remarks>`forward` will not invoke any registered hooks for the module.</remarks>
        </member>
        <member name="M:TorchSharp.torch.nn.Module`4.call(`0,`1,`2)">
            <summary>
            Invoke the logic of the module.
            </summary>
            <remarks>`call` will invoke any registered hooks for the module.</remarks>
        </member>
        <member name="T:TorchSharp.torch.nn.Module`5">
            <summary>
            Base class for concrete modules with a forward() that takes four arguments.
            </summary>
            <typeparam name="T1">The first argument type of the module's forward() function.</typeparam>
            <typeparam name="T2">The second argument type of the module's forward() function.</typeparam>
            <typeparam name="T3">The third argument type of the module's forward() function.</typeparam>
            <typeparam name="T4">The fourth argument type of the module's forward() function.</typeparam>
            <typeparam name="TResult">The return type of the module's forward() function.</typeparam>
        </member>
        <member name="M:TorchSharp.torch.nn.Module`5.forward(`0,`1,`2,`3)">
            <summary>
            Invoke the logic of the module.
            </summary>
            <remarks>`forward` will not invoke any registered hooks for the module.</remarks>
        </member>
        <member name="M:TorchSharp.torch.nn.Module`5.call(`0,`1,`2,`3)">
            <summary>
            Invoke the logic of the module.
            </summary>
            <remarks>`call` will invoke any registered hooks for the module.</remarks>
        </member>
        <member name="T:TorchSharp.torch.nn.Module`6">
            <summary>
            Base class for concrete modules with a forward() that takes five arguments.
            </summary>
            <typeparam name="T1">The first argument type of the module's forward() function.</typeparam>
            <typeparam name="T2">The second argument type of the module's forward() function.</typeparam>
            <typeparam name="T3">The third argument type of the module's forward() function.</typeparam>
            <typeparam name="T4">The fourth argument type of the module's forward() function.</typeparam>
            <typeparam name="T5">The fifth argument type of the module's forward() function.</typeparam>
            <typeparam name="TResult">The return type of the module's forward() function.</typeparam>
        </member>
        <member name="M:TorchSharp.torch.nn.Module`6.forward(`0,`1,`2,`3,`4)">
            <summary>
            Invoke the logic of the module.
            </summary>
            <remarks>`forward` will not invoke any registered hooks for the module.</remarks>
        </member>
        <member name="M:TorchSharp.torch.nn.Module`6.call(`0,`1,`2,`3,`4)">
            <summary>
            Invoke the logic of the module.
            </summary>
            <remarks>`call` will invoke any registered hooks for the module.</remarks>
        </member>
        <member name="T:TorchSharp.torch.nn.Module`7">
            <summary>
            Base class for concrete modules with a forward() that takes six arguments.
            </summary>
            <typeparam name="T1">The first argument type of the module's forward() function.</typeparam>
            <typeparam name="T2">The second argument type of the module's forward() function.</typeparam>
            <typeparam name="T3">The third argument type of the module's forward() function.</typeparam>
            <typeparam name="T4">The fourth argument type of the module's forward() function.</typeparam>
            <typeparam name="T5">The fifth argument type of the module's forward() function.</typeparam>
            <typeparam name="T6">The sixth argument type of the module's forward() function.</typeparam>
            <typeparam name="TResult">The return type of the module's forward() function.</typeparam>
        </member>
        <member name="M:TorchSharp.torch.nn.Module`7.forward(`0,`1,`2,`3,`4,`5)">
            <summary>
            Invoke the logic of the module.
            </summary>
            <remarks>`forward` will not invoke any registered hooks for the module.</remarks>
        </member>
        <member name="M:TorchSharp.torch.nn.Module`7.call(`0,`1,`2,`3,`4,`5)">
            <summary>
            Invoke the logic of the module.
            </summary>
            <remarks>`call` will invoke any registered hooks for the module.</remarks>
        </member>
        <member name="M:TorchSharp.torch.nn.ModuleDict(System.ValueTuple{System.String,TorchSharp.torch.nn.Module}[])">
             <summary>
             Create a ModuleDict instance from an array of modules.
             </summary>
             <param name="modules">A list of (name,module) tuples.</param>
             <returns></returns>
             <remarks>
             ModuleDict can be indexed like a regular dictionary, but the modules it
             contains are properly registered, and will be visible by all Module methods.
            
             ModuleDict is an ordered dictionary that respects the order of insertion, and
             in update(), the order of the merged OrderedDict or another ModuleDict (the argument to update()).
             </remarks>
        </member>
        <member name="M:TorchSharp.torch.nn.ModuleDict``1(System.ValueTuple{System.String,``0}[])">
             <summary>
             Create a ModuleDict instance from an array of modules.
             </summary>
             <param name="modules">A list of (name,module) tuples.</param>
             <returns></returns>
             <remarks>
             ModuleDict can be indexed like a regular dictionary, but the modules it
             contains are properly registered, and will be visible by all Module methods.
            
             ModuleDict is an ordered dictionary that respects the order of insertion, and
             in update(), the order of the merged OrderedDict or another ModuleDict (the argument to update()).
             </remarks>
        </member>
        <member name="M:TorchSharp.torch.nn.ModuleList(TorchSharp.torch.nn.Module[])">
            <summary>
            Create a ModuleList instance from an array of modules.
            </summary>
            <param name="modules">A list of modules.</param>
            <remarks>
            ModuleList can be indexed like a regular list, but modules it contains are properly registered, and will be visible by all Module methods.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.nn.ModuleList``1(``0[])">
            <summary>
            Create a ModuleList instance from an array of modules.
            </summary>
            <param name="modules">A list of modules.</param>
            <remarks>
            ModuleList can be indexed like a regular list, but modules it contains are properly registered, and will be visible by all Module methods.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.nn.MultiheadAttention(System.Int64,System.Int64,System.Double,System.Boolean,System.Boolean,System.Boolean,System.Nullable{System.Int64},System.Nullable{System.Int64})">
            <summary>
            Allows the model to jointly attend to information from different representation subspaces (based on the paper “Attention Is All You Need”).
            </summary>
            <param name="embedded_dim">total dimension of the model</param>
            <param name="num_heads">parallel attention heads</param>
            <param name="dropout">a Dropout layer on attn_output_weights. Default: 0.0</param>
            <param name="bias">add bias as module parameter. Default: true</param>
            <param name="add_bias_kv">add bias to the key and value sequences at dim=0</param>
            <param name="add_zero_attn">add a new batch of zeros to the key and value sequences at dim=1</param>
            <param name="kdim">total number of features in key</param>
            <param name="vdim">total number of features in value</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.BatchNorm1d(System.Int64,System.Double,System.Double,System.Boolean,System.Boolean,TorchSharp.torch.Device,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Applies Batch Normalization over a 2D or 3D input (a mini-batch of 1D inputs with optional additional channel dimension) as described in the paper Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift .
            </summary>
            <param name="num_features">C from an expected input of size (N,C,L) or LL from input of size (N, L)</param>
            <param name="eps">A value added to the denominator for numerical stability. Default: 1e-5</param>
            <param name="momentum">The value used for the running_mean and running_var computation. Can be set to None for cumulative moving average (i.e. simple average). Default: 0.1</param>
            <param name="affine">A boolean value that when set to True, this module has learnable affine parameters. Default: true</param>
            <param name="track_running_stats">A boolean value that when set to True, this module tracks the running mean and variance, and when set to False,
            this module does not track such statistics, and initializes statistics buffers running_mean and running_var as None.
            When these buffers are None, this module always uses batch statistics. in both training and eval modes. Default: true</param>
            <param name="device">The desired device of the parameters and buffers in this module</param>
            <param name="dtype">The desired floating point or complex dtype of the parameters and buffers in this module</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.BatchNorm2d(System.Int64,System.Double,System.Double,System.Boolean,System.Boolean,TorchSharp.torch.Device,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Applies Batch Normalization over a 4D input (a mini-batch of 2D inputs with additional channel dimension) as described in the paper Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift.
            </summary>
            <param name="num_features">C from an expected input of size (N,C,H,W)</param>
            <param name="eps">A value added to the denominator for numerical stability. Default: 1e-5</param>
            <param name="momentum">The value used for the running_mean and running_var computation. Can be set to None for cumulative moving average (i.e. simple average). Default: 0.1</param>
            <param name="affine">A boolean value that when set to True, this module has learnable affine parameters. Default: true</param>
            <param name="track_running_stats">A boolean value that when set to True, this module tracks the running mean and variance, and when set to False,
            this module does not track such statistics, and initializes statistics buffers running_mean and running_var as None.
            When these buffers are None, this module always uses batch statistics. in both training and eval modes. Default: true</param>
            <param name="device">The desired device of the parameters and buffers in this module</param>
            <param name="dtype">The desired floating point or complex dtype of the parameters and buffers in this module</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.BatchNorm3d(System.Int64,System.Double,System.Double,System.Boolean,System.Boolean,TorchSharp.torch.Device,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Applies Batch Normalization over a 5D input (a mini-batch of 3D inputs with additional channel dimension) as described in the paper Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift.
            </summary>
            <param name="num_features">C from an expected input of size (N,C,D,H,W)</param>
            <param name="eps">A value added to the denominator for numerical stability. Default: 1e-5</param>
            <param name="momentum">The value used for the running_mean and running_var computation. Can be set to None for cumulative moving average (i.e. simple average). Default: 0.1</param>
            <param name="affine">A boolean value that when set to True, this module has learnable affine parameters. Default: true</param>
            <param name="track_running_stats">A boolean value that when set to True, this module tracks the running mean and variance, and when set to False,
            this module does not track such statistics, and initializes statistics buffers running_mean and running_var as None.
            When these buffers are None, this module always uses batch statistics. in both training and eval modes. Default: true</param>
            <param name="device">The desired device of the parameters and buffers in this module</param>
            <param name="dtype">The desired floating point or complex dtype of the parameters and buffers in this module</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.GroupNorm(System.Int64,System.Int64,System.Double,System.Boolean,TorchSharp.torch.Device,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Applies Group Normalization over a mini-batch of inputs as described in the paper Group Normalization
            </summary>
            <param name="num_groups">Number of groups to separate the channels into</param>
            <param name="num_channels">Number of channels expected in input</param>
            <param name="eps">A value added to the denominator for numerical stability.</param>
            <param name="affine">A boolean value that when set to true, this module has learnable per-channel affine parameters initialized to ones (for weights) and zeros (for biases).</param>
            <param name="device">The desired device of the parameters and buffers in this module</param>
            <param name="dtype">The desired floating point or complex dtype of the parameters and buffers in this module</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.InstanceNorm1d(System.Int64,System.Double,System.Double,System.Boolean,System.Boolean,TorchSharp.torch.Device,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Applies Instance Normalization over a 3D input (a mini-batch of 1D inputs with optional additional channel dimension) as described in the paper Instance Normalization: The Missing Ingredient for Fast Stylization.
            </summary>
            <param name="num_features">C from an expected input of size (N,C,L) or LL from input of size (N, L)</param>
            <param name="eps">A value added to the denominator for numerical stability. Default: 1e-5</param>
            <param name="momentum">The value used for the running_mean and running_var computation. Can be set to None for cumulative moving average (i.e. simple average). Default: 0.1</param>
            <param name="affine">A boolean value that when set to True, this module has learnable affine parameters. Default: true</param>
            <param name="track_running_stats">A boolean value that when set to True, this module tracks the running mean and variance, and when set to False,
            this module does not track such statistics, and initializes statistics buffers running_mean and running_var as None.
            When these buffers are None, this module always uses batch statistics. in both training and eval modes. Default: true</param>
            <param name="device">The desired device of the parameters and buffers in this module</param>
            <param name="dtype">The desired floating point or complex dtype of the parameters and buffers in this module</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.InstanceNorm2d(System.Int64,System.Double,System.Double,System.Boolean,System.Boolean,TorchSharp.torch.Device,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Applies Instance Normalization over a 4D input (a mini-batch of 2D inputs with additional channel dimension) as described in the paper Instance Normalization: The Missing Ingredient for Fast Stylization.
            </summary>
            <param name="num_features">C from an expected input of size (N,C,H,W)</param>
            <param name="eps">A value added to the denominator for numerical stability. Default: 1e-5</param>
            <param name="momentum">The value used for the running_mean and running_var computation. Can be set to None for cumulative moving average (i.e. simple average). Default: 0.1</param>
            <param name="affine">A boolean value that when set to True, this module has learnable affine parameters. Default: true</param>
            <param name="track_running_stats">A boolean value that when set to True, this module tracks the running mean and variance, and when set to False,
            this module does not track such statistics, and initializes statistics buffers running_mean and running_var as None.
            When these buffers are None, this module always uses batch statistics. in both training and eval modes. Default: true</param>
            <param name="device">The desired device of the parameters and buffers in this module</param>
            <param name="dtype">The desired floating point or complex dtype of the parameters and buffers in this module</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.InstanceNorm3d(System.Int64,System.Double,System.Double,System.Boolean,System.Boolean,TorchSharp.torch.Device,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Applies Instance Normalization over a 5D input (a mini-batch of 3D inputs with additional channel dimension) as described in the paper Instance Normalization: The Missing Ingredient for Fast Stylization.
            </summary>
            <param name="num_features">C from an expected input of size (N,C,D,H,W)</param>
            <param name="eps">A value added to the denominator for numerical stability. Default: 1e-5</param>
            <param name="momentum">The value used for the running_mean and running_var computation. Can be set to None for cumulative moving average (i.e. simple average). Default: 0.1</param>
            <param name="affine">A boolean value that when set to True, this module has learnable affine parameters. Default: true</param>
            <param name="track_running_stats">A boolean value that when set to True, this module tracks the running mean and variance, and when set to False,
            this module does not track such statistics, and initializes statistics buffers running_mean and running_var as None.
            When these buffers are None, this module always uses batch statistics. in both training and eval modes. Default: true</param>
            <param name="device">The desired device of the parameters and buffers in this module</param>
            <param name="dtype">The desired floating point or complex dtype of the parameters and buffers in this module</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.LayerNorm(System.Int64[],System.Double,System.Boolean,System.Boolean,TorchSharp.torch.Device,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Applies Layer Normalization over a mini-batch of inputs as described in the paper Layer Normalization
            </summary>
            <param name="normalized_shape">Input shape from an expected input.</param>
            <param name="eps">A value added to the denominator for numerical stability. Default: 1e-5</param>
            <param name="elementwise_affine">a boolean value that when set to true, this module has learnable per-element affine parameters initialized to ones (for weights) and zeros (for biases).</param>
            <param name="bias">A boolean value that when set to true, this module has learnable per-element bias parameters initialized to zeros</param>
            <param name="device">The desired device of the parameters and buffers in this module</param>
            <param name="dtype">The desired floating point or complex dtype of the parameters and buffers in this module</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.LayerNorm(System.Int64,System.Double,System.Boolean,System.Boolean,TorchSharp.torch.Device,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Applies Layer Normalization over a mini-batch of inputs as described in the paper Layer Normalization
            </summary>
            <param name="normalized_shape">Input shape from an expected input.</param>
            <param name="eps">A value added to the denominator for numerical stability. Default: 1e-5</param>
            <param name="elementwise_affine">a boolean value that when set to true, this module has learnable per-element affine parameters initialized to ones (for weights) and zeros (for biases).</param>
            <param name="bias">A boolean value that when set to true, this module has learnable per-element bias parameters initialized to zeros</param>
            <param name="device">The desired device of the parameters and buffers in this module</param>
            <param name="dtype">The desired floating point or complex dtype of the parameters and buffers in this module</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.LocalResponseNorm(System.Int64,System.Double,System.Double,System.Double)">
            <summary>
            Applies local response normalization over an input signal composed of several input planes, where channels occupy the second dimension. Applies normalization across channels.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.nn.ConstantPad1d(System.Int64,System.Double)">
            <summary>
            Pads the input tensor boundaries with a constant value.
            </summary>
            <param name="padding">The size of the padding.</param>
            <param name="value"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.ConstantPad1d(System.ValueTuple{System.Int64,System.Int64},System.Double)">
            <summary>
            Pads the input tensor boundaries with a constant value.
            </summary>
            <param name="padding">The size of the padding: (padding_right, padding_left).</param>
            <param name="value"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.ConstantPad2d(System.Int64,System.Double)">
            <summary>
            Pads the input tensor boundaries with a constant value.
            </summary>
            <param name="padding">The size of the padding.</param>
            <param name="value"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.ConstantPad2d(System.ValueTuple{System.Int64,System.Int64,System.Int64,System.Int64},System.Double)">
            <summary>
            Pads the input tensor boundaries with a constant value.
            </summary>
            <param name="padding">The size of the padding:  (padding_left, padding_right, padding_top, padding_bottom)</param>
            <param name="value"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.ConstantPad3d(System.Int64,System.Double)">
            <summary>
            Pads the input tensor boundaries with a constant value.
            </summary>
            <param name="value"></param>
            <param name="padding">The size of the padding.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.ConstantPad3d(System.ValueTuple{System.Int64,System.Int64,System.Int64,System.Int64,System.Int64,System.Int64},System.Double)">
            <summary>
            Pads the input tensor boundaries with a constant value.
            </summary>
            <param name="value"></param>
            <param name="padding">The size of the padding (padding_left, padding_right, padding_top, padding_bottom, padding_front, padding_back)</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.ReflectionPad1d(System.Int64)">
            <summary>
            Pads the input tensor using the reflection of the input boundary.
            </summary>
            <param name="padding">The size of the padding.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.ReflectionPad1d(System.ValueTuple{System.Int64,System.Int64})">
            <summary>
            Pads the input tensor using the reflection of the input boundary.
            </summary>
            <param name="padding">The size of the padding: (padding_right, padding_left).</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.ReflectionPad2d(System.Int64)">
            <summary>
            Pads the input tensor using the reflection of the input boundary.
            </summary>
            <param name="padding">The size of the padding.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.ReflectionPad2d(System.ValueTuple{System.Int64,System.Int64,System.Int64,System.Int64})">
            <summary>
            Pads the input tensor using reflection of the input boundary.
            </summary>
            <param name="padding">The size of the padding: (padding_left, padding_right, padding_top, padding_bottom).</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.ReflectionPad3d(System.Int64)">
            <summary>
            Pads the input tensor using the reflection of the input boundary.
            </summary>
            <param name="padding">The size of the padding.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.ReflectionPad3d(System.ValueTuple{System.Int64,System.Int64,System.Int64,System.Int64,System.Int64,System.Int64})">
            <summary>
            Pads the input tensor using reflection of the input boundary.
            </summary>
            <param name="padding">The size of the padding: (padding_left, padding_right, padding_top, padding_bottom, padding_front, padding_back).</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.ReplicationPad1d(System.Int64)">
            <summary>
            Pads the input tensor using replication of the input boundary.
            </summary>
            <param name="padding">The size of the padding.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.ReplicationPad1d(System.ValueTuple{System.Int64,System.Int64})">
            <summary>
            Pads the input tensor using replication of the input boundary.
            </summary>
            <param name="padding">The size of the padding: (padding_right, padding_left).</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.ReplicationPad2d(System.Int64)">
            <summary>
            Pads the input tensor using the replication of the input boundary.
            </summary>
            <param name="padding">The size of the padding.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.ReplicationPad2d(System.ValueTuple{System.Int64,System.Int64,System.Int64,System.Int64})">
            <summary>
            Pads the input tensor using replication of the input boundary.
            </summary>
            <param name="padding">The size of the padding: (padding_left, padding_right, padding_top, padding_bottom).</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.ReplicationPad3d(System.Int64)">
            <summary>
            Pads the input tensor using replication of the input boundary.
            </summary>
            <param name="padding">The size of the padding.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.ReplicationPad3d(System.ValueTuple{System.Int64,System.Int64,System.Int64,System.Int64,System.Int64,System.Int64})">
            <summary>
            Pads the input tensor using replication of the input boundary.
            </summary>
            <param name="padding">The size of the padding: (padding_left, padding_right, padding_top, padding_bottom, padding_front, padding_back).</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.ZeroPad2d(System.Int64)">
            <summary>
            Pads the input tensor boundaries with zero.
            </summary>
            <param name="padding">The size of the padding.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.ZeroPad2d(System.ValueTuple{System.Int64,System.Int64,System.Int64,System.Int64})">
            <summary>
            Pads the input tensor boundaring with zero
            </summary>
            <param name="padding">The size of the padding: (padding_left, padding_right, padding_top, padding_bottom).</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.ParameterDict(System.ValueTuple{System.String,TorchSharp.Modules.Parameter}[])">
             <summary>
             Create a ParameterList instance from an array of parameter tensors.
             </summary>
             <param name="parameters">A tuple of (name,parameter).</param>
             <remarks>
             ParameterDict can be indexed like a regular dictionary, but the parameters it
             contains are properly registered, and will be visible by all Module methods.
            
             ParameterDict is an ordered dictionary that respects the order of insertion, and
             in update(), the order of the merged OrderedDict or another ParameterDict (the argument to update()).
             </remarks>
        </member>
        <member name="M:TorchSharp.torch.nn.ParameterList(TorchSharp.Modules.Parameter[])">
            <summary>
            Create a ParameterList instance from an array of parameter tensors.
            </summary>
            <param name="parameters">A list of modules.</param>
            <remarks>
            ParameterList can be indexed like a regular list, but the parameters it contains are properly registered.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.nn.PixelShuffle(System.Int64)">
            <summary>
            Rearranges elements in a tensor of shape (*, C * r^2, H, W) to a tensor of shape(*, C, H * r, W * r), where r is an upscale factor.
            This is useful for implementing efficient sub-pixel convolution with a stride of 1/r.
            </summary>
            <param name="upscale_factor">Factor to increase spatial resolution by</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.PixelUnshuffle(System.Int64)">
            <summary>
            Reverses the PixelShuffle operation by rearranging elements in a tensor of shape (*, C, H * r, W * r) to a tensor of shape (*, C * r^2, H, W), where r is an downscale factor.
            </summary>
            <param name="downscale_factor">Factor to increase spatial resolution by</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.AdaptiveAvgPool1d(System.Int64)">
            <summary>
            Applies a 1D adaptive average pooling over an input signal composed of several input planes.
            The output size is H, for any input size.The number of output features is equal to the number of input planes.
            </summary>
            <param name="output_size">the target output size H</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.AdaptiveAvgPool2d(System.Int64[])">
            <summary>
            Applies a 2D adaptive average pooling over an input signal composed of several input planes.
            The output is of size H x W, for any input size.The number of output features is equal to the number of input planes.
            </summary>
            <param name="output_size">The target output size (H,W) of the image of the form H x W.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.AdaptiveAvgPool2d(System.ValueTuple{System.Int64,System.Int64})">
            <summary>
            Applies a 2D adaptive average pooling over an input signal composed of several input planes.
            The output is of size H x W, for any input size.The number of output features is equal to the number of input planes.
            </summary>
            <param name="output_size">The target output size (H,W) of the image of the form H x W.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.AdaptiveAvgPool2d(System.Int64)">
            <summary>
            Applies a 2D adaptive average pooling over an input signal composed of several input planes.
            The output is of size H x W, for any input size.The number of output features is equal to the number of input planes.
            </summary>
            <param name="output_size">The target output size (H,W) of the image of the form H x W.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.AdaptiveAvgPool3d(System.Int64[])">
            <summary>
            Applies a 3D adaptive average pooling over an input signal composed of several input planes.
            The output is of size D x H x W, for any input size.The number of output features is equal to the number of input planes.
            </summary>
            <param name="output_size">The target output size of the image of the form D x H x W.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.AdaptiveAvgPool3d(System.ValueTuple{System.Int64,System.Int64,System.Int64})">
            <summary>
            Applies a 3D adaptive average pooling over an input signal composed of several input planes.
            The output is of size D x H x W, for any input size.The number of output features is equal to the number of input planes.
            </summary>
            <param name="output_size">The target output size (D,H,W) of the image of the form D x H x W.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.AdaptiveAvgPool3d(System.Int64)">
            <summary>
            Applies a 3D adaptive average pooling over an input signal composed of several input planes.
            The output is of size D x H x W, for any input size.The number of output features is equal to the number of input planes.
            </summary>
            <param name="output_size">The target output size (D,H,W) of the image of the form H x W.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.AdaptiveMaxPool1d(System.Int64)">
            <summary>
            Applies a 1D adaptive max pooling over an input signal composed of several input planes.
            The output size is H, for any input size.The number of output features is equal to the number of input planes.
            </summary>
            <param name="output_size">The target output size H.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.AdaptiveMaxPool2d(System.Int64[])">
            <summary>
            Applies a 2D adaptive max pooling over an input signal composed of several input planes.
            The output is of size H x W, for any input size.The number of output features is equal to the number of input planes.
            </summary>
            <param name="output_size">Applies a 2D adaptive max pooling over an input signal composed of several input planes.
            The output is of size H x W, for any input size.The number of output features is equal to the number of input planes.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.AdaptiveMaxPool3d(System.Int64[])">
            <summary>
            Applies a 3D adaptive max pooling over an input signal composed of several input planes.
            The output is of size D x H x W, for any input size.The number of output features is equal to the number of input planes.
            </summary>
            <param name="output_size">The target output size of the image of the form D x H x W.
            Can be a tuple (D, H, W) or a single D for a cube D x D x D. D, H and W can be either a int, or null which means the size will be the same as that of the input.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.AvgPool1d(System.Int64,System.Nullable{System.Int64},System.Int64,System.Boolean,System.Boolean)">
            <summary>
            Applies a 1D average pooling over an input signal composed of several input planes.
            </summary>
            <param name="kernel_size">The size of the window</param>
            <param name="stride">The stride of the window. Default value is kernel_size</param>
            <param name="padding">implicit zero padding to be added on both sides</param>
            <param name="ceil_mode">Whether to use ceil instead of floor to compute the output shape</param>
            <param name="count_include_pad">Whether to include the zero-padding in the averaging calculation</param>
        </member>
        <member name="M:TorchSharp.torch.nn.AvgPool2d(System.Int64[],System.Int64[],System.Int64[],System.Boolean,System.Boolean,System.Nullable{System.Int64})">
            <summary>
            Applies a 2D average pooling over an input signal composed of several input planes.
            </summary>
            <param name="kernel_size">The size of the window</param>
            <param name="stride">The stride of the window. Default value is kernel_size</param>
            <param name="padding">implicit zero padding to be added on both sides</param>
            <param name="ceil_mode">Whether to use ceil instead of floor to compute the output shape</param>
            <param name="count_include_pad">Whether to include the zero-padding in the averaging calculation</param>
            <param name="divisor_override">If specified, it will be used as divisor, otherwise size of the pooling region will be used</param>
        </member>
        <member name="M:TorchSharp.torch.nn.AvgPool2d(System.ValueTuple{System.Int64,System.Int64},System.Nullable{System.ValueTuple{System.Int64,System.Int64}},System.Nullable{System.ValueTuple{System.Int64,System.Int64}},System.Boolean,System.Boolean,System.Nullable{System.Int64})">
            <summary>
            Applies a 2D average pooling over an input signal composed of several input planes.
            </summary>
            <param name="kernel_size">The size of the window</param>
            <param name="stride">The stride of the window.</param>
            <param name="padding">implicit zero padding to be added on both sides</param>
            <param name="ceil_mode">Whether to use ceil instead of floor to compute the output shape</param>
            <param name="count_include_pad">Whether to include the zero-padding in the averaging calculation</param>
            <param name="divisor_override">If specified, it will be used as divisor, otherwise size of the pooling region will be used</param>
        </member>
        <member name="M:TorchSharp.torch.nn.AvgPool2d(System.Int64,System.Nullable{System.Int64},System.Nullable{System.Int64},System.Boolean,System.Boolean,System.Nullable{System.Int64})">
            <summary>
            Applies a 2D average pooling over an input signal composed of several input planes.
            </summary>
            <param name="kernel_size">The size of the window</param>
            <param name="stride">The stride of the window.</param>
            <param name="padding">implicit zero padding to be added on both sides</param>
            <param name="ceil_mode">Whether to use ceil instead of floor to compute the output shape</param>
            <param name="count_include_pad">Whether to include the zero-padding in the averaging calculation</param>
            <param name="divisor_override">If specified, it will be used as divisor, otherwise size of the pooling region will be used</param>
        </member>
        <member name="M:TorchSharp.torch.nn.AvgPool3d(System.Int64[],System.Int64[],System.Int64[],System.Boolean,System.Boolean,System.Nullable{System.Int64})">
            <summary>
            Applies a 3D average pooling over an input signal composed of several input planes.
            </summary>
            <param name="kernel_size">The size of the window</param>
            <param name="stride">The stride of the window. Default value is kernel_size</param>
            <param name="padding">implicit zero padding to be added on both sides</param>
            <param name="ceil_mode">Whether to use ceil instead of floor to compute the output shape</param>
            <param name="count_include_pad">Whether to include the zero-padding in the averaging calculation</param>
            <param name="divisor_override">If specified, it will be used as divisor, otherwise size of the pooling region will be used</param>
        </member>
        <member name="M:TorchSharp.torch.nn.AvgPool3d(System.ValueTuple{System.Int64,System.Int64,System.Int64},System.Nullable{System.ValueTuple{System.Int64,System.Int64,System.Int64}},System.Nullable{System.ValueTuple{System.Int64,System.Int64,System.Int64}},System.Boolean,System.Boolean,System.Nullable{System.Int64})">
            <summary>
            Applies a 3D average pooling over an input signal composed of several input planes.
            </summary>
            <param name="kernel_size">The size of the window</param>
            <param name="stride">The stride of the window. Default value is kernel_size</param>
            <param name="padding">implicit zero padding to be added on both sides</param>
            <param name="ceil_mode">Whether to use ceil instead of floor to compute the output shape</param>
            <param name="count_include_pad">Whether to include the zero-padding in the averaging calculation</param>
            <param name="divisor_override">If specified, it will be used as divisor, otherwise size of the pooling region will be used</param>
        </member>
        <member name="M:TorchSharp.torch.nn.AvgPool3d(System.Int64,System.Nullable{System.Int64},System.Nullable{System.Int64},System.Boolean,System.Boolean,System.Nullable{System.Int64})">
            <summary>
            Applies a 3D average pooling over an input signal composed of several input planes.
            </summary>
            <param name="kernel_size">The size of the window</param>
            <param name="stride">The stride of the window. Default value is kernel_size</param>
            <param name="padding">implicit zero padding to be added on both sides</param>
            <param name="ceil_mode">Whether to use ceil instead of floor to compute the output shape</param>
            <param name="count_include_pad">Whether to include the zero-padding in the averaging calculation</param>
            <param name="divisor_override">If specified, it will be used as divisor, otherwise size of the pooling region will be used</param>
        </member>
        <member name="M:TorchSharp.torch.nn.FractionalMaxPool2d(System.Int64,System.Nullable{System.Int64},System.Nullable{System.Double})">
             <summary>
             Applies a 2D fractional max pooling over an input signal composed of several input planes.
            
             Fractional MaxPooling is described in detail in the paper Fractional MaxPooling by Ben Graham,
             see: https://arxiv.org/abs/1412.6071
             </summary>
             <param name="kernel_size">The size of the sliding window, must be > 0.</param>
             <param name="output_size">The target output size of the image of the form oH x oW. Can be a tuple (oH, oW) or a single number oH for a square image oH x oH</param>
             <param name="output_ratio">If one wants to have an output size as a ratio of the input size, this option can be given. This has to be a number or tuple in the range (0, 1)</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.FractionalMaxPool2d(System.ValueTuple{System.Int64,System.Int64},System.Nullable{System.ValueTuple{System.Int64,System.Int64}},System.Nullable{System.ValueTuple{System.Double,System.Double}})">
             <summary>
             Applies a 2D fractional max pooling over an input signal composed of several input planes.
            
             Fractional MaxPooling is described in detail in the paper Fractional MaxPooling by Ben Graham,
             see: https://arxiv.org/abs/1412.6071
             </summary>
             <param name="kernel_size">The size of the sliding window, must be > 0.</param>
             <param name="output_size">The target output size of the image of the form oH x oW. Can be a tuple (oH, oW) or a single number oH for a square image oH x oH</param>
             <param name="output_ratio">If one wants to have an output size as a ratio of the input size, this option can be given. This has to be a number or tuple in the range (0, 1)</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.FractionalMaxPool2d(System.Int64[],System.Int64[],System.Double[])">
             <summary>
             Applies a 2D fractional max pooling over an input signal composed of several input planes.
            
             Fractional MaxPooling is described in detail in the paper Fractional MaxPooling by Ben Graham,
             see: https://arxiv.org/abs/1412.6071
             </summary>
             <param name="kernel_size">The size of the sliding window, must be > 0.</param>
             <param name="output_size">The target output size of the image of the form oH x oW. Can be a tuple (oH, oW) or a single number oH for a square image oH x oH</param>
             <param name="output_ratio">If one wants to have an output size as a ratio of the input size, this option can be given. This has to be a number or tuple in the range (0, 1)</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.FractionalMaxPool3d(System.Int64,System.Nullable{System.Int64},System.Nullable{System.Double})">
             <summary>
             Applies a 3d fractional max pooling over an input signal composed of several input planes.
            
             Fractional MaxPooling is described in detail in the paper Fractional MaxPooling by Ben Graham,
             see: https://arxiv.org/abs/1412.6071
             </summary>
             <param name="kernel_size">The size of the sliding window, must be > 0.</param>
             <param name="output_size">The target output size of the image of the form oH x oW. Can be a tuple (oH, oW) or a single number oH for a square image oH x oH</param>
             <param name="output_ratio">If one wants to have an output size as a ratio of the input size, this option can be given. This has to be a number or tuple in the range (0, 1)</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.FractionalMaxPool3d(System.ValueTuple{System.Int64,System.Int64,System.Int64},System.Nullable{System.ValueTuple{System.Int64,System.Int64,System.Int64}},System.Nullable{System.ValueTuple{System.Double,System.Double,System.Double}})">
             <summary>
             Applies a 3d fractional max pooling over an input signal composed of several input planes.
            
             Fractional MaxPooling is described in detail in the paper Fractional MaxPooling by Ben Graham,
             see: https://arxiv.org/abs/1412.6071
             </summary>
             <param name="kernel_size">The size of the sliding window, must be > 0.</param>
             <param name="output_size">The target output size of the image of the form oH x oW. Can be a tuple (oH, oW) or a single number oH for a square image oH x oH</param>
             <param name="output_ratio">If one wants to have an output size as a ratio of the input size, this option can be given. This has to be a number or tuple in the range (0, 1)</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.FractionalMaxPool3d(System.Int64[],System.Int64[],System.Double[])">
             <summary>
             Applies a 3d fractional max pooling over an input signal composed of several input planes.
            
             Fractional MaxPooling is described in detail in the paper Fractional MaxPooling by Ben Graham,
             see: https://arxiv.org/abs/1412.6071
             </summary>
             <param name="kernel_size">The size of the sliding window, must be > 0.</param>
             <param name="output_size">The target output size of the image of the form oH x oW. Can be a tuple (oH, oW) or a single number oH for a square image oH x oH</param>
             <param name="output_ratio">If one wants to have an output size as a ratio of the input size, this option can be given. This has to be a number or tuple in the range (0, 1)</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.LPPool1d(System.Double,System.Int64,System.Nullable{System.Int64},System.Boolean)">
            <summary>
            Applies a 1D power-average pooling over an input signal composed of several input planes.
            </summary>
            <param name="norm_type">The LP norm (exponent)</param>
            <param name="kernel_size">The size of the window</param>
            <param name="stride">The stride of the window. Default value is kernel_size</param>
            <param name="ceil_mode">Use ceil instead of floor to compute the output shape</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.LPPool2d(System.Double,System.Int64[],System.Int64[],System.Boolean)">
            <summary>
            Applies a 2D power-average pooling over an input signal composed of several input planes.
            </summary>
            <param name="norm_type">The LP norm (exponent)</param>
            <param name="kernel_size">The size of the window</param>
            <param name="stride">The stride of the window. Default value is kernel_size</param>
            <param name="ceil_mode">Use ceil instead of floor to compute the output shape</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.LPPool2d(System.Double,System.Int64,System.Nullable{System.Int64},System.Boolean)">
            <summary>
            Applies a 2D power-average pooling over an input signal composed of several input planes.
            </summary>
            <param name="norm_type">The LP norm (exponent)</param>
            <param name="kernel_size">The size of the window</param>
            <param name="stride">The stride of the window.</param>
            <param name="ceil_mode">Use ceil instead of floor to compute the output shape</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.MaxPool1d(System.Int64,System.Nullable{System.Int64},System.Nullable{System.Int64},System.Nullable{System.Int64},System.Boolean)">
            <summary>
            Applies a 1D max pooling over an input signal composed of several input planes.
            </summary>
            <param name="kernel_size">The size of the sliding window, must be > 0.</param>
            <param name="stride">The stride of the sliding window, must be > 0. Default value is kernel_size.</param>
            <param name="padding">Implicit negative infinity padding to be added on both sides, must be >= 0 and less than or equal to kernel_size / 2</param>
            <param name="dilation">The stride between elements within a sliding window, must be > 0.</param>
            <param name="ceil_mode">If true, will use ceil instead of floor to compute the output shape. This ensures that every element in the input tensor is covered by a sliding window.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.MaxPool2d(System.Int64,System.Nullable{System.Int64},System.Nullable{System.Int64},System.Nullable{System.Int64},System.Boolean)">
            <summary>
            Applies a 2D max pooling over an input signal composed of several input planes.
            </summary>
            <param name="kernel_size">The size of the sliding window, must be > 0.</param>
            <param name="stride">The stride of the sliding window, must be > 0. Default value is kernel_size.</param>
            <param name="padding">Implicit negative infinity padding to be added on both sides, must be >= 0 and less than or equal to kernel_size / 2</param>
            <param name="dilation">The stride between elements within a sliding window, must be > 0.</param>
            <param name="ceil_mode">If true, will use ceil instead of floor to compute the output shape. This ensures that every element in the input tensor is covered by a sliding window.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.MaxPool2d(System.ValueTuple{System.Int64,System.Int64},System.Nullable{System.ValueTuple{System.Int64,System.Int64}},System.Nullable{System.ValueTuple{System.Int64,System.Int64}},System.Nullable{System.ValueTuple{System.Int64,System.Int64}},System.Boolean)">
            <summary>
            Applies a 2D max pooling over an input signal composed of several input planes.
            </summary>
            <param name="kernel_size">The size of the sliding window, must be > 0.</param>
            <param name="stride">The stride of the sliding window, must be > 0. Default value is kernel_size.</param>
            <param name="padding">Implicit negative infinity padding to be added on both sides, must be >= 0 and less than or equal to kernel_size / 2</param>
            <param name="dilation">The stride between elements within a sliding window, must be > 0.</param>
            <param name="ceil_mode">If true, will use ceil instead of floor to compute the output shape. This ensures that every element in the input tensor is covered by a sliding window.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.MaxPool2d(System.Int64[],System.Int64[],System.Int64[],System.Int64[],System.Boolean)">
            <summary>
            Applies a 2D max pooling over an input signal composed of several input planes.
            </summary>
            <param name="kernel_size">The size of the sliding window, must be > 0.</param>
            <param name="stride">The stride of the sliding window, must be > 0. Default value is kernel_size.</param>
            <param name="padding">Implicit negative infinity padding to be added on both sides, must be >= 0 and less than or equal to kernel_size / 2</param>
            <param name="dilation">The stride between elements within a sliding window, must be > 0.</param>
            <param name="ceil_mode">If true, will use ceil instead of floor to compute the output shape. This ensures that every element in the input tensor is covered by a sliding window.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.MaxPool3d(System.Int64,System.Nullable{System.Int64},System.Nullable{System.Int64},System.Nullable{System.Int64},System.Boolean)">
            <summary>
            Applies a 3D max pooling over an input signal composed of several input planes.
            </summary>
            <param name="kernel_size">The size of the sliding window, must be > 0.</param>
            <param name="stride">The stride of the sliding window, must be > 0. Default value is kernel_size.</param>
            <param name="padding">Implicit negative infinity padding to be added on both sides, must be >= 0 and less than or equal to kernel_size / 2</param>
            <param name="dilation">The stride between elements within a sliding window, must be > 0.</param>
            <param name="ceil_mode">If true, will use ceil instead of floor to compute the output shape. This ensures that every element in the input tensor is covered by a sliding window.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.MaxPool3d(System.ValueTuple{System.Int64,System.Int64,System.Int64},System.Nullable{System.ValueTuple{System.Int64,System.Int64,System.Int64}},System.Nullable{System.ValueTuple{System.Int64,System.Int64,System.Int64}},System.Nullable{System.ValueTuple{System.Int64,System.Int64,System.Int64}},System.Boolean)">
            <summary>
            Applies a 3D max pooling over an input signal composed of several input planes.
            </summary>
            <param name="kernel_size">The size of the sliding window, must be > 0.</param>
            <param name="stride">The stride of the sliding window, must be > 0. Default value is kernel_size.</param>
            <param name="padding">Implicit negative infinity padding to be added on both sides, must be >= 0 and less than or equal to kernel_size / 2</param>
            <param name="dilation">The stride between elements within a sliding window, must be > 0.</param>
            <param name="ceil_mode">If true, will use ceil instead of floor to compute the output shape. This ensures that every element in the input tensor is covered by a sliding window.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.MaxPool3d(System.Int64[],System.Int64[],System.Int64[],System.Int64[],System.Boolean)">
            <summary>
            Applies a 3D max pooling over an input signal composed of several input planes.
            </summary>
            <param name="kernel_size">The size of the sliding window, must be > 0.</param>
            <param name="stride">The stride of the sliding window, must be > 0. Default value is kernel_size.</param>
            <param name="padding">Implicit negative infinity padding to be added on both sides, must be >= 0 and less than or equal to kernel_size / 2</param>
            <param name="dilation">The stride between elements within a sliding window, must be > 0.</param>
            <param name="ceil_mode">If true, will use ceil instead of floor to compute the output shape. This ensures that every element in the input tensor is covered by a sliding window.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.MaxUnpool1d(System.Int64,System.Nullable{System.Int64},System.Nullable{System.Int64})">
            <summary>
            Computes a partial inverse of :class:`MaxPool1d`.
            </summary>
            <param name="kernel_size">The size of the sliding window, must be > 0.</param>
            <param name="stride">The stride of the sliding window, must be > 0. Default value is kernel_size.</param>
            <param name="padding">Implicit negative infinity padding to be added on both sides, must be >= 0 and less than or equal to kernel_size / 2</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.MaxUnpool2d(System.Int64,System.Nullable{System.Int64},System.Nullable{System.Int64})">
            <summary>
            Applies a 2D max pooling over an input signal composed of several input planes.
            </summary>
            <param name="kernel_size">The size of the sliding window, must be > 0.</param>
            <param name="stride">The stride of the sliding window, must be > 0. Default value is kernel_size.</param>
            <param name="padding">Implicit negative infinity padding to be added on both sides, must be >= 0 and less than or equal to kernel_size / 2</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.MaxUnpool2d(System.ValueTuple{System.Int64,System.Int64},System.Nullable{System.ValueTuple{System.Int64,System.Int64}},System.Nullable{System.ValueTuple{System.Int64,System.Int64}})">
            <summary>
            Applies a 2D max pooling over an input signal composed of several input planes.
            </summary>
            <param name="kernel_size">The size of the sliding window, must be > 0.</param>
            <param name="stride">The stride of the sliding window, must be > 0. Default value is kernel_size.</param>
            <param name="padding">Implicit negative infinity padding to be added on both sides, must be >= 0 and less than or equal to kernel_size / 2</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.MaxUnpool2d(System.Int64[],System.Int64[],System.Int64[])">
            <summary>
            Applies a 2D max pooling over an input signal composed of several input planes.
            </summary>
            <param name="kernel_size">The size of the sliding window, must be > 0.</param>
            <param name="stride">The stride of the sliding window, must be > 0. Default value is kernel_size.</param>
            <param name="padding">Implicit negative infinity padding to be added on both sides, must be >= 0 and less than or equal to kernel_size / 2</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.MaxUnpool3d(System.Int64,System.Nullable{System.Int64},System.Nullable{System.Int64})">
            <summary>
            Applies a 3D max pooling over an input signal composed of several input planes.
            </summary>
            <param name="kernel_size">The size of the sliding window, must be > 0.</param>
            <param name="stride">The stride of the sliding window, must be > 0. Default value is kernel_size.</param>
            <param name="padding">Implicit negative infinity padding to be added on both sides, must be >= 0 and less than or equal to kernel_size / 2</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.MaxUnpool3d(System.ValueTuple{System.Int64,System.Int64,System.Int64},System.Nullable{System.ValueTuple{System.Int64,System.Int64,System.Int64}},System.Nullable{System.ValueTuple{System.Int64,System.Int64,System.Int64}})">
            <summary>
            Applies a 3D max pooling over an input signal composed of several input planes.
            </summary>
            <param name="kernel_size">The size of the sliding window, must be > 0.</param>
            <param name="stride">The stride of the sliding window, must be > 0. Default value is kernel_size.</param>
            <param name="padding">Implicit negative infinity padding to be added on both sides, must be >= 0 and less than or equal to kernel_size / 2</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.MaxUnpool3d(System.Int64[],System.Int64[],System.Int64[])">
            <summary>
            Applies a 3D max pooling over an input signal composed of several input planes.
            </summary>
            <param name="kernel_size">The size of the sliding window, must be > 0.</param>
            <param name="stride">The stride of the sliding window, must be > 0. Default value is kernel_size.</param>
            <param name="padding">Implicit negative infinity padding to be added on both sides, must be >= 0 and less than or equal to kernel_size / 2</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.GRU(System.Int64,System.Int64,System.Int64,System.Boolean,System.Boolean,System.Double,System.Boolean,TorchSharp.torch.Device,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Creates multi-layer gated recurrent unit (GRU) RNN module.
            </summary>
            <param name="inputSize">The number of expected features in the input x</param>
            <param name="hiddenSize">The number of features in the hidden state h</param>
            <param name="numLayers">Number of recurrent layers. Default: 1</param>
            <param name="bias">If False, then the layer does not use bias weights b_ih and b_hh. Default: True</param>
            <param name="batchFirst">if true, then the input and output tensors are provided as (batch, seq, feature). Default: False</param>
            <param name="dropout">If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0</param>
            <param name="bidirectional">if true, becomes a bidirectional RNN. Default: False</param>
            <param name="device">The desired device of the parameters and buffers in this module</param>
            <param name="dtype">The desired floating point or complex dtype of the parameters and buffers in this module</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.GRUCell(System.Int64,System.Int64,System.Boolean,TorchSharp.torch.Device,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            A gated recurrent unit (GRU) cell
            </summary>
            <param name="inputSize">The number of expected features in the input x</param>
            <param name="hiddenSize">The number of features in the hidden state h</param>
            <param name="device">The desired device of the parameters and buffers in this module</param>
            <param name="dtype">The desired floating point or complex dtype of the parameters and buffers in this module</param>
            <param name="bias">If False, then the layer does not use bias weights b_ih and b_hh. Default: True</param>
        </member>
        <member name="M:TorchSharp.torch.nn.LSTM(System.Int64,System.Int64,System.Int64,System.Boolean,System.Boolean,System.Double,System.Boolean,TorchSharp.torch.Device,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Creates a multi-layer long short-term memory (LSTM) RNN module.
            </summary>
            <param name="inputSize">The number of expected features in the input x</param>
            <param name="hiddenSize">The number of features in the hidden state h</param>
            <param name="numLayers">Number of recurrent layers. Default: 1</param>
            <param name="bias">If False, then the layer does not use bias weights b_ih and b_hh. Default: True</param>
            <param name="batchFirst">if true, then the input and output tensors are provided as (batch, seq, feature). Default: False</param>
            <param name="dropout">If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0</param>
            <param name="bidirectional">if true, becomes a bidirectional RNN. Default: False</param>
            <param name="device">The desired device of the parameters and buffers in this module</param>
            <param name="dtype">The desired floating point or complex dtype of the parameters and buffers in this module</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.LSTMCell(System.Int64,System.Int64,System.Boolean,TorchSharp.torch.Device,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            A long short-term memory (LSTM) cell.
            </summary>
            <param name="inputSize">The number of expected features in the input x</param>
            <param name="hiddenSize">The number of features in the hidden state h</param>
            <param name="bias">If False, then the layer does not use bias weights b_ih and b_hh. Default: True</param>
            <param name="device">The desired device of the parameters and buffers in this module</param>
            <param name="dtype">The desired floating point or complex dtype of the parameters and buffers in this module</param>
        </member>
        <member name="M:TorchSharp.torch.nn.RNN(System.Int64,System.Int64,System.Int64,TorchSharp.torch.nn.NonLinearities,System.Boolean,System.Boolean,System.Double,System.Boolean,TorchSharp.torch.Device,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Creates an Elman RNN module with tanh or ReLU non-linearity.
            </summary>
            <param name="inputSize">The number of expected features in the input x</param>
            <param name="hiddenSize">The number of features in the hidden state h</param>
            <param name="numLayers">Number of recurrent layers. Default: 1</param>
            <param name="nonLinearity">The non-linearity to use. Can be either 'tanh' or 'relu'. Default: 'tanh'</param>
            <param name="bias">If False, then the layer does not use bias weights b_ih and b_hh. Default: True</param>
            <param name="batchFirst">if true, then the input and output tensors are provided as (batch, seq, feature). Default: False</param>
            <param name="dropout">If non-zero, introduces a Dropout layer on the outputs of each RNN layer except the last layer, with dropout probability equal to dropout. Default: 0</param>
            <param name="bidirectional">if true, becomes a bidirectional RNN. Default: False</param>
            <param name="device">The desired device of the parameters and buffers in this module</param>
            <param name="dtype">The desired floating point or complex dtype of the parameters and buffers in this module</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.RNNCell(System.Int64,System.Int64,TorchSharp.torch.nn.NonLinearities,System.Boolean,TorchSharp.torch.Device,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            An Elman RNN cell with tanh or ReLU non-linearity.
            </summary>
            <param name="inputSize">The number of expected features in the input x</param>
            <param name="hiddenSize">The number of features in the hidden state h</param>
            <param name="nonLinearity">The non-linearity to use. Can be either 'tanh' or 'relu'. Default: 'tanh'</param>
            <param name="bias">If False, then the layer does not use bias weights b_ih and b_hh. Default: True</param>
            <param name="device">The desired device of the parameters and buffers in this module</param>
            <param name="dtype">The desired floating point or complex dtype of the parameters and buffers in this module</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Sequential">
            <summary>
            Get empty sequential
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Sequential(System.ValueTuple{System.String,TorchSharp.torch.nn.Module{TorchSharp.torch.Tensor,TorchSharp.torch.Tensor}}[])">
            <summary>
            A sequential container. Modules will be added to it in the order they are passed in the constructor.
            Alternatively, an OrderedDict of modules can be passed in. The forward() method of Sequential accepts any input and forwards it to the first module it contains.
            It then “chains” outputs to inputs sequentially for each subsequent module, finally returning the output of the last module.
            The value a Sequential provides over manually calling a sequence of modules is that it allows treating the whole container as a single module,
            such that performing a transformation on the Sequential applies to each of the modules it stores (which are each a registered submodule of the Sequential).
            </summary>
            <param name="modules">An ordered list of the contained modules.</param>
            <returns></returns>
            <remarks>Sequential will take ownership of the modules and dispose of them when disposed.</remarks>
        </member>
        <member name="M:TorchSharp.torch.nn.Sequential(TorchSharp.torch.nn.Module{TorchSharp.torch.Tensor,TorchSharp.torch.Tensor}[])">
            <summary>
            A sequential container. Modules will be added to it in the order they are passed in the constructor.
            It then “chains” outputs to inputs sequentially for each subsequent module, finally returning the output of the last module.
            The value a Sequential provides over manually calling a sequence of modules is that it allows treating the whole container as a single module,
            such that performing a transformation on the Sequential applies to each of the modules it stores (which are each a registered submodule of the Sequential).
            </summary>
            <param name="modules">An ordered list of the contained modules.</param>
            <returns></returns>
            <remarks>Sequential will take ownership of the modules and dispose of them when disposed.</remarks>
        </member>
        <member name="M:TorchSharp.torch.nn.Sequential(System.Tuple{System.String,TorchSharp.torch.nn.Module{TorchSharp.torch.Tensor,TorchSharp.torch.Tensor}}[])">
            <summary>
            A sequential container. Modules will be added to it in the order they are passed in the constructor.
            Alternatively, an OrderedDict of modules can be passed in. The forward() method of Sequential accepts any input and forwards it to the first module it contains.
            It then “chains” outputs to inputs sequentially for each subsequent module, finally returning the output of the last module.
            The value a Sequential provides over manually calling a sequence of modules is that it allows treating the whole container as a single module,
            such that performing a transformation on the Sequential applies to each of the modules it stores (which are each a registered submodule of the Sequential).
            </summary>
            <param name="modules">An ordered list of the contained modules.</param>
            <remarks>Sequential will take ownership of the modules and dispose of them when disposed.</remarks>
        </member>
        <member name="M:TorchSharp.torch.nn.Sequential(System.Collections.Generic.IEnumerable{System.ValueTuple{System.String,TorchSharp.torch.nn.Module{TorchSharp.torch.Tensor,TorchSharp.torch.Tensor}}})">
            <summary>
            A sequential container. Modules will be added to it in the order they are passed in the constructor.
            Alternatively, an OrderedDict of modules can be passed in. The forward() method of Sequential accepts any input and forwards it to the first module it contains.
            It then “chains” outputs to inputs sequentially for each subsequent module, finally returning the output of the last module.
            The value a Sequential provides over manually calling a sequence of modules is that it allows treating the whole container as a single module,
            such that performing a transformation on the Sequential applies to each of the modules it stores (which are each a registered submodule of the Sequential).
            </summary>
            <param name="modules">An ordered list of the contained modules.</param>
            <remarks>Sequential will take ownership of the modules and dispose of them when disposed.</remarks>
        </member>
        <member name="M:TorchSharp.torch.nn.Sequential(System.Collections.Generic.IEnumerable{System.Tuple{System.String,TorchSharp.torch.nn.Module{TorchSharp.torch.Tensor,TorchSharp.torch.Tensor}}})">
            <summary>
            A sequential container. Modules will be added to it in the order they are passed in the constructor.
            Alternatively, an OrderedDict of modules can be passed in. The forward() method of Sequential accepts any input and forwards it to the first module it contains.
            It then “chains” outputs to inputs sequentially for each subsequent module, finally returning the output of the last module.
            The value a Sequential provides over manually calling a sequence of modules is that it allows treating the whole container as a single module,
            such that performing a transformation on the Sequential applies to each of the modules it stores (which are each a registered submodule of the Sequential).
            </summary>
            <param name="modules">An ordered list of the contained modules.</param>
            <remarks>Sequential will take ownership of the modules and dispose of them when disposed.</remarks>
        </member>
        <member name="M:TorchSharp.torch.nn.Sequential(System.Collections.Generic.IEnumerable{TorchSharp.torch.nn.Module{TorchSharp.torch.Tensor,TorchSharp.torch.Tensor}})">
            <summary>
            A sequential container. Modules will be added to it in the order they are passed in the constructor.
            It then “chains” outputs to inputs sequentially for each subsequent module, finally returning the output of the last module.
            The value a Sequential provides over manually calling a sequence of modules is that it allows treating the whole container as a single module,
            such that performing a transformation on the Sequential applies to each of the modules it stores (which are each a registered submodule of the Sequential).
            </summary>
            <param name="modules">An ordered list of the contained modules.</param>
            <returns></returns>
            <remarks>Sequential will take ownership of the modules and dispose of them when disposed.</remarks>
        </member>
        <member name="M:TorchSharp.torch.nn.ChannelShuffle(System.Int64)">
             <summary>
             Divide the channels in a tensor into g groups and rearrange them.
            
             See: https://pytorch.org/docs/1.10/generated/torch.nn.ChannelShuffle.html#channelshuffle
             </summary>
             <param name="groups">The number of groups to divide channels in.</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Transformer(System.Int64,System.Int64,System.Int64,System.Int64,System.Int64,System.Double,TorchSharp.torch.nn.Activations)">
            <summary>
            A transformer model. User is able to modify the attributes as needed. The architecture is based on the paper “Attention Is All You Need”.
            </summary>
            <param name="d_model">The number of expected features in the encoder/decoder inputs (default=512).</param>
            <param name="nhead">The number of heads in the multiheadattention models (default=8).</param>
            <param name="num_encoder_layers">The number of sub-encoder-layers in the encoder (default=6).</param>
            <param name="num_decoder_layers">The number of sub-decoder-layers in the decoder (default=6).</param>
            <param name="dim_feedforward">The dimension of the feedforward network model (default=2048).</param>
            <param name="dropout">The dropout value (default=0.1).</param>
            <param name="activation">The activation function of encoder/decoder intermediate layer, relu or gelu (default=relu).</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.TransformerDecoder(TorchSharp.Modules.TransformerDecoderLayer,System.Int64)">
            <summary>
            TransformerDecoder is a stack of N decoder layers
            </summary>
            <param name="decoder_layer">An instance of the TransformerDecoderLayer class (required).</param>
            <param name="num_layers">The number of sub-decoder-layers in the decoder (required).</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.TransformerDecoderLayer(System.Int64,System.Int64,System.Int64,System.Double,TorchSharp.torch.nn.Activations)">
            <summary>
            TransformerDecoderLayer is made up of self-attn, multi-head-attn and feedforward network. This standard decoder layer is based on the paper “Attention Is All You Need”.
            </summary>
            <param name="d_model">The number of expected features in the input (required).</param>
            <param name="nhead">The number of heads in the multiheadattention models (required).</param>
            <param name="dim_feedforward">The dimension of the feedforward network model (default=2048).</param>
            <param name="dropout">The dropout value (default=0.1).</param>
            <param name="activation">The activation function of intermediate layer, relu or gelu (default=relu).</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.TransformerEncoder(TorchSharp.Modules.TransformerEncoderLayer,System.Int64)">
            <summary>
            TransformerEncoder is a stack of N encoder layers
            </summary>
            <param name="encoder_layer">An instance of the TransformerEncoderLayer class (required).</param>
            <param name="num_layers">The number of sub-encoder-layers in the encoder (required).</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.TransformerEncoderLayer(System.Int64,System.Int64,System.Int64,System.Double,TorchSharp.torch.nn.Activations)">
            <summary>
            TransformerEncoderLayer is made up of self-attn and feedforward network. This standard encoder layer is based on the paper “Attention Is All You Need”.
            </summary>
            <param name="d_model">The number of expected features in the input (required).</param>
            <param name="nhead">The number of heads in the multiheadattention models (required).</param>
            <param name="dim_feedforward">The dimension of the feedforward network model (default=2048).</param>
            <param name="dropout">The dropout value (default=0.1).</param>
            <param name="activation">The activation function of intermediate layer, relu or gelu (default=relu).</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Unflatten(System.Int64,System.Int64[])">
            <summary>
            Unflattens a tensor dim expanding it to a desired shape. For use with Sequential.
            </summary>
            <param name="dim">Dimension to be unflattened</param>
            <param name="unflattened_size">New shape of the unflattened dimension</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.Unfold(System.Int64,System.Int64,System.Int64,System.Int64)">
            <summary>
            Extracts sliding local blocks from a batched input tensor.
            </summary>
            <param name="kernel_size">The size of the sliding blocks</param>
            <param name="dilation">A parameter that controls the stride of elements within the neighborhood.</param>
            <param name="padding">Implicit zero padding to be added on both sides of input.</param>
            <param name="stride">The stride of the sliding blocks in the input spatial dimensions.</param>
            <remarks>Currently, only 4-D input tensors (batched image-like tensors) are supported.</remarks>
        </member>
        <member name="M:TorchSharp.torch.nn.Unfold(System.ValueTuple{System.Int64,System.Int64},System.Nullable{System.ValueTuple{System.Int64,System.Int64}},System.Nullable{System.ValueTuple{System.Int64,System.Int64}},System.Nullable{System.ValueTuple{System.Int64,System.Int64}})">
            <summary>
            Extracts sliding local blocks from a batched input tensor.
            </summary>
            <param name="kernel_size">The size of the sliding blocks</param>
            <param name="dilation">A parameter that controls the stride of elements within the neighborhood.</param>
            <param name="padding">Implicit zero padding to be added on both sides of input.</param>
            <param name="stride">The stride of the sliding blocks in the input spatial dimensions.</param>
            <remarks>Currently, only 4-D input tensors (batched image-like tensors) are supported.</remarks>
        </member>
        <member name="M:TorchSharp.torch.nn.Upsample(System.Int64[],System.Double[],TorchSharp.torch.UpsampleMode,System.Nullable{System.Boolean},System.Nullable{System.Boolean})">
            <summary>
            Upsamples a given multi-channel 1D (temporal), 2D (spatial) or 3D (volumetric) data.
            The input data is assumed to be of the form minibatch x channels x[optional depth] x[optional height] x width.
            Hence, for spatial inputs, we expect a 4D Tensor and for volumetric inputs, we expect a 5D Tensor.
            </summary>
            <param name="size">Output spatial sizes</param>
            <param name="scale_factor">Multiplier for spatial size. Has to match input size</param>
            <param name="mode">The upsampling algorithm: one of 'nearest', 'linear', 'bilinear', 'bicubic' and 'trilinear'. Default: 'nearest'</param>
            <param name="align_corners">If true, the corner pixels of the input and output tensors are aligned, and thus preserving the values at those pixels.
            This only has effect when mode is 'linear', 'bilinear', or 'trilinear'. Default: false</param>
            <param name="recompute_scale_factor">recompute the scale_factor for use in the interpolation calculation. If `recompute_scale_factor` is ``True``, then `scale_factor` must be passed in and `scale_factor` is used to compute the output `size`. The computed output `size` will be used to infer new scales for the interpolation. Note that when `scale_factor` is floating-point, it may differ from the recomputed `scale_factor` due to rounding and precision issues. If `recompute_scale_factor` is ``False``, then `size` or `scale_factor` will be used directly for interpolation.</param>
            <returns></returns>
        </member>
        <member name="T:TorchSharp.torch.nn.utils.rnn.PackedSequence">
            <summary>
            A packed batch of variable length sequences.
            </summary>
        </member>
        <member name="T:TorchSharp.torch.nn.utils.rnn.PackedSequence.HType">
            <summary>
            Class wrapping PyTorch's packedsequence object reference.
            </summary>
        </member>
        <member name="F:TorchSharp.torch.nn.utils.rnn.PackedSequence.data">
            <summary>
            The packed sequences
            </summary>
        </member>
        <member name="F:TorchSharp.torch.nn.utils.rnn.PackedSequence.batch_sizes">
            <summary>
            Batch size at each sequence step
            </summary>
        </member>
        <member name="F:TorchSharp.torch.nn.utils.rnn.PackedSequence.sorted_indices">
            <summary>
            The sorted indices
            </summary>
        </member>
        <member name="F:TorchSharp.torch.nn.utils.rnn.PackedSequence.unsorted_indices">
            <summary>
            The original indices
            </summary>
        </member>
        <member name="P:TorchSharp.torch.nn.utils.rnn.PackedSequence.IsInvalid">
            <summary>
            Is true if the PackedSequence has been disposed, false otherwise.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.nn.utils.rnn.PackedSequence.Dispose">
            <summary>
              Releases the storage.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.nn.utils.rnn.PackedSequence.MoveToOuterDisposeScope">
            <summary>
            Moves PackedSequence to the outer DisposeScope. If there is no outer DisposeScope, it's detached from the
            DisposeScope system.
            </summary>
            <returns>The same PackedSequence that the method was called on</returns>
        </member>
        <member name="M:TorchSharp.torch.nn.utils.rnn.PackedSequence.DetachFromDisposeScope">
            <summary>
            Detaches the PackedSequence completely from the DisposeScope system.
            </summary>
            <returns>The same PackedSequence that the method was called on</returns>
        </member>
        <member name="M:TorchSharp.torch.nn.utils.rnn.pack_padded_sequence(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Boolean,System.Boolean)">
            <summary>
            Pack a padded sequences.
            </summary>
            <param name="input">The padded input tensor</param>
            <param name="lengths">The lengths of sequences</param>
            <param name="batch_first">If true, the size of input tensor is (batch, seq, *), otherwise (seq, batch, *)</param>
            <param name="enforce_sorted">if true, checks that the input contains sequences sorted by length in a decreasing order.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nn.utils.rnn.pad_packed_sequence(TorchSharp.torch.nn.utils.rnn.PackedSequence,System.Boolean,System.Double,System.Nullable{System.Int64})">
            <summary>
            Pad a packed batch of variable length sequences.
            </summary>
            <param name="sequence">A packed batch</param>
            <param name="batch_first">If true, the size of output tensor is (batch, seq, *), otherwise (seq, batch, *)</param>
            <param name="padding_value">The values of padding.</param>
            <param name="total_length">If not null, the output tensor is padded to the length of total_length.</param>
            <returns>The padded tensor</returns>
        </member>
        <member name="M:TorchSharp.torch.nn.utils.rnn.pad_sequence(System.Collections.Generic.IEnumerable{TorchSharp.torch.Tensor},System.Boolean,System.Double)">
            <summary>
            Pad a list of variable length sequences.
            </summary>
            <param name="sequences">A list of variable length sequences</param>
            <param name="batch_first">If true, the size of output tensor is (batch, seq, *), otherwise (seq, batch, *)</param>
            <param name="padding_value">The values of padding.</param>
            <returns>The padded tensor</returns>
        </member>
        <member name="M:TorchSharp.torch.nn.utils.rnn.pack_sequence(System.Collections.Generic.IEnumerable{TorchSharp.torch.Tensor},System.Boolean)">
            <summary>
            Pack a list of variable length sequences.
            </summary>
            <param name="sequences">A list of variable length sequences</param>
            <param name="enforce_sorted">if true, checks that the input contains sequences sorted by length in a decreasing order.</param>
            <returns>The packed batch of variable length sequences</returns>
        </member>
        <member name="M:TorchSharp.torch.nn.utils.clip_grad_norm_(System.Collections.Generic.IEnumerable{TorchSharp.Modules.Parameter},System.Double,System.Double)">
            <summary>
            Clips gradient norm of an iterable of parameters.
            The norm is computed over all gradients together, as if they were concatenated into a single vector.
            </summary>
            <param name="tensors"></param>
            <param name="max_norm"></param>
            <param name="norm_type"></param>
            <remarks>Gradients are modified in-place.</remarks>
        </member>
        <member name="M:TorchSharp.torch.nn.utils.clip_grad_value_(System.Collections.Generic.IEnumerable{TorchSharp.Modules.Parameter},System.Double)">
            <summary>
            Clips gradient of an iterable of parameters at specified value.
            </summary>
            <param name="tensors">An enumeration of Tensors that will have gradients normalized</param>
            <param name="clip_value">Maximum allowed value of the gradients. The gradients are clipped in the range [-clip_value,clip_value]</param>
            <remarks>Gradients are modified in-place.</remarks>
        </member>
        <member name="M:TorchSharp.torch.nn.utils.parameters_to_vector(System.Collections.Generic.IEnumerable{TorchSharp.Modules.Parameter})">
            <summary>
            Convert parameters to one vector
            </summary>
            <param name="tensors">An enumeration of Tensors that are the parameters of a model.</param>
            <returns>A one-dimensional tensor with the values of all the parameters.</returns>
        </member>
        <member name="M:TorchSharp.torch.nn.utils.vector_to_parameters(TorchSharp.torch.Tensor,System.Collections.Generic.IEnumerable{TorchSharp.Modules.Parameter})">
            <summary>
            Convert one vector to parameters.
            </summary>
            <param name="vec">a single vector represents the parameters of a model.</param>
            <param name="tensors">An enumeration of Tensors that are the parameters of a model.</param>
            <returns>A one-dimensional tensor with the values of all the parameters.</returns>
        </member>
        <member name="M:TorchSharp.torch.nn.utils.fuse_conv_bn_weights(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Double,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Boolean)">
            <summary>
            Fuse convolutional module parameters and BatchNorm module parameters into new convolutional module parameters.
            </summary>
            <param name="conv_w">Convolutional weight.</param>
            <param name="conv_b">Convolutional bias.</param>
            <param name="bn_rm">BatchNorm running mean.</param>
            <param name="bn_rv">BatchNorm running variance.</param>
            <param name="bn_eps">BatchNorm epsilon.</param>
            <param name="bn_w">BatchNorm weight.</param>
            <param name="bn_b">BatchNorm bias.</param>
            <param name="transpose">If <c>true</c>, transpose the conv weight. Defaults to <c>false</c>.</param>
            <returns>Fused convolutional weight and bias.</returns>
        </member>
        <member name="M:TorchSharp.torch.nn.utils.fuse_linear_bn_weights(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Double,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Fuse linear module parameters and BatchNorm module parameters into new linear module parameters.
            </summary>
            <param name="linear_w">Linear weight.</param>
            <param name="linear_b">Linear bias.</param>
            <param name="bn_rm">BatchNorm running mean.</param>
            <param name="bn_rv">BatchNorm running variance.</param>
            <param name="bn_eps">BatchNorm epsilon.</param>
            <param name="bn_w">BatchNorm weight.</param>
            <param name="bn_b">BatchNorm bias.</param>
            <returns>Fused linear weight and bias.</returns>
        </member>
        <member name="M:TorchSharp.torch.optim.Adadelta(System.Collections.Generic.IEnumerable{TorchSharp.Modules.Parameter},System.Double,System.Double,System.Double,System.Double,System.Boolean)">
             <summary>
             Implements the Adadelta algorithm.
            
             It has been proposed in ADADELTA: An Adaptive Learning Rate Method.
             https://arxiv.org/abs/1212.5701
             </summary>
             <param name="parameters">Parameters to optimize. This optimizer requires the <b>named</b> parameters collection.</param>
             <param name="lr ">Learning rate</param>
             <param name="rho">Coefficient used for computing a running average of squared gradients (default: 0.9)</param>
             <param name="eps">Term added to the denominator to improve numerical stability, i.e. avoid division-by-zero (default: 1e-6)</param>
             <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
             <param name="maximize">Maximize the params based on the objective, instead of minimizing</param>
        </member>
        <member name="M:TorchSharp.torch.optim.Adadelta(System.Collections.Generic.IEnumerable{System.ValueTuple{System.String,TorchSharp.Modules.Parameter}},System.Double,System.Double,System.Double,System.Double,System.Boolean)">
             <summary>
             Implements the Adadelta algorithm.
            
             It has been proposed in ADADELTA: An Adaptive Learning Rate Method.
             https://arxiv.org/abs/1212.5701
             </summary>
             <param name="parameters">Parameters to optimize. This optimizer requires the <b>named</b> parameters collection.</param>
             <param name="lr ">Learning rate</param>
             <param name="rho">Coefficient used for computing a running average of squared gradients (default: 0.9)</param>
             <param name="eps">Term added to the denominator to improve numerical stability, i.e. avoid division-by-zero (default: 1e-6)</param>
             <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
             <param name="maximize">Maximize the params based on the objective, instead of minimizing</param>
        </member>
        <member name="M:TorchSharp.torch.optim.Adadelta(System.Collections.Generic.IEnumerable{TorchSharp.Modules.Adadelta.ParamGroup},System.Double,System.Double,System.Double,System.Double,System.Boolean)">
             <summary>
             Implements the Adadelta algorithm.
            
             It has been proposed in ADADELTA: An Adaptive Learning Rate Method.
             https://arxiv.org/abs/1212.5701
             </summary>
             <param name="parameters">Parameters to optimize. This optimizer requires the <b>named</b> parameters collection.</param>
             <param name="lr ">Learning rate</param>
             <param name="rho">Coefficient used for computing a running average of squared gradients (default: 0.9)</param>
             <param name="eps">Term added to the denominator to improve numerical stability, i.e. avoid division-by-zero (default: 1e-6)</param>
             <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
             <param name="maximize">Maximize the params based on the objective, instead of minimizing</param>
        </member>
        <member name="M:TorchSharp.torch.optim.Adagrad(System.Collections.Generic.IEnumerable{TorchSharp.Modules.Parameter},System.Double,System.Double,System.Double,System.Double,System.Double)">
             <summary>
             Implements the Adagrad algorithm.
            
             It has been proposed in Adaptive Subgradient Methods for Online Learning and Stochastic Optimization.
             http://jmlr.org/papers/v12/duchi11a.html
             </summary>
             <param name="parameters">Parameters to optimize</param>
             <param name="lr">learning rate (default: 1e-2)</param>
             <param name="lr_decay">learning rate decay (default: 0)</param>
             <param name="weight_decay">weight decay (L2 penalty) (default: 0)</param>
             <param name="initial_accumulator_value"></param>
             <param name="eps">Term added to the denominator to improve numerical stability (default: 1e-10)</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.optim.Adagrad(System.Collections.Generic.IEnumerable{System.ValueTuple{System.String,TorchSharp.Modules.Parameter}},System.Double,System.Double,System.Double,System.Double,System.Double)">
             <summary>
             Implements the Adagrad algorithm.
            
             It has been proposed in Adaptive Subgradient Methods for Online Learning and Stochastic Optimization.
             http://jmlr.org/papers/v12/duchi11a.html
             </summary>
             <param name="parameters">Parameters to optimize</param>
             <param name="lr">learning rate (default: 1e-2)</param>
             <param name="lr_decay">learning rate decay (default: 0)</param>
             <param name="weight_decay">weight decay (L2 penalty) (default: 0)</param>
             <param name="initial_accumulator_value"></param>
             <param name="eps">Term added to the denominator to improve numerical stability (default: 1e-10)</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.optim.Adagrad(System.Collections.Generic.IEnumerable{TorchSharp.Modules.Adagrad.ParamGroup},System.Double,System.Double,System.Double,System.Double,System.Double)">
             <summary>
             Implements the Adagrad algorithm.
            
             It has been proposed in Adaptive Subgradient Methods for Online Learning and Stochastic Optimization.
             http://jmlr.org/papers/v12/duchi11a.html
             </summary>
             <param name="parameters">Parameters to optimize</param>
             <param name="lr">learning rate (default: 1e-2)</param>
             <param name="lr_decay">learning rate decay (default: 0)</param>
             <param name="weight_decay">weight decay (L2 penalty) (default: 0)</param>
             <param name="initial_accumulator_value"></param>
             <param name="eps">Term added to the denominator to improve numerical stability (default: 1e-10)</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.optim.Adam(System.Collections.Generic.IEnumerable{TorchSharp.Modules.Parameter},System.Double,System.Double,System.Double,System.Double,System.Double,System.Boolean,System.Boolean)">
             <summary>
             Implements the Adam algorithm.
            
             It has been proposed in Adam: A Method for Stochastic Optimization.
             https://arxiv.org/abs/1412.6980
             </summary>
             <param name="parameters">Parameters to optimize</param>
             <param name="lr">learning rate (default: 1e-3)</param>
             <param name="beta1">Coefficient used for computing running averages of gradient and its square (default: 0.9)</param>
             <param name="beta2">Coefficient used for computing running averages of gradient and its square (default: 0.999)</param>
             <param name="eps">Term added to the denominator to improve numerical stability (default: 1e-8)</param>
             <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
             <param name="amsgrad">Whether to use the AMSGrad variant of this algorithm. (default: False)</param>
             <param name="maximize">Maximize the params based on the objective, instead of minimizing</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.optim.Adam(System.Collections.Generic.IEnumerable{System.ValueTuple{System.String,TorchSharp.Modules.Parameter}},System.Double,System.Double,System.Double,System.Double,System.Double,System.Boolean,System.Boolean)">
             <summary>
             Implements the Adam algorithm.
            
             It has been proposed in Adam: A Method for Stochastic Optimization.
             https://arxiv.org/abs/1412.6980
             </summary>
             <param name="parameters">Parameters to optimize</param>
             <param name="lr">learning rate (default: 1e-3)</param>
             <param name="beta1">Coefficient used for computing running averages of gradient and its square (default: 0.9)</param>
             <param name="beta2">Coefficient used for computing running averages of gradient and its square (default: 0.999)</param>
             <param name="eps">Term added to the denominator to improve numerical stability (default: 1e-8)</param>
             <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
             <param name="amsgrad">Whether to use the AMSGrad variant of this algorithm. (default: False)</param>
             <param name="maximize">Maximize the params based on the objective, instead of minimizing</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.optim.Adam(System.Collections.Generic.IEnumerable{TorchSharp.Modules.Adam.ParamGroup},System.Double,System.Double,System.Double,System.Double,System.Double,System.Boolean,System.Boolean)">
             <summary>
             Implements the Adam algorithm.
            
             It has been proposed in Adam: A Method for Stochastic Optimization.
             https://arxiv.org/abs/1412.6980
             </summary>
             <param name="parameters">Parameters to optimize</param>
             <param name="lr">learning rate (default: 1e-3)</param>
             <param name="beta1">Coefficient used for computing running averages of gradient and its square (default: 0.9)</param>
             <param name="beta2">Coefficient used for computing running averages of gradient and its square (default: 0.999)</param>
             <param name="eps">Term added to the denominator to improve numerical stability (default: 1e-8)</param>
             <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
             <param name="amsgrad">Whether to use the AMSGrad variant of this algorithm. (default: False)</param>
             <param name="maximize">Maximize the params based on the objective, instead of minimizing</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.optim.Adamax(System.Collections.Generic.IEnumerable{TorchSharp.Modules.Parameter},System.Double,System.Double,System.Double,System.Double,System.Double)">
             <summary>
             Implements the Adamax algorithm (a variant of Adam based on infinity norm).
            
             It has been proposed in Adam: A Method for Stochastic Optimization.
             https://arxiv.org/abs/1412.6980
             </summary>
             <param name="parameters">Parameters to optimize.</param>
             <param name="lr ">Learning rate</param>
             <param name="beta1">Coefficient used for computing running averages of gradient and its square (default: 0.9)</param>
             <param name="beta2">Coefficient used for computing running averages of gradient and its square (default: 0.999)</param>
             <param name="eps">Term added to the denominator to improve numerical stability, i.e. avoid division-by-zero (default: 1e-8)</param>
             <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.optim.Adamax(System.Collections.Generic.IEnumerable{System.ValueTuple{System.String,TorchSharp.Modules.Parameter}},System.Double,System.Double,System.Double,System.Double,System.Double)">
             <summary>
             Implements the Adamax algorithm (a variant of Adam based on infinity norm).
            
             It has been proposed in Adam: A Method for Stochastic Optimization.
             https://arxiv.org/abs/1412.6980
             </summary>
             <param name="parameters">Parameters to optimize.</param>
             <param name="lr ">Learning rate</param>
             <param name="beta1">Coefficient used for computing running averages of gradient and its square (default: 0.9)</param>
             <param name="beta2">Coefficient used for computing running averages of gradient and its square (default: 0.999)</param>
             <param name="eps">Term added to the denominator to improve numerical stability, i.e. avoid division-by-zero (default: 1e-8)</param>
             <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.optim.Adamax(System.Collections.Generic.IEnumerable{TorchSharp.Modules.Adamax.ParamGroup},System.Double,System.Double,System.Double,System.Double,System.Double)">
             <summary>
             Implements the Adamax algorithm (a variant of Adam based on infinity norm).
            
             It has been proposed in Adam: A Method for Stochastic Optimization.
             https://arxiv.org/abs/1412.6980
             </summary>
             <param name="parameters">Parameters to optimize.</param>
             <param name="lr ">Learning rate</param>
             <param name="beta1">Coefficient used for computing running averages of gradient and its square (default: 0.9)</param>
             <param name="beta2">Coefficient used for computing running averages of gradient and its square (default: 0.999)</param>
             <param name="eps">Term added to the denominator to improve numerical stability, i.e. avoid division-by-zero (default: 1e-8)</param>
             <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.optim.AdamW(System.Collections.Generic.IEnumerable{TorchSharp.Modules.Parameter},System.Double,System.Double,System.Double,System.Double,System.Double,System.Boolean,System.Boolean)">
             <summary>
             Implements the AdamW algorithm.
            
             The AdamW variant was proposed in Decoupled Weight Decay Regularization.
              https://arxiv.org/abs/1711.05101
             </summary>
             <param name="parameters">Parameters to optimize</param>
             <param name="lr">learning rate (default: 1e-3)</param>
             <param name="beta1">Coefficient used for computing running averages of gradient and its square (default: 0.9)</param>
             <param name="beta2">Coefficient used for computing running averages of gradient and its square (default: 0.999)</param>
             <param name="eps">Term added to the denominator to improve numerical stability (default: 1e-8)</param>
             <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
             <param name="amsgrad">Whether to use the AMSGrad variant of this algorithm. (default: False)</param>
             <param name="maximize"></param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.optim.AdamW(System.Collections.Generic.IEnumerable{System.ValueTuple{System.String,TorchSharp.Modules.Parameter}},System.Double,System.Double,System.Double,System.Double,System.Double,System.Boolean,System.Boolean)">
             <summary>
             Implements the AdamW algorithm.
            
             The AdamW variant was proposed in Decoupled Weight Decay Regularization.
              https://arxiv.org/abs/1711.05101
             </summary>
             <param name="parameters">Parameters to optimize</param>
             <param name="lr">learning rate (default: 1e-3)</param>
             <param name="beta1">Coefficient used for computing running averages of gradient and its square (default: 0.9)</param>
             <param name="beta2">Coefficient used for computing running averages of gradient and its square (default: 0.999)</param>
             <param name="eps">Term added to the denominator to improve numerical stability (default: 1e-8)</param>
             <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
             <param name="amsgrad">Whether to use the AMSGrad variant of this algorithm. (default: False)</param>
             <param name="maximize"></param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.optim.AdamW(System.Collections.Generic.IEnumerable{TorchSharp.Modules.AdamW.ParamGroup},System.Double,System.Double,System.Double,System.Double,System.Double,System.Boolean,System.Boolean)">
             <summary>
             Implements the AdamW algorithm.
            
             The AdamW variant was proposed in Decoupled Weight Decay Regularization.
              https://arxiv.org/abs/1711.05101
             </summary>
             <param name="parameters">Parameters to optimize</param>
             <param name="lr">learning rate (default: 1e-3)</param>
             <param name="beta1">Coefficient used for computing running averages of gradient and its square (default: 0.9)</param>
             <param name="beta2">Coefficient used for computing running averages of gradient and its square (default: 0.999)</param>
             <param name="eps">Term added to the denominator to improve numerical stability (default: 1e-8)</param>
             <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
             <param name="amsgrad">Whether to use the AMSGrad variant of this algorithm. (default: False)</param>
             <param name="maximize"></param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.optim.ASGD(System.Collections.Generic.IEnumerable{TorchSharp.Modules.Parameter},System.Double,System.Double,System.Double,System.Double,System.Double,System.Boolean)">
             <summary>
             Implements the Averaged Stochastic Gradient Descent.
            
             It has been proposed in Acceleration of stochastic approximation by averaging.
             https://dl.acm.org/citation.cfm?id=131098
             </summary>
             <param name="parameters">Parameters to optimize. This optimizer requires the <b>named</b> parameters collection.</param>
             <param name="lr ">Learning rate</param>
             <param name="lambd">Decay term (default: 1e-4)</param>
             <param name="alpha">Power for eta update (default: 0.75)</param>
             <param name="t0">Point at which to start averaging (default: 1e6)</param>
             <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
             <param name="maximize">Maximize the params based on the objective, instead of minimizing.</param>
        </member>
        <member name="M:TorchSharp.torch.optim.ASGD(System.Collections.Generic.IEnumerable{System.ValueTuple{System.String,TorchSharp.Modules.Parameter}},System.Double,System.Double,System.Double,System.Double,System.Double,System.Boolean)">
             <summary>
             Implements the Averaged Stochastic Gradient Descent.
            
             It has been proposed in Acceleration of stochastic approximation by averaging.
             https://dl.acm.org/citation.cfm?id=131098
             </summary>
             <param name="parameters">Parameters to optimize. This optimizer requires the <b>named</b> parameters collection.</param>
             <param name="lr ">Learning rate</param>
             <param name="lambd">Decay term (default: 1e-4)</param>
             <param name="alpha">Power for eta update (default: 0.75)</param>
             <param name="t0">Point at which to start averaging (default: 1e6)</param>
             <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
             <param name="maximize">Maximize the params based on the objective, instead of minimizing.</param>
        </member>
        <member name="M:TorchSharp.torch.optim.ASGD(System.Collections.Generic.IEnumerable{TorchSharp.Modules.ParamGroup{TorchSharp.Modules.ASGD.Options}},System.Double,System.Double,System.Double,System.Double,System.Double,System.Boolean)">
             <summary>
             Implements the Averaged Stochastic Gradient Descent.
            
             It has been proposed in Acceleration of stochastic approximation by averaging.
             https://dl.acm.org/citation.cfm?id=131098
             </summary>
             <param name="parameters">Parameters to optimize. This optimizer requires the <b>named</b> parameters collection.</param>
             <param name="lr ">Learning rate</param>
             <param name="lambd">Decay term (default: 1e-4)</param>
             <param name="alpha">Power for eta update (default: 0.75)</param>
             <param name="t0">Point at which to start averaging (default: 1e6)</param>
             <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
             <param name="maximize">Maximize the params based on the objective, instead of minimizing.</param>
        </member>
        <member name="M:TorchSharp.torch.optim.LBFGS(System.Collections.Generic.IEnumerable{System.ValueTuple{System.String,TorchSharp.Modules.Parameter}},System.Double,System.Int64,System.Nullable{System.Int64},System.Double,System.Double,System.Int64)">
             <summary>
             Implements the L-BFGS algorithm, heavily inspired by `minFunc`
            
             https://www.cs.ubc.ca/~schmidtm/Software/minFunc.html
             </summary>
             <param name="parameters">Parameters to optimize</param>
             <param name="lr">Learning rate (default: 1e-2)</param>
             <param name="max_iter">Maximal number of iterations per optimization step</param>
             <param name="max_eval">Maximal number of function evaluations per optimization step</param>
             <param name="tolerange_grad">Termination tolerance on first order optimality</param>
             <param name="tolerance_change">Termination tolerance on function value/parameter changes</param>
             <param name="history_size">Update history size</param>
        </member>
        <member name="M:TorchSharp.torch.optim.LBFGS(System.Collections.Generic.IEnumerable{TorchSharp.Modules.Parameter},System.Double,System.Int64,System.Nullable{System.Int64},System.Double,System.Double,System.Int64)">
             <summary>
             Implements the L-BFGS algorithm, heavily inspired by `minFunc`
            
             https://www.cs.ubc.ca/~schmidtm/Software/minFunc.html
             </summary>
             <param name="parameters">Parameters to optimize</param>
             <param name="lr">Learning rate (default: 1e-2)</param>
             <param name="max_iter">Maximal number of iterations per optimization step</param>
             <param name="max_eval">Maximal number of function evaluations per optimization step</param>
             <param name="tolerange_grad">Termination tolerance on first order optimality</param>
             <param name="tolerance_change">Termination tolerance on function value/parameter changes</param>
             <param name="history_size">Update history size</param>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.LRScheduler.step">
            <summary>
            Advance the learning rate schedule.                 
            </summary>
            <remarks>Typically, this is done once per epoch or once every N batches.</remarks>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.LRScheduler.step(System.Nullable{System.Int32})">
            <summary>
            Advance the learning rate schedule.                 
            </summary>
            <remarks>Typically, this is done once per epoch or once every N batches.</remarks>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.LRScheduler.step(System.Double,System.Nullable{System.Int32})">
            <summary>
            Advance the learning rate scheduler, passing in the current value of some metric.
            </summary>
            <remarks>
            The metric value is ignored by most LR schedulers.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.LRScheduler.get_lr">
            <summary>
            Compute the current learning rate for the scheduler.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.LRScheduler.get_closed_form_lr">
            <summary>
            Computes the current closed-form learning rate.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.LRScheduler.get_last_lr">
            <summary>
            Return last computed learning rate by current scheduler.
            </summary>
        </member>
        <member name="T:TorchSharp.torch.optim.lr_scheduler.impl.LambdaLR">
            <summary>
            Sets the learning rate of each parameter group to the initial lr times a given function.
            When last_epoch=-1, sets initial lr as lr.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.impl.LambdaLR.#ctor(TorchSharp.torch.optim.Optimizer,System.Func{System.Int32,System.Double},System.Int32,System.Boolean)">
            <summary>
            Constructor
            </summary>
            <param name="optimizer">Wrapped optimizer.</param>
            <param name="lr_lambda">A function which computes a multiplicative factor given an integer parameter epoch.</param>
            <param name="last_epoch">The index of last epoch. Default: -1.</param>
            <param name="verbose"> If true, prints a message to stdout for each update. Default: false.</param>
            <returns>A scheduler</returns>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.impl.LambdaLR.#ctor(TorchSharp.torch.optim.Optimizer,System.Collections.Generic.IEnumerable{System.Func{System.Int32,System.Double}},System.Int32,System.Boolean)">
            <summary>
            Constructor
            </summary>
            <param name="optimizer">Wrapped optimizer.</param>
            <param name="lr_lambdas">A list of functions, one for each paramater group, which computes a multiplicative factor given an integer parameter epoch.</param>
            <param name="last_epoch">The index of last epoch. Default: -1.</param>
            <param name="verbose"> If true, prints a message to stdout for each update. Default: false.</param>
            <returns>A scheduler</returns>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.impl.LambdaLR.get_lr">
            <summary>
            Compute the current learning rate for the scheduler.
            </summary>
        </member>
        <member name="T:TorchSharp.torch.optim.lr_scheduler.impl.MultiplicativeLR">
            <summary>
            Multiply the learning rate of each parameter group by the factor given in the specified function.
            When last_epoch = -1, sets initial lr as lr.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.impl.MultiplicativeLR.#ctor(TorchSharp.torch.optim.Optimizer,System.Collections.Generic.IEnumerable{System.Func{System.Int32,System.Double}},System.Int32,System.Boolean)">
            <summary>
            Constructor
            </summary>
            <param name="optimizer">Wrapped optimizer.</param>
            <param name="lr_lambdas">A list of functions, one for each paramater group, which computes a multiplicative factor given an integer parameter epoch.</param>
            <param name="last_epoch">The index of last epoch. Default: -1.</param>
            <param name="verbose"> If true, prints a message to stdout for each update. Default: false.</param>
            <returns>A scheduler</returns>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.impl.MultiplicativeLR.#ctor(TorchSharp.torch.optim.Optimizer,System.Func{System.Int32,System.Double},System.Int32,System.Boolean)">
            <summary>
            Constructor
            </summary>
            <param name="optimizer">Wrapped optimizer.</param>
            <param name="lr_lambda">A function which computes a multiplicative factor given an integer parameter epoch.</param>
            <param name="last_epoch">The index of last epoch. Default: -1.</param>
            <param name="verbose"> If true, prints a message to stdout for each update. Default: false.</param>
            <returns>A scheduler</returns>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.impl.MultiplicativeLR.get_lr">
            <summary>
            Compute the current learning rate for the scheduler.
            </summary>
        </member>
        <member name="T:TorchSharp.torch.optim.lr_scheduler.impl.StepLR">
            <summary>
            Decays the learning rate of each parameter group by gamma every step_size epochs.
            Notice that such decay can happen simultaneously with other changes to the learning rate from outside this scheduler.
            When last_epoch=-1, sets initial lr as lr.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.impl.StepLR.#ctor(TorchSharp.torch.optim.Optimizer,System.Int32,System.Double,System.Int32,System.Boolean)">
            <summary>
            Constructor
            </summary>
            <param name="optimizer">Wrapped optimizer.</param>
            <param name="step_size">Period of learning rate decay.</param>
            <param name="gamma">Multiplicative factor of learning rate decay. Default: 0.1.</param>
            <param name="last_epoch">The index of last epoch. Default: -1.</param>
            <param name="verbose"> If true, prints a message to stdout for each update. Default: false.</param>
            <returns>A scheduler</returns>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.impl.StepLR.get_lr">
            <summary>
            Compute the current learning rate for the scheduler.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.impl.StepLR.get_closed_form_lr">
            <summary>
            Computes the current closed-form learning rate.
            </summary>
        </member>
        <member name="T:TorchSharp.torch.optim.lr_scheduler.impl.MultiStepLR">
            <summary>
            Decays the learning rate of each parameter group by gamma once the number of epoch reaches one of the milestones.
            Notice that such decay can happen simultaneously with other changes to the learning rate from outside this scheduler.
            When last_epoch=-1, sets initial lr as lr.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.impl.MultiStepLR.#ctor(TorchSharp.torch.optim.Optimizer,System.Collections.Generic.IList{System.Int32},System.Double,System.Int32,System.Boolean)">
            <summary>
            Constructor
            </summary>
            <param name="optimizer">Wrapped optimizer.</param>
            <param name="milestones">List of epoch indices. Must be increasing.</param>
            <param name="gamma">Multiplicative factor of learning rate decay. Default: 0.1.</param>
            <param name="last_epoch">The index of last epoch. Default: -1.</param>
            <param name="verbose"> If true, prints a message to stdout for each update. Default: false.</param>
            <returns>A scheduler</returns>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.impl.MultiStepLR.get_lr">
            <summary>
            Compute the current learning rate for the scheduler.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.impl.MultiStepLR.get_closed_form_lr">
            <summary>
            Computes the current closed-form learning rate.
            </summary>
        </member>
        <member name="T:TorchSharp.torch.optim.lr_scheduler.impl.PolynomialLR">
            <summary>
            Decays the learning rate of each parameter group using a polynomial function in the given total_iters.
            When last_epoch=-1, sets initial lr as lr.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.impl.PolynomialLR.#ctor(TorchSharp.torch.optim.Optimizer,System.Int32,System.Int32,System.Int32,System.Boolean)">
            <summary>
            Constructor
            </summary>
            <param name="optimizer">Wrapped optimizer.</param>
            <param name="total_iters">The number of steps that the scheduler decays the learning rate.</param>
            <param name="power">The power of the polynomial.</param>
            <param name="last_epoch">The index of last epoch. Default: -1.</param>
            <param name="verbose"> If true, prints a message to stdout for each update. Default: false.</param>
            <returns>A scheduler</returns>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.impl.PolynomialLR.get_lr">
            <summary>
            Compute the current learning rate for the scheduler.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.impl.PolynomialLR.get_closed_form_lr">
            <summary>
            Computes the current closed-form learning rate.
            </summary>
        </member>
        <member name="T:TorchSharp.torch.optim.lr_scheduler.impl.ExponentialLR">
            <summary>
            Decays the learning rate of each parameter group by gamma every epoch.
            Notice that such decay can happen simultaneously with other changes to the learning rate from outside this scheduler.
            When last_epoch=-1, sets initial lr as lr.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.impl.ExponentialLR.#ctor(TorchSharp.torch.optim.Optimizer,System.Double,System.Int32,System.Boolean)">
            <summary>
            Constructor
            </summary>
            <param name="optimizer">Wrapped optimizer.</param>
            <param name="gamma">Multiplicative factor of learning rate decay. Default: 0.1.</param>
            <param name="last_epoch">The index of last epoch. Default: -1.</param>
            <param name="verbose"> If true, prints a message to stdout for each update. Default: false.</param>
            <returns>A scheduler</returns>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.impl.ExponentialLR.get_lr">
            <summary>
            Compute the current learning rate for the scheduler.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.impl.ExponentialLR.get_closed_form_lr">
            <summary>
            Computes the current closed-form learning rate.
            </summary>
        </member>
        <member name="T:TorchSharp.torch.optim.lr_scheduler.impl.ConstantLR">
            <summary>
            Decays the learning rate of each parameter group by a small constant factor until the number of epoch reaches a pre-defined milestone: total_iters.
            Notice that such decay can happen simultaneously with other changes to the learning rate from outside this scheduler.
            When last_epoch=-1, sets initial lr as lr.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.impl.ConstantLR.#ctor(TorchSharp.torch.optim.Optimizer,System.Double,System.Int32,System.Int32,System.Boolean)">
            <summary>
            Constructor
            </summary>
            <param name="optimizer">Wrapped optimizer.</param>
            <param name="factor">The number we multiply learning rate until the milestone.</param>
            <param name="total_iters">The number of steps that the scheduler decays the learning rate.</param>
            <param name="last_epoch">The index of last epoch. Default: -1.</param>
            <param name="verbose"> If true, prints a message to stdout for each update. Default: false.</param>
            <returns>A scheduler</returns>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.impl.ConstantLR.get_lr">
            <summary>
            Compute the current learning rate for the scheduler.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.impl.ConstantLR.get_closed_form_lr">
            <summary>
            Computes the current closed-form learning rate.
            </summary>
        </member>
        <member name="T:TorchSharp.torch.optim.lr_scheduler.impl.LinearLR">
            <summary>
            Decays the learning rate of each parameter group by linearly changing small multiplicative factor until the
            number of epoch reaches a pre-defined milestone: total_iters.
            Notice that such decay can happen simultaneously with other changes to the learning rate from outside this scheduler.
            When last_epoch=-1, sets initial lr as lr.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.impl.LinearLR.#ctor(TorchSharp.torch.optim.Optimizer,System.Double,System.Double,System.Int32,System.Int32,System.Boolean)">
            <summary>
            Constructor
            </summary>
            <param name="optimizer">Wrapped optimizer.</param>
            <param name="start_factor">The number we multiply learning rate in the first epoch. The multiplication factor changes towards end_factor in the following epochs.</param>
            <param name="end_factor">The number we multiply learning rate at the end of linear changing process.</param>
            <param name="total_iters">The number of steps that the scheduler decays the learning rate.</param>
            <param name="last_epoch">The index of last epoch. Default: -1.</param>
            <param name="verbose"> If true, prints a message to stdout for each update. Default: false.</param>
            <returns>A scheduler</returns>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.impl.LinearLR.get_lr">
            <summary>
            Compute the current learning rate for the scheduler.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.impl.LinearLR.get_closed_form_lr">
            <summary>
            Computes the current closed-form learning rate.
            </summary>
        </member>
        <member name="T:TorchSharp.torch.optim.lr_scheduler.impl.SequentialLR">
            <summary>
            Receives the list of schedulers that is expected to be called sequentially during optimization process and milestone points that provides exact intervals to reflect which scheduler is supposed to be called at a given epoch.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.impl.SequentialLR.get_lr">
            <summary>
            Compute the current learning rate for the scheduler.
            </summary>
        </member>
        <member name="T:TorchSharp.torch.optim.lr_scheduler.impl.CosineAnnealingLR">
            <summary>
            Set the learning rate of each parameter group using a cosine annealing schedule.
            When last_epoch=-1, sets initial lr as lr.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.impl.CosineAnnealingLR.#ctor(TorchSharp.torch.optim.Optimizer,System.Double,System.Double,System.Int32,System.Boolean)">
            <summary>
            Constructor
            </summary>
            <param name="optimizer">Wrapped optimizer.</param>
            <param name="T_max">Maximum number of iterations.</param>
            <param name="eta_min">Minimum learning rate.</param>
            <param name="last_epoch">The index of last epoch. Default: -1.</param>
            <param name="verbose"> If true, prints a message to stdout for each update. Default: false.</param>
            <returns>A scheduler</returns>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.impl.CosineAnnealingLR.get_lr">
            <summary>
            Compute the current learning rate for the scheduler.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.impl.CosineAnnealingLR.get_closed_form_lr">
            <summary>
            Computes the current closed-form learning rate.
            </summary>
        </member>
        <member name="T:TorchSharp.torch.optim.lr_scheduler.impl.ReduceLROnPlateau">
            <summary>
            Set the learning rate of each parameter group using a cosine annealing schedule.
            When last_epoch=-1, sets initial lr as lr.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.impl.ReduceLROnPlateau.#ctor(TorchSharp.torch.optim.Optimizer,System.String,System.Double,System.Int32,System.Double,System.String,System.Int32,System.Collections.Generic.IList{System.Double},System.Double,System.Boolean)">
            <summary>
            Constructor
            </summary>
            <returns>A scheduler</returns>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.impl.ReduceLROnPlateau.step(System.Double,System.Nullable{System.Int32})">
            <summary>
            Advance the LR scheduler one epoch.
            Unlike other LR schedulers, you're supposed to pass in the most recent value of the metric
            that is used to decided whether to modify the learning rates. 
            </summary>
            <param name="current">The current value of the metric that we're interested in imvproving.</param>
            <param name="epoch">The current epoch.</param>
        </member>
        <member name="T:TorchSharp.torch.optim.lr_scheduler.impl.CyclicLR">
             <summary>
             Sets the learning rate of each parameter group according to cyclical learning rate policy(CLR).
            
             The policy cycles the learning rate between two boundaries with a constant frequency, as detailed in
             the paper `Cyclical Learning Rates for Training Neural Networks`_.
             
             The distance between the two boundaries can be scaled on a per-iteration or per-cycle basis.
             </summary>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.impl.CyclicLR.#ctor(TorchSharp.torch.optim.Optimizer,System.Double,System.Double,System.Int32,System.Int32,TorchSharp.torch.optim.lr_scheduler.impl.CyclicLR.Mode,System.Double,System.Func{System.Double,System.Double},TorchSharp.torch.optim.lr_scheduler.impl.CyclicLR.ScaleMode,System.Boolean,System.Double,System.Double,System.Int32,System.Boolean)">
            <summary>
            Constructor
            </summary>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.impl.CyclicLR.#ctor(TorchSharp.torch.optim.Optimizer,System.Collections.Generic.IEnumerable{System.Double},System.Collections.Generic.IEnumerable{System.Double},System.Int32,System.Int32,TorchSharp.torch.optim.lr_scheduler.impl.CyclicLR.Mode,System.Double,System.Func{System.Double,System.Double},TorchSharp.torch.optim.lr_scheduler.impl.CyclicLR.ScaleMode,System.Boolean,System.Collections.Generic.IEnumerable{System.Double},System.Collections.Generic.IEnumerable{System.Double},System.Int32,System.Boolean)">
            <summary>
            Constructor
            </summary>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.impl.CyclicLR.get_lr">
            <summary>
            Compute the current learning rate for the scheduler.
            </summary>
        </member>
        <member name="T:TorchSharp.torch.optim.lr_scheduler.impl.OneCycleLR">
            <summary>
            Sets the learning rate of each parameter group according to the 1cycle learning rate policy.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.impl.OneCycleLR.#ctor(TorchSharp.torch.optim.Optimizer,System.Double,System.Int32,System.Int32,System.Int32,System.Double,TorchSharp.torch.optim.lr_scheduler.impl.OneCycleLR.AnnealStrategy,System.Boolean,System.Double,System.Double,System.Double,System.Double,System.Boolean,System.Int32,System.Boolean)">
            <summary>
            Constructor
            </summary>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.impl.OneCycleLR.#ctor(TorchSharp.torch.optim.Optimizer,System.Collections.Generic.IEnumerable{System.Double},System.Int32,System.Int32,System.Int32,System.Double,TorchSharp.torch.optim.lr_scheduler.impl.OneCycleLR.AnnealStrategy,System.Boolean,System.Collections.Generic.IEnumerable{System.Double},System.Collections.Generic.IEnumerable{System.Double},System.Double,System.Double,System.Boolean,System.Int32,System.Boolean)">
            <summary>
            Constructor
            </summary>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.impl.OneCycleLR.get_lr">
            <summary>
            Compute the current learning rate for the scheduler.
            </summary>
        </member>
        <member name="T:TorchSharp.torch.optim.lr_scheduler.impl.ChainedLR">
            <summary>
            Chains list of learning rate schedulers. It takes a list of chainable learning rate schedulers and applies step() to all of them.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.impl.ChainedLR.#ctor(System.Collections.Generic.IEnumerable{TorchSharp.torch.optim.lr_scheduler.LRScheduler})">
            <summary>
            Constructor
            </summary>
            <param name="schedulers">List of chained schedulers.</param>
            <returns>A scheduler</returns>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.StepLR(TorchSharp.torch.optim.Optimizer,System.Int32,System.Double,System.Int32,System.Boolean)">
            <summary>
            Decays the learning rate of each parameter group by gamma every step_size epochs.
            Notice that such decay can happen simultaneously with other changes to the learning rate from outside this scheduler.
            When last_epoch=-1, sets initial lr as lr.
            </summary>
            <param name="optimizer">Wrapped optimizer.</param>
            <param name="step_size">Period of learning rate decay.</param>
            <param name="gamma">Multiplicative factor of learning rate decay. Default: 0.1.</param>
            <param name="last_epoch">
            The index of the last batch. This parameter is used when resuming a training job.Since `step()` should be invoked after each
            batch instead of after each epoch, this number represents the total number of *batches* computed, not the total number of epochs computed.
            When last_epoch = -1, the schedule is started from the beginning.
            </param>
            <param name="verbose"> If true, prints a message to stdout for each update. Default: false.</param>
            <returns>A scheduler</returns>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.LambdaLR(TorchSharp.torch.optim.Optimizer,System.Func{System.Int32,System.Double},System.Int32,System.Boolean)">
            <summary>
            Sets the learning rate of each parameter group to the initial lr times a given function.
            When last_epoch=-1, sets initial lr as lr.
            </summary>
            <param name="optimizer">Wrapped optimizer.</param>
            <param name="lr_lambda">A function which computes a multiplicative factor given an integer parameter epoch.</param>
            <param name="last_epoch">
            The index of the last batch. This parameter is used when resuming a training job.Since `step()` should be invoked after each
            batch instead of after each epoch, this number represents the total number of *batches* computed, not the total number of epochs computed.
            When last_epoch = -1, the schedule is started from the beginning.
            </param>
            <param name="verbose"> If true, prints a message to stdout for each update. Default: false.</param>
            <returns>A scheduler</returns>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.MultiStepLR(TorchSharp.torch.optim.Optimizer,System.Collections.Generic.IList{System.Int32},System.Double,System.Int32,System.Boolean)">
            <summary>
            Decays the learning rate of each parameter group by gamma once the number of epoch reaches one of the milestones.
            Notice that such decay can happen simultaneously with other changes to the learning rate from outside this scheduler.
            When last_epoch=-1, sets initial lr as lr.
            </summary>
            <param name="optimizer">Wrapped optimizer.</param>
            <param name="milestones">List of epoch indices. Must be increasing.</param>
            <param name="gamma">Multiplicative factor of learning rate decay. Default: 0.1.</param>
            <param name="last_epoch">
            The index of the last batch. This parameter is used when resuming a training job.Since `step()` should be invoked after each
            batch instead of after each epoch, this number represents the total number of *batches* computed, not the total number of epochs computed.
            When last_epoch = -1, the schedule is started from the beginning.
            </param>
            <param name="verbose"> If true, prints a message to stdout for each update. Default: false.</param>
            <returns>A scheduler</returns>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.PolynomialLR(TorchSharp.torch.optim.Optimizer,System.Int32,System.Int32,System.Int32,System.Boolean)">
            <summary>
            Constructor
            </summary>
            <param name="optimizer">Wrapped optimizer.</param>
            <param name="total_iters">The number of steps that the scheduler decays the learning rate.</param>
            <param name="power">The power of the polynomial.</param>
            <param name="last_epoch">The index of last epoch. Default: -1.</param>
            <param name="verbose"> If true, prints a message to stdout for each update. Default: false.</param>
            <returns>A scheduler</returns>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.MultiplicativeLR(TorchSharp.torch.optim.Optimizer,System.Func{System.Int32,System.Double},System.Int32,System.Boolean)">
            <summary>
            Multiply the learning rate of each parameter group by the factor given in the specified function.
            When last_epoch = -1, sets initial lr as lr.
            </summary>
            <param name="optimizer">Wrapped optimizer.</param>
            <param name="lr_lambda">A function which computes a multiplicative factor given an integer parameter epoch.</param>
            <param name="last_epoch">
            The index of the last batch. This parameter is used when resuming a training job.Since `step()` should be invoked after each
            batch instead of after each epoch, this number represents the total number of *batches* computed, not the total number of epochs computed.
            When last_epoch = -1, the schedule is started from the beginning.
            </param>
            <param name="verbose"> If true, prints a message to stdout for each update. Default: false.</param>
            <returns>A scheduler</returns>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.ExponentialLR(TorchSharp.torch.optim.Optimizer,System.Double,System.Int32,System.Boolean)">
            <summary>
            Decays the learning rate of each parameter group by gamma every epoch.
            Notice that such decay can happen simultaneously with other changes to the learning rate from outside this scheduler.
            When last_epoch=-1, sets initial lr as lr.
            </summary>
            <param name="optimizer">Wrapped optimizer.</param>
            <param name="gamma">Multiplicative factor of learning rate decay. Default: 0.1.</param>
            <param name="last_epoch">
            The index of the last batch. This parameter is used when resuming a training job.Since `step()` should be invoked after each
            batch instead of after each epoch, this number represents the total number of *batches* computed, not the total number of epochs computed.
            When last_epoch = -1, the schedule is started from the beginning.
            </param>
            <param name="verbose"> If true, prints a message to stdout for each update. Default: false.</param>
            <returns>A scheduler</returns>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.ConstantLR(TorchSharp.torch.optim.Optimizer,System.Double,System.Int32,System.Int32,System.Boolean)">
            <summary>
            Decays the learning rate of each parameter group by a small constant factor until the number of epoch reaches a pre-defined milestone: total_iters.
            Notice that such decay can happen simultaneously with other changes to the learning rate from outside this scheduler.
            When last_epoch=-1, sets initial lr as lr.
            </summary>
            <param name="optimizer">Wrapped optimizer.</param>
            <param name="factor">The number we multiply learning rate until the milestone.</param>
            <param name="total_iters">The number of steps that the scheduler decays the learning rate.</param>
            <param name="last_epoch">
            The index of the last batch. This parameter is used when resuming a training job.Since `step()` should be invoked after each
            batch instead of after each epoch, this number represents the total number of *batches* computed, not the total number of epochs computed.
            When last_epoch = -1, the schedule is started from the beginning.
            </param>
            <param name="verbose">If true, prints a message to stdout for each update. Default: false.</param>
            <returns>A scheduler</returns>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.SequentialLR(TorchSharp.torch.optim.Optimizer,System.Collections.Generic.IEnumerable{TorchSharp.torch.optim.lr_scheduler.LRScheduler},System.Collections.Generic.IEnumerable{System.Int32},System.Int32)">
            <summary>
            Uses a list of schedulers, chosen based on the epoch. A sequence of milestones determines when a switch occurs from one scheduler to the next.
            </summary>
            <param name="optimizer">Wrapped optimizer. All sub-schedulers must be bound to the same optimizer.</param>
            <param name="schedulers">List of chained schedulers. Should be one more than the number of milestones.</param>
            <param name="milestones">List of integers reflecting the milestone points.</param>
            <param name="last_epoch">The index of last epoch. Default: -1.</param>
            <returns></returns>
            <remarks>The 'verbose' flag should be passed to each individual sub-scheduler.</remarks>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.LinearLR(TorchSharp.torch.optim.Optimizer,System.Double,System.Double,System.Int32,System.Int32,System.Boolean)">
            <summary>
            Decays the learning rate of each parameter group by linearly changing small multiplicative factor until the
            number of epoch reaches a pre-defined milestone: total_iters.
            </summary>
            <param name="optimizer">Wrapped optimizer.</param>
            <param name="start_factor">The number we multiply learning rate in the first epoch. The multiplication factor changes towards end_factor in the following epochs.</param>
            <param name="end_factor">The number we multiply learning rate at the end of linear changing process.</param>
            <param name="total_iters">The number of steps that the scheduler decays the learning rate.</param>
            <param name="last_epoch">
            The index of the last batch. This parameter is used when resuming a training job.Since `step()` should be invoked after each
            batch instead of after each epoch, this number represents the total number of *batches* computed, not the total number of epochs computed.
            When last_epoch = -1, the schedule is started from the beginning.
            </param>
            <param name="verbose">If true, prints a message to stdout for each update. Default: false.</param>
            <returns>A scheduler</returns>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.ChainedLR(System.Collections.Generic.IEnumerable{TorchSharp.torch.optim.lr_scheduler.LRScheduler})">
             <summary>
             Chains list of learning rate schedulers. It takes a list of chainable learning rate schedulers and applies step() to all of them.
             </summary>
            <param name="schedulers">List of chained schedulers.</param>
             <returns>A scheduler</returns>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.CosineAnnealingLR(TorchSharp.torch.optim.Optimizer,System.Double,System.Double,System.Int32,System.Boolean)">
            <summary>
            Sets the learning rate using a cosine annealing schedule.
            </summary>
            <param name="optimizer">Wrapped optimizer.</param>
            <param name="T_max">Maximum number of iterations.</param>
            <param name="eta_min">Minimum learning rate.</param>
            <param name="last_epoch">
            The index of the last batch. This parameter is used when resuming a training job.Since `step()` should be invoked after each
            batch instead of after each epoch, this number represents the total number of *batches* computed, not the total number of epochs computed.
            When last_epoch = -1, the schedule is started from the beginning.
            </param>
            <param name="verbose"> If true, prints a message to stdout for each update. Default: false.</param>
            <returns>A scheduler</returns>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.OneCycleLR(TorchSharp.torch.optim.Optimizer,System.Double,System.Int32,System.Int32,System.Int32,System.Double,TorchSharp.torch.optim.lr_scheduler.impl.OneCycleLR.AnnealStrategy,System.Boolean,System.Double,System.Double,System.Double,System.Double,System.Boolean,System.Int32,System.Boolean)">
             <summary>
             Sets the learning rate of each parameter group according to the
             1cycle learning rate policy.The 1cycle policy anneals the learning
             rate from an initial learning rate to some maximum learning rate and then
             from that maximum learning rate to some minimum learning rate much lower
             than the initial learning rate.
             
             This policy was initially described in the paper `Super-Convergence:
             Very Fast Training of Neural Networks Using Large Learning Rates`_.
            
             The 1cycle learning rate policy changes the learning rate after every batch.
             `step` should be called after a batch has been used for training.
            
             This scheduler is not chainable.                
             </summary>
             <param name="optimizer">Wrapped optimizer.</param>
             <param name="max_lr">Upper learning rate boundaries in the cycle</param>
             <param name="total_steps">
             The total number of steps in the cycle.
             Note that if a value is not provided here, then it must be inferred by providing a value for epochs and steps_per_epoch.
             </param>
             <param name="epochs">
             The number of epochs to train for. This is used along
             with steps_per_epoch in order to infer the total number of steps in the cycle
             if a value for total_steps is not provided.
             </param>
             <param name="steps_per_epoch">
             The number of steps per epoch to train for. This is
             used along with epochs in order to infer the total number of steps in the
             cycle if a value for total_steps is not provided.
             </param>
             <param name="pct_start">The percentage of the cycle (in number of steps) spent increasing the learning rate.</param>
             <param name="anneal_strategy">Specifies the annealing strategy: "cos" for cosine annealing, "linear" for linear annealing.</param>
             <param name="cycle_momentum">If true, momentum is cycled inversely to learning rate between 'base_momentum' and 'max_momentum'.</param>
             <param name="base_momentum">
             Lower momentum boundaries in the cycle
             for each parameter group.Note that momentum is cycled inversely
             to learning rate; at the peak of a cycle, momentum is
             'base_momentum' and learning rate is 'max_lr'.
             </param>
             <param name="max_momentum">
             Upper momentum boundaries in the cycle for each parameter group.
             Functionally, it defines the cycle amplitude(max_momentum - base_momentum).
             Note that momentum is cycled inversely to learning rate; at the start of a cycle, momentum is 'max_momentum'
             and learning rate is 'base_lr'
             </param>
             <param name="div_factor">Determines the initial learning rate via initial_lr = max_lr/div_factor</param>
             <param name="final_div_factor">Determines the minimum learning rate via min_lr = initial_lr/final_div_factor</param>
             <param name="three_phase">
             If ``True``, use a third phase of the schedule to annihilate the
             learning rate according to 'final_div_factor' instead of modifying the second
             phase (the first two phases will be symmetrical about the step indicated by 'pct_start').
             </param>
             <param name="last_epoch">
             The index of the last batch. This parameter is used when resuming a training job.Since `step()` should be invoked after each
             batch instead of after each epoch, this number represents the total number of *batches* computed, not the total number of epochs computed.
             When last_epoch = -1, the schedule is started from the beginning.
             </param>
             <param name="verbose"> If true, prints a message to stdout for each update. Default: false.</param>
             <returns>A scheduler</returns>
             <remarks>
             Note also that the total number of steps in the cycle can be determined in one
             of two ways (listed in order of precedence):
            
             #. A value for total_steps is explicitly provided.
             #. A number of epochs (epochs) and a number of steps per epoch
             (steps_per_epoch) are provided.
             In this case, the number of total steps is inferred by
             total_steps = epochs * steps_per_epoch
            
             You must either provide a value for total_steps or provide a value for both
             epochs and steps_per_epoch.
            
             The default behaviour of this scheduler follows the fastai implementation of 1cycle, which
             claims that "unpublished work has shown even better results by using only two phases". To
             mimic the behaviour of the original paper instead, set ``three_phase= True``.
             </remarks>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.OneCycleLR(TorchSharp.torch.optim.Optimizer,System.Collections.Generic.IEnumerable{System.Double},System.Int32,System.Int32,System.Int32,System.Double,TorchSharp.torch.optim.lr_scheduler.impl.OneCycleLR.AnnealStrategy,System.Boolean,System.Collections.Generic.IEnumerable{System.Double},System.Collections.Generic.IEnumerable{System.Double},System.Double,System.Double,System.Boolean,System.Int32,System.Boolean)">
             <summary>
             Sets the learning rate of each parameter group according to the
             1cycle learning rate policy.The 1cycle policy anneals the learning
             rate from an initial learning rate to some maximum learning rate and then
             from that maximum learning rate to some minimum learning rate much lower
             than the initial learning rate.
             
             This policy was initially described in the paper `Super-Convergence:
             Very Fast Training of Neural Networks Using Large Learning Rates`_.
            
             The 1cycle learning rate policy changes the learning rate after every batch.
             `step` should be called after a batch has been used for training.
            
             This scheduler is not chainable.                
             </summary>
             <param name="optimizer">Wrapped optimizer.</param>
             <param name="max_lr">Upper learning rate boundaries in the cycle</param>
             <param name="total_steps">
             The total number of steps in the cycle.
             Note that if a value is not provided here, then it must be inferred by providing a value for epochs and steps_per_epoch.
             </param>
             <param name="epochs">
             The number of epochs to train for. This is used along
             with steps_per_epoch in order to infer the total number of steps in the cycle
             if a value for total_steps is not provided.
             </param>
             <param name="steps_per_epoch">
             The number of steps per epoch to train for. This is
             used along with epochs in order to infer the total number of steps in the
             cycle if a value for total_steps is not provided.
             </param>
             <param name="pct_start">The percentage of the cycle (in number of steps) spent increasing the learning rate.</param>
             <param name="anneal_strategy">Specifies the annealing strategy: "cos" for cosine annealing, "linear" for linear annealing.</param>
             <param name="cycle_momentum">If true, momentum is cycled inversely to learning rate between 'base_momentum' and 'max_momentum'.</param>
             <param name="base_momentum">
             Lower momentum boundaries in the cycle
             for each parameter group.Note that momentum is cycled inversely
             to learning rate; at the peak of a cycle, momentum is
             'base_momentum' and learning rate is 'max_lr'.
             </param>
             <param name="max_momentum">
             Upper momentum boundaries in the cycle for each parameter group.
             Functionally, it defines the cycle amplitude(max_momentum - base_momentum).
             Note that momentum is cycled inversely to learning rate; at the start of a cycle, momentum is 'max_momentum'
             and learning rate is 'base_lr'
             </param>
             <param name="div_factor">Determines the initial learning rate via initial_lr = max_lr/div_factor</param>
             <param name="final_div_factor">Determines the minimum learning rate via min_lr = initial_lr/final_div_factor</param>
             <param name="three_phase">
             If ``True``, use a third phase of the schedule to annihilate the
             learning rate according to 'final_div_factor' instead of modifying the second
             phase (the first two phases will be symmetrical about the step indicated by 'pct_start').
             </param>
             <param name="last_epoch">
             The index of the last batch. This parameter is used when resuming a training job.Since `step()` should be invoked after each
             batch instead of after each epoch, this number represents the total number of *batches* computed, not the total number of epochs computed.
             When last_epoch = -1, the schedule is started from the beginning.
             </param>
             <param name="verbose"> If true, prints a message to stdout for each update. Default: false.</param>
             <returns>A scheduler</returns>
             <remarks>
             Note also that the total number of steps in the cycle can be determined in one
             of two ways (listed in order of precedence):
            
             #. A value for total_steps is explicitly provided.
             #. A number of epochs (epochs) and a number of steps per epoch
             (steps_per_epoch) are provided.
             In this case, the number of total steps is inferred by
             total_steps = epochs * steps_per_epoch
            
             You must either provide a value for total_steps or provide a value for both
             epochs and steps_per_epoch.
            
             The default behaviour of this scheduler follows the fastai implementation of 1cycle, which
             claims that "unpublished work has shown even better results by using only two phases". To
             mimic the behaviour of the original paper instead, set ``three_phase= True``.
             </remarks>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.CyclicLR(TorchSharp.torch.optim.Optimizer,System.Double,System.Double,System.Int32,System.Int32,TorchSharp.torch.optim.lr_scheduler.impl.CyclicLR.Mode,System.Double,System.Func{System.Double,System.Double},TorchSharp.torch.optim.lr_scheduler.impl.CyclicLR.ScaleMode,System.Boolean,System.Double,System.Double,System.Int32,System.Boolean)">
             <summary>
             Sets the learning rate of each parameter group according to
             cyclical learning rate policy(CLR). The policy cycles the learning
             rate between two boundaries with a constant frequency, as detailed in
             the paper `Cyclical Learning Rates for Training Neural Networks`_.
             The distance between the two boundaries can be scaled on a per-iteration
             or per-cycle basis.
            
             Cyclical learning rate policy changes the learning rate after every batch.
             `step` should be called after a batch has been used for training.
            
             This class has three built-in policies, as put forth in the paper:
                * "triangular": A basic triangular cycle without amplitude scaling.
                * "triangular2": A basic triangular cycle that scales initial amplitude by half each cycle.
                * "exp_range": A cycle that scales initial amplitude by gamma^(cycle iterations).
                }`
             at each cycle iteration.
             /// </summary>
             <param name="optimizer">Wrapped optimizer.</param>
             <param name="base_lr">Initial learning rate which is the lower boundary in the cycle</param>
             <param name="max_lr">
             Upper learning rate boundaries in the cycle for each parameter group.
             Functionally, it defines the cycle amplitude(max_lr - base_lr).
             The lr at any cycle is the sum of base_lr and some scaling of the amplitude; therefore 
             max_lr may not actually be reached depending on the scaling function.
             </param>
             <param name="step_size_up">Number of training iterations in the increasing half of a cycle.</param>
             <param name="step_size_down">
             Number of training iterations in the decreasing half of a cycle.
             If step_size_down is -1, it is set to step_size_up.
             </param>
             <param name="mode">Values correspond to policies detailed above. If scale_fn is non-null, this argument is ignored.</param>
             <param name="gamma">Constant in 'exp_range' scaling function</param>
             <param name="scale_fn">Custom scaling policy defined by a single argument lambda function. If specified, then 'mode' is ignored.</param>
             <param name="scale_mode">Defines whether scale_fn is evaluated on cycle number or cycle iterations(training iterations since start of cycle)</param>
             <param name="cycle_momentum">If true, momentum is cycled inversely to learning rate between 'base_momentum' and 'max_momentum'.</param>
             <param name="base_momentum">Lower momentum boundaries in the cycle. Note that momentum is cycled inversely to learning rate</param>
             <param name="max_momentum">
             Upper momentum boundaries in the cycle.
             Functionally, it defines the cycle amplitude(max_momentum - base_momentum).
             The momentum at any cycle is the difference of max_momentum and some scaling of the amplitude; therefore
             base_momentum may not actually be reached depending on the scaling function.
             </param>
             <param name="last_epoch">
             The index of the last batch. This parameter is used when resuming a training job.Since `step()` should be invoked after each
             batch instead of after each epoch, this number represents the total number of *batches* computed, not the total number of epochs computed.
             When last_epoch = -1, the schedule is started from the beginning.
             </param>
             <param name="verbose"> If true, prints a message to stdout for each update. Default: false.</param>
             <returns>A scheduler</returns>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.CyclicLR(TorchSharp.torch.optim.Optimizer,System.Collections.Generic.IEnumerable{System.Double},System.Collections.Generic.IEnumerable{System.Double},System.Int32,System.Int32,TorchSharp.torch.optim.lr_scheduler.impl.CyclicLR.Mode,System.Double,System.Func{System.Double,System.Double},TorchSharp.torch.optim.lr_scheduler.impl.CyclicLR.ScaleMode,System.Boolean,System.Collections.Generic.IEnumerable{System.Double},System.Collections.Generic.IEnumerable{System.Double},System.Int32,System.Boolean)">
             <summary>
             Sets the learning rate of each parameter group according to
             cyclical learning rate policy(CLR). The policy cycles the learning
             rate between two boundaries with a constant frequency, as detailed in
             the paper `Cyclical Learning Rates for Training Neural Networks`_.
             The distance between the two boundaries can be scaled on a per-iteration
             or per-cycle basis.
            
             Cyclical learning rate policy changes the learning rate after every batch.
             `step` should be called after a batch has been used for training.
            
             This class has three built-in policies, as put forth in the paper:
                * "triangular": A basic triangular cycle without amplitude scaling.
                * "triangular2": A basic triangular cycle that scales initial amplitude by half each cycle.
                * "exp_range": A cycle that scales initial amplitude by gamma^(cycle iterations).
                }`
             at each cycle iteration.
             /// </summary>
             <param name="optimizer">Wrapped optimizer.</param>
             <param name="base_lr">Initial learning rate which is the lower boundary in the cycle</param>
             <param name="max_lr">
             Upper learning rate boundaries in the cycle for each parameter group.
             Functionally, it defines the cycle amplitude(max_lr - base_lr).
             The lr at any cycle is the sum of base_lr and some scaling of the amplitude; therefore 
             max_lr may not actually be reached depending on the scaling function.
             </param>
             <param name="step_size_up">Number of training iterations in the increasing half of a cycle.</param>
             <param name="step_size_down">
             Number of training iterations in the decreasing half of a cycle.
             If step_size_down is -1, it is set to step_size_up.
             </param>
             <param name="mode">Values correspond to policies detailed above. If scale_fn is non-null, this argument is ignored.</param>
             <param name="gamma">Constant in 'exp_range' scaling function</param>
             <param name="scale_fn">Custom scaling policy defined by a single argument lambda function. If specified, then 'mode' is ignored.</param>
             <param name="scale_mode">Defines whether scale_fn is evaluated on cycle number or cycle iterations(training iterations since start of cycle)</param>
             <param name="cycle_momentum">If true, momentum is cycled inversely to learning rate between 'base_momentum' and 'max_momentum'.</param>
             <param name="base_momentum">Lower momentum boundaries in the cycle. Note that momentum is cycled inversely to learning rate</param>
             <param name="max_momentum">
             Upper momentum boundaries in the cycle.
             Functionally, it defines the cycle amplitude(max_momentum - base_momentum).
             The momentum at any cycle is the difference of max_momentum and some scaling of the amplitude; therefore
             base_momentum may not actually be reached depending on the scaling function.
             </param>
             <param name="last_epoch">
             The index of the last batch. This parameter is used when resuming a training job.Since `step()` should be invoked after each
             batch instead of after each epoch, this number represents the total number of *batches* computed, not the total number of epochs computed.
             When last_epoch = -1, the schedule is started from the beginning.
             </param>
             <param name="verbose"> If true, prints a message to stdout for each update. Default: false.</param>
             <returns>A scheduler</returns>
        </member>
        <member name="M:TorchSharp.torch.optim.lr_scheduler.ReduceLROnPlateau(TorchSharp.torch.optim.Optimizer,System.String,System.Double,System.Int32,System.Double,System.String,System.Int32,System.Collections.Generic.IList{System.Double},System.Double,System.Boolean)">
            <summary>
            Reduce learning rate when a metric has stopped improving.
            Models often benefit from reducing the learning rate by a factor of 2-10 once learning stagnates.
            This scheduler reads a metrics quantity and if no improvement is seen for a ‘patience’ number of epochs, the learning rate is reduced.
            </summary>
            <param name="optimizer">Wrapped optimizer.</param>
            <param name="mode">
            One of min, max. In min mode, lr will be reduced when the quantity monitored has stopped decreasing;
            in max mode it will be reduced when the quantity monitored has stopped increasing. Default: ‘min’
            </param>
            <param name="factor">Factor by which the learning rate will be reduced. new_lr = lr * factor.</param>
            <param name="patience">
            Number of epochs with no improvement after which learning rate will be reduced. For example, if patience = 2,
            then we will ignore the first 2 epochs with no improvement, and will only decrease the LR after the 3rd epoch if
            the loss still hasn’t improved then. Default: 10.</param>
            <param name="threshold">Threshold for measuring the new optimum, to only focus on significant changes. </param>
            <param name="threshold_mode">
            One of rel, abs. In rel mode, dynamic_threshold = best * ( 1 + threshold ) in ‘max’ mode or best * ( 1 - threshold ) in min mode. In abs mode, dynamic_threshold = best + threshold in max mode or best - threshold in min mode. Default: ‘rel’.
            </param>
            <param name="cooldown">Number of epochs to wait before resuming normal operation after lr has been reduced.</param>
            <param name="min_lr">A scalar or a list of scalars. A lower bound on the learning rate of all param groups or each group respectively. Default: 0.</param>
            <param name="eps">Minimal decay applied to lr. If the difference between new and old lr is smaller than eps, the update is ignored. Default: 1e-8.</param>
            <param name="verbose">Indicates whether to print a message to stdout for each update</param>
        </member>
        <member name="M:TorchSharp.torch.optim.NAdam(System.Collections.Generic.IEnumerable{TorchSharp.Modules.Parameter},System.Double,System.Double,System.Double,System.Double,System.Double,System.Double)">
             <summary>
             Implements the NAdam algorithm.
            
             For further details regarding the algorithm we refer to Incorporating Nesterov Momentum into Adam.
             https://openreview.net/forum?id=OM0jvwB8jIp57ZJjtNEZ
             </summary>
             <param name="named_parameters">Parameters to optimize. This optimizer requires the <b>named</b> parameters collection.</param>
             <param name="lr ">Learning rate</param>
             <param name="beta1">Coefficient used for computing running averages of gradient and its square (default: 0.9)</param>
             <param name="beta2">Coefficient used for computing running averages of gradient and its square (default: 0.999)</param>
             <param name="eps">Term added to the denominator to improve numerical stability, i.e. avoid division-by-zero (default: 1e-8)</param>
             <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
             <param name="momentum_decay">Momentum decay</param>
        </member>
        <member name="M:TorchSharp.torch.optim.NAdam(System.Collections.Generic.IEnumerable{System.ValueTuple{System.String,TorchSharp.Modules.Parameter}},System.Double,System.Double,System.Double,System.Double,System.Double,System.Double)">
             <summary>
             Implements the NAdam algorithm.
            
             For further details regarding the algorithm we refer to Incorporating Nesterov Momentum into Adam.
             https://openreview.net/forum?id=OM0jvwB8jIp57ZJjtNEZ
             </summary>
             <param name="named_parameters">Parameters to optimize. This optimizer requires the <b>named</b> parameters collection.</param>
             <param name="lr ">Learning rate</param>
             <param name="beta1">Coefficient used for computing running averages of gradient and its square (default: 0.9)</param>
             <param name="beta2">Coefficient used for computing running averages of gradient and its square (default: 0.999)</param>
             <param name="eps">Term added to the denominator to improve numerical stability, i.e. avoid division-by-zero (default: 1e-8)</param>
             <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
             <param name="momentum_decay">Momentum decay</param>
        </member>
        <member name="M:TorchSharp.torch.optim.NAdam(System.Collections.Generic.IEnumerable{TorchSharp.Modules.NAdam.ParamGroup},System.Double,System.Double,System.Double,System.Double,System.Double,System.Double)">
             <summary>
             Implements the NAdam algorithm.
            
             For further details regarding the algorithm we refer to Incorporating Nesterov Momentum into Adam.
             https://openreview.net/forum?id=OM0jvwB8jIp57ZJjtNEZ
             </summary>
             <param name="parameters">Parameters to optimize. This optimizer requires the <b>named</b> parameters collection.</param>
             <param name="lr ">Learning rate</param>
             <param name="beta1">Coefficient used for computing running averages of gradient and its square (default: 0.9)</param>
             <param name="beta2">Coefficient used for computing running averages of gradient and its square (default: 0.999)</param>
             <param name="eps">Term added to the denominator to improve numerical stability, i.e. avoid division-by-zero (default: 1e-8)</param>
             <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
             <param name="momentum_decay">Momentum decay</param>
        </member>
        <member name="T:TorchSharp.torch.optim.Optimizer">
            <summary>
            Base class for all optimizers.
            </summary>
        </member>
        <member name="T:TorchSharp.torch.optim.Optimizer.HType">
            <summary>
            Class wrapping PyTorch's optimzer object reference.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.optim.Optimizer.#ctor(System.IntPtr)">
            <summary>
            Constructor used for optimizers implemented in native code.
            </summary>
            <param name="handle"></param>
        </member>
        <member name="M:TorchSharp.torch.optim.Optimizer.Dispose">
            <summary>
              Releases the storage.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.optim.Optimizer.Dispose(System.Boolean)">
            <summary>
              Implements the .NET Dispose pattern.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.optim.Optimizer.zero_grad">
            <summary>
            Sets the gradients of all parameters to zero.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.optim.Optimizer.add_param_group(TorchSharp.Modules.ParamGroup)">
            <summary>
            Add a param group to the Optimizer s param_groups.
            </summary>
            <param name="param_group"></param>
            <remarks>This can be useful when fine tuning a pre-trained network as frozen layers can be made trainable and added to the Optimizer as training progresses.</remarks>
        </member>
        <member name="M:TorchSharp.torch.optim.Optimizer.step(System.Func{TorchSharp.torch.Tensor})">
            <summary>
            Performs a single optimization step (parameter update).
            </summary>
            <param name="closure">A closure that reevaluates the model and returns the loss. Optional for most optimizers.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.optim.Optimizer.parameters">
            <summary>
            Get the parameters that the optimizer is handling.
            </summary>
        </member>
        <member name="T:TorchSharp.torch.optim.ILearningRateController">
            <summary>
            This interfce is used by learning rate schedulers to access and control
            the rates used by optimizers.
            </summary>
        </member>
        <member name="P:TorchSharp.torch.optim.ILearningRateController.LearningRate">
            <summary>
            The current LR
            </summary>
        </member>
        <member name="P:TorchSharp.torch.optim.ILearningRateController.InitialLearningRate">
            <summary>
            The initial LR
            </summary>
        </member>
        <member name="T:TorchSharp.torch.optim.IMomentum">
            <summary>
            Indicates optimizers with support for momentum, which some LR schedulers require.
            </summary>
        </member>
        <member name="T:TorchSharp.torch.optim.IBetas">
            <summary>
            Indicates optimizers with support for betas instead of momentum.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.optim.RAdam(System.Collections.Generic.IEnumerable{TorchSharp.Modules.Parameter},System.Double,System.Double,System.Double,System.Double,System.Double)">
             <summary>
             Implements the RAdam algorithm.
            
             For further details regarding the algorithm we refer to 'On the variance of the adaptive learning rate and beyond.'
             https://arxiv.org/abs/1908.03265
             </summary>
             <param name="parameters">Parameters to optimize.</param>
             <param name="lr ">Learning rate</param>
             <param name="beta1">Coefficient used for computing running averages of gradient and its square (default: 0.9)</param>
             <param name="beta2">Coefficient used for computing running averages of gradient and its square (default: 0.999)</param>
             <param name="eps">Term added to the denominator to improve numerical stability, i.e. avoid division-by-zero (default: 1e-8)</param>
             <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
        </member>
        <member name="M:TorchSharp.torch.optim.RAdam(System.Collections.Generic.IEnumerable{System.ValueTuple{System.String,TorchSharp.Modules.Parameter}},System.Double,System.Double,System.Double,System.Double,System.Double)">
             <summary>
             Implements the RAdam algorithm.
            
             For further details regarding the algorithm we refer to 'On the variance of the adaptive learning rate and beyond.'
             https://arxiv.org/abs/1908.03265
             </summary>
             <param name="parameters">Parameters to optimize.</param>
             <param name="lr ">Learning rate</param>
             <param name="beta1">Coefficient used for computing running averages of gradient and its square (default: 0.9)</param>
             <param name="beta2">Coefficient used for computing running averages of gradient and its square (default: 0.999)</param>
             <param name="eps">Term added to the denominator to improve numerical stability, i.e. avoid division-by-zero (default: 1e-8)</param>
             <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
        </member>
        <member name="M:TorchSharp.torch.optim.RAdam(System.Collections.Generic.IEnumerable{TorchSharp.Modules.RAdam.ParamGroup},System.Double,System.Double,System.Double,System.Double,System.Double)">
             <summary>
             Implements the RAdam algorithm.
            
             For further details regarding the algorithm we refer to 'On the variance of the adaptive learning rate and beyond.'
             https://arxiv.org/abs/1908.03265
             </summary>
             <param name="parameters">Parameters to optimize.</param>
             <param name="lr ">Learning rate</param>
             <param name="beta1">Coefficient used for computing running averages of gradient and its square (default: 0.9)</param>
             <param name="beta2">Coefficient used for computing running averages of gradient and its square (default: 0.999)</param>
             <param name="eps">Term added to the denominator to improve numerical stability, i.e. avoid division-by-zero (default: 1e-8)</param>
             <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
        </member>
        <member name="M:TorchSharp.torch.optim.RMSProp(System.Collections.Generic.IEnumerable{TorchSharp.Modules.Parameter},System.Double,System.Double,System.Double,System.Double,System.Double,System.Boolean,System.Boolean)">
             <summary>
             Implements the RMSprop algorithm.
            
             Proposed by G.Hinton in his course.
             https://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf
             </summary>
             <param name="parameters">Parameters to optimize</param>
             <param name="lr">Learning rate (default: 1e-2)</param>
             <param name="eps">Term added to the denominator to improve numerical stability (default: 1e-8)</param>
             <param name="alpha">Smoothing constant (default: 0.99)</param>
             <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
             <param name="momentum">Momentum factor (default: 0)</param>
             <param name="centered">if true, compute the centered RMSProp, the gradient is normalized by an estimation of its variance</param>
             <param name="maximize">Maximize the params based on the objective, instead of minimizing.</param>
        </member>
        <member name="M:TorchSharp.torch.optim.RMSProp(System.Collections.Generic.IEnumerable{System.ValueTuple{System.String,TorchSharp.Modules.Parameter}},System.Double,System.Double,System.Double,System.Double,System.Double,System.Boolean,System.Boolean)">
             <summary>
             Implements the RMSprop algorithm.
            
             Proposed by G.Hinton in his course.
             https://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf
             </summary>
             <param name="parameters">Parameters to optimize</param>
             <param name="lr">Learning rate (default: 1e-2)</param>
             <param name="eps">Term added to the denominator to improve numerical stability (default: 1e-8)</param>
             <param name="alpha">Smoothing constant (default: 0.99)</param>
             <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
             <param name="momentum">Momentum factor (default: 0)</param>
             <param name="centered">if true, compute the centered RMSProp, the gradient is normalized by an estimation of its variance</param>
             <param name="maximize">Maximize the params based on the objective, instead of minimizing.</param>
        </member>
        <member name="M:TorchSharp.torch.optim.RMSProp(System.Collections.Generic.IEnumerable{TorchSharp.Modules.RMSProp.ParamGroup},System.Double,System.Double,System.Double,System.Double,System.Double,System.Boolean,System.Boolean)">
             <summary>
             Implements the RMSprop algorithm.
            
             Proposed by G.Hinton in his course.
             https://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf
             </summary>
             <param name="parameters">Parameters to optimize</param>
             <param name="lr">Learning rate (default: 1e-2)</param>
             <param name="eps">Term added to the denominator to improve numerical stability (default: 1e-8)</param>
             <param name="alpha">Smoothing constant (default: 0.99)</param>
             <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
             <param name="momentum">Momentum factor (default: 0)</param>
             <param name="centered">if true, compute the centered RMSProp, the gradient is normalized by an estimation of its variance</param>
             <param name="maximize">Maximize the params based on the objective, instead of minimizing.</param>
        </member>
        <member name="M:TorchSharp.torch.optim.Rprop(System.Collections.Generic.IEnumerable{TorchSharp.Modules.Parameter},System.Double,System.Double,System.Double,System.Double,System.Double,System.Boolean)">
             <summary>
             Implements the the resilient backpropagation algorithm.
            
             A Direct Adaptive Method for Faster Backpropagation Learning: The RPROP Algorithm
             http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.21.1417
             </summary>
             <param name="parameters">Parameters to optimize. This optimizer requires the <b>named</b> parameters collection.</param>
             <param name="lr ">Learning rate</param>
             <param name="etaminus">Multiplicative increase factor.</param>
             <param name="etaplus">Multiplicative decrease factor.</param>
             <param name="min_step">Minimum allowed step size.</param>
             <param name="max_step">Maximum allowed step size.</param>
             <param name="maximize">Maximize the params based on the objective, instead of minimizing.</param>
        </member>
        <member name="M:TorchSharp.torch.optim.Rprop(System.Collections.Generic.IEnumerable{System.ValueTuple{System.String,TorchSharp.Modules.Parameter}},System.Double,System.Double,System.Double,System.Double,System.Double,System.Boolean)">
             <summary>
             Implements the the resilient backpropagation algorithm.
            
             A Direct Adaptive Method for Faster Backpropagation Learning: The RPROP Algorithm
             http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.21.1417
             </summary>
             <param name="parameters">Parameters to optimize. This optimizer requires the <b>named</b> parameters collection.</param>
             <param name="lr ">Learning rate</param>
             <param name="etaminus">Multiplicative increase factor.</param>
             <param name="etaplus">Multiplicative decrease factor.</param>
             <param name="min_step">Minimum allowed step size.</param>
             <param name="max_step">Maximum allowed step size.</param>
             <param name="maximize">Maximize the params based on the objective, instead of minimizing.</param>
        </member>
        <member name="M:TorchSharp.torch.optim.Rprop(System.Collections.Generic.IEnumerable{TorchSharp.Modules.Rprop.ParamGroup},System.Double,System.Double,System.Double,System.Double,System.Double,System.Boolean)">
             <summary>
             Implements the the resilient backpropagation algorithm.
            
             A Direct Adaptive Method for Faster Backpropagation Learning: The RPROP Algorithm
             http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.21.1417
             </summary>
             <param name="parameters">Parameters to optimize. This optimizer requires the <b>named</b> parameters collection.</param>
             <param name="lr ">Learning rate</param>
             <param name="etaminus">Multiplicative increase factor.</param>
             <param name="etaplus">Multiplicative decrease factor.</param>
             <param name="min_step">Minimum allowed step size.</param>
             <param name="max_step">Maximum allowed step size.</param>
             <param name="maximize">Maximize the params based on the objective, instead of minimizing.</param>
        </member>
        <member name="M:TorchSharp.torch.optim.SGD(System.Collections.Generic.IEnumerable{TorchSharp.Modules.Parameter},System.Double,System.Double,System.Double,System.Double,System.Boolean,System.Boolean)">
             <summary>
             Implements the stochastic gradient descent (optionally with momentum).
            
             The use of momentum is covered in:
             http://www.cs.toronto.edu/%7Ehinton/absps/momentum.pdf
             </summary>
             <param name="parameters">Parameters to optimize. This optimizer requires the <b>named</b> parameters collection.</param>
             <param name="learningRate">Learning rate</param>
             <param name="momentum">Momentum factor (default: 0)</param>
             <param name="dampening">Dampening for momentum (default: 0)</param>
             <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
             <param name="nesterov">Enables Nesterov momentum (default: False)</param>
             <param name="maximize"></param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.optim.SGD(System.Collections.Generic.IEnumerable{System.ValueTuple{System.String,TorchSharp.Modules.Parameter}},System.Double,System.Double,System.Double,System.Double,System.Boolean,System.Boolean)">
             <summary>
             Implements the stochastic gradient descent (optionally with momentum).
            
             The use of momentum is covered in:
             http://www.cs.toronto.edu/%7Ehinton/absps/momentum.pdf
             </summary>
             <param name="parameters">Parameters to optimize. This optimizer requires the <b>named</b> parameters collection.</param>
             <param name="learningRate">Learning rate</param>
             <param name="momentum">Momentum factor (default: 0)</param>
             <param name="dampening">Dampening for momentum (default: 0)</param>
             <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
             <param name="nesterov">Enables Nesterov momentum (default: False)</param>
             <param name="maximize"></param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.optim.SGD(System.Collections.Generic.IEnumerable{TorchSharp.Modules.SGD.ParamGroup},System.Double,System.Double,System.Double,System.Double,System.Boolean,System.Boolean)">
             <summary>
             Implements the stochastic gradient descent (optionally with momentum).
            
             The use of momentum is covered in:
             http://www.cs.toronto.edu/%7Ehinton/absps/momentum.pdf
             </summary>
             <param name="parameters">Parameters to optimize. This optimizer requires the <b>named</b> parameters collection.</param>
             <param name="learningRate">Learning rate</param>
             <param name="momentum">Momentum factor (default: 0)</param>
             <param name="dampening">Dampening for momentum (default: 0)</param>
             <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
             <param name="nesterov">Enables Nesterov momentum (default: False)</param>
             <param name="maximize"></param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.special.airy_ai(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Airy function.
            </summary>
            <param name="input">Input tensor</param>
            <param name="out">Optional output tensor, will be modified if present.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.special.bessel_j0(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Bessel function of the first kind of order 0.
            </summary>
            <param name="input">The input tensor</param>
            <param name="out">An optional output tensor, which will be modified if present.</param>
        </member>
        <member name="M:TorchSharp.torch.special.bessel_j1(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Bessel function of the first kind of order 1.
            </summary>
            <param name="input">The input tensor</param>
            <param name="out">An optional output tensor, which will be modified if present.</param>
        </member>
        <member name="M:TorchSharp.torch.special.bessel_y0(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Bessel function of the second kind of order 1.
            </summary>
            <param name="input">The input tensor</param>
            <param name="out">An optional output tensor, which will be modified if present.</param>
        </member>
        <member name="M:TorchSharp.torch.special.bessel_y1(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Bessel function of the second kind of order 1.
            </summary>
            <param name="input">The input tensor</param>
            <param name="out">An optional output tensor, which will be modified if present.</param>
        </member>
        <member name="M:TorchSharp.torch.special.modified_bessel_i0(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Modified Bessel function of the first kind of order 0.
            </summary>
            <param name="input">The input tensor</param>
            <param name="out">An optional output tensor, which will be modified if present.</param>
        </member>
        <member name="M:TorchSharp.torch.special.modified_bessel_i1(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Modified Bessel function of the first kind of order 1.
            </summary>
            <param name="input">The input tensor</param>
            <param name="out">An optional output tensor, which will be modified if present.</param>
        </member>
        <member name="M:TorchSharp.torch.special.modified_bessel_k0(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Modified Bessel function of the second kind of order 1.
            </summary>
            <param name="input">The input tensor</param>
            <param name="out">An optional output tensor, which will be modified if present.</param>
        </member>
        <member name="M:TorchSharp.torch.special.modified_bessel_k1(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Modified Bessel function of the second kind of order 1.
            </summary>
            <param name="input">The input tensor</param>
            <param name="out">An optional output tensor, which will be modified if present.</param>
        </member>
        <member name="M:TorchSharp.torch.special.scaled_modified_bessel_k0(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Scaled modified Bessel function of the second kind of order 0
            </summary>
            <param name="input">The input tensor</param>
            <param name="out">An optional output tensor, which will be modified if present.</param>
        </member>
        <member name="M:TorchSharp.torch.special.scaled_modified_bessel_k1(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Scaled modified Bessel function of the second kind of order 1
            </summary>
            <param name="input">The input tensor</param>
            <param name="out">An optional output tensor, which will be modified if present.</param>
        </member>
        <member name="M:TorchSharp.torch.special.spherical_bessel_j0(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Bessel function of the first kind of order 0.
            </summary>
            <param name="input">The input tensor</param>
            <param name="out">An optional output tensor, which will be modified if present.</param>
        </member>
        <member name="M:TorchSharp.torch.special.chebyshev_polynomial_t(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
             <summary>
             Computes the Chebyshev polynomial of the first kind.
            
             See: https://en.wikipedia.org/wiki/Chebyshev_polynomials
             </summary>
             <param name="x">The input tensor.</param>
             <param name="n">n</param>
             <param name="out">An optional output tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.special.chebyshev_polynomial_u(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
             <summary>
             Computes the Chebyshev polynomial of the second kind.
            
             See: https://en.wikipedia.org/wiki/Chebyshev_polynomials
             </summary>
             <param name="x">The input tensor.</param>
             <param name="n">n</param>
             <param name="out">An optional output tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.special.chebyshev_polynomial_v(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
             <summary>
             Computes the Chebyshev polynomial of the third kind.
            
             See: https://en.wikipedia.org/wiki/Chebyshev_polynomials
             </summary>
             <param name="x">The input tensor.</param>
             <param name="n">n</param>
             <param name="out">An optional output tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.special.chebyshev_polynomial_w(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
             <summary>
             Computes the Chebyshev polynomial of the fourth kind.
            
             See: https://en.wikipedia.org/wiki/Chebyshev_polynomials
             </summary>
             <param name="x">The input tensor.</param>
             <param name="n">n</param>
             <param name="out">An optional output tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.special.shifted_chebyshev_polynomial_t(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
             <summary>
             Computes the Chebyshev polynomial of the first kind.
            
             See: https://en.wikipedia.org/wiki/Chebyshev_polynomials
             </summary>
             <param name="x">The input tensor.</param>
             <param name="n">n</param>
             <param name="out">An optional output tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.special.shifted_chebyshev_polynomial_u(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
             <summary>
             Computes the Chebyshev polynomial of the second kind.
            
             See: https://en.wikipedia.org/wiki/Chebyshev_polynomials
             </summary>
             <param name="x">The input tensor.</param>
             <param name="n">n</param>
             <param name="out">An optional output tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.special.shifted_chebyshev_polynomial_v(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
             <summary>
             Computes the Chebyshev polynomial of the third kind.
            
             See: https://en.wikipedia.org/wiki/Chebyshev_polynomials
             </summary>
             <param name="x">The input tensor.</param>
             <param name="n">n</param>
             <param name="out">An optional output tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.special.shifted_chebyshev_polynomial_w(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
             <summary>
             Computes the Chebyshev polynomial of the fourth kind.
            
             See: https://en.wikipedia.org/wiki/Chebyshev_polynomials
             </summary>
             <param name="x">The input tensor.</param>
             <param name="n">n</param>
             <param name="out">An optional output tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.special.hermite_polynomial_h(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
             <summary>
             Probabilist's Hermite polynomials.
            
             See: https://en.wikipedia.org/wiki/Hermite_polynomials
             </summary>
             <param name="x">The input tensor.</param>
             <param name="n">n</param>
             <param name="out">An optional output tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.special.hermite_polynomial_he(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
             <summary>
             Physicists's Hermite polynomials.
            
             See: https://en.wikipedia.org/wiki/Hermite_polynomials
             </summary>
             <param name="x">The input tensor.</param>
             <param name="n">n</param>
             <param name="out">An optional output tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.special.laguerre_polynomial_l(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
             <summary>
             Laguerre polynomials
            
             See: https://en.wikipedia.org/wiki/Laguerre_polynomials
             </summary>
             <param name="x">The input tensor.</param>
             <param name="n">n</param>
             <param name="out">An optional output tensor.</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.special.legendre_polynomial_p(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
             <summary>
             Legendre polynomials
            
             https://en.wikipedia.org/wiki/Legendre_polynomials
             </summary>
             <param name="x">The input tensor.</param>
             <param name="n">n</param>
             <param name="out">An optional output tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.special.entr(TorchSharp.torch.Tensor)">
            <summary>
            Computes the entropy on input, elementwise.
            </summary>
            <param name="input">The input tensor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.special.erf(TorchSharp.torch.Tensor)">
            <summary>
            Computes the error function of input.
            </summary>
            <param name="input">The input tensor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.special.erfc(TorchSharp.torch.Tensor)">
            <summary>
            Computes the complementary error function of input.
            </summary>
            <param name="input">The input tensor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.special.erfcx(TorchSharp.torch.Tensor)">
            <summary>
            Computes the scaled complementary error function of input.
            </summary>
            <param name="input">The input tensor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.special.erfinv(TorchSharp.torch.Tensor)">
            <summary>
            Computes the inverse error function of input.
            </summary>
            <param name="input">The input tensor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.special.expit(TorchSharp.torch.Tensor)">
            <summary>
            Computes the expit (also known as the logistic sigmoid function) of the elements of input.
            </summary>
            <param name="input">The input tensor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.special.expm1(TorchSharp.torch.Tensor)">
            <summary>
            Computes the exponential of the elements minus 1 of input.
            </summary>
            <param name="input">The input tensor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.special.exp2(TorchSharp.torch.Tensor)">
            <summary>
            Computes the base two exponential function of input.
            </summary>
            <param name="input">The input tensor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.special.gammaln(TorchSharp.torch.Tensor)">
            <summary>
            Computes the natural logarithm of the absolute value of the gamma function on input.
            </summary>
            <param name="input">The input tensor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.special.gammainc(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Computes the regularized lower incomplete gamma function.
            </summary>
            <param name="input">The first non-negative input tensor</param>
            <param name="other">The second non-negative input tensor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.special.gammaincc(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Computes the regularized upper incomplete gamma function.
            </summary>
            <param name="input">The first non-negative input tensor</param>
            <param name="other">The second non-negative input tensor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.special.polygamma(System.Int64,TorchSharp.torch.Tensor)">
            <summary>
            Computes the n-th derivative of the digamma function on input.
            </summary>
            <param name="n">The order of the polygamma function</param>
            <param name="input">The second non-negative input tensor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.special.multigammaln(TorchSharp.torch.Tensor,System.Int64)">
            <summary>
            Computes the multivariate log-gamma function with dimension pp element-wise.
            </summary>
            <param name="input">The tensor to compute the multivariate log-gamma function</param>
            <param name="p">The number of dimensions</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.special.digamma(TorchSharp.torch.Tensor)">
            <summary>
            Computes the logarithmic derivative of the gamma function on input.
            </summary>
            <param name="input">The second non-negative input tensor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.special.psi(TorchSharp.torch.Tensor)">
            <summary>
            Computes the logarithmic derivative of the gamma function on input.
            </summary>
            <param name="input">The second non-negative input tensor</param>
        </member>
        <member name="M:TorchSharp.torch.special.i0(TorchSharp.torch.Tensor)">
            <summary>
            Computes the zeroth order modified Bessel function of the first kind for each element of input.
            </summary>
            <param name="input">The input tensor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.special.i0e(TorchSharp.torch.Tensor)">
            <summary>
            Computes the exponentially scaled zeroth order modified Bessel function of the first kind (as defined below) for each element of input.
            </summary>
            <param name="input">The input tensor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.special.i1(TorchSharp.torch.Tensor)">
            <summary>
            Computes the first order modified Bessel function of the first kind for each element of input.
            </summary>
            <param name="input">The input tensor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.special.i1e(TorchSharp.torch.Tensor)">
            <summary>
            Computes the exponentially scaled first order modified Bessel function of the first kind (as defined below) for each element of input.
            </summary>
            <param name="input">The input tensor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.special.logit(TorchSharp.torch.Tensor)">
            <summary>
            Returns a new tensor with the logit of the elements of input.
            </summary>
            <param name="input">The input tensor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.special.log_softmax(TorchSharp.torch.Tensor,System.Int64,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Returns a new tensor with the logit of the elements of input.
            </summary>
            <param name="input">The input tensor</param>
            <param name="dim">A dimension along which log_softmax will be computed.</param>
            <param name="dtype">The desired data type of returned tensor.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.special.ndtr(TorchSharp.torch.Tensor)">
            <summary>
            Computes the area under the standard Gaussian probability density function, integrated from minus infinity to input, elementwise.
            </summary>
            <param name="input">The input tensor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.special.ndtri(TorchSharp.torch.Tensor)">
            <summary>
            Computes the argument, x, for which the area under the Gaussian probability density function (integrated from minus infinity to x) is equal to input, elementwise.
            </summary>
            <param name="input">The input tensor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.special.sinc(TorchSharp.torch.Tensor)">
            <summary>
            Computes the normalized sinc of input.
            </summary>
            <param name="input">The input tensor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.special.sigmoid(TorchSharp.torch.Tensor)">
            <summary>
            Alias for torch.special.expit()
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.special.sigmoid_(TorchSharp.torch.Tensor)">
            <summary>
            Alias for torch.special.expit()
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.special.softmax(TorchSharp.torch.Tensor,System.Int64,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Computes the softmax function for the input tensor.
            </summary>
            <param name="input">The input tensor</param>
            <param name="dim">A dimension along which softmax will be computed.</param>
            <param name="dtype">The desired data type of returned tensor.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.special.xlog1py(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Computes input * log1p(other). Similar to SciPy’s scipy.special.xlog1py.
            </summary>
            <param name="input">The input tensor</param>
            <param name="other"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.special.zeta(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Computes the Hurwitz zeta function, elementwise.
            </summary>
            <param name="x">The input tensor corresponding to x</param>
            <param name="q">The input tensor corresponding to q</param>
            <remarks>The Riemann zeta function corresponds to the case when q = 1.</remarks>
        </member>
        <member name="M:TorchSharp.torch.empty(System.Int64[],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new tensor filled with empty
            </summary>
        </member>
        <member name="M:TorchSharp.torch.empty(System.ReadOnlySpan{System.Int64},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new tensor filled with empty
            </summary>
        </member>
        <member name="M:TorchSharp.torch.empty(System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new 1-D tensor filled with empty
            </summary>
        </member>
        <member name="M:TorchSharp.torch.empty(System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new 2-D tensor filled with empty
            </summary>
        </member>
        <member name="M:TorchSharp.torch.empty(System.Int64,System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new 3-D tensor filled with empty
            </summary>
        </member>
        <member name="M:TorchSharp.torch.empty(System.Int64,System.Int64,System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new 4-D tensor filled with empty
            </summary>
        </member>
        <member name="M:TorchSharp.torch.empty(System.Int32,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new 1-D tensor filled with empty
            </summary>
        </member>
        <member name="M:TorchSharp.torch.empty(System.Int32,System.Int32,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new 2-D tensor filled with empty
            </summary>
        </member>
        <member name="M:TorchSharp.torch.empty(System.Int32,System.Int32,System.Int32,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new 3-D tensor filled with empty
            </summary>
        </member>
        <member name="M:TorchSharp.torch.empty(System.Int32,System.Int32,System.Int32,System.Int32,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new 4-D tensor filled with empty
            </summary>
        </member>
        <member name="M:TorchSharp.torch.empty_like(TorchSharp.torch.Tensor,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Returns a tensor filled with uninitialized data, with the same size as input.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.empty_strided(System.Int64[],System.Int64[],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Returns a tensor filled with uninitialized data. The shape and strides of the tensor is defined by the variable argument size and stride respectively.
            </summary>
        </member>
        <member name="M:TorchSharp.torch._empty(System.ReadOnlySpan{System.Int64},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new tensor filled with empty
            </summary>
        </member>
        <member name="M:TorchSharp.torch.full(System.Int64[],TorchSharp.Scalar,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new tensor filled with a given value
            </summary>
        </member>
        <member name="M:TorchSharp.torch.full(System.ReadOnlySpan{System.Int64},TorchSharp.Scalar,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new tensor filled with a given value
            </summary>
        </member>
        <member name="M:TorchSharp.torch.full(System.Int64,TorchSharp.Scalar,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new 1-D tensor filled with given value
            </summary>
        </member>
        <member name="M:TorchSharp.torch.full(System.Int64,System.Int64,TorchSharp.Scalar,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new 2-D tensor filled with given value
            </summary>
        </member>
        <member name="M:TorchSharp.torch.full(System.Int64,System.Int64,System.Int64,TorchSharp.Scalar,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new 3-D tensor filled with given value
            </summary>
        </member>
        <member name="M:TorchSharp.torch.full(System.Int64,System.Int64,System.Int64,System.Int64,TorchSharp.Scalar,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new 4-D tensor filled with given value
            </summary>
        </member>
        <member name="M:TorchSharp.torch.full(System.Int32,TorchSharp.Scalar,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new 1-D tensor filled with given value
            </summary>
        </member>
        <member name="M:TorchSharp.torch.full(System.Int32,System.Int32,TorchSharp.Scalar,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new 2-D tensor filled with given value
            </summary>
        </member>
        <member name="M:TorchSharp.torch.full(System.Int32,System.Int32,System.Int32,TorchSharp.Scalar,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new 3-D tensor filled with given value
            </summary>
        </member>
        <member name="M:TorchSharp.torch.full(System.Int32,System.Int32,System.Int32,System.Int32,TorchSharp.Scalar,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new 4-D tensor filled with given value
            </summary>
        </member>
        <member name="M:TorchSharp.torch.full_like(TorchSharp.torch.Tensor,TorchSharp.Scalar,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Returns a tensor with the same size as input filled with 'value.'
            </summary>
        </member>
        <member name="M:TorchSharp.torch._full(System.ReadOnlySpan{System.Int64},TorchSharp.Scalar,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new tensor filled with a given value
            </summary>
        </member>
        <member name="M:TorchSharp.torch.ones(System.Int64[],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new tensor filled with ones
            </summary>
        </member>
        <member name="M:TorchSharp.torch.ones(System.ReadOnlySpan{System.Int64},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new tensor filled with ones
            </summary>
        </member>
        <member name="M:TorchSharp.torch.ones(System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new 1-D tensor filled with ones
            </summary>
        </member>
        <member name="M:TorchSharp.torch.ones(System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new 2-D tensor filled with ones
            </summary>
        </member>
        <member name="M:TorchSharp.torch.ones(System.Int64,System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new 3-D tensor filled with ones
            </summary>
        </member>
        <member name="M:TorchSharp.torch.ones(System.Int64,System.Int64,System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new 4-D tensor filled with ones
            </summary>
        </member>
        <member name="M:TorchSharp.torch.ones(System.Int32,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new 1-D tensor filled with ones
            </summary>
        </member>
        <member name="M:TorchSharp.torch.ones(System.Int32,System.Int32,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new 2-D tensor filled with ones
            </summary>
        </member>
        <member name="M:TorchSharp.torch.ones(System.Int32,System.Int32,System.Int32,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new 3-D tensor filled with ones
            </summary>
        </member>
        <member name="M:TorchSharp.torch.ones(System.Int32,System.Int32,System.Int32,System.Int32,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new 4-D tensor filled with ones
            </summary>
        </member>
        <member name="M:TorchSharp.torch.ones_like(TorchSharp.torch.Tensor,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Returns a tensor filled with the scalar value 1, with the same size as input.
            </summary>
        </member>
        <member name="M:TorchSharp.torch._ones(System.ReadOnlySpan{System.Int64},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new tensor filled with ones
            </summary>
        </member>
        <member name="M:TorchSharp.torch.randint(System.Int64,System.Int64,TorchSharp.torch.Size,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,TorchSharp.torch.Generator,System.String[])">
            <summary>
            Create a new tensor filled with random integer values taken from a uniform distribution in [low, high).
            </summary>
            <param name="low">Lowest integer to be drawn from the distribution.</param>
            <param name="high">One above the highest integer to be drawn from the distribution.</param>
            <param name="size">The shape of the output tensor.</param>
            <param name="dtype">The desired data type of the tensor.</param>
            <param name="device">The desired device of returned tensor.</param>
            <param name="requires_grad">If autograd should record operations on the returned tensor.</param>
            <param name="generator">An optional random number genertor object.</param>
            <param name="names">Names of the dimensions of the tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.randint(System.Int64,TorchSharp.torch.Size,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,TorchSharp.torch.Generator,System.String[])">
            <summary>
            Create a new tensor filled with random integer values taken from a uniform distribution in [0, high).
            </summary>
            <param name="high">One above the highest integer to be drawn from the distribution.</param>
            <param name="size">The shape of the output tensor.</param>
            <param name="dtype">The desired data type of the tensor.</param>
            <param name="device">The desired device of returned tensor.</param>
            <param name="requires_grad">If autograd should record operations on the returned tensor.</param>
            <param name="generator">An optional random number genertor object.</param>
            <param name="names">Names of the dimensions of the tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.randint(System.Int64,System.Int64[],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,TorchSharp.torch.Generator,System.String[])">
            <summary>
            Create a new tensor filled with random integer values taken from a uniform distribution in [0, high).
            </summary>
            <param name="high">One above the highest integer to be drawn from the distribution.</param>
            <param name="size">The shape of the output tensor.</param>
            <param name="dtype">The desired data type of the tensor.</param>
            <param name="device">The desired device of returned tensor.</param>
            <param name="requires_grad">If autograd should record operations on the returned tensor.</param>
            <param name="generator">An optional random number genertor object.</param>
            <param name="names">Names of the dimensions of the tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.randint(System.Int64,System.Int64,System.Int64[],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,TorchSharp.torch.Generator,System.String[])">
            <summary>
            Create a new tensor filled with random integer values taken from a uniform distribution in [low, high).
            </summary>
            <param name="low">Lowest integer to be drawn from the distribution.</param>
            <param name="high">One above the highest integer to be drawn from the distribution.</param>
            <param name="size">The shape of the output tensor.</param>
            <param name="dtype">The desired data type of the tensor.</param>
            <param name="device">The desired device of returned tensor.</param>
            <param name="requires_grad">If autograd should record operations on the returned tensor.</param>
            <param name="generator">An optional random number genertor object.</param>
            <param name="names">Names of the dimensions of the tensor.</param>
            <remarks>
            The array-size and 'int' overloads are necessary for F#, which doesn't implicitly convert types.
            Once implicit conversion support is broadly available, some of these overloads can be removed.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.randint(System.Int32,System.Int32,System.Int32[],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,TorchSharp.torch.Generator,System.String[])">
            <summary>
            Create a new tensor filled with random integer values taken from a uniform distribution in [low, high).
            </summary>
            <param name="low">Lowest integer to be drawn from the distribution.</param>
            <param name="high">One above the highest integer to be drawn from the distribution.</param>
            <param name="size">The shape of the output tensor.</param>
            <param name="dtype">The desired data type of the tensor.</param>
            <param name="device">The desired device of returned tensor.</param>
            <param name="requires_grad">If autograd should record operations on the returned tensor.</param>
            <param name="generator">An optional random number genertor object.</param>
            <param name="names">Names of the dimensions of the tensor.</param>
            <remarks>
            The array-size and 'int' overloads are necessary for F#, which doesn't implicitly convert types.
            Once implicit conversion support is broadly available, some of these overloads can be removed.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.randint(System.Int32,System.Int32[],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,TorchSharp.torch.Generator,System.String[])">
            <summary>
            Create a new tensor filled with random integer values taken from a uniform distribution in [0, high).
            </summary>
            <param name="high">One above the highest integer to be drawn from the distribution.</param>
            <param name="size">The shape of the output tensor.</param>
            <param name="dtype">The desired data type of the tensor.</param>
            <param name="device">The desired device of returned tensor.</param>
            <param name="requires_grad">If autograd should record operations on the returned tensor.</param>
            <param name="generator">An optional random number genertor object.</param>
            <param name="names">Names of the dimensions of the tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.randint_bool(TorchSharp.torch.Generator)">
            <summary>
            Create a random Boolean value.
            </summary>
            <param name="generator">An optional random number genertor object.</param>
            <remarks>This method does not exist in PyTorch, but is useful for getting a scalar from a torch RNG.</remarks>
        </member>
        <member name="M:TorchSharp.torch.randint_int(System.Int32,TorchSharp.torch.Generator)">
            <summary>
            Create a random integer value taken from a uniform distribution in [0, high).
            </summary>
            <param name="high">One above the highest integer to be drawn from the distribution.</param>
            <param name="generator">An optional random number genertor object.</param>
            <remarks>This method does not exist in PyTorch, but is useful for getting a scalar from a torch RNG.</remarks>
        </member>
        <member name="M:TorchSharp.torch.randint_int(System.Int32,System.Int32,TorchSharp.torch.Generator)">
            <summary>
            Create a random integer value taken from a uniform distribution in [low, high).
            </summary>
            <param name="low">Lowest integer to be drawn from the distribution.</param>
            <param name="high">One above the highest integer to be drawn from the distribution.</param>
            <param name="generator">An optional random number genertor object.</param>
            <remarks>This method does not exist in PyTorch, but is useful for getting a scalar from a torch RNG.</remarks>
        </member>
        <member name="M:TorchSharp.torch.randint_long(System.Int64,TorchSharp.torch.Generator)">
            <summary>
            Create a random integer value taken from a uniform distribution in [0, high).
            </summary>
            <param name="high">One above the highest integer to be drawn from the distribution.</param>
            <param name="generator">An optional random number genertor object.</param>
            <remarks>This method does not exist in PyTorch, but is useful for getting a scalar from a torch RNG.</remarks>
        </member>
        <member name="M:TorchSharp.torch.randint_long(System.Int64,System.Int64,TorchSharp.torch.Generator)">
            <summary>
            Create a random integer value taken from a uniform distribution in [low, high).
            </summary>
            <param name="low">Lowest integer to be drawn from the distribution.</param>
            <param name="high">One above the highest integer to be drawn from the distribution.</param>
            <param name="generator">An optional random number genertor object.</param>
            <remarks>This method does not exist in PyTorch, but is useful for getting a scalar from a torch RNG.</remarks>
        </member>
        <member name="M:TorchSharp.torch.randint_c32(System.IntPtr,System.Int64,System.Int64,System.Int64[],TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new 32-bit complex tensor filled with random integer values taken from a uniform distribution in [0, high).
            </summary>
            <param name="genHandle"></param>
            <param name="low">Lowest integer to be drawn from the distribution.</param>
            <param name="high">One above the highest integer to be drawn from the distribution.</param>
            <param name="size">The shape of the output tensor.</param>
            <param name="device">The desired device of returned tensor.</param>
            <param name="requires_grad">If autograd should record operations on the returned tensor.</param>
            <param name="names">Names of the dimensions of the tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.randint_c64(System.IntPtr,System.Int64,System.Int64,System.Int64[],TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new 64-bit complex tensor filled with random integer values taken from a uniform distribution in [0, max).
            </summary>
            <param name="genHandle"></param>
            <param name="low">Lowest integer to be drawn from the distribution.</param>
            <param name="high">One above the highest integer to be drawn from the distribution.</param>
            <param name="size">The shape of the output tensor.</param>
            <param name="device">The desired device of returned tensor.</param>
            <param name="requires_grad">If autograd should record operations on the returned tensor.</param>
            <param name="names">Names of the dimensions of the tensor.</param>
        </member>
        <member name="M:TorchSharp.torch._rand(System.ReadOnlySpan{System.Int64},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,TorchSharp.torch.Generator,System.String[])">
            <summary>
            Create a new tensor filled with random values taken from a uniform distribution in [0, 1).
            </summary>
        </member>
        <member name="M:TorchSharp.torch.rand(System.Int64[],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,TorchSharp.torch.Generator,System.String[])">
            <summary>
            Create a new tensor filled with random values taken from a uniform distribution in [0, 1).
            </summary>
        </member>
        <member name="M:TorchSharp.torch.rand(System.ReadOnlySpan{System.Int64},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,TorchSharp.torch.Generator,System.String[])">
            <summary>
            Create a new tensor filled with random values taken from a uniform distribution in [0, 1).
            </summary>
        </member>
        <member name="M:TorchSharp.torch.rand(System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,TorchSharp.torch.Generator,System.String[])">
            <summary>
            Create a new 1-D tensor filled with random values taken from a uniform distribution in [0, 1).
            </summary>
        </member>
        <member name="M:TorchSharp.torch.rand(System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,TorchSharp.torch.Generator,System.String[])">
            <summary>
            Create a new 2-D tensor filled with random values taken from a uniform distribution in [0, 1).
            </summary>
        </member>
        <member name="M:TorchSharp.torch.rand(System.Int64,System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,TorchSharp.torch.Generator,System.String[])">
            <summary>
            Create a new 3-D tensor filled with random values taken from a uniform distribution in [0, 1).
            </summary>
        </member>
        <member name="M:TorchSharp.torch.rand(System.Int64,System.Int64,System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,TorchSharp.torch.Generator,System.String[])">
            <summary>
            Create a new 4-D tensor filled with random values taken from a uniform distribution in [0, 1).
            </summary>
        </member>
        <member name="M:TorchSharp.torch.rand(System.Int32,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,TorchSharp.torch.Generator,System.String[])">
            <summary>
            Create a new 1-D tensor filled with random values taken from a uniform distribution in [0, 1).
            </summary>
        </member>
        <member name="M:TorchSharp.torch.rand(System.Int32,System.Int32,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,TorchSharp.torch.Generator,System.String[])">
            <summary>
            Create a new 2-D tensor filled with random values taken from a uniform distribution in [0, 1).
            </summary>
        </member>
        <member name="M:TorchSharp.torch.rand(System.Int32,System.Int32,System.Int32,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,TorchSharp.torch.Generator,System.String[])">
            <summary>
            Create a new 3-D tensor filled with random values taken from a uniform distribution in [0, 1).
            </summary>
        </member>
        <member name="M:TorchSharp.torch.rand(System.Int32,System.Int32,System.Int32,System.Int32,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,TorchSharp.torch.Generator,System.String[])">
            <summary>
            Create a new 4-D tensor filled with random values taken from a uniform distribution in [0, 1).
            </summary>
        </member>
        <member name="M:TorchSharp.torch.rand_float(TorchSharp.torch.Generator)">
            <summary>
            Create a random floating-point value taken from a uniform distribution in [0, 1).
            </summary>
            <param name="generator">An optional random number genertor object.</param>
            <remarks>This method does not exist in PyTorch, but is useful for getting a scalar from a torch RNG.</remarks>
        </member>
        <member name="M:TorchSharp.torch._randn(System.ReadOnlySpan{System.Int64},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,TorchSharp.torch.Generator,System.String[])">
            <summary>
            Create a new tensor filled with random values taken from a normal distribution with mean 0 and variance 1.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.randn(System.Int64[],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,TorchSharp.torch.Generator,System.String[])">
            <summary>
            Create a new tensor filled with random values taken from a normal distribution with mean 0 and variance 1.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.randn(System.ReadOnlySpan{System.Int64},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,TorchSharp.torch.Generator,System.String[])">
            <summary>
            Create a new tensor filled with random values taken from a normal distribution with mean 0 and variance 1.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.randn(System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,TorchSharp.torch.Generator,System.String[])">
            <summary>
            Create a new 1-D tensor filled with random values taken from a normal distribution with mean 0 and variance 1.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.randn(System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,TorchSharp.torch.Generator,System.String[])">
            <summary>
            Create a new 2-D tensor filled with random values taken from a normal distribution with mean 0 and variance 1.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.randn(System.Int64,System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,TorchSharp.torch.Generator,System.String[])">
            <summary>
            Create a new 3-D tensor filled with random values taken from a normal distribution with mean 0 and variance 1.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.randn(System.Int64,System.Int64,System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,TorchSharp.torch.Generator,System.String[])">
            <summary>
            Create a new 4-D tensor filled with random values taken from a normal distribution with mean 0 and variance 1.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.randn(System.Int32,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,TorchSharp.torch.Generator,System.String[])">
            <summary>
            Create a new 1-D tensor filled with random values taken from a normal distribution with mean 0 and variance 1.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.randn(System.Int32,System.Int32,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,TorchSharp.torch.Generator,System.String[])">
            <summary>
            Create a new 2-D tensor filled with random values taken from a normal distribution with mean 0 and variance 1.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.randn(System.Int32,System.Int32,System.Int32,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,TorchSharp.torch.Generator,System.String[])">
            <summary>
            Create a new 3-D tensor filled with random values taken from a normal distribution with mean 0 and variance 1.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.randn(System.Int32,System.Int32,System.Int32,System.Int32,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,TorchSharp.torch.Generator,System.String[])">
            <summary>
            Create a new 4-D tensor filled with random values taken from a normal distribution with mean 0 and variance 1.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.randn_float(TorchSharp.torch.Generator)">
            <summary>
            Create a random floating-point value taken from a normal distribution with mean 0 and variance 1.
            </summary>
            <param name="generator">An optional random number genertor object.</param>
            <remarks>This method does not exist in PyTorch, but is useful for getting a scalar from a torch RNG.</remarks>
        </member>
        <member name="M:TorchSharp.torch.arange(TorchSharp.Scalar,TorchSharp.Scalar,TorchSharp.Scalar,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Creates 1-D tensor of size [(stop - start) / step] with values from interval [start, stop) and
            common difference step, starting from start
            </summary>
            <param name="start">The starting value for the set of points.</param>
            <param name="stop">The ending value for the set of points</param>
            <param name="step">The gap between each pair of adjacent points.</param>
            <param name="dtype">the desired data type of returned tensor.
            Default: if null, uses a global default (see torch.set_default_tensor_type()).
            If dtype is not given, infer the data type from the other input arguments.
            If any of start, end, or stop are floating-point, the dtype is inferred to be the default dtype, see get_default_dtype().
            Otherwise, the dtype is inferred to be torch.int64.</param>
            <param name="device"></param>
            <param name="requires_grad"> If autograd should record operations on the returned tensor. Default: false.</param>
        </member>
        <member name="M:TorchSharp.torch.arange(TorchSharp.Scalar,TorchSharp.Scalar,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Creates 1-D tensor of size [(stop - start) / step] with values from interval [start, stop) and
            common difference step, starting from start
            </summary>
        </member>
        <member name="M:TorchSharp.torch.arange(TorchSharp.Scalar,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Creates 1-D tensor of size [(stop - 0)] with values from interval [0, stop), starting from 0
            </summary>
        </member>
        <member name="M:TorchSharp.torch.eye(System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a 2-D tensor with ones on the diagonal and zeros elsewhere.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.normal(System.Double,System.Double,System.ReadOnlySpan{System.Int64},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,TorchSharp.torch.Generator,System.String[])">
            <summary>
            Similar to the function above, but the means and standard deviations are shared among all drawn elements. The resulting tensor has size given by size.
            </summary>
            <param name="mean">The mean for all distributions</param>
            <param name="std">The standard deviation for all distributions</param>
            <param name="size">A sequence of integers defining the shape of the output tensor.</param>
            <param name="dtype">The element type of the tensor to be created.</param>
            <param name="device">The device where the tensor should be located.</param>
            <param name="requires_grad">Whether the tensor should be tracking gradients.</param>
            <param name="generator">An optional random number generator</param>
            <param name="names">Names of the dimensions of the tensor.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch._tensor_generic(System.Array,System.ReadOnlySpan{System.Int64},System.SByte,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.Boolean,System.String[])">
            <summary>
            This private method handles most tensor creation, centrally.
            </summary>
            <param name="rawArray">An array of contiguous elements, to be used for creating the tensor.</param>
            <param name="dimensions">The dimensions of the tensor.</param>
            <param name="origType">The element type of the input array.</param>
            <param name="dtype">The element type of the tensor to be created.</param>
            <param name="device">The device where the tensor should be located.</param>
            <param name="requires_grad">Whether the tensor should be tracking gradients.</param>
            <param name="clone">Whether to clone the input array or use it as the backing storage for the tensor.</param>
            <param name="names">Names of the dimensions of the tensor.</param>
            <returns>A constructed tensor with elements of `dtype`</returns>
            <exception cref="T:System.ArgumentException"></exception>
        </member>
        <member name="M:TorchSharp.torch.from_array(System.Array,TorchSharp.torch.Device)">
            <summary>
            Creates a <see cref="T:TorchSharp.torch.Tensor">torch tensor</see> from an arbitrary <see cref="T:System.Array">array</see>.
            </summary>
            <param name="rawArray">The arbitrary array to create the tensor from.</param>
            <param name="device">The device where the tensor is to be located. Defaults to 'cpu'.</param>
            <returns>A <see cref="T:TorchSharp.torch.Tensor">torch tensor</see></returns>
            <remarks>
            This function roughly corresponds to torch.from_numpy(). It shares the underlying buffer between the input and output.
            torch.tensor() always makes a copy, which can be orders of magnitude slower.
            </remarks>
            <exception cref="T:System.InvalidOperationException">
            When <see cref="M:System.Type.GetElementType">Array.GetType().GetElementType()</see> does not return the .NET element type.
            </exception>
            <exception cref="T:System.NotSupportedException">
            When <see cref="M:System.Type.GetElementType">Array.GetType().GetElementType()</see> returns an unsupported .NET element type.
            Supported element types are <see cref="T:System.Boolean" />, <see cref="T:System.Byte" />, <see cref="T:System.SByte" />, <see cref="T:System.Int16" />,
            <see cref="T:System.Int32" />, <see cref="T:System.Int64" />, <see cref="T:System.Single" />, <see cref="T:System.Double" />,
            and <see cref="T:System.Numerics.Complex" />.
            </exception>
            <example>
            Tensor from array of rank 1
            <code>
            var array = new double[] { { 1, 2, 3, 4, 5, 6, 7, 8 } };
            var tensor = torch.from_array(rawArray: array, dtype: ScalarType.Float64, device: Device.CPU, requires_grad: false);
            </code>
            Tensor from array of rank 2
            <code>
            var array = new double[,] { { 1, 2, 3, 4 }, { 5, 6, 7, 8 } };
            var tensor = torch.from_array(rawArray: array, dtype: ScalarType.Float64, device: Device.CPU, requires_grad: false);
            </code>
            Tensor from array of rank 3
            <code>
            var array = new double[,,] { { { 1, 2 }, { 3, 4 } }, { { 5, 6 }, { 7, 8 } } };
            var tensor = torch.from_array(rawArray: array, dtype: ScalarType.Float64, device: Device.CPU, requires_grad: false);
            </code>
            </example>
        </member>
        <member name="M:TorchSharp.torch.from_array(System.Array,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Creates a <see cref="T:TorchSharp.torch.Tensor">torch tensor</see> from an arbitrary <see cref="T:System.Array">array</see>.
            </summary>
            <param name="rawArray">The arbitrary array to create the tensor from.</param>
            <param name="dtype">The element type to use in the created tensor. This can be different from the element type of the input.</param>
            <param name="device">The device where the tensor is to be located. Defaults to 'cpu'.</param>
            <param name="requires_grad"></param>
            <param name="names"></param>
            <returns></returns>
            <exception cref="T:System.InvalidOperationException"></exception>
        </member>
        <member name="M:TorchSharp.torch.frombuffer(System.Array,TorchSharp.torch.ScalarType,System.Int64,System.Int64,System.Boolean)">
             <summary>
             Creates a 1-dimensional Tensor from an array of n dimensions.
            
             Skips the first offset bytes in the buffer, and interprets the rest of the raw bytes as a 1-dimensional tensor of type dtype with count elements.
             </summary>
             <param name="rawArray">The input array</param>
             <param name="dtype">The torch data type.</param>
             <param name="count"></param>
             <param name="offset"></param>
             <param name="requires_grad">Set <value>true</value> if gradients need to be computed for this Tensor; <value>false</value> otherwise.</param>
             <returns></returns>
             <exception cref="T:System.ArgumentException"></exception>
             <exception cref="T:System.IndexOutOfRangeException"></exception>
             <remarks>The returned tensor and buffer share the same memory. Modifications to the tensor will be reflected in the buffer and vice versa.</remarks>
        </member>
        <member name="M:TorchSharp.torch.sparse_coo_tensor(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Int64[],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Constructs a sparse tensor in COO(rdinate) format with specified values at the given indices.
            </summary>
            <param name="indices">
            Initial data for the tensor. The indices are the coordinates of the non-zero values in the matrix,
            and thus should be two-dimensional where the first dimension is the number of tensor dimensions
            and the second dimension is the number of non-zero values.
            </param>
            <param name="values">nitial values for the tensor.</param>
            <param name="size">Size of the sparse tensor.</param>
            <param name="dtype">The element type to use in the created tensor. This can be different from the element type of the input.</param>
            <param name="device">The device where the tensor is to be located. Defaults to 'cpu'.</param>
            <param name="requires_grad">>Set <value>true</value> if gradients need to be computed for this Tensor; <value>false</value> otherwise.</param>
            <param name="names">Names for the dimensions of the tensor.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.sparse(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Int64[],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Constructs a sparse tensor in COO(rdinate) format with specified values at the given indices.
            </summary>
            <param name="indices">
            Initial data for the tensor. The indices are the coordinates of the non-zero values in the matrix,
            and thus should be two-dimensional where the first dimension is the number of tensor dimensions
            and the second dimension is the number of non-zero values.
            </param>
            <param name="values">nitial values for the tensor.</param>
            <param name="size">Size of the sparse tensor.</param>
            <param name="dtype">The element type to use in the created tensor. This can be different from the element type of the input.</param>
            <param name="device">The device where the tensor is to be located. Defaults to 'cpu'.</param>
            <param name="requires_grad">>Set <value>true</value> if gradients need to be computed for this Tensor; <value>false</value> otherwise.</param>
            <param name="names">Names for the dimensions of the tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.complex(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Constructs a complex tensor with its real part equal to real and its imaginary part equal to imag.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.polar(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Constructs a complex tensor whose elements are Cartesian coordinates corresponding to the polar coordinates with absolute value 'abs' and angle 'angle'.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.linspace(System.Double,System.Double,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Create a one-dimensional tensor of size steps whose values are evenly spaced from start to end, inclusive.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.logspace(System.Double,System.Double,System.Int64,System.Double,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Creates a one-dimensional tensor of size steps whose values are evenly spaced from base^start to base^end, inclusive, on a logarithmic scale with base 'base.'
            </summary>
        </member>
        <member name="T:TorchSharp.torch.Tensor">
            <summary>
            Represents a TorchSharp tensor.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.Load(System.IO.BinaryReader)">
            <summary>
            Load a tensor using a .NET-specific format.
            </summary>
            <param name="reader">A BinaryReader instance</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.Load(System.IO.Stream)">
            <summary>
            Load a tensor using a .NET-specific format.
            </summary>
            <param name="stream">A stream opened for reading binary data.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.Load(System.String)">
            <summary>
            Load a tensor using a .NET-specific format.
            </summary>
            <param name="location">A file name.</param>
        </member>
        <member name="F:TorchSharp.torch.Tensor.handle">
            <summary>
            A handle to the underlying native tensor.
            This field should only be used in rare circumstances. Instead, use the 'Handle' property, which
            validates that the handle is not zero.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.UnsafeCreateTensor(System.IntPtr)">
            <summary>
            Allows external packages to create tensors from the same native pointers that TorchSharp uses.
            </summary>
            <param name="handle">A pointer to a native at::Tensor.</param>
            <returns>A Tensor reference</returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.Equals(System.Object)">
            <summary>
            TODO
            </summary>
            <param name="obj"></param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.GetHashCode">
            <summary>
            TODO
            </summary>
        </member>
        <member name="P:TorchSharp.torch.Tensor.name">
            <summary>
            A friendly name for the tensor. This is useful for debugging purposes.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.Finalize">
            <summary>
            Finalize the tensor. Releases the tensor and its associated data.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.Dispose(System.Boolean)">
            <summary>
            Implements the .NET Dispose pattern.
            </summary>
        </member>
        <member name="P:TorchSharp.torch.Tensor.IsInvalid">
            <summary>
            Is true if the tensor has been disposed, false otherwise.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.MoveToOuterDisposeScope">
            <summary>
            Moves tensor to the outer DisposeScope. If there is no outer DisposeScope, it's detached from the
            DisposeScope system.
            </summary>
            <returns>The same tensor that the method was called on</returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.DetachFromDisposeScope">
            <summary>
            Detaches the tensor completely from the DisposeScope system.
            </summary>
            <returns>The same tensor that the method was called on</returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.DetatchFromDisposeScope">
            <summary>
            Detaches the tensor completely from the DisposeScope system.
            </summary>
            <returns>The same tensor that the method was called on</returns>
            <remarks>
            This was a misspelling of 'Detach'. Keeping it to avoid making a
            breaking change, but it is deprecated and will be removed in a future
            release.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.DecoupleFromNativeHandle">
             <summary>
             Decouple the managed tensor from its underlying native tensor.
            
             This is primarily useful when returning a tensor to native code in a callback,
             or when having created a managed tensor from a passed-in native handle.
            
             See the torch.nn.Module.Module(string name) constructor for an example of its use.
             </summary>
        </member>
        <member name="P:TorchSharp.torch.Tensor.TotalCount">
             <summary>
             The total number of allocated tensors.
             </summary>
             <remarks>
             Only tensors that are realized in managed code will be counted, so tensors
             resulting from computations that remain in native code will not be counted
             in this property.
            
             Further, two tensors may alias each other, pointing at the same underlying data.
            
             Therefore, this property is mostly useful for diagnostic purposes, to
             make sure that there is no drift in tensor count from epoch to epoch,
             for example.
             </remarks>
        </member>
        <member name="P:TorchSharp.torch.Tensor.PeakCount">
             <summary>
             The peak number of allocated tensors.
             </summary>
             <remarks>
             Only tensors that are realized in managed code will be counted, so tensors
             resulting from computations that remain in native code will not be counted
             in this property.
            
             Further, two tensors may alias each other, pointing at the same underlying data.
            
             Therefore, this property is mostly useful for diagnostic purposes.
             </remarks>
        </member>
        <member name="P:TorchSharp.torch.Tensor.Handle">
            <summary>
            Get the handle for the tensor, validating that it's not null.
            </summary>
            <remarks>
            This property validates the handle. If you **aboslutely** need to get the handle without validation,
            use the 'handle' field.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.MoveHandle">
            <summary>
            Disassociates the native tensor handle from the managed Tensor.
            </summary>
            <remarks>Used to create a Parameter instance.</remarks>
            <returns>The handle to the underlying native tensor.</returns>
        </member>
        <member name="P:TorchSharp.torch.Tensor.Dimensions">
            <summary>
            Returns the number of dimensions for this tensor
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.dim">
            <summary>
            Returns the number of dimensions for this tensor
            </summary>
        </member>
        <member name="P:TorchSharp.torch.Tensor.ndim">
            <summary>
            Returns the number of dimensions for this tensor
            </summary>
        </member>
        <member name="P:TorchSharp.torch.Tensor.NumberOfElements">
            <summary>
            Get the number of elements in the tensor.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.numel">
            <summary>
            Get the number of elements in the tensor.
            </summary>
        </member>
        <member name="P:TorchSharp.torch.Tensor.ElementSize">
            <summary>
            Get the size of each element in the tensor.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.is_floating_point">
            <summary>
            Returns True if the data type of input is a floating point data type.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.is_complex">
            <summary>
            Returns True if the data type of input is a complex data type i.e., one of torch.complex64, and torch.complex128.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.is_nonzero">
            <summary>
            Returns True if the input is a single element tensor which is not equal to zero after type conversions,
            i.e. not equal to torch.tensor([0.]) or torch.tensor([0]) or torch.tensor([False]).
            Throws an InvalidOperationException if torch.numel() != 1.
            </summary>
        </member>
        <member name="P:TorchSharp.torch.Tensor.is_leaf">
            <summary>
            All Tensors that have requires_grad which is true will be leaf Tensors by convention.
            For Tensors that have requires_grad which is true, they will be leaf Tensors if they were created by the user.This means that they are not the result of an operation and so grad_fn is None.
            Only leaf Tensors will have their grad populated during a call to backward(). To get grad populated for non-leaf Tensors, you can use retain_grad().
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.alias">
            <summary>
            Create a new reference to the same underlying native tensor.
            </summary>
            <returns>A fresh reference to the underlying native tensor.</returns>
            <remkars>
            This is useful for function implementations where a caller may expect the input and output to be
            distinct; in such situations, there's a risk that the tensor is disposed twice, with bad consequences.
            With 'alias(),' the reference count to the underlying native tensor is increased, meaning that the
            input and output can (and should) be disposed or finalized independently of each other.
            </remkars>
        </member>
        <member name="M:TorchSharp.torch.Tensor.storage``1">
            <summary>
            Returns the underlying storage.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.storage_offset">
            <summary>
            Returns the tensor’s offset in the underlying storage in terms of number of storage elements (not bytes).
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.data``1">
            <summary>
            Returns a pointer to the unmanaged data managed by this tensor.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.item``1">
            <summary>
            Returns the singleton value of a scalar tensor.
            </summary>
            <typeparam name="T"></typeparam>
            <returns>The scalar held in the tensor</returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.WriteBytesToStream(System.IO.Stream,System.Int32)">
            <summary>
            Writes the bytes of the tensor to a stream. Useful for when tensors are >2GB.
            </summary>
            <param name="stream">Stream to write the bytes to</param>
            <param name="bufferSize">The buffer size to use when writing to the stream</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.ReadBytesFromStream(System.IO.Stream,System.Int32)">
            <summary>
            Reads the bytes of the tensor from a stream.
            </summary>
            <param name="stream">Stream to read the bytes from</param>
            <param name="bufferSize">The buffer size to use when reading from the stream</param>
        </member>
        <member name="P:TorchSharp.torch.Tensor.bytes">
            <summary>
            Get or set the contents of a tensor as raw bytes.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.ReadCpuDouble(System.Int64)">
            <summary>
            Read the double-precision value at the given index.
            </summary>
            <param name="i">The index.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.ReadCpuSingle(System.Int64)">
            <summary>
            Read the single-precision float value at the given index.
            </summary>
            <param name="i">The index.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.ReadCpuInt32(System.Int64)">
            <summary>
            Read the 32-bit integer float value at the given index.
            </summary>
            <param name="i">The index.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.ReadCpuInt64(System.Int64)">
            <summary>
            Read the 64-bit integer value at the given index.
            </summary>
            <param name="i">The index.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.ReadCpuByte(System.Int64)">
            <summary>
            Read the byte value at the given index.
            </summary>
            <param name="i">The index.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.ReadCpuSByte(System.Int64)">
            <summary>
            Read the short value at the given index.
            </summary>
            <param name="i">The index.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.ReadCpuInt16(System.Int64)">
            <summary>
            Read the int16 value at the given index.
            </summary>
            <param name="i">The index.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.ReadCpuBool(System.Int64)">
            <summary>
            Read the Boolean value at the given index.
            </summary>
            <param name="i">The index.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.ReadCpuValue``1(System.Int64)">
            <summary>
            Read the value at the given index.
            </summary>
            <typeparam name="T">The type of the element to read.</typeparam>
            <param name="i">The index.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.ReadCpuFloat16(System.Int64)">
            <summary>
            Read the Float16 value at the given index.
            </summary>
            <param name="i">The index.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.ReadCpuBFloat16(System.Int64)">
            <summary>
            Read the BFloat16 value at the given index.
            </summary>
            <param name="i">The index.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.ToScalar">
            <summary>
            Convert to a scalar.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.fill_(TorchSharp.Scalar)">
            <summary>
            Fill the tensor with the provided scalar value.
            </summary>
            <param name="value">A scalar value</param>
        </member>
        <member name="P:TorchSharp.torch.Tensor.dtype">
            <summary>
            Gets the type of the tensor elements.
            </summary>
        </member>
        <member name="P:TorchSharp.torch.Tensor.device">
            <summary>
            Gets a string representing the device where the tensor is stored.
            </summary>
        </member>
        <member name="P:TorchSharp.torch.Tensor.device_index">
            <summary>
            Gets a index of the device where the tensor is stored.
            </summary>
        </member>
        <member name="P:TorchSharp.torch.Tensor.device_type">
            <summary>
            Gets the type ('CPU', 'CUDA', etc.) of the device where the tensor is stored.
            </summary>
        </member>
        <member name="P:TorchSharp.torch.Tensor.is_sparse">
            <summary>
            Is the tensor a sparse tensor?
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.load(System.String)">
            <summary>
            Creates a tensor by loading it from a file.
            </summary>
            <param name="location">The file path where tensor values are stored.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.save(System.String)">
            <summary>
            Save the contents of a tensor to a file.
            </summary>
            <param name="location">The file path where tensor values are to be stored.</param>
        </member>
        <member name="P:TorchSharp.torch.Tensor.requires_grad">
            <summary>
            Is the tensor tracking gradients?
            </summary>
            <remarks>Typically, gradients are tracked when the tensor is used as parameters of a module.</remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.retain_grad">
            <summary>
            Enables this Tensor to have their grad populated during backward(). This is a no-op for leaf tensors.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.with_requires_grad(System.Boolean)">
            <summary>
            Adds gradient tracking.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.is_cpu">
            <summary>
            Returns true if the tensor is on the CPU
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.cpu">
            <summary>
            Moves the tensor data to the CPU device
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.mps(System.Boolean)">
            <summary>
            Moves the tensor data to the MPS device
            </summary>
            <param name="non_blocking">Try to convert asynchronously with respect to the host if possible, e.g., converting a CPU Tensor with pinned memory to a CUDA Tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.cuda(TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Returns a copy of this object in CUDA memory.
            If this object is already in CUDA memory and on the correct device, then no copy is performed and the original object is returned.
            </summary>
            <param name="device">The target device</param>
            <param name="non_blocking">Try to convert asynchronously with respect to the host if possible, e.g., converting a CPU Tensor with pinned memory to a CUDA Tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.to_type(TorchSharp.torch.ScalarType,System.Boolean,System.Boolean,System.Boolean)">
            <summary>
            Cast the tensor to the given element type.
            </summary>
            <param name="type">The target type</param>
            <param name="copy">When copy is set, a new Tensor is created even when the Tensor already matches the desired conversion.</param>
            <param name="disposeAfter">When disposeAfter is set, the current Tensor will be disposed after creating the new one</param>
            <param name="non_blocking">Try to convert asynchronously with respect to the host if possible, e.g., converting a CPU Tensor with pinned memory to a CUDA Tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.type_as(TorchSharp.torch.Tensor)">
            <summary>
            Returns this tensor cast to the type of the given tensor.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.set_(TorchSharp.torch.Tensor)">
            <summary>
            Overwrite an existing tensor with the contents of another tensor.
            </summary>
            <param name="source">The source tensor</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.to(TorchSharp.DeviceType,System.Int32,System.Boolean,System.Boolean,System.Boolean)">
            <summary>
            Moves the tensor data to a specific device.
            </summary>
            <param name="deviceType">The device type, e.g. 'CPU' or 'CUDA'.</param>
            <param name="deviceIndex">The optional device index.</param>
            <param name="copy">When copy is set, a new Tensor is created even when the Tensor already matches the desired conversion.</param>
            <param name="disposeAfter">When disposeAfter is set, the current Tensor will be disposed after creating the new one</param>
            <param name="non_blocking">Try to convert asynchronously with respect to the host if possible, e.g., converting a CPU Tensor with pinned memory to a CUDA Tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.to(TorchSharp.torch.ScalarType,TorchSharp.torch.Device,System.Boolean,System.Boolean,System.Boolean)">
            <summary>
            Moves the tensor data and casts it to the given element type.
            </summary>
            <param name="type">The target type</param>
            <param name="device">The target device</param>
            <param name="copy">When copy is set, a new Tensor is created even when the Tensor already matches the desired conversion.</param>
            <param name="disposeAfter">When disposeAfter is set, the current Tensor will be disposed after creating the new one</param>
            <param name="non_blocking">Try to convert asynchronously with respect to the host if possible, e.g., converting a CPU Tensor with pinned memory to a CUDA Tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.to(TorchSharp.torch.ScalarType,System.Boolean,System.Boolean,System.Boolean)">
            <summary>
            Cast the tensor to the given element type.
            </summary>
            <param name="type">The target type</param>
            <param name="copy">When copy is set, a new Tensor is created even when the Tensor already matches the desired conversion.</param>
            <param name="disposeAfter">When disposeAfter is set, the current Tensor will be disposed after creating the new one</param>
            <param name="non_blocking">Try to convert asynchronously with respect to the host if possible, e.g., converting a CPU Tensor with pinned memory to a CUDA Tensor.</param>
            <remarks>Alias for to_type</remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.to(System.String,System.Boolean,System.Boolean,System.Boolean)">
            <summary>
            Moves the tensor data.
            </summary>
            <param name="device">A string denoting the target device.</param>
            <param name="copy">When copy is set, a new Tensor is created even when the Tensor already matches the desired conversion.</param>
            <param name="disposeAfter">When disposeAfter is set, the current Tensor will be disposed after creating the new one</param>
            <param name="non_blocking">Try to convert asynchronously with respect to the host if possible, e.g., converting a CPU Tensor with pinned memory to a CUDA Tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.to(TorchSharp.torch.Device,System.Boolean,System.Boolean,System.Boolean)">
            <summary>
            Moves the tensor data.
            </summary>
            <param name="device">The target device</param>
            <param name="copy">When copy is set, a new Tensor is created even when the Tensor already matches the desired conversion.</param>
            <param name="disposeAfter">When disposeAfter is set, the current Tensor will be disposed after creating the new one</param>
            <param name="non_blocking">Try to convert asynchronously with respect to the host if possible, e.g., converting a CPU Tensor with pinned memory to a CUDA Tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.to(TorchSharp.torch.Tensor,System.Boolean)">
            <summary>
            Moves the tensor data.
            </summary>
            <param name="other">The tensor serving as a template.</param>
            <param name="non_blocking">Try to convert asynchronously with respect to the host if possible, e.g., converting a CPU Tensor with pinned memory to a CUDA Tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.size(System.Int32)">
            <summary>
            Retrieves the size of the specified dimension in the tensor.
            </summary>
            <param name="dim">The dimension for which to retrieve the size.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.size">
            <summary>
            Retrieves the sizes of all dimensions of the tensor.
            </summary>
        </member>
        <member name="P:TorchSharp.torch.Tensor.shape">
            <summary>
            Returns the tensor shape, this is an array whose size determines the number of dimensions on the tensor,
            and each element is the size of the dimension
            </summary>
            <remarks>
            An array of size 0 is used for constants, an array of size 1 is used
            for single-dimension arrays, where the dimension is the value of the
            first element. And so on.
            </remarks>
        </member>
        <member name="P:TorchSharp.torch.Tensor.names">
             <summary>
             Stores names for each of this tensor’s dimensions.
            
             names[idx] corresponds to the name of tensor dimension idx.Names are either a string if the dimension is named or None if the dimension is unnamed.
             Dimension names may contain characters or underscore.Furthermore, a dimension name must be a valid Python variable name(i.e., does not start with underscore).
             Tensors may not have two named dimensions with the same name.
             </summary>
             <remarks>The named tensor API is experimental and subject to change.</remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.rename(System.Collections.Generic.IEnumerable{System.String})">
            <summary>
            Renames dimension names of the input tensor.
            </summary>
            <param name="names">A list of names, one for each dimension in the tensor. Passing 'null' clears out all the names.</param>
            <remarks>The named tensor API is experimental and subject to change.</remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.rename_(System.Collections.Generic.IEnumerable{System.String})">
            <summary>
            Renames dimension names of the input tensor, in place.
            </summary>
            <param name="names">A list of names, one for each dimension in the tensor. Passing 'null' clears out all the names.</param>
            <remarks>The named tensor API is experimental and subject to change.</remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.refine_names(System.Collections.Generic.IEnumerable{System.String})">
             <summary>
             Refines the dimension names of the input tensor according to names.
            
             Refining is a special case of renaming that “lifts” unnamed dimensions.A None dim can be refined to have any name; a named dim can only be refined to have the same name.
             Because named tensors can coexist with unnamed tensors, refining names gives a nice way to write named-tensor-aware code that works with both named and unnamed tensors.
             names may contain up to one ellipsis argument, passed as "...". The ellipsis is expanded greedily; it is expanded in-place to fill names to the same length as
             this.shape using names from the corresponding indices of this.names.
             </summary>
             <param name="names">A list of names, one for each dimension in the tensor.</param>
             <remarks>The named tensor API is experimental and subject to change.</remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.refine_names(System.String[])">
             <summary>
             Refines the dimension names of the input tensor according to names.
            
             Refining is a special case of renaming that “lifts” unnamed dimensions.A None dim can be refined to have any name; a named dim can only be refined to have the same name.
             Because named tensors can coexist with unnamed tensors, refining names gives a nice way to write named-tensor-aware code that works with both named and unnamed tensors.
             names may contain up to one ellipsis argument, passed as "...". The ellipsis is expanded greedily; it is expanded in-place to fill names to the same length as
             this.shape using names from the corresponding indices of this.names.
             </summary>
             <param name="names">A list of names, one for each dimension in the tensor.</param>
             <remarks>The named tensor API is experimental and subject to change.</remarks>
        </member>
        <member name="P:TorchSharp.torch.Tensor.SparseIndices">
            <summary>
            Return the indices tensor of a sparse COO tensor.
            </summary>
        </member>
        <member name="P:TorchSharp.torch.Tensor.SparseValues">
            <summary>
            Return the values tensor of a sparse COO tensor.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.vander(System.Int64,System.Boolean)">
            <summary>
            Generates a Vandermonde matrix.
            </summary>
            <param name="N">Number of columns in the output. If N is not specified, a square array is returned (N = len(x)).</param>
            <param name="increasing">
            Order of the powers of the columns.
            If true, the powers increase from left to right, if false (the default) they are reversed.
            </param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.stride">
            <summary>
            Retrieves the stride of all dimensions of the tensor.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.stride(System.Int32)">
            <summary>
            Retrieves the stride of the specified dimension in the tensor.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.as_strided(System.Int64[],System.Int64[],System.Int64)">
            <summary>
            Create a view of an existing torch.Tensor input with specified size, stride and storage offset.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.backward">
            <summary>
            Computes the gradient of current tensor w.r.t. graph leaves.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.to_dense">
            <summary>
            Creates a strided copy of the input tensor.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.clone">
            <summary>
            Returns a copy of the tensor input.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.copy_(TorchSharp.torch.Tensor,System.Boolean)">
            <summary>
            Copies the elements from source into the tensor and returns it.
            </summary>
            <remarks>The src tensor must be broadcastable with the target 'this' tensor. It may be of a different data type or reside on a different device.</remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.is_contiguous">
            <summary>
            Returns true if the tensor is contiguous.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.contiguous">
            <summary>
            Returns a contiguous in memory tensor containing the same data as the input tensor.
            If tensor is already in the specified memory format, this function returns the original tensor.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.is_pinned">
            <summary>
            Returns true if the tensor is contiguous.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.pin_memory">
            <summary>
            Returns a contiguous in memory tensor containing the same data as the input tensor.
            If tensor is already in the specified memory format, this function returns the original tensor.
            </summary>
        </member>
        <member name="P:TorchSharp.torch.Tensor.grad">
            <summary>
            This attribute is null by default and becomes a Tensor the first time a call to backward() computes gradients for the tensor.
            The attribute will then contain the gradients computed and future calls to backward() will accumulate (add) gradients into it.
            </summary>
        </member>
        <member name="P:TorchSharp.torch.Tensor.TensorItems(TorchSharp.torch.TensorIndex[])">
            <summary>
            Index into the tensor using Python-like indexing expressions.
            </summary>
        </member>
        <member name="P:TorchSharp.torch.Tensor.TensorItems(System.Int64)">
            <summary>
            Tensor indexer.
            </summary>
            <param name="i1">The first-dimension index.</param>
        </member>
        <member name="P:TorchSharp.torch.Tensor.TensorItems(System.Int64,System.Int64)">
            <summary>
            Tensor indexer.
            </summary>
            <param name="i1">The first-dimension index.</param>
            <param name="i2">The second-dimension index.</param>
        </member>
        <member name="P:TorchSharp.torch.Tensor.TensorItems(System.Int64,System.Int64,System.Int64)">
            <summary>
            Tensor indexer.
            </summary>
            <param name="i1">The first-dimension index.</param>
            <param name="i2">The second-dimension index.</param>
            <param name="i3">The third-dimension index</param>
        </member>
        <member name="P:TorchSharp.torch.Tensor.TensorItems(System.Int64,System.Int64,System.Int64,System.Int64)">
            <summary>
            Tensor indexer.
            </summary>
            <param name="i1">The first-dimension index.</param>
            <param name="i2">The second-dimension index.</param>
            <param name="i3">The third-dimension index</param>
            <param name="i4">The fourth-dimension index</param>
        </member>
        <member name="P:TorchSharp.torch.Tensor.TensorItems(System.Int64,System.Int64,System.Int64,System.Int64,System.Int64)">
            <summary>
            Tensor indexer.
            </summary>
            <param name="i1">The first-dimension index.</param>
            <param name="i2">The second-dimension index.</param>
            <param name="i3">The third-dimension index</param>
            <param name="i4">The fourth-dimension index</param>
            <param name="i5">The fifth-dimension index</param>
        </member>
        <member name="P:TorchSharp.torch.Tensor.TensorItems(System.Int64,System.Int64,System.Int64,System.Int64,System.Int64,System.Int64)">
            <summary>
            Tensor indexer.
            </summary>
            <param name="i1">The first-dimension index.</param>
            <param name="i2">The second-dimension index.</param>
            <param name="i3">The third-dimension index</param>
            <param name="i4">The fourth-dimension index</param>
            <param name="i5">The fifth-dimension index</param>
            <param name="i6">The sixth-dimension index</param>
        </member>
        <member name="P:TorchSharp.torch.Tensor.TensorItems(System.Int64[])">
            <summary>
            Tensor indexer.
            </summary>
            <param name="indices">A variable-lenght list of indices.</param>
            <returns>A tensor, possbily singleton.</returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.index(TorchSharp.torch.TensorIndex[])">
            <summary>
            Index into the tensor using Python-like indexing expressions.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.index(TorchSharp.torch.Tensor[])">
            <summary>
            Index into the tensor using Python-like indexing expressions.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.index_put_(TorchSharp.torch.Tensor,TorchSharp.torch.TensorIndex[])">
            <summary>
            Index into the tensor using Python-like indexing expressions and place a tensor at the index.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.index_put_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor[])">
            <summary>
            Index into the tensor using Python-like indexing expressions and place a tensor at the index.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.index_put_(TorchSharp.Scalar,TorchSharp.torch.TensorIndex[])">
            <summary>
            Index into the tensor using Python-like indexing expressions and place a scalar tensor at the index.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.index_put_(TorchSharp.Scalar,TorchSharp.torch.Tensor[])">
            <summary>
            Index into the tensor using Python-like indexing expressions and place a scalar tensor at the index.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.index_select(System.Int64,TorchSharp.torch.Tensor)">
            <summary>
            Returns a new tensor which indexes the input tensor along dimension dim using the entries in index which is a LongTensor.
            </summary>
            <param name="dim">The dimension in which we index</param>
            <param name="index">The 1-D tensor containing the indices to index</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.select(System.Int64,System.Int64)">
            <summary>
            Slices the input tensor along the selected dimension at the given index.
            This function returns a view of the original tensor with the given dimension removed.
            </summary>
            <param name="dim">The dimension to slice</param>
            <param name="index">The index to select with</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.take(TorchSharp.torch.Tensor)">
            <summary>
            Returns a new tensor with the elements of input at the given indices. The input tensor is treated as if it were viewed as a 1-D tensor.
            The result takes the same shape as the indices.
            </summary>
            <param name="index">The indices into tensor, an Int64 tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.argwhere">
            <summary>
            Returns a tensor containing the indices of all non-zero elements of input.
            Each row in the result contains the indices of a non-zero element in input.
            The result is sorted lexicographically, with the last index changing the fastest (C-style).
            If input has n dimensions, then the resulting indices tensor out is of size (z×n), where
            z is the total number of non-zero elements in the input tensor.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.take_along_dim(TorchSharp.torch.Tensor)">
            <summary>
            Selects values from input at the 1-dimensional indices from indices along the given dim.
            </summary>
            <param name="indices">The indices into input. Must have long dtype.</param>
            <remarks>Functions that return indices along a dimension, like torch.argmax() and torch.argsort(), are designed to work with this function.</remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.take_along_dim(System.Collections.Generic.IEnumerable{System.Int64})">
            <summary>
            Selects values from input at the 1-dimensional indices from indices along the given dim.
            </summary>
            <param name="indices">The indices into input. Must have long dtype.</param>
            <remarks>Functions that return indices along a dimension, like torch.argmax() and torch.argsort(), are designed to work with this function.</remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.take_along_dim(TorchSharp.torch.Tensor,System.Int64)">
            <summary>
            Selects values from input at the 1-dimensional indices from indices along the given dim.
            </summary>
            <param name="indices">The indices into input. Must have long dtype.</param>
            <param name="dim">Dimension to select along.</param>
            <remarks>Functions that return indices along a dimension, like torch.argmax() and torch.argsort(), are designed to work with this function.</remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.take_along_dim(System.Collections.Generic.IEnumerable{System.Int64},System.Int64)">
            <summary>
            Selects values from input at the 1-dimensional indices from indices along the given dim.
            </summary>
            <param name="indices">The indices into input. Must have long dtype.</param>
            <param name="dim">Dimension to select along.</param>
            <remarks>Functions that return indices along a dimension, like torch.argmax() and torch.argsort(), are designed to work with this function.</remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.index_add(System.Int64,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.Scalar)">
             <summary>
             Accumulate the elements of alpha times source into the input tensor by adding to the indices in the order given in index.
            
             For example, if dim == 0, index[i] == j, and alpha=-1, then the ith row of source is subtracted from the jth row of the input tensor.
             The dimth dimension of source must have the same size as the length of index(which must be a vector), and all other dimensions must match the input tensor, or an error will be raised.
             </summary>
             <param name="dim">Dimension along which to index</param>
             <param name="index">Indices of source to select from, should have dtype either torch.int64 or torch.int32</param>
             <param name="source">The tensor containing values to add</param>
             <param name="alpha">The scalar multiplier for source</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.index_add_(System.Int64,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.Scalar)">
             <summary>
             Accumulate, in place, the elements of alpha times source into the input tensor by adding to the indices in the order given in index.
            
             For example, if dim == 0, index[i] == j, and alpha=-1, then the ith row of source is subtracted from the jth row of the input tensor.
             The dimth dimension of source must have the same size as the length of index(which must be a vector), and all other dimensions must match the input tensor, or an error will be raised.
             </summary>
             <param name="dim">Dimension along which to index</param>
             <param name="index">Indices of source to select from, should have dtype either torch.int64 or torch.int32</param>
             <param name="source">The tensor containing values to add</param>
             <param name="alpha">The scalar multiplier for source</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.index_copy(System.Int64,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
             <summary>
             Copies the elements of the source tensor into the input tensor by selecting the indices in the order given in index.
            
             For example, if dim == 0 and index[i] == j, then the ith row of tensor is copied to the jth row of the input tensor.
             The dimth dimension of source must have the same size as the length of index(which must be a vector), and all other dimensions must match the input tensor, or an error will be raised.
             </summary>
             <param name="dim">Dimension along which to index</param>
             <param name="index">Indices of source to select from, should have dtype either torch.int64 or torch.int32</param>
             <param name="source">The tensor containing values to copy</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.index_copy_(System.Int64,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
             <summary>
             Copies, in place, the elements of the source tensor into the input tensor by selecting the indices in the order given in index.
            
             For example, if dim == 0 and index[i] == j, then the ith row of tensor is copied to the jth row of the input tensor.
             The dimth dimension of source must have the same size as the length of index(which must be a vector), and all other dimensions must match the input tensor, or an error will be raised.
             </summary>
             <param name="dim">Dimension along which to index</param>
             <param name="index">Indices of source to select from, should have dtype either torch.int64 or torch.int32</param>
             <param name="source">The tensor containing values to copy</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.index_fill(System.Int64,TorchSharp.torch.Tensor,TorchSharp.Scalar)">
             <summary>
             Fills the elements of the input tensor with value value by selecting the indices in the order given in index.
            
             For example, if dim == 0, index[i] == j, and alpha=-1, then the ith row of source is subtracted from the jth row of the input tensor.
             The dimth dimension of source must have the same size as the length of index(which must be a vector), and all other dimensions must match the input tensor, or an error will be raised.
             </summary>
             <param name="dim">Dimension along which to index</param>
             <param name="index">Indices of source to select from, should have dtype either torch.int64 or torch.int32</param>
             <param name="value">The scalar multiplier for source</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.index_fill_(System.Int64,TorchSharp.torch.Tensor,TorchSharp.Scalar)">
             <summary>
             Fills, in place, the elements of the input tensor with value value by selecting the indices in the order given in index.
            
             For example, if dim == 0, index[i] == j, and alpha=-1, then the ith row of source is subtracted from the jth row of the input tensor.
             The dimth dimension of source must have the same size as the length of index(which must be a vector), and all other dimensions must match the input tensor, or an error will be raised.
             </summary>
             <param name="dim">Dimension along which to index</param>
             <param name="index">Indices of source to select from, should have dtype either torch.int64 or torch.int32</param>
             <param name="value">The scalar multiplier for source</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.reshape(System.Int64[])">
            <summary>
            Returns a tensor with the same data and number of elements as the input tensor but with the specified shape.
            </summary>
            <param name="shape">The new tensor shape.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.flatten(System.Int64,System.Int64)">
            <summary>
            Flattens input by reshaping it into a one-dimensional tensor.
            </summary>
            <param name="start_dim">The first dim to flatten</param>
            <param name="end_dim">The last dim to flatten.</param>
            <remarks>Flattening a zero-dimensional tensor will return a one-dimensional view.</remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.flatten(System.Collections.Generic.IList{System.String},System.String)">
            <summary>
            Flattens dims into a single dimension with name out_dim.
            </summary>
            <param name="dims">The named dimensions to flatten.</param>
            <param name="out_dim">The name of the output dimension.</param>
            <remarks>The named tensor API is experimental and subject to change.</remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.unflatten(System.Int64,System.Int64[])">
            <summary>
            Expands the dimension dim of the input tensor over multiple dimensions of sizes given by sizes.
            </summary>
            <param name="dim">Dimension to unflatten.</param>
            <param name="sizes">New shape of the unflattened dimension.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.unflatten(System.String,System.ValueTuple{System.String,System.Int64}[])">
            <summary>
            Expands the dimension dim of the input tensor over multiple dimensions of sizes given by sizes.
            </summary>
            <param name="dim">Dimension to unflatten.</param>
            <param name="sizes">New names and sizes of the unflattened dimension.</param>
            <remarks>The named tensor API is experimental and subject to change.</remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.align_to(System.Collections.Generic.IEnumerable{System.String})">
             <summary>
             Permutes the dimensions of the input tensor to match the order specified in names, adding size-one dims for any new names.
            
             All of the dims of the input tensor must be named in order to use this method.The resulting tensor is a view on the original tensor.
             All dimension names of the input tensor must be present in names.names may contain additional names that are not in this.names; the output tensor has a size-one dimension for each of those new names.
             names may contain up to one ellipsis "...". The ellipsis is expanded to be equal to all dimension names of the input tensor that are not mentioned in names, in the order that they appear in the input tensor.
             </summary>
             <param name="names">The desired dimension ordering of the output tensor. May contain up to one ellipsis that is expanded to all unmentioned dim names of the input tensor.</param>
             <remarks>The named tensor API is experimental and subject to change.</remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.align_to(System.String[])">
             <summary>
             Permutes the dimensions of the input tensor to match the order specified in names, adding size-one dims for any new names.
            
             All of the dims of the input tensor must be named in order to use this method.The resulting tensor is a view on the original tensor.
             All dimension names of the input tensor must be present in names.names may contain additional names that are not in this.names; the output tensor has a size-one dimension for each of those new names.
             names may contain up to one ellipsis "...". The ellipsis is expanded to be equal to all dimension names of the input tensor that are not mentioned in names, in the order that they appear in the input tensor.
             </summary>
             <param name="names">The desired dimension ordering of the output tensor. May contain up to one ellipsis that is expanded to all unmentioned dim names of the input tensor.</param>
             <remarks>The named tensor API is experimental and subject to change.</remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.align_as(TorchSharp.torch.Tensor)">
             <summary>
             Permutes the dimensions of the input tensor to match the dimension order in the other tensor, adding size-one dims for any new names.
            
             This operation is useful for explicit broadcasting by names.
             All of the dims of the input tensor must be named in order to use this method.The resulting tensor is a view on the original tensor.
             All dimension names of the input tensor must be present in other.names.other may contain named dimensions that are not in this.names; the output tensor has a size-one dimension for each of those new names.
             To align a tensor to a specific order, use align_to().
             </summary>
             <param name="other"></param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.unique(System.Boolean,System.Boolean,System.Boolean,System.Nullable{System.Int32})">
            <summary>
            Returns the unique elements of the input tensor.
            </summary>
            <param name="sorted">Whether to sort the unique elements in ascending order before returning as output.</param>
            <param name="return_inverse">Whether to also return the indices for where elements in the original input ended up in the returned unique list.</param>
            <param name="return_counts">Whether to also return the counts for each unique element.</param>
            <param name="dim">The dimension to apply unique. If null, the unique of the flattened input is returned.</param>
            <returns></returns>
            <remarks>This function is different from torch.unique_consecutive() in the sense that this function also eliminates non-consecutive duplicate values.</remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.unique_consecutive(System.Boolean,System.Boolean,System.Nullable{System.Int32})">
            <summary>
            Returns the unique elements of the input tensor.
            </summary>
            <param name="return_inverse">Whether to also return the indices for where elements in the original input ended up in the returned unique list.</param>
            <param name="return_counts">Whether to also return the counts for each unique element.</param>
            <param name="dim">The dimension to apply unique. If null, the unique of the flattened input is returned.</param>
            <returns>A tuple with the output, the indices, and counts. The latter two may be 'null'</returns>
            <remarks>This function is different from torch.unique_consecutive() in the sense that this function also eliminates non-consecutive duplicate values.</remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.unflatten(System.Int64,TorchSharp.torch.Size)">
            <summary>
            Expands the dimension dim of the input tensor over multiple dimensions of sizes given by sizes.
            </summary>
            <param name="dim">Dimension to unflatten.</param>
            <param name="sizes">New shape of the unflattened dimension.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.squeeze(System.Nullable{System.Int64})">
            <summary>
            Returns a tensor with all the dimensions of input of size 1 removed. When dim is given, a squeeze operation is done only in the given dimension.
            </summary>
            <param name="dim">If given, the input will be squeezed only in this dimension</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.squeeze_(System.Nullable{System.Int64})">
            <summary>
            Modify (in-palce) a tensor with all the dimensions of input of size 1 removed. When dim is given, a squeeze operation is done only in the given dimension.
            </summary>
            <param name="dim">If given, the input will be squeezed only in this dimension</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.t">
            <summary>
            Expects input to be 1- or 2-D tensor and transposes dimensions 0 and 1.
            </summary>
        </member>
        <member name="P:TorchSharp.torch.Tensor.T">
            <summary>
            Is this Tensor with its dimensions reversed.
            </summary>
            <remarks>
            Starting with Pytorch 1.11, 'T' should not be used for tensors that do not represents matrices:
            https://github.com/pytorch/pytorch/pull/64180
            </remarks>
        </member>
        <member name="P:TorchSharp.torch.Tensor.H">
            <summary>
            Is this Tensor with its dimensions reversed.
            </summary>
        </member>
        <member name="P:TorchSharp.torch.Tensor.mT">
            <summary>
            Returns a view of this tensor with the last two dimensions transposed.
            </summary>
        </member>
        <member name="P:TorchSharp.torch.Tensor.mH">
            <summary>
            Accessing this property is equivalent to calling adjoint().
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.transpose(System.Int64,System.Int64)">
            <summary>
            Returns a tensor that is a transposed version of input. The given dimensions dim0 and dim1 are swapped.
            </summary>
            <param name="dim0"></param>
            <param name="dim1"></param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.transpose_(System.Int64,System.Int64)">
            <summary>
            Returns a tensor that is a transposed version of input. The given dimensions dim0 and dim1 are swapped.
            Inplace version of transpose()
            </summary>
            <param name="dim0"></param>
            <param name="dim1"></param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.adjoint">
            <summary>
            Returns a view of the tensor conjugated and with the last two dimensions transposed.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.tril(System.Int64)">
            <summary>
            Returns the lower triangular part of the matrix (2-D tensor) or batch of matrices input, the other elements of the result tensor out are set to 0.
            The lower triangular part of the matrix is defined as the elements on and below the diagonal.
            </summary>
            <param name="diagonal">The diagonal to consider</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.tril_(System.Int64)">
            <summary>
            Returns the lower triangular part of the matrix (2-D tensor) or batch of matrices input, the other elements of the result tensor out are set to 0.
            The lower triangular part of the matrix is defined as the elements on and below the diagonal.
            In-place version of `tril()`
            </summary>
            <param name="diagonal">The diagonal to consider</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.triu(System.Int64)">
            <summary>
            Returns the upper triangular part of a matrix (2-D tensor) or batch of matrices input, the other elements of the result tensor out are set to 0.
            The upper triangular part of the matrix is defined as the elements on and above the diagonal.
            </summary>
            <param name="diagonal">The diagonal to consider</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.triu_(System.Int64)">
            <summary>
            Returns the upper triangular part of a matrix (2-D tensor) or batch of matrices input, the other elements of the result tensor out are set to 0.
            The upper triangular part of the matrix is defined as the elements on and above the diagonal.
            In-place version of `triu()`
            </summary>
            <param name="diagonal">The diagonal to consider</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.swapdims(System.Int64,System.Int64)">
            <summary>
            Returns a tensor that is a transposed version of input. The given dimensions dim0 and dim1 are swapped.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.swapaxes(System.Int64,System.Int64)">
            <summary>
            Returns a tensor that is a transposed version of input. The given dimensions dim0 and dim1 are swapped.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.view(System.Int64[])">
            <summary>
            Returns a new tensor with the same data as the input tensor but of a different shape.
            </summary>
            <param name="shape">The shape of the view</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.view_as(TorchSharp.torch.Tensor)">
            <summary>
            View this tensor as the same size as other.
            </summary>
            <param name="other">The result tensor has the same size as other.</param>
            <remarks>
            this.view_as(other) is equivalent to this.view(other.size()).
            Please see view() for more information about view.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.view_as_complex">
            <summary>
            Returns a view of input as a complex tensor.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.view_as_real">
            <summary>
            Returns a view of input as a real tensor.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.all">
            <summary>
            Tests if all elements in input evaluate to true.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.all(System.Int64,System.Boolean)">
            <summary>
            Tests if all elements in input evaluate to true.
            </summary>
            <param name="dim">The dimension to reduce</param>
            <param name="keepdim">Keep the dimension to reduce</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.amax(System.Int64[],System.Boolean,TorchSharp.torch.Tensor)">
            <summary>
            Returns the maximum value of each slice of the input tensor in the given dimension(s) dim.
            </summary>
            <param name="dims">The dimension or dimensions to reduce.</param>
            <param name="keepdim">Whether the output tensor has dim retained or not.</param>
            <param name="out">The output tensor -- optional.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.amax(System.Int64[])">
            <summary>
            Returns the maximum value of each slice of the input tensor in the given dimension(s) dim.
            </summary>
            <param name="dims">The dimension or dimensions to reduce.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.amax(System.ReadOnlySpan{System.Int64},System.Boolean,TorchSharp.torch.Tensor)">
            <summary>
            Returns the maximum value of each slice of the input tensor in the given dimension(s) dim.
            </summary>
            <param name="dims">The dimension or dimensions to reduce.</param>
            <param name="keepdim">Whether the output tensor has dim retained or not.</param>
            <param name="out">The output tensor -- optional.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.amin(System.ReadOnlySpan{System.Int64},System.Boolean,TorchSharp.torch.Tensor)">
            <summary>
            Returns the minimum value of each slice of the input tensor in the given dimension(s) dim.
            </summary>
            <param name="dims">The dimension or dimensions to reduce.</param>
            <param name="keepdim">Whether the output tensor has dim retained or not.</param>
            <param name="out">The output tensor -- optional.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.amin(System.Int64[],System.Boolean,TorchSharp.torch.Tensor)">
            <summary>
            Returns the minimum value of each slice of the input tensor in the given dimension(s) dim.
            </summary>
            <param name="dims">The dimension or dimensions to reduce.</param>
            <param name="keepdim">Whether the output tensor has dim retained or not.</param>
            <param name="out">The output tensor -- optional.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.amin(System.Int64[])">
            <summary>
            Returns the minimum value of each slice of the input tensor in the given dimension(s) dim.
            </summary>
            <param name="dims">The dimension or dimensions to reduce.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.aminmax(System.Nullable{System.Int64},System.Boolean)">
            <summary>
            Computes the minimum and maximum values of the input tensor.
            </summary>
            <param name="dim">The dimension along which to compute the values. If null, computes the values over the entire input tensor</param>
            <param name="keepdim"> If true, the reduced dimensions will be kept in the output tensor as dimensions with size 1 for broadcasting.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.any">
            <summary>
            Tests if any element in input evaluate to true.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.any(System.Int64,System.Boolean)">
            <summary>
            Tests if any element in input evaluate to true.
            </summary>
            <param name="dim">The dimension to reduce</param>
            <param name="keepdim">Keep the dimension to reduce</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.argmax">
            <summary>
            Returns the indices of the maximum value of all elements in the input tensor.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.argmax(System.Int64,System.Boolean)">
            <summary>
            Returns the indices of the maximum value of all elements in the input tensor.
            </summary>
            <param name="dim"></param>
            <param name="keepdim"></param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.argmin">
            <summary>
            Returns the indices of the minimum value of all elements in the input tensor.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.argmin(System.Int64,System.Boolean)">
            <summary>
            Returns the indices of the minimum value of all elements in the input tensor.
            </summary>
            <param name="dim"></param>
            <param name="keepdim"></param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.argsort(System.Int64,System.Boolean)">
            <summary>
            Returns the indices that sort a tensor along a given dimension in ascending order by value.
            </summary>
            <param name="dim">The dimension to sort along</param>
            <param name="descending">Controls the sorting order (ascending or descending)</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.deg2rad">
            <summary>
            Convert each element from degrees to radians.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.rad2deg">
            <summary>
            Convert each element from radians to degrees.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.copysign(TorchSharp.torch.Tensor)">
            <summary>
            Create a new floating-point tensor with the magnitude of input and the sign of other, elementwise.
            Supports broadcasting to a common shape, and integer and float inputs.
            </summary>
            <param name="other">contains value(s) whose signbit(s) are applied to the magnitudes in input.</param>
            <returns>the output tensor</returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.count_nonzero(System.Int64[])">
            <summary>
            Counts the number of non-zero values in the tensor input along the given dim. If no dim is specified then all non-zeros in the tensor are counted.
            </summary>
            <param name="dims">List of dims along which to count non-zeros.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.cov(System.Int64,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Estimates the covariance matrix of the variables given by the input matrix, where rows are the variables and columns are the observations.
            </summary>
            <param name="correction">
            Difference between the sample size and sample degrees of freedom.
            Defaults to Bessel’s correction, correction = 1 which returns the unbiased estimate,
            even if both fweights and aweights are specified.
            Correction = 0 will return the simple average.
            </param>
            <param name="fweights">
            A Scalar or 1D tensor of observation vector frequencies representing the number of times each observation should be repeated.
            Its numel must equal the number of columns of input.
            Must have integral dtype.</param>
            <param name="aweights">A Scalar or 1D array of observation vector weights.
            These relative weights are typically large for observations considered “important” and smaller for
            observations considered less “important”.
            Its numel must equal the number of columns of input.
            Must have floating point dtype.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.corrcoef">
            <summary>
            Estimates the Pearson product-moment correlation coefficient matrix of the variables given by the input matrix, where rows are the variables and columns are the observations.
            </summary>
            <remarks>
            Due to floating point rounding, the resulting array may not be Hermitian and its diagonal elements may not be 1.
            The real and imaginary values are clipped to the interval [-1, 1] in an attempt to improve this situation.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.tile(System.Int64[])">
            <summary>
            Constructs a tensor by repeating the elements of input. The reps argument specifies the number of repetitions in each dimension.
            </summary>
            <param name="reps">The number of repetitions per dimension.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.digamma">
            <summary>
            Computes the logarithmic derivative of the gamma function on input.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.digamma_">
            <summary>
            Computes the logarithmic derivative of the gamma function on input, in place.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.lgamma">
            <summary>
            Computes the logarithm of the gamma function on input.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.lgamma_">
            <summary>
            Computes the logarithm of the gamma function on input, in place.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.mvlgamma(System.Int64)">
            <summary>
            Computes the multivariate log-gamma function) with dimension pp element-wise
            </summary>
            <param name="p">The number of dimensions</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.mvlgamma_(System.Int64)">
            <summary>
            Computes the multivariate log-gamma function) with dimension pp element-wise, in place.
            </summary>
            <param name="p">The number of dimensions</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.positive">
            <summary>
            Returns input. Throws a runtime error if input is a bool tensor.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.softmax(System.Int64,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Computes the softmax function for the input tensor.
            </summary>
            <param name="dim">A dimension along which softmax will be computed.</param>
            <param name="dtype">The desired data type of returned tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.igamma(TorchSharp.torch.Tensor)">
            <summary>
            Computes the regularized lower incomplete gamma function
            </summary>
            <param name="other">The second non-negative input tensor</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.igammac(TorchSharp.torch.Tensor)">
            <summary>
            Computes the regularized upper incomplete gamma function.
            </summary>
            <param name="other">The second non-negative input tensor</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.i0">
            <summary>
            Computes the zeroth order modified Bessel function of the first kind for each element of input.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.isclose(TorchSharp.torch.Tensor,System.Double,System.Double,System.Boolean)">
            <summary>
            Returns a new tensor with boolean elements representing if each element of input is “close” to the corresponding element of other.
            </summary>
            <param name="other">Second tensor to compare</param>
            <param name="rtol">Relative tolerance</param>
            <param name="atol">Absolute tolerance</param>
            <param name="nanEqual">If true, then two NaN s will be considered equal</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.isin(TorchSharp.torch.Tensor,System.Boolean,System.Boolean)">
            <summary>
            Tests if each element of elements is in test_elements.
            Returns a boolean tensor of the same shape as elements that is true for elements in test_elements and false otherwise.
            </summary>
            <param name="test_elements">Values against which to test for each input element</param>
            <param name="assumeUnique">If true, assumes both elements and test_elements contain unique elements, which can speed up the calculation.</param>
            <param name="invert">If true, inverts the boolean return tensor, resulting in true values for elements not in test_elements.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.isnan">
            <summary>
            Returns a new tensor with boolean elements representing if each element of input is <value>NaN</value> or not.
            Complex values are considered <value>NaN</value> when either their real and/or imaginary part is <value>NaN</value>.
            </summary>
            <returns>A boolean tensor that is <value>True</value> where tensor is <value>NaN</value> and <value>False</value> elsewhere</returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.lerp(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Does a linear interpolation of two tensors start (given by input) and end based on a scalar or
            tensor weight and returns the resulting out tensor.
            </summary>
            <param name="end">The tensor with the ending points</param>
            <param name="weight">The weight for the interpolation formula</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.lerp_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Does an inplace linear interpolation of two tensors start (given by input) and end based on a scalar or
            tensor weight and returns the resulting out tensor.
            </summary>
            <param name="end">The tensor with the ending points</param>
            <param name="weight">The weight for the interpolation formula</param>
            <remarks>The 'start' tensor will be overwritten by the operation.</remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.baddbmm(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Single,System.Single)">
            <summary>
            Performs a batch matrix-matrix product of matrices in batch1 and batch2. input is added to the final result.
            batch1 and batch2 must be 3-D tensors each containing the same number of matrices.
            </summary>
            <param name="batch1">The first batch of matrices to be multiplied</param>
            <param name="batch2">The second batch of matrices to be multiplied</param>
            <param name="beta">A multiplier for input</param>
            <param name="alpha">A multiplier for batch1 @ batch2</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.bmm(TorchSharp.torch.Tensor)">
            <summary>
            Performs a batch matrix-matrix product of matrices stored in input and mat2.
            </summary>
            <param name="batch2">the second batch of matrices to be multiplied</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.bucketize(TorchSharp.torch.Tensor,System.Boolean,System.Boolean)">
            <summary>
            Returns the indices of the buckets to which each value in the input belongs, where the boundaries of the buckets are set by boundaries.
            Return a new tensor with the same size as input. If right is false (default), then the left boundary is closed.
            </summary>
            <param name="boundaries">1-D tensor, must contain a monotonically increasing sequence.</param>
            <param name="outInt32">indicate the output data type. torch.int32 if True, torch.int64 otherwise.
            Default value is False, i.e. default output data type is torch.int64.</param>
            <param name="right">if false, return the first suitable location that is found. If rrue, return the last such index.
            If no suitable index found, return 0 for non-numerical value (eg. nan, inf) or the size of boundaries (one pass the last index).
            In other words, if false, gets the lower bound index for each value in input from boundaries.
            If true, gets the upper bound index instead. Default value is False.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.bincount(TorchSharp.torch.Tensor,System.Int64)">
            <summary>
            Count the frequency of each value in an array of non-negative ints.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.channel_shuffle(System.Int64)">
             <summary>
             Divide the channels in a tensor into g groups and rearrange them.
            
             See: https://pytorch.org/docs/1.10/generated/torch.nn.ChannelShuffle.html#channelshuffle
             </summary>
             <param name="groups">The number of groups to divide channels in.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.clamp(TorchSharp.Scalar,TorchSharp.Scalar)">
            <summary>
            Clamps all elements in input into the range [ min, max ].
            </summary>
            <param name="min">The minimum value</param>
            <param name="max">The maximum value</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.clamp(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Clamps all elements in input into the range [ min, max ].
            </summary>
            <param name="min">The minimum value</param>
            <param name="max">The maximum value</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.clip(TorchSharp.Scalar,TorchSharp.Scalar)">
            <summary>
            Alias for 'clamp'
            </summary>
            <param name="min">The minimum value</param>
            <param name="max">The maximum value</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.clamp_(TorchSharp.Scalar,TorchSharp.Scalar)">
            <summary>
            Clamps all elements in input into the range [ min, max ] in place.
            </summary>
            <param name="min">The minimum value</param>
            <param name="max">The maximum value</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.clamp_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Clamps all elements in input into the range [ min, max ] in place.
            </summary>
            <param name="min">The minimum value</param>
            <param name="max">The maximum value</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.diff(System.Int64,System.Int64,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Computes the n-th forward difference along the given dimension.
            </summary>
            <param name="n">The number of times to recursively compute the difference</param>
            <param name="dim">The dimension to compute the difference along. Default is the last dimension.</param>
            <param name="prepend">
            Values to prepend or append to input along dim before computing the difference.
            Their dimensions must be equivalent to that of input, and their shapes must match input’s shape except on dim.
            </param>
            <param name="append">
            Values to prepend or append to input along dim before computing the difference.
            Their dimensions must be equivalent to that of input, and their shapes must match input’s shape except on dim.
            </param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.diag(System.Int64)">
            <summary>
            If input is a vector (1-D tensor), then returns a 2-D square tensor with the elements of input as the diagonal.
            If input is a matrix (2-D tensor), then returns a 1-D tensor with the diagonal elements of input.
            </summary>
            <param name="diagonal">
            The argument diagonal controls which diagonal to consider:
            If diagonal is 0, it is the main diagonal.
            If diagonal is greater than 0, it is above the main diagonal.
            If diagonal is less than 0, it is below the main diagonal.
            </param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.trace">
            <summary>
            Returns the sum of the elements of the diagonal of the input 2-D matrix.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.diag_embed(System.Int64,System.Int64,System.Int64)">
             <summary>
             Creates a tensor whose diagonals of certain 2D planes (specified by dim1 and dim2) are filled by input.
             To facilitate creating batched diagonal matrices, the 2D planes formed by the last two dimensions of the returned tensor are chosen by default.
            
             The argument offset controls which diagonal to consider:
               If offset is equal to 0, it is the main diagonal.
               If offset is greater than 0, it is above the main diagonal.
               If offset is less than 0, it is below the main diagonal.
            
             The size of the new matrix will be calculated to make the specified diagonal of the size of the last input dimension.Note that for offset other than 0,
            
             the order of dim1 and dim2 matters.Exchanging them is equivalent to changing the sign of offset.
             </summary>
             <param name="offset">Which diagonal to consider.</param>
             <param name="dim1">First dimension with respect to which to take diagonal. </param>
             <param name="dim2">Second dimension with respect to which to take diagonal</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.diagflat(System.Int64)">
            <summary>
            If input is a vector (1-D tensor), then returns a 2-D square tensor with the elements of input as the diagonal.
            If input is a matrix (2-D tensor), then returns a 2-D tensor with diagonal elements equal to a flattened input.
            </summary>
            <param name="offset">
            The argument diagonal controls which diagonal to consider:
            If diagonal is 0, it is the main diagonal.
            If diagonal is greater than 0, it is above the main diagonal.
            If diagonal is less than 0, it is below the main diagonal.
            </param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.diagonal(System.Int64,System.Int64,System.Int64)">
             <summary>
             Returns a partial view of input with the its diagonal elements with respect to dim1 and dim2 appended as a dimension at the end of the shape.
             The argument offset controls which diagonal to consider:
            
             If offset = 0, it is the main diagonal.
             If offset &gt; 0, it is above the main diagonal.
             If offset &lt; 0, it is below the main diagonal.
             </summary>
             <param name="offset">Which diagonal to consider. Default: 0 (main diagonal).</param>
             <param name="dim1">First dimension with respect to which to take diagonal. Default: 0.</param>
             <param name="dim2">Second dimension with respect to which to take diagonal. Default: 1.</param>
             <remarks>
             Applying torch.diag_embed() to the output of this function with the same arguments yields a diagonal matrix with the diagonal entries of the input.
             However, torch.diag_embed() has different default dimensions, so those need to be explicitly specified.
             </remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.erf">
            <summary>
            Computes the error function of the input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.erf_">
            <summary>
            Computes the error function of the input in place.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.erfc">
            <summary>
            Computes the complementary error function of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.erfc_">
            <summary>
            Computes the complementary error function of input in place
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.erfinv">
            <summary>
            Computes the inverse error function of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.erfinv_">
            <summary>
            Computes the inverse error function of input in place.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.allclose(TorchSharp.torch.Tensor,System.Double,System.Double,System.Boolean)">
            <summary>
            This function checks if all input and other lie within a certain distance from each other
            </summary>
            <param name="target"></param>
            <param name="rtol">Relative tolerance</param>
            <param name="atol">Absolute tolerance</param>
            <param name="equal_nan">If true, then two NaN s will be considered equal</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.kron(TorchSharp.torch.Tensor)">
            <summary>
            Computes the Kronecker product of input and other.
            </summary>
            <param name="other">The second tensor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.lcm(TorchSharp.torch.Tensor)">
            <summary>
            Computes the element-wise least common multiple (LCM) of input and other.
            </summary>
            <param name="other">The second input tensor.</param>
            <remarks>Both input and other must have integer types.</remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.lcm_(TorchSharp.torch.Tensor)">
            <summary>
            Computes the element-wise least common multiple (LCM) of input and other, in place.
            </summary>
            <param name="other">The second input tensor.</param>
            <remarks>Both input and other must have integer types.</remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.ldexp(TorchSharp.torch.Tensor)">
            <summary>
            Multiplies input by pow(2,other).
            </summary>
            <param name="other">A tensor of exponents, typically integers</param>
            <remarks>Typically this function is used to construct floating point numbers by multiplying mantissas in input with integral powers of two created from the exponents in other.</remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.ldexp_(TorchSharp.torch.Tensor)">
            <summary>
            Multiplies input by pow(2,other) in place.
            </summary>
            <param name="other">A tensor of exponents, typically integers</param>
            <remarks>Typically this function is used to construct floating point numbers by multiplying mantissas in input with integral powers of two created from the exponents in other.</remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.unbind(System.Int64)">
            <summary>
            Removes a tensor dimension.
            </summary>
            <param name="dimension">The dimension to remove.</param>
            <returns>An array of all slices along a given dimension, already without it.</returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.unfold(System.Int64,System.Int64,System.Int64)">
            <summary>
            Returns a view of the original tensor which contains all slices of size 'size' from the tensor in the given dimension.
            </summary>
            <param name="dimension">Dimension in which unfolding happens</param>
            <param name="size">The size of each slice that is unfolded</param>
            <param name="step">The step between each slice</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.split(System.Int64,System.Int32)">
            <summary>
            Splits the tensor into chunks. Each chunk is a view of the original tensor.
            </summary>
            <param name="size">The size of a single chunk</param>
            <param name="dim">The dimension along which to split the tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.split(System.ReadOnlySpan{System.Int64},System.Int64)">
            <summary>
            Splits the tensor into chunks. Each chunk is a view of the original tensor.
            </summary>
            <param name="sizes">A list of sizes for each chunk</param>
            <param name="dim">The dimension along which to split the tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.split(System.Int64[],System.Int64)">
            <summary>
            Splits the tensor into chunks. Each chunk is a view of the original tensor.
            </summary>
            <param name="sizes">A list of sizes for each chunk</param>
            <param name="dim">The dimension along which to split the tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.split(System.Int64[])">
            <summary>
            Splits the tensor into chunks. Each chunk is a view of the original tensor.
            </summary>
            <param name="sizes">A list of sizes for each chunk</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.tensor_split(System.Int64,System.Int64)">
            <summary>
            Splits a tensor into multiple sub-tensors, all of which are views of input, along dimension dim according to the indices or number of sections specified by indices_or_sections.
            </summary>
            <param name="size"></param>
            <param name="dim"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.tensor_split(System.Int64[],System.Int64)">
            <summary>
            Splits a tensor into multiple sub-tensors, all of which are views of input, along dimension dim according to the indices or number of sections specified by indices_or_sections.
            </summary>
            <param name="sizes"></param>
            <param name="dim"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.vsplit(System.Int64)">
            <summary>
            Splits input, a tensor with one or more dimensions, into multiple tensors vertically according to sizes.
            </summary>
            <param name="size">The size of each chunk</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.vsplit(System.Int64[])">
            <summary>
            Splits input, a tensor with one or more dimensions, into multiple tensors vertically according to sizes.
            </summary>
            <param name="sizes">A list of split points</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.vsplit(TorchSharp.torch.Tensor)">
            <summary>
            Splits input, a tensor with one or more dimensions, into multiple tensors vertically according to indices.
            </summary>
            <param name="indices">A list of split points</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.hsplit(System.Int64)">
            <summary>
            Splits input, a tensor with one or more dimensions, into multiple tensors horizontally according to sizes.
            </summary>
            <param name="size">The size of each chunk</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.hsplit(System.Int64[])">
            <summary>
            Splits input, a tensor with one or more dimensions, into multiple tensors horizontally according to sizes.
            </summary>
            <param name="sizes">A list of split points</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.hsplit(TorchSharp.torch.Tensor)">
            <summary>
            Splits input, a tensor with one or more dimensions, into multiple tensors horizontally according to indices.
            </summary>
            <param name="indices">A list of split points</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.dsplit(System.Int64)">
            <summary>
            Splits input, a tensor with three or more dimensions, into multiple tensors depthwise according to indices_or_sections. Each split is a view of input.
            </summary>
            <param name="size">The size of each chunk</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.dsplit(System.ValueTuple{System.Int64,System.Int64})">
            <summary>
            Splits input, a tensor with three or more dimensions, into multiple tensors depthwise according to indices_or_sections. Each split is a view of input.
            </summary>
            <param name="indices_or_sections">A list of split points</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.dsplit(System.ValueTuple{System.Int64,System.Int64,System.Int64})">
            <summary>
            Splits input, a tensor with three or more dimensions, into multiple tensors depthwise according to indices_or_sections. Each split is a view of input.
            </summary>
            <param name="indices_or_sections">A list of split points</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.dsplit(System.ValueTuple{System.Int64,System.Int64,System.Int64,System.Int64})">
            <summary>
            Splits input, a tensor with three or more dimensions, into multiple tensors depthwise according to indices_or_sections. Each split is a view of input.
            </summary>
            <param name="indices_or_sections">A list of split points</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.dsplit(System.Int64[])">
            <summary>
            Splits input, a tensor with three or more dimensions, into multiple tensors depthwise according to indices_or_sections. Each split is a view of input.
            </summary>
            <param name="sizes">A list of split points</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.dsplit(TorchSharp.torch.Tensor)">
            <summary>
            Splits input, a tensor with three or more dimensions, into multiple tensors depthwise according to indices_or_sections. Each split is a view of input.
            </summary>
            <param name="indices">A list of split points</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.chunk(System.Int64,System.Int64)">
            <summary>
            Splits a tensor into a specific number of chunks. Each chunk is a view of the input tensor.
            </summary>
            <param name="chunks">The number of chunks to return</param>
            <param name="dim">Dimension along which to split the tensor</param>
            <remarks>The last chunk will be smaller if the tensor size along the given dimension dim is not divisible by chunks.</remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.kthvalue(System.Int64,System.Nullable{System.Int64},System.Boolean)">
            <summary>
            Returns a named tuple (values, indices) where values is the k th smallest element of each row of the input tensor in the given dimension dim. And indices is the index location of each element found.
            If dim is not given, the last dimension of the input is chosen.
            </summary>
            <param name="k">k for the k-th smallest element</param>
            <param name="dim">The dimension to find the kth value along</param>
            <param name="keepdim">Whether the output tensor has dim retained or not.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.kthvalue(TorchSharp.torch.Tensor,System.Int64,System.Nullable{System.Int64},System.Boolean)">
            <summary>
            Returns a named tuple (values, indices) where values is the k th smallest element of each row of the input tensor in the given dimension dim. And indices is the index location of each element found.
            If dim is not given, the last dimension of the input is chosen.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="k">k for the k-th smallest element</param>
            <param name="dim">The dimension to find the kth value along</param>
            <param name="keepdim">Whether the output tensor has dim retained or not.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.max">
            <summary>
            Returns the maximum value of all elements in the input tensor.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.maximum(TorchSharp.torch.Tensor)">
            <summary>
            Computes the element-wise maximum of input and other.
            </summary>
            <param name="other">The second input tensor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.max(TorchSharp.torch.Tensor)">
            <summary>
            Computes the element-wise maximum of input and other.
            </summary>
            <param name="other">The second input tensor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.max(System.Int64,System.Boolean)">
            <summary>
            Returns a named tuple (values, indexes) where values is the maximum value of each row of the input tensor in the given dimension dim.
            And indices is the index location of each maximum value found (argmax).
            </summary>
            <param name="dim">the dimension to reduce.</param>
            <param name="keepdim">whether the output tensor has dim retained or not. Default: false.</param>
            <remarks>If keepdim is true, the output tensors are of the same size as input except in the dimension dim where they are of size 1.
            Otherwise, dim is squeezed(see torch.squeeze()), resulting in the output tensors having 1 fewer dimension than input.</remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.mean">
            <summary>
            Returns the mean value of all elements in the input tensor.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.quantile(TorchSharp.torch.Tensor,System.Int64,System.Boolean)">
            <summary>
            Returns the q-th quantiles of all elements in the input tensor, doing a linear interpolation when the q-th quantile lies between two data points.
            </summary>
            <param name="q">1D tensor of quantile values in the range [0, 1]</param>
            <param name="dim">The dimension to reduce.</param>
            <param name="keepdim">Whether the output tensor has dim retained or not.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.nanquantile(TorchSharp.torch.Tensor,System.Int64,System.Boolean)">
            <summary>
            This is a variant of torch.quantile() that “ignores” NaN values, computing the quantiles q as if NaN values in input did not exist.
            If all values in a reduced row are NaN then the quantiles for that reduction will be NaN.
            </summary>
            <seealso cref="M:TorchSharp.torch.Tensor.quantile(TorchSharp.torch.Tensor,System.Int64,System.Boolean)"/>
            <param name="q">1D tensor of quantile values in the range [0, 1]</param>
            <param name="dim">The dimension to reduce.</param>
            <param name="keepdim">Whether the output tensor has dim retained or not.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.mode(System.Int64,System.Boolean)">
            <summary>
            Returns a named tuple (values, indices) where values is the mode value of each row of the input tensor in the given dimension dim,
            i.e. a value which appears most often in that row, and indices is the index location of each mode value found.
            </summary>
            <param name="dim">The dimension to reduce, the last dimension by default.</param>
            <param name="keepdim">Whether the output tensor has dim retained or not</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.mean(System.Int64[],System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Returns the mean value of each row of the input tensor in the given dimension dim. If dim is a list of dimensions, reduce over all of them.
            </summary>
            <param name="dimensions">The dimension or dimensions to reduce.</param>
            <param name="keepdim">Whether the output tensor has dim retained or not.</param>
            <param name="type">The desired data type of returned tensor. If specified, the input tensor is cast to dtype before the operation is performed. This is useful for preventing data type overflows.</param>
            <remarks>
            If keepdim is True, the output tensor is of the same size as input except in the dimension(s) dim where it is of size 1.
            Otherwise, dim is squeezed(see torch.squeeze()), resulting in the output tensor having 1 (or len(dim)) fewer dimension(s).
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.median">
            <summary>
            Returns the median of the values in input.
            </summary>
            <remarks>
            The median is not unique for input tensors with an even number of elements.
            In this case the lower of the two medians is returned. To compute the mean of both medians, use torch.quantile() with q=0.5 instead.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.min">
            <summary>
            Returns the minimum value of all elements in the input tensor.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.min(TorchSharp.torch.Tensor)">
            <summary>
            Computes the element-wise minimum of input and other.
            </summary>
            <param name="other">The second input tensor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.minimum(TorchSharp.torch.Tensor)">
            <summary>
            Computes the element-wise minimum of input and other.
            </summary>
            <param name="other">The second input tensor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.min(System.Int64,System.Boolean)">
            <summary>
            Returns a named tuple (values, indexes) where values is the minimum value of each row of the input tensor in the given dimension dim.
            And indices is the index location of each minimum value found (argmin).
            </summary>
            <param name="dim">the dimension to reduce.</param>
            <param name="keepdim">whether the output tensor has dim retained or not. Default: false.</param>
            <remarks>
            If keepdim is true, the output tensors are of the same size as input except in the dimension dim where they are of size 1.
            Otherwise, dim is squeezed(see torch.squeeze()), resulting in the output tensors having 1 fewer dimension than input.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.msort">
            <summary>
            Sorts the elements of the input tensor along its first dimension in ascending order by value.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.sort(System.Int64,System.Boolean,System.Boolean)">
            <summary>
            Sorts the elements of the input tensor along a given dimension in ascending order by value.
            </summary>
            <param name="dim">The dimension to sort along. If dim is not given, the last dimension of the input is chosen.</param>
            <param name="descending">Controls the sorting order (ascending or descending)</param>
            <param name="stable">Makes the sorting routine stable, which guarantees that the order of equivalent elements is preserved.</param>
            <returns>A named tuple of (values, indices) is returned, where the values are the sorted values and indices are the indices of the elements in the original input tensor.</returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.dist(TorchSharp.torch.Tensor,System.Single)">
            <summary>
            Returns the p-norm of (input - other).
            The shapes of input and other must be broadcastable.
            </summary>
            <param name="other">Right-hand side input.</param>
            <param name="p">The norm to be computed.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.norm(System.Single)">
            <summary>
            Returns the matrix norm or vector norm of a given tensor.
            </summary>
            <param name="p">The norm to be computed.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.norm(System.Int32,System.Boolean,System.Single)">
            <summary>
            Returns the matrix norm or vector norm of a given tensor.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.outer(TorchSharp.torch.Tensor)">
            <summary>
            Outer product of input and vec2.
            </summary>
            <param name="vec2">1-D input vector.</param>
            <remarks>If input is a vector of size n and vec2 is a vector of size m, then out must be a matrix of size n×m.</remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.ger(TorchSharp.torch.Tensor)">
            <summary>
            Outer product of input and vec2.
            </summary>
            <param name="vec2">1-D input vector.</param>
            <remarks>If input is a vector of size n and vec2 is a vector of size m, then out must be a matrix of size n×m.</remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.inner(TorchSharp.torch.Tensor)">
            <summary>
            Computes the dot product for 1D tensors.
            For higher dimensions, sums the product of elements from input and other along their last dimension.
            </summary>
            <param name="vec2"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.inverse">
            <summary>
            Alias for torch.linalg.inv()
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.fmax(TorchSharp.torch.Tensor)">
             <summary>
             Computes the element-wise maximum of input and other.
            
             This is like torch.maximum() except it handles NaNs differently: if exactly one of the two elements being compared is a NaN
             then the non-NaN element is taken as the maximum.
             Only if both elements are NaN is NaN propagated.
             </summary>
             <param name="other">The second input tensor</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.fmin(TorchSharp.torch.Tensor)">
             <summary>
             Computes the element-wise minimum of input and other.
            
             This is like torch.minimum() except it handles NaNs differently: if exactly one of the two elements being compared is a NaN
             then the non-NaN element is taken as the minimum.
             Only if both elements are NaN is NaN propagated.
             </summary>
             <param name="other">The second input tensor</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.renorm(System.Single,System.Int64,System.Single)">
            <summary>
            Returns a tensor where each sub-tensor of input along dimension dim is normalized such that the p-norm of the sub-tensor is lower than the value maxnorm
            </summary>
            <param name="p">The power for the norm computation</param>
            <param name="dim">The dimension to slice over to get the sub-tensors</param>
            <param name="maxnorm">The maximum norm to keep each sub-tensor under</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.sigmoid">
            <summary>
            Alias for torch.special.expit()
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.sigmoid_">
            <summary>
            Alias for torch.special.expit(), works in place.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.std(System.Boolean)">
            <summary>
            Calculates the standard deviation of all elements in the tensor.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.var(System.Boolean)">
            <summary>
            Compute variance of elements of input tensor.
            </summary>
            <param name="unbiased">If unbiased is true, Bessel’s correction will be used. Otherwise, the sample variance is calculated, without any correction.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.std(System.ReadOnlySpan{System.Int64},System.Boolean,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>Calculates the standard deviation of all elements in the tensor.</summary>
            <remarks>
            If <paramref name="unbiased" /> is <value>true</value>, Bessel’s correction will be used.
            Otherwise, the sample deviation is calculated, without any correction.
            </remarks>
            <param name="dimensions">The dimensions to reduce.</param>
            <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
            <param name="keepdim">Whether the <see cref="T:TorchSharp.torch.Tensor">output tensor</see> has dim retained or not.</param>
            <param name="type"></param>
            <returns>The <see cref="T:TorchSharp.torch.Tensor">output tensor</see>.</returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.var(System.ReadOnlySpan{System.Int64},System.Boolean,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>Calculates the variance of all elements in the input tensor.</summary>
             <remarks>
             If <paramref name="unbiased" /> is <value>true</value>, Bessel’s correction will be used.
             Otherwise, the sample variance is calculated, without any correction.
             </remarks>
             <param name="dimensions">The dimensions to reduce.</param>
             <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
             <param name="keepdim">Whether the <see cref="T:TorchSharp.torch.Tensor">output tensor</see> has dim retained or not.</param>
             <param name="type"></param>
             <returns>The <see cref="T:TorchSharp.torch.Tensor">output tensor</see>.</returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.std(System.Int64[],System.Boolean,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>Calculates the standard deviation of all elements in the tensor.</summary>
            <remarks>
            If <paramref name="unbiased" /> is <value>true</value>, Bessel’s correction will be used.
            Otherwise, the sample deviation is calculated, without any correction.
            </remarks>
            <param name="dimensions">The dimensions to reduce.</param>
            <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
            <param name="keepdim">Whether the <see cref="T:TorchSharp.torch.Tensor">output tensor</see> has dim retained or not.</param>
            <param name="type"></param>
            <returns>The <see cref="T:TorchSharp.torch.Tensor">output tensor</see>.</returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.var(System.Int64[],System.Boolean,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>Calculates the variance of all elements in the input tensor.</summary>
             <remarks>
             If <paramref name="unbiased" /> is <value>true</value>, Bessel’s correction will be used.
             Otherwise, the sample variance is calculated, without any correction.
             </remarks>
             <param name="dimensions">The dimensions to reduce.</param>
             <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
             <param name="keepdim">Whether the <see cref="T:TorchSharp.torch.Tensor">output tensor</see> has dim retained or not.</param>
             <param name="type"></param>
             <returns>The <see cref="T:TorchSharp.torch.Tensor">output tensor</see>.</returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.std(System.Int64,System.Boolean,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>Calculates the standard deviation of all elements in the tensor.</summary>
            <remarks>
            If <paramref name="unbiased" /> is <value>true</value>, Bessel’s correction will be used.
            Otherwise, the sample deviation is calculated, without any correction.
            </remarks>
            <param name="dim">The dimension to reduce.</param>
            <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
            <param name="keepdim">Whether the <see cref="T:TorchSharp.torch.Tensor">output tensor</see> has <paramref name="dim" /> retained or not.</param>
            <param name="type"></param>
            <returns>The <see cref="T:TorchSharp.torch.Tensor">output tensor</see>.</returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.var(System.Int64,System.Boolean,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>Calculates the variance of all elements in the tensor.</summary>
            <remarks>
            If <paramref name="unbiased" /> is <value>true</value>, Bessel’s correction will be used.
            Otherwise, the sample variance is calculated, without any correction.
            </remarks>
            <param name="dim">The dimension to reduce.</param>
            <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
            <param name="keepdim">Whether the <see cref="T:TorchSharp.torch.Tensor">output tensor</see> has <paramref name="dim" /> retained or not.</param>
            <param name="type"></param>
            <returns>The <see cref="T:TorchSharp.torch.Tensor">output tensor</see>.</returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.std(System.ValueTuple{System.Int64,System.Int64},System.Boolean,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>Calculates the standard deviation of all elements in the tensor.</summary>
            <remarks>
            If <paramref name="unbiased" /> is <value>true</value>, Bessel’s correction will be used.
            Otherwise, the sample deviation is calculated, without any correction.
            </remarks>
            <param name="dim">The dimensions to reduce.</param>
            <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
            <param name="keepdim">Whether the <see cref="T:TorchSharp.torch.Tensor">output tensor</see> has <paramref name="dim" /> retained or not.</param>
            <param name="type"></param>
            <returns>The <see cref="T:TorchSharp.torch.Tensor">output tensor</see>.</returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.var(System.ValueTuple{System.Int64,System.Int64},System.Boolean,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>Calculates the variance of all elements in the tensor.</summary>
            <remarks>
            If <paramref name="unbiased" /> is <value>true</value>, Bessel’s correction will be used.
            Otherwise, the sample variance is calculated, without any correction.
            </remarks>
            <param name="dim">The dimensions to reduce.</param>
            <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
            <param name="keepdim">Whether the <see cref="T:TorchSharp.torch.Tensor">output tensor</see> has <paramref name="dim" /> retained or not.</param>
            <param name="type"></param>
            <returns>The <see cref="T:TorchSharp.torch.Tensor">output tensor</see>.</returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.std(System.ValueTuple{System.Int64,System.Int64,System.Int64},System.Boolean,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>Calculates the standard deviation of all elements in the tensor.</summary>
            <remarks>
            If <paramref name="unbiased" /> is <value>true</value>, Bessel’s correction will be used.
            Otherwise, the sample deviation is calculated, without any correction.
            </remarks>
            <param name="dim">The dimensions to reduce.</param>
            <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
            <param name="keepdim">Whether the <see cref="T:TorchSharp.torch.Tensor">output tensor</see> has <paramref name="dim" /> retained or not.</param>
            <param name="type"></param>
            <returns>The <see cref="T:TorchSharp.torch.Tensor">output tensor</see>.</returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.var(System.ValueTuple{System.Int64,System.Int64,System.Int64},System.Boolean,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>Calculates the variance of all elements in the tensor.</summary>
            <remarks>
            If <paramref name="unbiased" /> is <value>true</value>, Bessel’s correction will be used.
            Otherwise, the sample deviation is calculated, without any correction.
            </remarks>
            <param name="dim">The dimensions to reduce.</param>
            <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
            <param name="keepdim">Whether the <see cref="T:TorchSharp.torch.Tensor">output tensor</see> has <paramref name="dim" /> retained or not.</param>
            <param name="type"></param>
            <returns>The <see cref="T:TorchSharp.torch.Tensor">output tensor</see>.</returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.std_mean(System.Boolean)">
            <summary>
            Calculates the standard deviation and mean of all elements in the tensor.
            </summary>
            <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
            <returns>A <see cref="T:TorchSharp.torch.Tensor">tensor</see> tuple of the standard deviation and the mean.</returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.var_mean(System.Boolean)">
            <summary>
            Calculates the variance and mean of all elements in the tensor.
            </summary>
            <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
            <returns>A <see cref="T:TorchSharp.torch.Tensor">tensor</see> tuple of the variance and the mean.</returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.std_mean(System.Int64[],System.Boolean,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>Calculates the standard deviation and mean of all elements in the tensor.</summary>
            <remarks>
            If <paramref name="unbiased" /> is <value>true</value>, Bessel’s correction will be used.
            Otherwise, the sample deviation is calculated, without any correction.
            </remarks>
            <param name="dimensions">The dimensions to reduce.</param>
            <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
            <param name="keepdim">Whether the <see cref="T:TorchSharp.torch.Tensor">output tensor</see> has dim retained or not.</param>
            <param name="type"></param>
            <returns>A <see cref="T:TorchSharp.torch.Tensor">tensor</see> tuple of the standard deviation and the mean.</returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.var_mean(System.Int64[],System.Boolean,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>Calculates the variance and mean of all elements in the tensor.</summary>
            <remarks>
            If <paramref name="unbiased" /> is <value>true</value>, Bessel’s correction will be used.
            Otherwise, the sample variance is calculated, without any correction.
            </remarks>
            <param name="dimensions">The dimensions to reduce.</param>
            <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
            <param name="keepdim">Whether the <see cref="T:TorchSharp.torch.Tensor">output tensor</see> has dim retained or not.</param>
            <param name="type"></param>
            <returns>A <see cref="T:TorchSharp.torch.Tensor">tensor</see> tuple of the standard deviation and the mean.</returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.std_mean(System.ReadOnlySpan{System.Int64},System.Boolean,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>Calculates the standard deviation and mean of all elements in the tensor.</summary>
            <remarks>
            If <paramref name="unbiased" /> is <value>true</value>, Bessel’s correction will be used.
            Otherwise, the sample deviation is calculated, without any correction.
            </remarks>
            <param name="dimensions">The dimensions to reduce.</param>
            <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
            <param name="keepdim">Whether the <see cref="T:TorchSharp.torch.Tensor">output tensor</see> has dim retained or not.</param>
            <param name="type"></param>
            <returns>A <see cref="T:TorchSharp.torch.Tensor">tensor</see> tuple of the standard deviation and the mean.</returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.var_mean(System.ReadOnlySpan{System.Int64},System.Boolean,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>Calculates the variance and mean of all elements in the tensor.</summary>
            <remarks>
            If <paramref name="unbiased" /> is <value>true</value>, Bessel’s correction will be used.
            Otherwise, the sample variance is calculated, without any correction.
            </remarks>
            <param name="dimensions">The dimensions to reduce.</param>
            <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
            <param name="keepdim">Whether the <see cref="T:TorchSharp.torch.Tensor">output tensor</see> has dim retained or not.</param>
            <param name="type"></param>
            <returns>A <see cref="T:TorchSharp.torch.Tensor">tensor</see> tuple of the standard deviation and the mean.</returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.std_mean(System.Int64,System.Boolean,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>Calculates the standard deviation and mean of all elements in the tensor.</summary>
            <remarks>
            If <paramref name="unbiased" /> is <value>true</value>, Bessel’s correction will be used.
            Otherwise, the sample deviation is calculated, without any correction.
            </remarks>
            <param name="dim">The dimension to reduce.</param>
            <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
            <param name="keepdim">Whether the <see cref="T:TorchSharp.torch.Tensor">output tensor</see> has <paramref name="dim" /> retained or not.</param>
            <param name="type"></param>
            <returns>A <see cref="T:TorchSharp.torch.Tensor">tensor</see> tuple of the standard deviation and the mean.</returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.var_mean(System.Int64,System.Boolean,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>Calculates the variance and mean of all elements in the tensor.</summary>
            <remarks>
            If <paramref name="unbiased" /> is <value>true</value>, Bessel’s correction will be used.
            Otherwise, the sample variance is calculated, without any correction.
            </remarks>
            <param name="dim">The dimension to reduce.</param>
            <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
            <param name="keepdim">Whether the <see cref="T:TorchSharp.torch.Tensor">output tensor</see> has <paramref name="dim" /> retained or not.</param>
            <param name="type"></param>
            <returns>A <see cref="T:TorchSharp.torch.Tensor">tensor</see> tuple of the variance and the mean.</returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.std_mean(System.ValueTuple{System.Int64,System.Int64},System.Boolean,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>Calculates the standard deviation and mean of all elements in the tensor.</summary>
            <remarks>
            If <paramref name="unbiased" /> is <value>true</value>, Bessel’s correction will be used.
            Otherwise, the sample deviation is calculated, without any correction.
            </remarks>
            <param name="dim">The dimensions to reduce.</param>
            <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
            <param name="keepdim">Whether the <see cref="T:TorchSharp.torch.Tensor">output tensor</see> has <paramref name="dim" /> retained or not.</param>
            <param name="type"></param>
            <returns>A <see cref="T:TorchSharp.torch.Tensor">tensor</see> tuple of the standard deviation and the mean.</returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.var_mean(System.ValueTuple{System.Int64,System.Int64},System.Boolean,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>Calculates the variance and mean of all elements in the tensor.</summary>
            <remarks>
            If <paramref name="unbiased" /> is <value>true</value>, Bessel’s correction will be used.
            Otherwise, the sample variance is calculated, without any correction.
            </remarks>
            <param name="dim">The dimensions to reduce.</param>
            <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
            <param name="keepdim">Whether the <see cref="T:TorchSharp.torch.Tensor">output tensor</see> has <paramref name="dim" /> retained or not.</param>
            <param name="type"></param>
            <returns>A <see cref="T:TorchSharp.torch.Tensor">tensor</see> tuple of the variance and the mean.</returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.std_mean(System.ValueTuple{System.Int64,System.Int64,System.Int64},System.Boolean,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>Calculates the standard deviation and mean of all elements in the tensor.</summary>
            <remarks>
            If <paramref name="unbiased" /> is <value>true</value>, Bessel’s correction will be used.
            Otherwise, the sample deviation is calculated, without any correction.
            </remarks>
            <param name="dim">The dimensions to reduce.</param>
            <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
            <param name="keepdim">Whether the <see cref="T:TorchSharp.torch.Tensor">output tensor</see> has <paramref name="dim" /> retained or not.</param>
            <param name="type"></param>
            <returns>A <see cref="T:TorchSharp.torch.Tensor">tensor</see> tuple of the standard deviation and the mean.</returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.var_mean(System.ValueTuple{System.Int64,System.Int64,System.Int64},System.Boolean,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>Calculates the variance and mean of all elements in the tensor.</summary>
            <remarks>
            If <paramref name="unbiased" /> is <value>true</value>, Bessel’s correction will be used.
            Otherwise, the sample variance is calculated, without any correction.
            </remarks>
            <param name="dim">The dimensions to reduce.</param>
            <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
            <param name="keepdim">Whether the <see cref="T:TorchSharp.torch.Tensor">output tensor</see> has <paramref name="dim" /> retained or not.</param>
            <param name="type"></param>
            <returns>A <see cref="T:TorchSharp.torch.Tensor">tensor</see> tuple of the variance and the mean.</returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.prod(System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Returns the product of all elements in the :attr:`input` tensor.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.prod(System.Int64,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Returns the product of each row of the input tensor in the given dimension.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.sum(System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Returns the sum of all elements in the :attr:`input` tensor.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.sum(System.Int64[],System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Returns the sum of each row of the input tensor in the given dimensions.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.sum(System.ReadOnlySpan{System.Int64},System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Returns the sum of each row of the input tensor in the given dimensions.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.sum(System.Int64,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Returns the sum of each row of the input tensor in the given dimension.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.sum(System.Int64,System.Int64,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Returns the sum of each row of the input tensor in the given dimensions.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.sum(System.Int64,System.Int64,System.Int64,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Returns the sum of each row of the input tensor in the given dimensions.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.expand(System.ReadOnlySpan{System.Int64},System.Boolean)">
            <summary>
            Returns a new view of the tensor with singleton dimensions expanded to a larger size.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.expand(System.Int64[],System.Boolean)">
            <summary>
            Returns a new view of the tensor with singleton dimensions expanded to a larger size.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.expand_as(TorchSharp.torch.Tensor)">
            <summary>
            Expand this tensor to the same size as other.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.expand(System.Int64[])">
            <summary>
            Returns a new view of the tensor with singleton dimensions expanded to a larger size.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.repeat(System.Int64[])">
            <summary>
            Repeats this tensor along the specified dimensions.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.broadcast_to(System.Int64[])">
            <summary>
            Broadcasts input to the shape shape. Equivalent to calling input.expand(shape).
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.randn_out(System.Int64[])">
            <summary>
            Mutates the tensor to be filled with random values taken from a normal distribution with mean 0 and variance 1.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.rand_out(System.Int64[])">
            <summary>
            Mutates the tensor to be filled with random values taken from a uniform distribution in [0, 1).
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.randint_out(System.Int64,System.Int64[])">
            <summary>
            Mutates the tensor to be filled with random values taken from a normal distribution with mean 0 and variance 1.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.rand_like(System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Returns a tensor with the same size as input that is filled with random numbers from a uniform distribution on the interval [0,1) .
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.randn_like(System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Returns a tensor with the same size as input that is filled with random numbers from a normal distribution with mean 0 and variance 1.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.randint_like(System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Returns a tensor with the same shape as Tensor input filled with random integers generated uniformly in the range [low,high).
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.randperm_out(System.Int64)">
            <summary>
            Mutates the tensor to be a 1-D tensor of size [n] with a random permutation of [0, n).
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.bernoulli(TorchSharp.torch.Generator)">
            <summary>
            Draws binary random numbers (0 or 1) from a Bernoulli distribution.
            The input tensor should be a tensor containing probabilities to be used for drawing the binary random number.
            </summary>
            <param name="generator">A pseudorandom number generator for sampling</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.multinomial(System.Int64,System.Boolean,TorchSharp.torch.Generator)">
            <summary>
            Returns a tensor where each row contains num_samples indices sampled from the multinomial probability distribution located in the corresponding row of tensor input.
            </summary>
            <param name="num_samples">number of samples to draw</param>
            <param name="replacement">whether to draw with replacement or not</param>
            <param name="generator">A pseudorandom number generator for sampling</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.poisson(TorchSharp.torch.Generator)">
            <summary>
            Returns a tensor of the same size as input with each element sampled from a Poisson distribution with rate parameter given by the corresponding element in input
            </summary>
            <param name="generator">Optional random number generator</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.bernoulli_(System.Double,TorchSharp.torch.Generator)">
            <summary>
            Fills each location of the input tensor with an independent sample from Bernoulli(p)
            </summary>
            <param name="p">Probability</param>
            <param name="generator">Optional random-number generator.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.bernoulli_(TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Fills each location of the input tensor with an independent sample from Bernoulli(p)
            </summary>
            <param name="p">Probability tensor</param>
            <param name="generator">Optional random-number generator.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.cauchy_(System.Double,System.Double,TorchSharp.torch.Generator)">
            <summary>
            Fills the tensor with numbers drawn from the Cauchy distribution.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.exponential_(System.Double,TorchSharp.torch.Generator)">
            <summary>
            Fills the input tensor with elements drawn from the exponential distribution
            </summary>
            <param name="lambda"></param>
            <param name="generator">Optional random-number generator.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.geometric_(System.Double,TorchSharp.torch.Generator)">
            <summary>
            Fills the input tensor with elements drawn from a geometric distribution.
            </summary>
            <param name="p"></param>
            <param name="generator">Optional random-number generator.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.normal_(System.Double,System.Double,TorchSharp.torch.Generator)">
            <summary>
            Fills the input tensor with elements samples from the normal distribution parameterized by mean and std.
            </summary>
            <param name="mean">The mean of the underlying normal distribution.</param>
            <param name="std">The standard deviation of the underlying normal distribution.</param>
            <param name="generator">Optional random-number generator.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.log_normal_(System.Double,System.Double,TorchSharp.torch.Generator)">
            <summary>
            Fills the input tensor with numbers samples from the log-normal distribution parameterized by the given mean and standard deviation.
            </summary>
            <param name="mean">The mean of the underlying normal distribution.</param>
            <param name="std">The standard deviation of the underlying normal distribution.</param>
            <param name="generator">Optional random-number generator.</param>
            <remarks>Note that mean and std are the mean and standard deviation of the underlying normal distribution, and not of the returned distribution.</remarks>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.random_(System.Double,System.Double,TorchSharp.torch.Generator)">
            <summary>
            Fills the input tensor with numbers sampled from the discrete uniform distribution over [from, to - 1].
            If not specified, the values are usually only bounded by the input tensor’s data type.
            </summary>
            <param name="from">The lower bound.</param>
            <param name="to">The uppoer bound.</param>
            <param name="generator">Optional random-number generator.</param>
            <remarks>
            For floating point types, if unspecified, the range will be [0, 2^mantissa] to ensure that every value is representable. For example, torch.tensor(1, dtype=torch.double).random_() will be uniform in [0, 2^53].
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.uniform_(System.Double,System.Double,TorchSharp.torch.Generator)">
            <summary>
            Fills the input tensor with numbers sampled from the continuous uniform distribution:
            </summary>
            <param name="from">Lower bound.</param>
            <param name="to">Upper bound</param>
            <param name="generator">Optional random-number generator.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.arange_out(TorchSharp.Scalar,TorchSharp.Scalar,TorchSharp.Scalar)">
            <summary>
            Mutates the tensor to be filled with with values from interval [start, end) and
            common difference step, starting from start.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.permute(System.Int64[])">
            <summary>
            Returns a view of the original tensor with its dimensions permuted.
            </summary>
            <param name="permutation">The desired ordering of dimensions</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.permute(System.Collections.Generic.IEnumerable{System.Int64})">
            <summary>
            Returns a view of the original tensor with its dimensions permuted.
            </summary>
            <param name="permutation">The desired ordering of dimensions</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.ones(System.Int64[])">
            <summary>
            Mutates the tensor to have the given size with all values set to 1
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.new_ones(System.ReadOnlySpan{System.Int64},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Create a new tensor filled with ones
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.new_ones(System.Int64[],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Create a new tensor filled with ones
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.new_ones(System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Create a new 1-D tensor filled with ones
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.new_ones(System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Create a new 2-D tensor filled with ones
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.new_ones(System.Int64,System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Create a new 3-D tensor filled with ones
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.new_ones(System.Int64,System.Int64,System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Create a new 4-D tensor filled with ones
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.zeros(System.Int64[])">
            <summary>
            Mutates the tensor to have the given size with all values set to 0
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.zero_">
            <summary>
            Fills the tensor with zeros.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.new_zeros(System.Int64[],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Create a new tensor filled with zeros
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.new_zeros(System.ReadOnlySpan{System.Int64},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Create a new tensor filled with zeros
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.new_zeros(System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Create a new 1-D tensor filled with zeros
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.new_zeros(System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Create a new 2-D tensor filled with zeros
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.new_zeros(System.Int64,System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Create a new 3-D tensor filled with zeros
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.new_zeros(System.Int64,System.Int64,System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Create a new 4-D tensor filled with zeros
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.zeros_like(System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Returns a tensor filled with the scalar value 0, with the same size as input.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.ones_like(System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Returns a tensor filled with the scalar value 1, with the same size as input.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.new_empty(System.Int64[],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Create a new tensor filled with empty
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.new_empty(System.ReadOnlySpan{System.Int64},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Create a new tensor filled with empty
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.new_empty(System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Create a new 1-D tensor filled with empty
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.new_empty(System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Create a new 2-D tensor filled with empty
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.new_empty(System.Int64,System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Create a new 3-D tensor filled with empty
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.new_empty(System.Int64,System.Int64,System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Create a new 4-D tensor filled with empty
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.empty(System.Int64[])">
            <summary>
            Mutates the tensor to have the given size with all values uninitialized
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.empty_like(System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Returns an uninitialized tensor with the same size as input.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.full(System.Int64[],TorchSharp.Scalar)">
            <summary>
            Mutates the tensor to have the given size with all values uninitialized
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.full(System.ReadOnlySpan{System.Int64},TorchSharp.Scalar)">
            <summary>
            Mutates the tensor to have the given size with all values uninitialized
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.new_full(System.Int64[],TorchSharp.Scalar,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Create a new tensor filled with a given value
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.new_full(System.ReadOnlySpan{System.Int64},TorchSharp.Scalar,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Create a new tensor filled with a given value
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.new_full(System.Int64,TorchSharp.Scalar,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Create a new 1-D tensor filled with a given value
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.new_full(System.Int64,System.Int64,TorchSharp.Scalar,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Create a new 2-D tensor filled with a given value
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.new_full(System.Int64,System.Int64,System.Int64,TorchSharp.Scalar,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Create a new 3-D tensor filled with a given value
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.new_full(System.Int64,System.Int64,System.Int64,System.Int64,TorchSharp.Scalar,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Create a new 4-D tensor filled with a given value
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.full_like(TorchSharp.Scalar,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Returns a tensor with the same size as input filled with 'value.'
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.eye(System.Int64,System.Int64)">
            <summary>
            Mutates the tensor into a 2-D tensor with ones on the diagonal and zeros elsewhere.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.scatter(System.Int64,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Writes all values from the tensor src into the input tensor at the indices specified in the index tensor. For each
            value in src, its output index is specified by its index in src for dimension != dim and by the #
            corresponding value in index for dimension = dim.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.scatter_(System.Int64,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Writes all values from the tensor src into the input tensor at the indices specified in the index tensor. For each
            value in src, its output index is specified by its index in src for dimension != dim and by the #
            corresponding value in index for dimension = dim.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.scatter_add(System.Int64,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Adds all values from the tensor other into the input tensor at the indices specified in the index tensor in a similar fashion as scatter_().
            For each value in src, it is added to an index in the input tensor which is specified by its index in src for dimension != dim and by the
            corresponding value in index for dimension = dim.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.scatter_add_(System.Int64,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Adds all values from the tensor other into the input tensor at the indices specified in the index tensor in a similar fashion as scatter_().
            For each value in src, it is added to an index in the input tensor which is specified by its index in src for dimension != dim and by the
            corresponding value in index for dimension = dim.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.diagonal_scatter(TorchSharp.torch.Tensor,System.Int64,System.Int64,System.Int64)">
            <summary>
            Embeds the values of the src tensor into input along the diagonal elements of input, with respect to dim1 and dim2.
            </summary>
            <param name="src">The input tensor.</param>
            <param name="offset">
            The argument offset controls which diagonal to consider:
            If offset == 0, it is the main diagonal.
            If offset is greater than 0, it is above the main diagonal.
            If offset is less than 0, it is below the main diagonal.
            </param>
            <param name="dim1">First dimension with respect to which to take diagonal.</param>
            <param name="dim2">Second dimension with respect to which to take diagonal.</param>
            <remarks>This function returns a tensor with fresh storage; it does not return a view.</remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.select_scatter(TorchSharp.torch.Tensor,System.Int64,System.Int64)">
            <summary>
            Embeds the values of the src tensor into input at the given index. This function returns a tensor with fresh storage; it does not create a view.
            </summary>
            <param name="src">The tensor to embed into 'this'</param>
            <param name="dim">The dimension to insert the slice into</param>
            <param name="index">The index to select with</param>
            <remarks>This function returns a tensor with fresh storage; it does not create a view.</remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.slice_scatter(TorchSharp.torch.Tensor,System.Int64,System.Nullable{System.Int64},System.Nullable{System.Int64},System.Int64)">
            <summary>
            Embeds the values of the src tensor into input at the given dimension.
            </summary>
            <param name="src">The tensor to embed into 'this'.</param>
            <param name="dim">The dimension to insert the slice into</param>
            <param name="start">The start index of where to insert the slice</param>
            <param name="end">The end index of where to insert the slice</param>
            <param name="step">How many elements to skip</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.gather(System.Int64,TorchSharp.torch.Tensor)">
            <summary>
            Gathers values along an axis specified by dim.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.flip(System.Int64[])">
            <summary>
            Reverse the order of a n-D tensor along given axis in dims.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.fliplr">
            <summary>
            Flip tensor in the left/right direction, returning a new tensor.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.flipud">
            <summary>
            Flip tensor in the up/down direction, returning a new tensor.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.nanmean(System.Nullable{System.Int32},System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Returns the mean of the values in input, ignoring NaN values.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.nanmedian">
            <summary>
            Returns the median of the values in input, ignoring NaN values.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.nansum">
            <summary>
            Returns the sum of all elements in the input tensor, treating NaN as zero.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.nan_to_num(System.Double,System.Nullable{System.Double},System.Nullable{System.Double})">
            <summary>
            Replaces NaN, positive infinity, and negative infinity values in input with the values specified by nan, posinf, and neginf, respectively.
            By default, NaN`s are replaced with zero, positive infinity is replaced with the greatest finite value representable by input’s dtype,
            and negative infinity is replaced with the least finite value representable by input’s dtype.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.nextafter(TorchSharp.torch.Tensor)">
            <summary>
            Return the next floating-point value after input towards other, elementwise.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.narrow(System.Int64,System.Int64,System.Int64)">
            <summary>
            Returns a new tensor that is a narrowed version of the input along one dimension. The
            dimension is input from start to start + length. The
            returned tensor and the input tensor share the same underlying storage.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.nonzero">
            <summary>
            Returns a tensor containing the indices of all non-zero elements of input.
            Each row in the result contains the indices of a non-zero element in input.
            The result is sorted lexicographically, with the last index changing the fastest (C-style).
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.roll(System.Int64,System.Nullable{System.Int64})">
            <summary>
            Roll the tensor along the given dimension(s).
            Elements that are shifted beyond the last position are re-introduced at the first position.
            If a dimension is not specified, the tensor will be flattened before rolling and then restored to the original shape.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.roll(System.ValueTuple{System.Int64,System.Int64},System.ValueTuple{System.Int64,System.Int64})">
            <summary>
            Roll the tensor along the given dimension(s).
            Elements that are shifted beyond the last position are re-introduced at the first position.
            If a dimension is not specified, the tensor will be flattened before rolling and then restored to the original shape.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.roll(System.Int64[],System.Int64[])">
            <summary>
            Roll the tensor along the given dimension(s).
            Elements that are shifted beyond the last position are re-introduced at the first position.
            If a dimension is not specified, the tensor will be flattened before rolling and then restored to the original shape.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.roll(System.Int64[])">
            <summary>
            Roll the tensor along the given dimension(s).
            Elements that are shifted beyond the last position are re-introduced at the first position.
            If a dimension is not specified, the tensor will be flattened before rolling and then restored to the original shape.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.rot90(System.Int64,System.Nullable{System.ValueTuple{System.Int64,System.Int64}})">
            <summary>
            Rotate a n-D tensor by 90 degrees in the plane specified by dims axis.
            Rotation direction is from the first towards the second axis if k is greater than 0,
            and from the second towards the first for k less than 0.
            </summary>
            <param name="k">The number of times to rotate.</param>
            <param name="dims">Axes to rotate</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.roll(System.ValueTuple{System.Int64,System.Int64,System.Int64},System.ValueTuple{System.Int64,System.Int64,System.Int64})">
            <summary>
            Roll the tensor along the given dimension(s).
            Elements that are shifted beyond the last position are re-introduced at the first position.
            If a dimension is not specified, the tensor will be flattened before rolling and then restored to the original shape.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.roll(System.ReadOnlySpan{System.Int64},System.ReadOnlySpan{System.Int64})">
            <summary>
            Roll the tensor along the given dimension(s).
            Elements that are shifted beyond the last position are re-introduced at the first position.
            If a dimension is not specified, the tensor will be flattened before rolling and then restored to the original shape.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.slice(System.Int64,System.Int64,System.Int64,System.Int64)">
            <summary>
            Returns a new tensor that is a sliced version of the input along one dimension. The
            dimension is input from start to finish-1. The
            returned tensor and the input tensor share the same underlying storage.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.unsqueeze(System.Int64)">
            <summary>
            Returns a new tensor with a dimension of size one inserted at the specified position.
            The returned tensor shares the same underlying data with this tensor.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.unsqueeze_(System.Int64)">
            <summary>
            Inserts a dimension of size one at the specified position. The tensor is modified in place.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.where(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Return a tensor of elements selected from either x or y, depending on condition.
            </summary>
            <param name="condition"></param>
            <param name="y"></param>
            <returns></returns>
            <exception cref="T:System.ArgumentException"></exception>
        </member>
        <member name="M:TorchSharp.torch.Tensor.op_Implicit(System.Byte)~TorchSharp.torch.Tensor">
            <summary>
            Useful when assigning a .NET numeric value to an index of a Tensor.
            </summary>
            <param name="value">The numeric value.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.op_Implicit(System.SByte)~TorchSharp.torch.Tensor">
            <summary>
            Useful when assigning a .NET numeric value to an index of a Tensor.
            </summary>
            <param name="value">The numeric value.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.op_Implicit(System.Int16)~TorchSharp.torch.Tensor">
            <summary>
            Useful when assigning a .NET numeric value to an index of a Tensor.
            </summary>
            <param name="value">The numeric value.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.op_Implicit(System.Int32)~TorchSharp.torch.Tensor">
            <summary>
            Useful when assigning a .NET numeric value to an index of a Tensor.
            </summary>
            <param name="value">The numeric value.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.op_Implicit(System.Int64)~TorchSharp.torch.Tensor">
            <summary>
            Useful when assigning a .NET numeric value to an index of a Tensor.
            </summary>
            <param name="value">The numeric value.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.op_Implicit(System.Single)~TorchSharp.torch.Tensor">
            <summary>
            Useful when assigning a .NET numeric value to an index of a Tensor.
            </summary>
            <param name="value">The numeric value.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.op_Implicit(System.Double)~TorchSharp.torch.Tensor">
            <summary>
            Useful when assigning a .NET numeric value to an index of a Tensor.
            </summary>
            <param name="value">The numeric value.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.op_Implicit(System.Boolean)~TorchSharp.torch.Tensor">
            <summary>
            Useful when assigning a .NET numeric value to an index of a Tensor.
            </summary>
            <param name="value">The numeric value.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.op_Implicit(System.ValueTuple{System.Single,System.Single})~TorchSharp.torch.Tensor">
            <summary>
            Useful when assigning a .NET numeric value to an index of a Tensor.
            </summary>
            <param name="value">The numeric value.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.op_Implicit(System.Numerics.Complex)~TorchSharp.torch.Tensor">
            <summary>
            Useful when assigning a .NET numeric value to an index of a Tensor.
            </summary>
            <param name="value">The numeric value.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.op_Implicit(System.Byte[])~TorchSharp.torch.Tensor">
            <summary>
            Useful when creating a tensor from a .NET array of numbers.
            </summary>
            <param name="value">The numeric value array.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.op_Implicit(System.SByte[])~TorchSharp.torch.Tensor">
            <summary>
            Useful when creating a tensor from a .NET array of numbers.
            </summary>
            <param name="value">The numeric value array.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.op_Implicit(System.Int16[])~TorchSharp.torch.Tensor">
            <summary>
            Useful when creating a tensor from a .NET array of numbers.
            </summary>
            <param name="value">The numeric value array.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.op_Implicit(System.Int32[])~TorchSharp.torch.Tensor">
            <summary>
            Useful when creating a tensor from a .NET array of numbers.
            </summary>
            <param name="value">The numeric value array.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.op_Implicit(System.Int64[])~TorchSharp.torch.Tensor">
            <summary>
            Useful when creating a tensor from a .NET array of numbers.
            </summary>
            <param name="value">The numeric value array.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.op_Implicit(System.Single[])~TorchSharp.torch.Tensor">
            <summary>
            Useful when creating a tensor from a .NET array of numbers.
            </summary>
            <param name="value">The numeric value array.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.op_Implicit(System.Double[])~TorchSharp.torch.Tensor">
            <summary>
            Useful when creating a tensor from a .NET array of numbers.
            </summary>
            <param name="value">The numeric value array.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.op_Implicit(System.Boolean[])~TorchSharp.torch.Tensor">
            <summary>
            Useful when creating a tensor from a .NET array of numbers.
            </summary>
            <param name="value">The numeric value array.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.op_Implicit(System.ValueTuple{System.Single,System.Single}[])~TorchSharp.torch.Tensor">
            <summary>
            Useful when creating a tensor from a .NET array of numbers.
            </summary>
            <param name="value">The numeric value array.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.op_Implicit(System.Numerics.Complex[])~TorchSharp.torch.Tensor">
            <summary>
            Useful when creating a tensor from a .NET array of numbers.
            </summary>
            <param name="value">The numeric value array.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.op_Implicit(TorchSharp.Scalar)~TorchSharp.torch.Tensor">
            <summary>
            This is only here in order to help the C# compiler make the right choice vis-a-vis
            implicit conversions.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.ToString(System.Boolean,System.String,System.Nullable{System.Int32},System.Globalization.CultureInfo,System.String)">
            <summary>
            Tensor-specific ToString(), for backward-compat with pre-0.96.4 versions.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.ToString(TorchSharp.TensorStringStyle,System.String,System.Nullable{System.Int32},System.Globalization.CultureInfo,System.String)">
            <summary>
            Tensor-specific ToString()
            </summary>
            <param name="style">
            The style to use -- either 'default,' 'metadata,' 'julia,' or 'numpy'
            </param>
            <param name="fltFormat">The floating point format to use for each individual number.</param>
            <param name="width">The line width to enforce</param>
            <param name="cultureInfo">The culture, which affects how numbers are formatted.</param>
            <param name="newLine">The newline string to use, defaults to system default.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.ToMetadataString">
            <summary>
            Get a string representation of the tensor.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.ToJuliaString(System.String,System.Int32,System.Globalization.CultureInfo,System.String)">
            <summary>
            Get a verbose string representation of a tensor.
            </summary>
            <param name="fltFormat">The format string to use for floating point values.</param>
            <param name="width">The width of each line of the output string.</param>
            <param name="cultureInfo">The CulturInfo to use when formatting the text</param>
            <param name="newLine">The newline string to use, defaults to system default.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.block_diag(TorchSharp.torch.Tensor[])">
            <summary>
            Create a block diagonal matrix from provided tensors.
            </summary>
            <param name="tensors">One or more tensors with 0, 1, or 2 dimensions.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.atleast_1d">
            <summary>
            Returns a 1-dimensional view of an input tensor with zero dimensions. Input tensors with one or more dimensions are returned as-is.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.atleast_2d">
            <summary>
            Returns a 2-dimensional view of an input tensor with zero dimensions. Input tensors with two or more dimensions are returned as-is.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.atleast_3d">
            <summary>
            Returns a 3-dimensional view of an input tensor with zero dimensions. Input tensors with three or more dimensions are returned as-is.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.stft(System.Int64,System.Int64,System.Int64,TorchSharp.torch.Tensor,System.Boolean,TorchSharp.PaddingModes,System.Boolean,System.Nullable{System.Boolean},System.Nullable{System.Boolean})">
            <summary>
            Short-time Fourier transform (STFT).
            </summary>
            <param name="n_fft">size of Fourier transform</param>
            <param name="hop_length">the distance between neighboring sliding window frames</param>
            <param name="win_length">the size of window frame and STFT filter.</param>
            <param name="window">The optional window function.</param>
            <param name="center">whether to pad input on both sides so that the tt-th frame is centered at time t * hop_length</param>
            <param name="pad_mode"> controls the padding method used when center is True</param>
            <param name="normalized">controls whether to return the normalized STFT results</param>
            <param name="onesided">controls whether to return half of results to avoid redundancy for real inputs.</param>
            <param name="return_complex">whether to return a complex tensor, or a real tensor with an extra last dimension for the real and imaginary components.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.istft(System.Int64,System.Int64,System.Int64,TorchSharp.torch.Tensor,System.Boolean,System.Boolean,System.Nullable{System.Boolean},System.Int64,System.Boolean)">
            <summary>
            Inverse short time Fourier Transform. This is expected to be the inverse of stft().
            It has the same parameters (+ additional optional parameter of length) and it should return the least squares estimation of the original signal.
            The algorithm will check using the NOLA condition (nonzero overlap).
            </summary>
            <param name="n_fft">size of Fourier transform</param>
            <param name="hop_length">the distance between neighboring sliding window frames</param>
            <param name="win_length">the size of window frame and STFT filter.</param>
            <param name="window">The optional window function.</param>
            <param name="center">whether to pad input on both sides so that the tt-th frame is centered at time t * hop_length</param>
            <param name="normalized">controls whether to return the normalized STFT results</param>
            <param name="onesided">controls whether to return half of results to avoid redundancy for real inputs.</param>
            <param name="length">The amount to trim the signal by.</param>
            <param name="return_complex">whether to return a complex tensor, or a real tensor with an extra last dimension for the real and imaginary components.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.tensordot(TorchSharp.torch.Tensor,System.Int64[],System.Int64[])">
            <summary>
            Returns a contraction of a and b over multiple dimensions.
            tensordot implements a generalized matrix product.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.tensordot(TorchSharp.torch.Tensor,System.ValueTuple{System.Int64,System.Int64}[])">
            <summary>
            Returns a contraction of this tensor and <paramref name="b"/> over multiple dimensions.
            tensordot implements a generalized matrix product.
            </summary>
            <param name="b">Right tensor to contract</param>
            <param name="dims">dimensions to contract for this tensor and <paramref name="b"/> respectively</param>
            <returns>contraction</returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.tensordot(TorchSharp.torch.Tensor,System.Int64)">
            <summary>
            Returns a contraction of this tensor and <paramref name="b"/> over multiple dimensions.
            tensordot implements a generalized matrix product.
            </summary>
            <param name="b">Right tensor to contract</param>
            <param name="dims">number of dimensions to contract for this tensor and <paramref name="b"/></param>
            <returns>contraction</returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.cholesky(System.Boolean)">
            <summary>
            Computes the Cholesky decomposition of a symmetric positive-definite matrix AA or for batches of symmetric positive-definite matrices.
            </summary>
            <param name="upper">If upper is true, the returned matrix U is upper-triangular. If upper is false, the returned matrix L is lower-triangular</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.cholesky_inverse(System.Boolean)">
            <summary>
            Computes the inverse of a symmetric positive-definite matrix AA using its Cholesky factor uu : returns matrix inv
            </summary>
            <param name="upper"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.cholesky_solve(TorchSharp.torch.Tensor,System.Boolean)">
            <summary>
            Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrix u.
            </summary>
            <param name="input2"></param>
            <param name="upper"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.cross(TorchSharp.Scalar,System.Int64)">
            <summary>
            Computes the cross product of two 3-dimensional vectors.
            </summary>
            <remarks>
            Supports input of float, double, cfloat and cdouble dtypes. Also supports batches of vectors,
            for which it computes the product along the dimension dim. In this case, the output has the
            same batch dimensions as the inputs broadcast to a common shape.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.det">
            <summary>
            Computes the determinant of a square matrix.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.logdet">
            <summary>
            Calculates log determinant of a square matrix or batches of square matrices.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.geqrf">
            <summary>
            This is a low-level function for calling LAPACK’s geqrf directly.
            This function returns a namedtuple (a, tau) as defined in LAPACK documentation for geqrf.
            </summary>
            <remarks>
            Computes a QR decomposition of input. Both Q and R matrices are stored in the same output tensor a.
            The elements of R are stored on and above the diagonal. Elementary reflectors (or Householder vectors)
            implicitly defining matrix Q are stored below the diagonal. The results of this function can be used
            together with torch.linalg.householder_product() to obtain the Q matrix or with torch.ormqr(), which
            uses an implicit representation of the Q matrix, for an efficient matrix-matrix multiplication.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.matmul(TorchSharp.torch.Tensor)">
            <summary>
            Matrix product of two tensors.
            </summary>
            <param name="target"></param>
            <returns></returns>
            <remarks>
            The behavior depends on the dimensionality of the tensors as follows:
            1. If both tensors are 1-dimensional, the dot product (scalar) is returned
            2. If both arguments are 2-dimensional, the matrix-matrix product is returned.
            3. If the first argument is 1-dimensional and the second argument is 2-dimensional, a 1 is prepended to its dimension for the purpose of the matrix multiply. After the matrix multiply, the prepended dimension is removed.
            4. If the first argument is 2-dimensional and the second argument is 1-dimensional, the matrix-vector product is returned.
            5. If both arguments are at least 1-dimensional and at least one argument is N-dimensional (where N > 2), then a batched matrix multiply is returned.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.mm(TorchSharp.torch.Tensor)">
            <summary>
            Performs a matrix multiplication of the matrices input and mat2.
            </summary>
            <param name="target"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.mv(TorchSharp.torch.Tensor)">
            <summary>
            Performs a matrix-vector product of the matrix input and the vector vec.
            </summary>
            <param name="target"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.matrix_exp">
            <summary>
            Computes the matrix exponential of a square matrix or of each square matrix in a batch.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.matrix_power(System.Int32)">
            <summary>
            Computes the n-th power of a square matrix for an integer n.
            </summary>
            <param name="n">The exponent</param>
            <returns></returns>
            <remarks>Input tensor must be of shape (*, m, m) where * is zero or more batch dimensions.</remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.vdot(TorchSharp.torch.Tensor)">
            <summary>
            Computes the dot product of two 1D tensors.
            </summary>
            <returns></returns>
            <remarks>
            The vdot(a, b) function handles complex numbers differently than dot(a, b).
            If the first argument is complex, the complex conjugate of the first argument is used for the calculation of the dot product.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.dot(TorchSharp.torch.Tensor)">
            <summary>
            Computes the dot product of two 1D tensors.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.pinverse(System.Double,System.Boolean)">
            <summary>
            Computes the pseudoinverse (Moore-Penrose inverse) of a matrix.
            </summary>
            <param name="rcond">The tolerance value to determine when is a singular value zero </param>
            <param name="hermitian">Indicates whether A is Hermitian if complex or symmetric if real. </param>
            <remarks>Input should be tensor of shape (*, m, n) where * is zero or more batch dimensions.</remarks>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.ormqr(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Boolean,System.Boolean)">
            <summary>
            Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.
            </summary>
            <param name="tau">Tensor of shape (*, min(mn, k)) where * is zero or more batch dimensions.</param>
            <param name="other">Tensor of shape (*, m, n) where * is zero or more batch dimensions.</param>
            <param name="left">Controls the order of multiplication.</param>
            <param name="transpose">Controls whether the matrix Q is conjugate transposed or not.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.abs">
            <summary>
            Compute the absolute value of each element in the tensor
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.absolute">
            <summary>
            Compute the absolute value of each element in the tensor
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.abs_">
            <summary>
            Compute the absolute value of each element in the tensor, in-place.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.absolute_">
            <summary>
            Compute the absolute value of each element in the tensor, in-place
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.add(TorchSharp.torch.Tensor)">
            <summary>
            Add two tensors, element-wise
            </summary>
            <param name="target">The right-hand-side operand.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.add(TorchSharp.torch.Tensor,TorchSharp.Scalar)">
            <summary>
            Add two tensors, element-wise, scaling the second operator by 'alpha'
            </summary>
            <param name="target">The right-hand-side operand.</param>
            <param name="alpha">The RHS scale factor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.add(TorchSharp.Scalar)">
            <summary>
            Add a scalar value to each element in the target tensor.
            </summary>
            <param name="scalar">The right-hand-side operand.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.add(TorchSharp.Scalar,TorchSharp.Scalar)">
            <summary>
            Add a scalar value to each element in the target tensor, scaled by 'alpha'
            </summary>
            <param name="scalar">The right-hand-side operand.</param>
            <param name="alpha">The RHS scale factor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.add_(TorchSharp.torch.Tensor)">
            <summary>
            In-place element-wise addition.
            </summary>
            <param name="target">The right-hand operand.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.add_(TorchSharp.torch.Tensor,TorchSharp.Scalar)">
            <summary>
            In-place element-wise addition, with scaling
            </summary>
            <param name="target">The right-hand operand.</param>
            <param name="alpha">Scale factor for the right-hand operand.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.add_(TorchSharp.Scalar)">
            <summary>
            In-place scalar addition.
            </summary>
            <param name="scalar">The right-hand operand.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.add_(TorchSharp.Scalar,TorchSharp.Scalar)">
            <summary>
            In-place scalar addition, scaled.
            </summary>
            <param name="scalar">The right-hand operand.</param>
            <param name="alpha">Scale factor for the right-hand operand.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.addbmm(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Single,System.Single)">
            <summary>
            Performs a batch matrix-matrix product of matrices stored in batch1 and batch2, with a reduced
            add step (all matrix multiplications get accumulated along the first dimension).
            input is added to the final result.
            </summary>
            <param name="batch1">The first batch of matrices to be multiplied</param>
            <param name="batch2">The second batch of matrices to be multiplied</param>
            <param name="beta">Nultiplier for input (β)</param>
            <param name="alpha">Multiplier for batch1 @ batch2 (α)</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.addbmm_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Single,System.Single)">
            <summary>
            Performs an in-place batch matrix-matrix product of matrices stored in batch1 and batch2, with a reduced
            add step (all matrix multiplications get accumulated along the first dimension).
            input is added to the final result.
            </summary>
            <param name="batch1">The first batch of matrices to be multiplied</param>
            <param name="batch2">The second batch of matrices to be multiplied</param>
            <param name="beta">Nultiplier for input (β)</param>
            <param name="alpha">Multiplier for batch1 @ batch2 (α)</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.addcdiv(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.Scalar)">
            <summary>
            Performs the element-wise division of tensor1 by tensor2, multiply the result by the scalar value and add it to input.
            </summary>
            <param name="tensor1">First tensor</param>
            <param name="tensor2">Second tensor</param>
            <param name="value">Scale factor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.addcdiv(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Perform the element-wise division of tensor1 by tensor2 and add it to input.
            </summary>
            <param name="tensor1">First tensor</param>
            <param name="tensor2">Second tensor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.addcdiv_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.Scalar)">
            <summary>
            Performs the in-place element-wise division of tensor1 by tensor2, multiply the result by the scalar value and add it to input.
            </summary>
            <param name="tensor1">First tensor</param>
            <param name="tensor2">Second tensor</param>
            <param name="value">Scale factor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.addcdiv_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Performs the in-place element-wise division of tensor1 by tensor2 and add it to input.
            </summary>
            <param name="tensor1">First tensor</param>
            <param name="tensor2">Second tensor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.addcmul(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.Scalar)">
            <summary>
            Performs the element-wise multiplication of tensor1 by tensor2, multiply the result by the scalar value and add it to input.
            </summary>
            <param name="tensor1">First tensor</param>
            <param name="tensor2">Second tensor</param>
            <param name="value">Scale factor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.addcmul_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.Scalar)">
            <summary>
            Performs the in-place element-wise multiplication of tensor1 by tensor2, multiply the result by the scalar value and add it to input.
            </summary>
            <param name="tensor1">First tensor</param>
            <param name="tensor2">Second tensor</param>
            <param name="value">Scale factor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.addmm(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Single,System.Single)">
            <summary>
            Performs a matrix multiplication of the matrices mat1 and mat2. The matrix input is added to the final result.
            </summary>
            <param name="mat1">First matrix</param>
            <param name="mat2">Second matrix</param>
            <param name="beta">Input scale factor</param>
            <param name="alpha">Matrix multiplication scale factor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.addmm_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Single,System.Single)">
            <summary>
            Performs an in-place matrix multiplication of the matrices mat1 and mat2. The matrix input is added to the final result.
            </summary>
            <param name="mat1">First matrix</param>
            <param name="mat2">Second matrix</param>
            <param name="beta">Input scale factor</param>
            <param name="alpha">Matrix multiplication scale factor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.addmv(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Single,System.Single)">
            <summary>
            Performs a matrix-vector product of the matrix mat and the vector vec. The vector input is added to the final result.
            </summary>
            <param name="mat">Matrix to be matrix multiplied</param>
            <param name="vec">Vector to be matrix multiplied</param>
            <param name="beta">Input scale factor</param>
            <param name="alpha">Matrix multiplication scale factor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.addmv_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Single,System.Single)">
            <summary>
            Performs a matrix-vector product of the matrix mat and the vector vec. The vector input is added to the final result.
            </summary>
            <param name="mat">Matrix to be matrix multiplied</param>
            <param name="vec">Vector to be matrix multiplied</param>
            <param name="beta">Input scale factor</param>
            <param name="alpha">Matrix multiplication scale factor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.addr(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Single,System.Single)">
            <summary>
            Performs the outer-product of vectors vec1 and vec2 and adds it to the input tensor.
            </summary>
            <param name="vec1">The first vector of the outer product</param>
            <param name="vec2">The second vector of the outer product</param>
            <param name="beta">Input scale factor</param>
            <param name="alpha">Outer-product scale factor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.addr_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Single,System.Single)">
             <summary>
             Performs the outer-product of vectors vec1 and vec2 and adds it to the input tensor.
            
             In-place version of 'addr'
             </summary>
             <param name="vec1">The first vector of the outer product</param>
             <param name="vec2">The second vector of the outer product</param>
             <param name="beta">Input scale factor</param>
             <param name="alpha">Outer-product scale factor</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.bitwise_and(TorchSharp.torch.Tensor)">
            <summary>
            Element-wise bitwise AND
            </summary>
            <param name="other">Right-hand operand.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.bitwise_and_(TorchSharp.torch.Tensor)">
            <summary>
            Element-wise bitwise AND, in-place
            </summary>
            <param name="other">Right-hand operand.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.bitwise_not">
            <summary>
            Element-wise bitwise NOT
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.bitwise_not_">
            <summary>
            Element-wise bitwise NOT, in-place
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.bitwise_or(TorchSharp.torch.Tensor)">
            <summary>
            Element-wise bitwise OR
            </summary>
            <param name="other">Right-hand operand.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.bitwise_or_(TorchSharp.torch.Tensor)">
            <summary>
            Element-wise bitwise OR, in-place
            </summary>
            <param name="other">Right-hand operand.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.bitwise_xor(TorchSharp.torch.Tensor)">
            <summary>
            Element-wise bitwise XOR
            </summary>
            <param name="other">Right-hand operand.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.bitwise_xor_(TorchSharp.torch.Tensor)">
            <summary>
            Element-wise bitwise XOR, in-place.
            </summary>
            <param name="other">Right-hand operand.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.bitwise_left_shift(TorchSharp.torch.Tensor)">
            <summary>
            Element-wise bitwise left_shift
            </summary>
            <param name="other">Right-hand operand.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.bitwise_left_shift_(TorchSharp.torch.Tensor)">
            <summary>
            Element-wise bitwise left_shift, in-place.
            </summary>
            <param name="other">Right-hand operand.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.bitwise_right_shift(TorchSharp.torch.Tensor)">
            <summary>
            Element-wise bitwise right_shift
            </summary>
            <param name="other">Right-hand operand.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.bitwise_right_shift_(TorchSharp.torch.Tensor)">
            <summary>
            Element-wise bitwise right_shift, in-place.
            </summary>
            <param name="other">Right-hand operand.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.ceil">
            <summary>
            Returns a new tensor with the ceil of the elements of input, the smallest integer greater than or equal to each element.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.ceil_">
            <summary>
            Replaces each element of the input with the smallest integer greater than or equal to the element.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.conj">
            <summary>
            Returns a view of input with a flipped conjugate bit. If input has a non-complex dtype, this function just returns input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.conj_physical">
            <summary>
            Computes the element-wise conjugate of the given input tensor. If input has a non-complex dtype, this function just returns input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.conj_physical_">
            <summary>
            In-place version of conj_physical
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.is_conj">
            <summary>
            Returns true if the input is a conjugated tensor, i.e. its conjugate bit is set to True.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.resolve_conj">
            <summary>
            Returns a new tensor with materialized conjugation if input’s conjugate bit is set to True, else returns input.
            The output tensor will always have its conjugate bit set to False.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.is_neg">
            <summary>
            Returns true if the input's negative bit is set to True.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.resolve_neg">
            <summary>
            Returns a new tensor with materialized negation if input’s negative bit is set to True, else returns input.
            The output tensor will always have its negative bit set to False.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.cummax(System.Int64)">
            <summary>
            Returns a tuple (values, indices) where values is the cumulative maximum of elements of input in the dimension dim.
            Indices is the index location of each maximum value found in the dimension dim.
            </summary>
            <param name="dim">The dimension to do the operation over</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.cummin(System.Int64)">
            <summary>
            Returns a tuple (values, indices) where values is the cumulative minimum of elements of input in the dimension dim.
            Indices is the index location of each minimum value found in the dimension dim.
            </summary>
            <param name="dim">The dimension to do the operation over</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.cumsum(System.Int64,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Returns the cumulative sum of elements of input in the dimension dim.
            </summary>
            <param name="dim">The dimension to do the operation over</param>
            <param name="type">The desired data type of returned tensor. If specified, the input tensor is casted to dtype before the operation is performed.
            This is useful for preventing data type overflows.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.cumprod(System.Int64,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Returns the cumulative product of elements of input in the dimension dim.
            </summary>
            <param name="dim">The dimension to do the operation over</param>
            <param name="type">The desired data type of returned tensor. If specified, the input tensor is casted to dtype before the operation is performed.
            This is useful for preventing data type overflows.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.div(TorchSharp.torch.Tensor,TorchSharp.torch.RoundingMode)">
            <summary>
            Divides each element of the input by the corresponding element of other.
            </summary>
            <param name="target">Denominator</param>
            <param name="rounding_mode">Rounding mode.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.divide(TorchSharp.torch.Tensor,TorchSharp.torch.RoundingMode)">
            <summary>
            Divides each element of the input by the corresponding element of other.
            </summary>
            <param name="target">Denominator</param>
            <param name="rounding_mode">Rounding mode.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.div(TorchSharp.Scalar,TorchSharp.torch.RoundingMode)">
            <summary>
            Scalar division
            </summary>
            <param name="target">Denominator</param>
            <param name="rounding_mode">Rounding mode.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.divide(TorchSharp.Scalar,TorchSharp.torch.RoundingMode)">
            <summary>
            Scalar division
            </summary>
            <param name="target">Denominator</param>
            <param name="rounding_mode">Rounding mode.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.div_(TorchSharp.torch.Tensor,TorchSharp.torch.RoundingMode)">
            <summary>
            In-place division
            </summary>
            <param name="target">Denominator</param>
            <param name="rounding_mode">Rounding mode.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.divide_(TorchSharp.torch.Tensor,TorchSharp.torch.RoundingMode)">
            <summary>
            In-place division
            </summary>
            <param name="target">Denominator</param>
            <param name="rounding_mode">Rounding mode.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.div_(TorchSharp.Scalar,TorchSharp.torch.RoundingMode)">
            <summary>
            In-place scalar division
            </summary>
            <param name="target">Denominator</param>
            <param name="rounding_mode">Rounding mode.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.divide_(TorchSharp.Scalar,TorchSharp.torch.RoundingMode)">
            <summary>
            In-place scalar division
            </summary>
            <param name="target">Denominator</param>
            <param name="rounding_mode">Rounding mode.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.exp">
            <summary>
            Returns a new tensor with the exponential of the elements of the input tensor.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.exp_">
            <summary>
            Replaces the tensor with the exponential of the elements of the input tensor.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.exp2">
            <summary>
            Computes the base 2 exponential function of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.expm1">
            <summary>
            Returns a new tensor with the exponential of the elements minus 1 of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.expm1_">
            <summary>
            Replaces each element with the exponential of the element minus 1 of input, in-place.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.float_power(TorchSharp.torch.Tensor)">
            <summary>
            Raises input to the power of exponent, elementwise, in double precision.
            </summary>
            <param name="target">The exponent.</param>
            <returns></returns>
            <remarks> If neither input is complex returns a torch.float64 tensor, and if one or more inputs is complex returns a torch.complex128 tensor.</remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.floor">
            <summary>
            Returns a new tensor with the floor of the elements of input, the largest integer less than or equal to each element.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.floor_">
            <summary>
            Replaces each element with the floor of the input, the largest integer less than or equal to each element.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.floor_divide(TorchSharp.torch.Tensor)">
            <summary>
            Computes input divided by other, elementwise, and floors the result.
            </summary>
            <param name="other">the divisor</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.floor_divide(TorchSharp.Scalar)">
            <summary>
            Computes input divided by other, elementwise, and floors the result.
            </summary>
            <param name="other">the divisor</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.floor_divide_(TorchSharp.torch.Tensor)">
            <summary>
            Computes input divided by other, elementwise, and floors the result, computation done in place.
            </summary>
            <param name="other">the divisor</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.floor_divide_(TorchSharp.Scalar)">
            <summary>
            Computes input divided by other, elementwise, and floors the result, computation done in place.
            </summary>
            <param name="other">the divisor</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.fmod(TorchSharp.torch.Tensor)">
            <summary>
            Computes the element-wise remainder of division.
            </summary>
            <param name="target">Denominator</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.fmod_(TorchSharp.torch.Tensor)">
            <summary>
            Computes the element-wise remainder of division, in-place.
            </summary>
            <param name="target">Denominator</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.fmod(TorchSharp.Scalar)">
            <summary>
            Computes the element-wise remainder of division.
            </summary>
            <param name="scalar">Denominator</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.fmod_(TorchSharp.Scalar)">
            <summary>
            Computes the element-wise remainder of division, in-place
            </summary>
            <param name="scalar">Denominator</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.frac">
            <summary>
            Computes the fractional portion of each element in input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.frac_">
            <summary>
            Computes the fractional portion of each element in input, in-place.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.frexp">
            <summary>
            Decomposes input into mantissa and exponent tensors
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.gcd(TorchSharp.torch.Tensor)">
            <summary>
            Computes the element-wise greatest common divisor (GCD) of input and other.
            </summary>
            <param name="other">Right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.gcd_(TorchSharp.torch.Tensor)">
            <summary>
            Computes the element-wise greatest common divisor (GCD) of input and other.
            </summary>
            <param name="other">Right-hand operand.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.histc(System.Int64,System.Int64,System.Int64)">
            <summary>
            Computes the histogram of a tensor.
            The elements are sorted into equal width bins between min and max.If min and max are both zero, the minimum and maximum values of the data are used.
            Elements lower than min and higher than max are ignored.
            </summary>
            <param name="bins">Number of histogram bins</param>
            <param name="min">Lower end of the range (inclusive)</param>
            <param name="max">Upper end of the range (inclusive)</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.hypot(TorchSharp.torch.Tensor)">
            <summary>
            Element-wise: given the legs of a right triangle, return its hypotenuse.
            </summary>
            <param name="other">The second input tensor.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.log">
            <summary>
            Returns a new tensor with the natural logarithm of the input elements.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.log_">
            <summary>
            Replaces each elements with the natural logarithm of the input.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Tensor.logaddexp(TorchSharp.torch.Tensor)">
            <summary>
            Logarithm of the sum of exponentiations of the inputs.
            </summary>
            <param name="other">The second input tensor.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.logaddexp2(TorchSharp.torch.Tensor)">
            <summary>
            Logarithm of the sum of exponentiations of the inputs in base-2.
            </summary>
            <param name="other">The second input tensor.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.logcumsumexp(System.Int64)">
            <summary>
            Returns the logarithm of the cumulative summation of the exponentiation of elements of input in the dimension dim.
            </summary>
            <param name="dim">The dimension to do the operation over</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.logsumexp(System.Int64,System.Boolean)">
            <summary>
            Returns the log of summed exponentials of each row of the input tensor in the given dimension dim.
            </summary>
            <param name="dim">The dimension to do the operation over</param>
            <param name="keepdim">Thether the output tensor has dim retained or not.</param>
            <returns></returns>
            <remarks>The computation is numerically stabilized.</remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.log_softmax(System.Int64,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Returns a new tensor with the logit of the elements of input.
            </summary>
            <param name="dim">A dimension along which log_softmax will be computed.</param>
            <param name="dtype">The desired data type of returned tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.log10">
            <summary>
            Returns a new tensor with the logarithm to the base 10 of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.log10_">
            <summary>
            Replaces elements with the logarithm to the base 10 of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.log1p">
            <summary>
            Returns a new tensor with the natural logarithm of (1 + input).
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.log1p_">
            <summary>
            Returns a new tensor with the natural logarithm of (1 + input), inplace.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.log2">
            <summary>
            Returns a new tensor with the logarithm to the base 2 of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.log2_">
            <summary>
            Replaces each element with the logarithm to the base 2 of the input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.logical_and(TorchSharp.torch.Tensor)">
            <summary>
            Logical AND
            </summary>
            <param name="other">Right-hand operand.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.logical_and_(TorchSharp.torch.Tensor)">
            <summary>
            Logical AND, in place
            </summary>
            <param name="other">Right-hand operand.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.logical_not">
            <summary>
            Logical NOT
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.logical_not_">
            <summary>
            Logical NOT, in place
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.logical_or(TorchSharp.torch.Tensor)">
            <summary>
            Logical OR
            </summary>
            <param name="other">Right-hand operand.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.logical_or_(TorchSharp.torch.Tensor)">
            <summary>
            Logical OR, in place
            </summary>
            <param name="other">Right-hand operand.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.logical_xor(TorchSharp.torch.Tensor)">
            <summary>
            Logical XOR
            </summary>
            <param name="other">Right-hand operand.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.logical_xor_(TorchSharp.torch.Tensor)">
            <summary>
            Logical XOR, in place
            </summary>
            <param name="other">Right-hand operand.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.logit(System.Nullable{System.Double})">
            <summary>
            Returns a new tensor with the logit of the elements of input.
            input is clamped to [eps, 1 - eps] when eps is not null
            </summary>
            <param name="eps">The epsilon for input clamp bound.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.mul(TorchSharp.torch.Tensor)">
            <summary>
            Element-wise multiplication
            </summary>
            <param name="target">Right-hand operand</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.multiply(TorchSharp.torch.Tensor)">
            <summary>
            Element-wise multiplication
            </summary>
            <param name="target">Right-hand operand</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.mul(TorchSharp.Scalar)">
            <summary>
            Element-wise multiplication
            </summary>
            <param name="target">Right-hand operand</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.multiply(TorchSharp.Scalar)">
            <summary>
            Element-wise multiplcation
            </summary>
            <param name="target">Right-hand operand</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.mul_(TorchSharp.torch.Tensor)">
            <summary>
            Element-wise multiplication, in place
            </summary>
            <param name="target">Right-hand operand</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.mul_(TorchSharp.Scalar)">
            <summary>
            Element-wise multiplication, in place
            </summary>
            <param name="target">Right-hand operand</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.neg">
            <summary>
            Negation
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.negative">
            <summary>
            Negation
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.neg_">
            <summary>
            In-place negation
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.pow(TorchSharp.torch.Tensor)">
            <summary>
            Takes the power of each element in input with exponent and returns a tensor with the result.
            </summary>
            <param name="exponent">The exponent.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.pow_(TorchSharp.torch.Tensor)">
            <summary>
            Replaces each element in input with the power of the element and the exponent.
            </summary>
            <param name="exponent">The exponent.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.pow(TorchSharp.Scalar)">
            <summary>
            Takes the power of each element in input with exponent and returns a tensor with the result.
            </summary>
            <param name="exponent">The exponent.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.pow_(TorchSharp.Scalar)">
            <summary>
            Replaces each element in input with the power of the element and the exponent.
            </summary>
            <param name="exponent">The exponent.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.reciprocal">
            <summary>
            Returns a new tensor with the reciprocal of the elements of input
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.reciprocal_">
            <summary>
            Replaces each element with the reciprocal of the input
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.remainder(TorchSharp.torch.Tensor)">
            <summary>
            Computes the element-wise remainder of division.
            </summary>
            <param name="target">Denominator</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.remainder_(TorchSharp.torch.Tensor)">
            <summary>
            Computes the element-wise remainder of division, in place
            </summary>
            <param name="target">Denominator</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.remainder(TorchSharp.Scalar)">
            <summary>
            Computes the element-wise remainder of division.
            </summary>
            <param name="scalar">Denominator</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.remainder_(TorchSharp.Scalar)">
            <summary>
            Computes the element-wise remainder of division.
            </summary>
            <param name="scalar">Denominator</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.round(System.Int64)">
            <summary>
            Returns a new tensor with each of the elements of input rounded to the closest value with the given number of decimals.
            </summary>
            <param name="decimals">Number of decimal places to round to (default: 0). If decimals is negative, it specifies the number of positions to the left of the decimal point.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.round_(System.Int64)">
            <summary>
            Replaces each of the elements of input with the element rounded to the closest value with the given number of decimals.
            </summary>
            <param name="decimals">Number of decimal places to round to (default: 0). If decimals is negative, it specifies the number of positions to the left of the decimal point.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.rsqrt">
            <summary>
            Returns a new tensor with the reciprocal of the square-root of each of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.rsqrt_">
            <summary>
            Replaces each of the elements of input with  the reciprocal of the square-root of each of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.square">
            <summary>
            Computes the element-wise square
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.sqrt">
            <summary>
            Computes the element-wise square root
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.sqrt_">
            <summary>
            Computes the element-wise square root, in place
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.sign">
            <summary>
            Returns a new tensor with the signs (-1, 0, 1) of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.sign_">
            <summary>
            Replaces each element with the signs (-1, 0, 1) of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.sgn">
            <summary>
            This function is an extension of torch.sign() to complex tensors.
            It computes a new tensor whose elements have the same angles as the corresponding
            elements of input and absolute values (i.e. magnitudes) of one for complex tensors
            and is equivalent to torch.sign() for non-complex tensors.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.sgn_">
            <summary>
            This function is an extension of torch.sign() to complex tensors.
            It computes a new tensor whose elements have the same angles as the corresponding
            elements of input and absolute values (i.e. magnitudes) of one for complex tensors
            and is equivalent to torch.sign() for non-complex tensors. In-place version.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.signbit">
            <summary>
            Tests if each element of input has its sign bit set (is less than zero) or not.
            </summary>
            <returns>A boolean tensor of the same shape as the input.</returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.sub(TorchSharp.torch.Tensor)">
            <summary>
            Element-wise subtraction
            </summary>
            <param name="target">Right-hand operand</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.sub(TorchSharp.Scalar)">
            <summary>
            Element-wise subtraction
            </summary>
            <param name="target">Right-hand operand</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.sub_(TorchSharp.torch.Tensor)">
            <summary>
            Element-wise subtraction, in place
            </summary>
            <param name="target">Right-hand operand</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.sub_(TorchSharp.Scalar)">
            <summary>
            Element-wise subtraction, in-place
            </summary>
            <param name="target">Right-hand operand</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.cumulative_trapezoid(System.Double,System.Int64)">
            <summary>
            Cumulatively computes the trapezoidal rule along dim. By default the spacing between elements is assumed to be 1,
            but dx can be used to specify a different constant spacing.
            </summary>
            <param name="dx">Constant spacing between values.</param>
            <param name="dim">The dimension along which to compute the trapezoidal rule. The last (inner-most) dimension by default.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.cumulative_trapezoid(TorchSharp.torch.Tensor,System.Int64)">
            <summary>
            Cumulatively computes the trapezoidal rule along dim. By default the spacing between elements is assumed to be 1,
            but x can be used to specify arbitrary spacing along dim.
            </summary>
            <param name="x">Defines spacing between values as specified above.</param>
            <param name="dim">The dimension along which to compute the trapezoidal rule. The last (inner-most) dimension by default.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.trapezoid(System.Double,System.Int64)">
            <summary>
            Computes the trapezoidal rule along dim. By default the spacing between elements is assumed to be 1,
            but dx can be used to specify a different constant spacing.
            </summary>
            <param name="dx">Constant spacing between values.</param>
            <param name="dim">The dimension along which to compute the trapezoidal rule. The last (inner-most) dimension by default.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.trapezoid(TorchSharp.torch.Tensor,System.Int64)">
            <summary>
            Computes the trapezoidal rule along dim. By default the spacing between elements is assumed to be 1,
            but x can be used to specify arbitrary spacing along dim.
            </summary>
            <param name="x">Defines spacing between values as specified above.</param>
            <param name="dim">The dimension along which to compute the trapezoidal rule. The last (inner-most) dimension by default.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.true_divide(TorchSharp.torch.Tensor)">
            <summary>
            Computes input divided by other, elementwise, and floors the result.
            </summary>
            <param name="other">the divisor</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.true_divide(TorchSharp.Scalar)">
            <summary>
            Computes input divided by other, elementwise, and floors the result.
            </summary>
            <param name="other">the divisor</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.true_divide_(TorchSharp.torch.Tensor)">
            <summary>
            Computes input divided by other, elementwise, and floors the result, computation done in place.
            </summary>
            <param name="other">the divisor</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.true_divide_(TorchSharp.Scalar)">
            <summary>
            Computes input divided by other, elementwise, and floors the result, computation done in place.
            </summary>
            <param name="other">the divisor</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.trunc">
            <summary>
            Returns a new tensor with the truncated integer values of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.fix">
            <summary>
            Returns a new tensor with the truncated integer values of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.trunc_">
            <summary>
            Replaces each element with the truncated integer values of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.fix_">
            <summary>
            Replaces each element with the truncated integer values of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.xlogy(TorchSharp.torch.Tensor)">
            <summary>
            Computes x * log(y)
            </summary>
            <param name="y">The 'y' operand.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.xlogy_(TorchSharp.torch.Tensor)">
            <summary>
            Computes x * log(y) in place
            </summary>
            <param name="y">The 'y' operand.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.xlogy(TorchSharp.Scalar)">
            <summary>
            Computes x * log(y)
            </summary>
            <param name="y">The 'y' operand.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.xlogy_(TorchSharp.Scalar)">
            <summary>
            Computes x * log(y) in place
            </summary>
            <param name="y">The 'y' operand.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.angle">
            <summary>
            Computes the element-wise angle (in radians) of the given input tensor.
            </summary>
            <returns></returns>
            <remarks>
            Starting in Torch 1.8, angle returns pi for negative real numbers, zero for non-negative real numbers, and propagates NaNs.
            Previously the function would return zero for all real numbers and not propagate floating-point NaNs.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.Tensor.asin">
            <summary>
            Computes the arcsine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.arcsin">
            <summary>
            Computes the arcsine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.asin_">
            <summary>
            Computes the arcsine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.acos">
            <summary>
            Computes the arccosine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.arccos">
            <summary>
            Computes the arccosine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.acos_">
            <summary>
            Computes the arccosine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.arccos_">
            <summary>
            Computes the arccosine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.atan">
            <summary>
            Computes the arctangent of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.arctan">
            <summary>
            Computes the arctangent of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.atan_">
            <summary>
            Computes the arctangent of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.arctan_">
            <summary>
            Computes the arctangent of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.atan2(TorchSharp.torch.Tensor)">
            <summary>
            Element-wise arctangent of input / other with consideration of the quadrant.
            </summary>
            <param name="other">The second tensor</param>
        </member>
        <member name="M:TorchSharp.torch.Tensor.atan2_(TorchSharp.torch.Tensor)">
            <summary>
            Element-wise arctangent of input / other with consideration of the quadrant.
            </summary>
            <param name="other">The second tensor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.cos">
            <summary>
            Computes the cosine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.cos_">
            <summary>
            Computes the cosine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.sin">
            <summary>
            Computes the sine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.sin_">
            <summary>
            Computes the sine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.tan">
            <summary>
            Computes the tangent of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.tan_">
            <summary>
            Computes the tangent of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.sinc">
            <summary>
            Computes the normalized sinc of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.sinc_">
            <summary>
            Computes the normalized sinc of input, in place.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.sinh">
            <summary>
            Computes the hyperbolic sine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.sinh_">
            <summary>
            Computes the hyperbolic sine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.cosh">
            <summary>
            Computes the hyperbolic cosine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.cosh_">
            <summary>
            Computes the hyperbolic cosine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.tanh">
            <summary>
            Computes the hyperbolic tangent of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.tanh_">
            <summary>
            Computes the hyperbolic tangent of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.arcsinh">
            <summary>
            Computes the hyperbolic arcsine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.asinh">
            <summary>
            Computes the hyperbolic arcsine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.arcsinh_">
            <summary>
            Computes the hyperbolic arcsine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.asinh_">
            <summary>
            Computes the hyperbolic arcsine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.arccosh">
            <summary>
            Computes the hyperbolic arccosine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.acosh">
            <summary>
            Computes the hyperbolic arccosine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.arccosh_">
            <summary>
            Computes the hyperbolic arccosine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.acosh_">
            <summary>
            Computes the hyperbolic arccosine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.arctanh">
            <summary>
            Computes the hyperbolic arctangent of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.atanh">
            <summary>
            Computes the hyperbolic arctangent of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.arctanh_">
            <summary>
            Computes the hyperbolic arctangent of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Tensor.atanh_">
            <summary>
            Computes the hyperbolic arctangent of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Boolean,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Create a scalar tensor from a single value
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.Boolean},System.ReadOnlySpan{System.Int64},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, shaping it based on the shape passed in.
            </summary>
            <remarks>The Torch runtime does not take ownership of the data, so there is no device argument.</remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Boolean[],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, shaping it based on the shape passed in.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.Boolean},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a 1-D tensor from an array of values, shaping it based on the input array.
            </summary>
            <remarks>The Torch runtime does not take ownership of the data, so there is no device argument.</remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.Boolean},System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, organizing it as a two-dimensional tensor.
            </summary>
            <remarks>
            The Torch runtime does not take ownership of the data, so there is no device argument.
            The input array must have rows * columns elements.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.Boolean},System.Int64,System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, organizing it as a three-dimensional tensor.
            </summary>
            <remarks>
            The Torch runtime does not take ownership of the data, so there is no device argument.
            The input array must have dim0*dim1*dim2 elements.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.Boolean},System.Int64,System.Int64,System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, organizing it as a four-dimensional tensor.
            </summary>
            <remarks>
            The Torch runtime does not take ownership of the data, so there is no device argument.
            The input array must have dim0*dim1*dim2*dim3 elements.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Boolean[0:,0:],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a two-dimensional tensor from a two-dimensional array of values.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Boolean[0:,0:,0:],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a three-dimensional tensor from a three-dimensional array of values.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Boolean[0:,0:,0:,0:],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a four-dimensional tensor from a four-dimensional array of values.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.BoolTensor(TorchSharp.torch.Tensor)">
            <summary>
            Cast a tensor to a Boolean tensor.
            </summary>
            <param name="t">The input tensor</param>
            <returns>'this' if the tensor is already a Boolean tensor; otherwise, a new tensor.</returns>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Byte,TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Create a scalar tensor from a single value
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.Byte},System.ReadOnlySpan{System.Int64},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, shaping it based on the shape passed in.
            </summary>
            <remarks>The Torch runtime does not take ownership of the data, so there is no device argument.</remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Byte[],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, shaping it based on the shape passed in.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Byte[],System.ReadOnlySpan{System.Int64},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, shaping it based on the array passed in.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.Byte},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a 1-D tensor from an array of values, shaping it based on the input array.
            </summary>
            <remarks>The Torch runtime does not take ownership of the data, so there is no device argument.</remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.Byte},System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, organizing it as a two-dimensional tensor.
            </summary>
            <remarks>
            The Torch runtime does not take ownership of the data, so there is no device argument.
            The input array must have rows * columns elements.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.Byte},System.Int64,System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, organizing it as a three-dimensional tensor.
            </summary>
            <remarks>
            The Torch runtime does not take ownership of the data, so there is no device argument.
            The input array must have dim0*dim1*dim2 elements.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.Byte},System.Int64,System.Int64,System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, organizing it as a four-dimensional tensor.
            </summary>
            <remarks>
            The Torch runtime does not take ownership of the data, so there is no device argument.
            The input array must have dim0*dim1*dim2*dim3 elements.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Byte[0:,0:],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a two-dimensional tensor from a two-dimensional array of values.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Byte[0:,0:,0:],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a three-dimensional tensor from a three-dimensional array of values.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Byte[0:,0:,0:,0:],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a four-dimensional tensor from a four-dimensional array of values.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Memory{System.Byte},System.ReadOnlySpan{System.Int64},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, shaping it based on the shape passed in.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.ByteTensor(TorchSharp.torch.Tensor)">
            <summary>
            Cast a tensor to a byte tensor.
            </summary>
            <param name="t">The input tensor</param>
            <returns>'this' if the tensor is already a byte tensor; otherwise, a new tensor.</returns>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Numerics.Complex,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Create a scalar tensor from a single value
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.ValueTuple{System.Single,System.Single}},System.ReadOnlySpan{System.Int64},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, shaping it based on the shape passed in.
            </summary>
            <remarks>The Torch runtime does not take ownership of the data, so there is no device argument.</remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.ValueTuple{System.Single,System.Single}[],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, shaping it based on the shape passed in.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.ValueTuple{System.Single,System.Single}[],System.ReadOnlySpan{System.Int64},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, shaping it based on the shape passed in.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.ValueTuple{System.Single,System.Single}},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a 1-D tensor from an array of values, shaping it based on the input array.
            </summary>
            <remarks>The Torch runtime does not take ownership of the data, so there is no device argument.</remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.ValueTuple{System.Single,System.Single}},System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, organizing it as a two-dimensional tensor.
            </summary>
            <remarks>
            The Torch runtime does not take ownership of the data, so there is no device argument.
            The input array must have rows * columns elements.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.ValueTuple{System.Single,System.Single}},System.Int64,System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, organizing it as a three-dimensional tensor.
            </summary>
            <remarks>
            The Torch runtime does not take ownership of the data, so there is no device argument.
            The input array must have dim0*dim1*dim2 elements.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.ValueTuple{System.Single,System.Single}},System.Int64,System.Int64,System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, organizing it as a four-dimensional tensor.
            </summary>
            <remarks>
            The Torch runtime does not take ownership of the data, so there is no device argument.
            The input array must have dim0*dim1*dim2*dim3 elements.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.ValueTuple{System.Single,System.Single}[0:,0:],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a two-dimensional tensor from a two-dimensional array of values.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.ValueTuple{System.Single,System.Single}[0:,0:,0:],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a three-dimensional tensor from a three-dimensional array of values.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.ValueTuple{System.Single,System.Single}[0:,0:,0:,0:],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a four-dimensional tensor from a four-dimensional array of values.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.Numerics.Complex},System.ReadOnlySpan{System.Int64},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, shaping it based on the shape passed in.
            </summary>
            <remarks>The Torch runtime does not take ownership of the data, so there is no device argument.</remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Numerics.Complex[],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, shaping it based on the shape passed in.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Numerics.Complex[],System.ReadOnlySpan{System.Int64},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, shaping it based on the shape passed in.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.Numerics.Complex},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a 1-D tensor from an array of values, shaping it based on the input array.
            </summary>
            <remarks>The Torch runtime does not take ownership of the data, so there is no device argument.</remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.Numerics.Complex},System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, organizing it as a two-dimensional tensor.
            </summary>
            <remarks>
            The Torch runtime does not take ownership of the data, so there is no device argument.
            The input array must have rows * columns elements.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.Numerics.Complex},System.Int64,System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, organizing it as a three-dimensional tensor.
            </summary>
            <remarks>
            The Torch runtime does not take ownership of the data, so there is no device argument.
            The input array must have dim0*dim1*dim2 elements.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.Numerics.Complex},System.Int64,System.Int64,System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, organizing it as a four-dimensional tensor.
            </summary>
            <remarks>
            The Torch runtime does not take ownership of the data, so there is no device argument.
            The input array must have dim0*dim1*dim2*dim3 elements.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Numerics.Complex[0:,0:],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a two-dimensional tensor from a two-dimensional array of values.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Numerics.Complex[0:,0:,0:],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a three-dimensional tensor from a three-dimensional array of values.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Numerics.Complex[0:,0:,0:,0:],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a four-dimensional tensor from a four-dimensional array of values.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Memory{System.Numerics.Complex},System.ReadOnlySpan{System.Int64},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, shaping it based on the shape passed in.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Double,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Create a scalar tensor from a single value
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.ValueTuple{System.Double,System.Double},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Create a scalar complex number tensor from a tuple of (real, imaginary)
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Double,System.Double,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Create a scalar complex number tensor from independent real and imaginary components
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.Double},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, shaping it based on the shape passed in.
            </summary>
            <remarks>The Torch runtime does not take ownership of the data, so there is no device argument.</remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Double[],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, shaping it based on the shape passed in.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Double[],System.ReadOnlySpan{System.Int64},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, shaping it based on the shape passed in.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.Double},System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, organizing it as a two-dimensional tensor.
            </summary>
            <remarks>
            The Torch runtime does not take ownership of the data, so there is no device argument.
            The input array must have rows * columns elements.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.Double},System.Int64,System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, organizing it as a three-dimensional tensor.
            </summary>
            <remarks>
            The Torch runtime does not take ownership of the data, so there is no device argument.
            The input array must have dim0*dim1*dim2 elements.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.Double},System.Int64,System.Int64,System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, organizing it as a four-dimensional tensor.
            </summary>
            <remarks>The Torch runtime does not take ownership of the data, so there is no device argument.
            The input array must have dim0*dim1*dim2*dim3 elements.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Double[0:,0:],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a two-dimensional tensor from a two-dimensional array of values.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Double[0:,0:,0:],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a three-dimensional tensor from a three-dimensional array of values.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Double[0:,0:,0:,0:],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a four-dimensional tensor from a four-dimensional array of values.from
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Memory{System.Double},System.ReadOnlySpan{System.Int64},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, shaping it based on the shape passed in.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.DoubleTensor(TorchSharp.torch.Tensor)">
            <summary>
            Cast a tensor to a 64-bit floating point tensor.
            </summary>
            <param name="t">The input tensor</param>
            <returns>'this' if the tensor is already a 64-bit floating point tensor; otherwise, a new tensor.</returns>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Single,TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Create a scalar tensor from a single value
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Single,System.Single,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Create a scalar complex number tensor from independent real and imaginary components
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.ValueTuple{System.Single,System.Single},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Create a scalar complex number tensor from a tuple of (real, imaginary)
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.Single},System.ReadOnlySpan{System.Int64},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, shaping it based on the shape passed in.
            </summary>
            <remarks>The Torch runtime does not take ownership of the data, so there is no device argument.</remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Single[],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, shaping it based on the shape passed in.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Single[],System.ReadOnlySpan{System.Int64},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, shaping it based on the shape passed in.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.Single},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a 1-D tensor from an array of values, shaping it based on the input array.
            </summary>
            <remarks>The Torch runtime does not take ownership of the data, so there is no device argument.</remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.Single},System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, organizing it as a two-dimensional tensor.
            </summary>
            <remarks>
            The Torch runtime does not take ownership of the data, so there is no device argument.
            The input array must have rows * columns elements.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.Single},System.Int64,System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, organizing it as a three-dimensional tensor.
            </summary>
            <remarks>
            The Torch runtime does not take ownership of the data, so there is no device argument.
            The input array must have dim0*dim1*dim2 elements.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.Single},System.Int64,System.Int64,System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, organizing it as a four-dimensional tensor.
            </summary>
            <remarks>
            The Torch runtime does not take ownership of the data, so there is no device argument.
            The input array must have dim0*dim1*dim2*dim3 elements.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Single[0:,0:],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a two-dimensional tensor from a two-dimensional array of values.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Single[0:,0:,0:],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a three-dimensional tensor from a three-dimensional array of values.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Single[0:,0:,0:,0:],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a four-dimensional tensor from a four-dimensional array of values.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Memory{System.Single},System.ReadOnlySpan{System.Int64},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, shaping it based on the shape passed in.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.FloatTensor(TorchSharp.torch.Tensor)">
            <summary>
            Cast a tensor to a 32-bit floating point tensor.
            </summary>
            <param name="t">The input tensor</param>
            <returns>'this' if the tensor is already a 32-bit floating point; otherwise, a new tensor.</returns>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.Half},System.ReadOnlySpan{System.Int64},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, shaping it based on the shape passed in.
            </summary>
            <remarks>The Torch runtime does not take ownership of the data, so there is no device argument.</remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Half[],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, shaping it based on the shape passed in.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Half[],System.ReadOnlySpan{System.Int64},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, shaping it based on the shape passed in.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.Half},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a 1-D tensor from an array of values, shaping it based on the input array.
            </summary>
            <remarks>The Torch runtime does not take ownership of the data, so there is no device argument.</remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.Half},System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, organizing it as a two-dimensional tensor.
            </summary>
            <remarks>
            The Torch runtime does not take ownership of the data, so there is no device argument.
            The input array must have rows * columns elements.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.Half},System.Int64,System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, organizing it as a three-dimensional tensor.
            </summary>
            <remarks>
            The Torch runtime does not take ownership of the data, so there is no device argument.
            The input array must have dim0*dim1*dim2 elements.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.Half},System.Int64,System.Int64,System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, organizing it as a four-dimensional tensor.
            </summary>
            <remarks>
            The Torch runtime does not take ownership of the data, so there is no device argument.
            The input array must have dim0*dim1*dim2*dim3 elements.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Half[0:,0:],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a two-dimensional tensor from a two-dimensional array of values.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Half[0:,0:,0:],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a three-dimensional tensor from a three-dimensional array of values.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Half[0:,0:,0:,0:],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a four-dimensional tensor from a four-dimensional array of values.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Memory{System.Half},System.ReadOnlySpan{System.Int64},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, shaping it based on the shape passed in.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Int32,TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Create a scalar tensor from a single value
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.Int32},System.ReadOnlySpan{System.Int64},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, shaping it based on the shape passed in.
            </summary>
            <remarks>The Torch runtime does not take ownership of the data, so there is no device argument.</remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Int32[],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, shaping it based on the shape passed in.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Int32[],System.ReadOnlySpan{System.Int64},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, shaping it based on the shape passed in.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.Int32},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a 1-D tensor from an array of values, shaping it based on the input array.
            </summary>
            <remarks>The Torch runtime does not take ownership of the data, so there is no device argument.</remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.Int32},System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, organizing it as a two-dimensional tensor.
            </summary>
            <remarks>
            The Torch runtime does not take ownership of the data, so there is no device argument.
            The input array must have rows * columns elements.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.Int32},System.Int64,System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, organizing it as a three-dimensional tensor.
            </summary>
            <remarks>
            The Torch runtime does not take ownership of the data, so there is no device argument.
            The input array must have dim0*dim1*dim2 elements.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Int32[],System.Int64,System.Int64,System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, organizing it as a four-dimensional tensor.
            </summary>
            <remarks>
            The Torch runtime does not take ownership of the data, so there is no device argument.
            The input array must have dim0*dim1*dim2*dim3 elements.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Int32[0:,0:],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a two-dimensional tensor from a two-dimensional array of values.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Int32[0:,0:,0:],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a three-dimensional tensor from a three-dimensional array of values.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Int32[0:,0:,0:,0:],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a four-dimensional tensor from a four-dimensional array of values.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Memory{System.Int32},System.ReadOnlySpan{System.Int64},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, shaping it based on the shape passed in.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.IntTensor(TorchSharp.torch.Tensor)">
            <summary>
            Cast a tensor to a 32-bit integer tensor.
            </summary>
            <param name="t">The input tensor</param>
            <returns>'this' if the tensor is already a 32-bit integer tensor; otherwise, a new tensor.</returns>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Create a scalar tensor from a single value
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.Int64},System.ReadOnlySpan{System.Int64},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, shaping it based on the shape passed in.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Int64[],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, shaping it based on the shape passed in.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Int64[],System.ReadOnlySpan{System.Int64},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, shaping it based on the shape passed in.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.Int64},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a 1-D tensor from an array of values, shaping it based on the input array.
            </summary>
            <remarks>The Torch runtime does not take ownership of the data, so there is no device argument.</remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.Int64},System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, organizing it as a two-dimensional tensor.
            </summary>
            <remarks>
            The Torch runtime does not take ownership of the data, so there is no device argument.
            The input array must have rows * columns elements.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.Int64},System.Int64,System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, organizing it as a three-dimensional tensor.
            </summary>
            <remarks>
            The Torch runtime does not take ownership of the data, so there is no device argument.
            The input array must have dim0*dim1*dim2 elements.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.Int64},System.Int64,System.Int64,System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, organizing it as a four-dimensional tensor.
            </summary>
            <remarks>
            The Torch runtime does not take ownership of the data, so there is no device argument.
            The input array must have dim0*dim1*dim2*dim3 elements.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Int64[0:,0:],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a two-dimensional tensor from a two-dimensional array of values.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Int64[0:,0:,0:],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a three-dimensional tensor from a three-dimensional array of values.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Int64[0:,0:,0:,0:],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a four-dimensional tensor from a four-dimensional array of values.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Memory{System.Int64},System.ReadOnlySpan{System.Int64},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, shaping it based on the shape passed in.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.LongTensor(TorchSharp.torch.Tensor)">
            <summary>
            Cast a tensor to a 64-bit integer tensor.
            </summary>
            <param name="t">The input tensor</param>
            <returns>'this' if the tensor is already a 64-bit integer tensor; otherwise, a new tensor.</returns>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.SByte,TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Create a scalar tensor from a single value
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.SByte},System.ReadOnlySpan{System.Int64},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, shaping it based on the shape passed in.
            </summary>
            <remarks>The Torch runtime does not take ownership of the data, so there is no device argument.</remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.SByte[],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, shaping it based on the shape passed in.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.SByte[],System.ReadOnlySpan{System.Int64},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, shaping it based on the shape passed in.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.SByte},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a 1-D tensor from an array of values, shaping it based on the input array.
            </summary>
            <remarks>The Torch runtime does not take ownership of the data, so there is no device argument.</remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.SByte},System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, organizing it as a two-dimensional tensor.
            </summary>
            <remarks>
            The Torch runtime does not take ownership of the data, so there is no device argument.
            The input array must have rows * columns elements.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.SByte},System.Int64,System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, organizing it as a three-dimensional tensor.
            </summary>
            <remarks>
            The Torch runtime does not take ownership of the data, so there is no device argument.
            The input array must have dim0*dim1*dim2 elements.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.SByte},System.Int64,System.Int64,System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, organizing it as a four-dimensional tensor.
            </summary>
            <remarks>
            The Torch runtime does not take ownership of the data, so there is no device argument.
            The input array must have dim0*dim1*dim2*dim3 elements.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.SByte[0:,0:],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a two-dimensional tensor from a two-dimensional array of values.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.SByte[0:,0:,0:],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a three-dimensional tensor from a three-dimensional array of values.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.SByte[0:,0:,0:,0:],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a four-dimensional tensor from a four-dimensional array of values.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Memory{System.SByte},System.ReadOnlySpan{System.Int64},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, shaping it based on the shape passed in.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Int16,TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Create a scalar tensor from a single value
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.Int16},System.ReadOnlySpan{System.Int64},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, shaping it based on the shape passed in.
            </summary>
            <remarks>The Torch runtime does not take ownership of the data, so there is no device argument.</remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Int16[],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, shaping it based on the shape passed in.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Int16[],System.ReadOnlySpan{System.Int64},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, shaping it based on the shape passed in.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.Int16},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a 1-D tensor from an array of values, shaping it based on the input array.
            </summary>
            <remarks>The Torch runtime does not take ownership of the data, so there is no device argument.</remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.Int16},System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, organizing it as a two-dimensional tensor.
            </summary>
            <remarks>
            The Torch runtime does not take ownership of the data, so there is no device argument.
            The input array must have rows * columns elements.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.Int16},System.Int64,System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, organizing it as a three-dimensional tensor.
            </summary>
            <remarks>
            The Torch runtime does not take ownership of the data, so there is no device argument.
            The input array must have dim0*dim1*dim2 elements.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Collections.Generic.IList{System.Int16},System.Int64,System.Int64,System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, organizing it as a four-dimensional tensor.
            </summary>
            <remarks>
            The Torch runtime does not take ownership of the data, so there is no device argument.
            The input array must have dim0*dim1*dim2*dim3 elements.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Int16[0:,0:],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a two-dimensional tensor from a two-dimensional array of values.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Int16[0:,0:,0:],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a three-dimensional tensor from a three-dimensional array of values.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Int16[0:,0:,0:,0:],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a four-dimensional tensor from a four-dimensional array of values.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensor(System.Memory{System.Int16},System.ReadOnlySpan{System.Int64},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a tensor from an array of values, shaping it based on the shape passed in.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.ShortTensor(TorchSharp.torch.Tensor)">
            <summary>
            Cast a tensor to a 16-bit integer tensor.
            </summary>
            <param name="t">The input tensor</param>
            <returns>'this' if the tensor is already a 16-bit integer tensor; otherwise, a new tensor.</returns>
        </member>
        <member name="M:TorchSharp.torch.zeros(System.Int64[],System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new tensor filled with zeros
            </summary>
        </member>
        <member name="M:TorchSharp.torch.zeros(System.ReadOnlySpan{System.Int64},System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new tensor filled with zeros
            </summary>
        </member>
        <member name="M:TorchSharp.torch.zeros(System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new 1-D tensor filled with zeros
            </summary>
        </member>
        <member name="M:TorchSharp.torch.zeros(System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new 2-D tensor filled with zeros
            </summary>
        </member>
        <member name="M:TorchSharp.torch.zeros(System.Int64,System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new 3-D tensor filled with zeros
            </summary>
        </member>
        <member name="M:TorchSharp.torch.zeros(System.Int64,System.Int64,System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new 4-D tensor filled with zeros
            </summary>
        </member>
        <member name="M:TorchSharp.torch.zeros(System.Int32,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new 1-D tensor filled with zeros
            </summary>
        </member>
        <member name="M:TorchSharp.torch.zeros(System.Int32,System.Int32,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new 2-D tensor filled with zeros
            </summary>
        </member>
        <member name="M:TorchSharp.torch.zeros(System.Int32,System.Int32,System.Int32,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new 3-D tensor filled with zeros
            </summary>
        </member>
        <member name="M:TorchSharp.torch.zeros(System.Int32,System.Int32,System.Int32,System.Int32,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Create a new 4-D tensor filled with zeros
            </summary>
        </member>
        <member name="M:TorchSharp.torch.zeros_like(TorchSharp.torch.Tensor,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,System.String[])">
            <summary>
            Returns a tensor filled with the scalar value 0, with the same size as input.
            </summary>
        </member>
        <member name="T:TorchSharp.torch.Size">
            <summary>
            Represents the dimensions of a tensor, that is, its shape.
            </summary>
            <remarks>
            The primary purpose of this type, at the moment, is to avoid having to declare
            too many overloads on tensor factories that take input sizes.
            The name was chosen to coincide with 'torch.Size' in PyTorch. It may later be
            used as the return value of 'Tensor.shape' and 'Tensor.size()'
            </remarks>
        </member>
        <member name="F:TorchSharp.torch.Size.Empty">
            <summary>
            Represents an empty size.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Size.#ctor(System.Int64[])">
            <summary>
            Constructor
            </summary>
            <param name="shape">An array of longs, the size of an N-D tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.Size.#ctor(System.Collections.Generic.IEnumerable{System.Int64})">
            <summary>
            Constructor
            </summary>
            <param name="shape">An enumerable of longs, the size of an N-D tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.Size.#ctor(System.Int32[])">
            <summary>
            Constructor
            </summary>
            <param name="shape">An array of longs, the size of an N-D tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.Size.#ctor(System.Int64)">
            <summary>
            Constructor
            </summary>
            <param name="size">The size of a 1D tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.Size.#ctor(System.ValueTuple{System.Int64,System.Int64})">
            <summary>
            Constructor
            </summary>
            <param name="size">The size of a 2D tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.Size.#ctor(System.ValueTuple{System.Int64,System.Int64,System.Int64})">
            <summary>
            Constructor
            </summary>
            <param name="size">The size of a 3D tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.Size.#ctor(System.ValueTuple{System.Int64,System.Int64,System.Int64,System.Int64})">
            <summary>
            Constructor
            </summary>
            <param name="size">The size of a 4D tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.Size.#ctor(System.ValueTuple{System.Int64,System.Int64,System.Int64,System.Int64,System.Int64})">
            <summary>
            Constructor
            </summary>
            <param name="size">The size of a 5D tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.Size.#ctor(System.ValueTuple{System.Int64,System.Int64,System.Int64,System.Int64,System.Int64,System.Int64})">
            <summary>
            Constructor
            </summary>
            <param name="size">The size of a 6D tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.Size.#ctor(System.Int32)">
            <summary>
            Constructor
            </summary>
            <param name="size">The size of a 1D tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.Size.#ctor(System.ValueTuple{System.Int32,System.Int32})">
            <summary>
            Constructor
            </summary>
            <param name="size">The size of a 2D tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.Size.#ctor(System.ValueTuple{System.Int32,System.Int32,System.Int32})">
            <summary>
            Constructor
            </summary>
            <param name="size">The size of a 3D tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.Size.#ctor(System.ValueTuple{System.Int32,System.Int32,System.Int32,System.Int32})">
            <summary>
            Constructor
            </summary>
            <param name="size">The size of a 4D tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.Size.#ctor(System.ValueTuple{System.Int32,System.Int32,System.Int32,System.Int32,System.Int32})">
            <summary>
            Constructor
            </summary>
            <param name="size">The size of a 5D tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.Size.#ctor(System.ValueTuple{System.Int32,System.Int32,System.Int32,System.Int32,System.Int32,System.Int32})">
            <summary>
            Constructor
            </summary>
            <param name="size">The size of a 6D tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.Size.op_Implicit(System.Int64)~TorchSharp.torch.Size">
            <summary>
            Implicit conversion operators. Useful to avoid overloads everywhere.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Size.numel">
            <summary>
            The number of elements in a tensor, the product of its shape elements.
            </summary>
            <returns></returns>
        </member>
        <member name="P:TorchSharp.torch.Size.Item(System.Int32)">
            <summary>
            Element accessor
            </summary>
            <param name="idx">The element index</param>
            <returns></returns>
        </member>
        <member name="P:TorchSharp.torch.Size.Item(System.Int64)">
            <summary>
            Element accessor
            </summary>
            <param name="idx">The element index</param>
            <returns></returns>
        </member>
        <member name="T:TorchSharp.torch.Storage">
            <summary>
            A torch.Storage is a contiguous, one-dimensional array of a single data type.
            Every tensor has a corresponding storage of the same data type.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Storage.bool">
            <summary>
            Convert to bool storage.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Storage.byte">
            <summary>
            Convert to byte storage.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Storage.char">
            <summary>
            Convert to char storage.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Storage.int">
            <summary>
            Convert to int storage.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Storage.long">
            <summary>
            Convert to long storage.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Storage.float">
            <summary>
            Convert to float storage.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Storage.double">
            <summary>
            Convert to double storage.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Storage.complex_float">
            <summary>
            Convert to 32-bit complex storage.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Storage.complex_double">
            <summary>
            Convert to 64-bit complex storage.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Storage.element_size">
            <summary>
            The size of each storage element.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Storage.data_ptr">
            <summary>
            A pointer to the raw data in memory.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Storage.nbytes">
            <summary>
            The number of bytes allocated to the storage.
            </summary>
            <returns></returns>
        </member>
        <member name="T:TorchSharp.torch.Storage`1">
            <summary>
            A torch.Storage is a contiguous, one-dimensional array of a single data type.
            Every tensor has a corresponding storage of the same data type.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Storage`1.element_size">
            <summary>
            Size of each storage element.
            </summary>
            <returns></returns>
        </member>
        <member name="P:TorchSharp.torch.Storage`1.device">
            <summary>
            The device where the storage is located.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Storage`1.cuda(TorchSharp.torch.Device)">
            <summary>
            Move the storage to a CUDA device.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Storage`1.cpu">
            <summary>
            Move the storage to the CPU.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Storage`1.ToArray">
            <summary>
            Convert the storage instance to a .NET array, copying its data.
            </summary>
            <returns></returns>
        </member>
        <member name="P:TorchSharp.torch.Storage`1.Item(System.Int32)">
            <summary>
            Accesses a single element of a storage.
            </summary>
            <param name="index">The index of the element.</param>
            <returns></returns>
        </member>
        <member name="P:TorchSharp.torch.Storage`1.Item(System.ValueTuple{System.Nullable{System.Int32},System.Nullable{System.Int32}})">
            <summary>
            Accesses a slice of a storage instance.
            </summary>
            <param name="range">The range, expressed as a tuple [start,end)</param>
        </member>
        <member name="P:TorchSharp.torch.Storage`1.Item(System.Range)">
            <summary>
            Accesses a slice of a storage instance.
            </summary>
            <param name="range">The range.</param>
        </member>
        <member name="P:TorchSharp.torch.Storage`1.Count">
            <summary>
            The number of elements in the storage.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.Storage`1.copy_(System.Collections.Generic.IList{`0})">
            <summary>
            Copy data from an array into a storage instance.
            </summary>
            <param name="array"></param>
        </member>
        <member name="M:TorchSharp.torch.Storage`1.fill_(`0)">
            <summary>
            Fill a storage instance with a single value.
            </summary>
            <param name="value"></param>
        </member>
        <member name="M:TorchSharp.torch.Storage`1.tolist">
            <summary>
            Convert the storage to a .NET list.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.Storage`1.CopyTo(System.Collections.Generic.IList{`0},System.Int32)">
            <summary>
            Copy the contents of the Storage instance into the provided array, starting at 'arrayIndex'
            </summary>
            <param name="array">A target array.</param>
            <param name="arrayIndex">The first offset in the array to write data to.</param>
        </member>
        <member name="M:TorchSharp.torch.Storage`1.CopyFrom(System.Collections.Generic.IList{`0},System.Int32)">
            <summary>
            Copy the contents of the provided array into the Storage instance, starting at 'arrayIndex' in the array.
            </summary>
            <param name="array">A source array.</param>
            <param name="arrayIndex">The first offset in the array to read data from.</param>
        </member>
        <member name="M:TorchSharp.torch.Storage`1.IndexOf(`0)">
            <summary>
            Look up a value and return the first index where it can be found.
            </summary>
            <param name="item">The item to look for.</param>
            <returns></returns>
        </member>
        <member name="T:TorchSharp.torch.TensorIndex">
            <summary>
            Type used to represent the variety of indexing capabilities that are
            available in Pyton, and therefore to PyTorch.
            </summary>
        </member>
        <member name="T:TorchSharp.torch.ScalarType">
            <summary>
            The element types of tensors.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.NewDisposeScope">
            <summary>
            Creates a new dispose scope for the current thread. Any tensor created within the dispose scope will
            be automatically disposed once the dispose scope is disposed.
            </summary>
        </member>
        <member name="P:TorchSharp.torch.CurrentDisposeScope">
            <summary>
            Get the current dispose scope for the current thread.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.WrappedTensorDisposeScope(System.Func{TorchSharp.torch.Tensor})">
            <summary>
            Creates a new dispose scope for the current thread, wrapping an expression.
            </summary>
        </member>
        <member name="P:TorchSharp.torch.TensorStringStyle">
            <summary>
            The default string formatting style used by ToString(), print(), and str()
            </summary>
        </member>
        <member name="M:TorchSharp.torch.set_printoptions(System.Int32,System.Nullable{System.Int32},System.String,System.Boolean,System.Nullable{System.Int32},System.Nullable{System.Int32})">
            <summary>
            Set options for printing.
            </summary>
            <param name="precision">Number of digits of precision for floating point output.</param>
            <param name="linewidth">The number of characters per line for the purpose of inserting line breaks (default = 100).</param>
            <param name="newLine">The string to use to represent new-lines. Starts out as 'Environment.NewLine'</param>
            <param name="sci_mode">Enable scientific notation.</param>
            <param name="maxRows">The maximum number of rows prrinted.</param>
            <param name="maxColumns">The maximum number of columns prrinted.</param>
        </member>
        <member name="M:TorchSharp.torch.set_printoptions(System.Nullable{TorchSharp.TensorStringStyle},System.String,System.Nullable{System.Int32},System.String,System.Nullable{System.Int32},System.Nullable{System.Int32})">
            <summary>
            Set options for printing.
            </summary>
            <param name="style">The default string formatting style used by ToString(), print(), and str()</param>
            <param name="floatFormat">
            The format string to use for floating point values.
            See: https://learn.microsoft.com/en-us/dotnet/standard/base-types/standard-numeric-format-strings
            </param>
            <param name="linewidth">The number of characters per line for the purpose of inserting line breaks (default = 100).</param>
            <param name="newLine">The string to use to represent new-lines. Starts out as 'Environment.NewLine'</param>
            <param name="maxRows">The maximum number of rows prrinted.</param>
            <param name="maxColumns">The maximum number of columns prrinted.</param>
        </member>
        <member name="M:TorchSharp.torch.ComplexFloat32Tensor.arange(TorchSharp.Scalar,TorchSharp.Scalar,TorchSharp.Scalar,TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Creates 1-D tensor of size [(end - start) / step] with values from interval [start, end) and
            common difference step, starting from start.
            </summary>
            <remarks>In the case of complex element types, 'arange' will create a complex tensor with img=0 in all elements.</remarks>
        </member>
        <member name="M:TorchSharp.torch.ComplexFloat32Tensor.from(System.ValueTuple{System.Single,System.Single},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Create a scalar tensor from a single value
            </summary>
        </member>
        <member name="M:TorchSharp.torch.ComplexFloat32Tensor.from(System.Single,System.Single,TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Create a scalar tensor from a single value
            </summary>
        </member>
        <member name="M:TorchSharp.torch.ComplexFloat32Tensor.randint(System.Int64,System.Int64[],TorchSharp.torch.Device,System.Boolean)">
            <summary>
             Create a new tensor filled with random integer values taken from a uniform distribution in [0, max).
             The real and imaginary parts will be filled independently of each other.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.ComplexFloat64Tensor.arange(TorchSharp.Scalar,TorchSharp.Scalar,TorchSharp.Scalar,TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Creates 1-D tensor of size [(end - start) / step] with values from interval [start, end) and
            common difference step, starting from start.
            </summary>
            <remarks>In the case of complex element types, 'arange' will create a complex tensor with img=0 in all elements.</remarks>
        </member>
        <member name="M:TorchSharp.torch.ComplexFloat64Tensor.from(System.Numerics.Complex,TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Create a scalar tensor from a single value
            </summary>
        </member>
        <member name="M:TorchSharp.torch.ComplexFloat64Tensor.from(System.Double,System.Double,TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Create a scalar tensor from a single value
            </summary>
        </member>
        <member name="M:TorchSharp.torch.ComplexFloat64Tensor.randint(System.Int64,System.Int64[],TorchSharp.torch.Device,System.Boolean)">
            <summary>
             Create a new tensor filled with random integer values taken from a uniform distribution in [0, max).
             The real and imaginary parts will be filled independently of each other.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.addbmm(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Single,System.Single)">
            <summary>
            Performs a batch matrix-matrix product of matrices stored in batch1 and batch2, with a reduced
            add step (all matrix multiplications get accumulated along the first dimension).
            input is added to the final result.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="batch1">The first batch of matrices to be multiplied</param>
            <param name="batch2">The second batch of matrices to be multiplied</param>
            <param name="beta">Nultiplier for input (β)</param>
            <param name="alpha">Multiplier for batch1 @ batch2 (α)</param>
        </member>
        <member name="M:TorchSharp.torch.addbmm_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Single,System.Single)">
            <summary>
            Performs a batch matrix-matrix product of matrices stored in batch1 and batch2, with a reduced
            add step (all matrix multiplications get accumulated along the first dimension).
            input is added to the final result.
            In-place version of addbmm.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="batch1">The first batch of matrices to be multiplied</param>
            <param name="batch2">The second batch of matrices to be multiplied</param>
            <param name="beta">Nultiplier for input (β)</param>
            <param name="alpha">Multiplier for batch1 @ batch2 (α)</param>
        </member>
        <member name="M:TorchSharp.torch.addmm(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Single,System.Single)">
            <summary>
            Performs a matrix multiplication of the matrices mat1 and mat2. The matrix input is added to the final result.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="mat1">First matrix</param>
            <param name="mat2">Second matrix</param>
            <param name="beta">Input scale factor</param>
            <param name="alpha">Matrix multiplication scale factor</param>
        </member>
        <member name="M:TorchSharp.torch.addmm_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Single,System.Single)">
            <summary>
            Performs a matrix multiplication of the matrices mat1 and mat2. The matrix input is added to the final result.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="mat1">First matrix</param>
            <param name="mat2">Second matrix</param>
            <param name="beta">Input scale factor</param>
            <param name="alpha">Matrix multiplication scale factor</param>
        </member>
        <member name="M:TorchSharp.torch.addmv(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Single,System.Single)">
            <summary>
            Performs a matrix multiplication of the matrices mat1 and mat2. The matrix input is added to the final result.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="mat1">First matrix</param>
            <param name="mat2">Second matrix</param>
            <param name="beta">Input scale factor</param>
            <param name="alpha">Matrix multiplication scale factor</param>
        </member>
        <member name="M:TorchSharp.torch.addmv_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Single,System.Single)">
            <summary>
            Performs a matrix multiplication of the matrices mat1 and mat2. The matrix input is added to the final result.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="mat1">First matrix</param>
            <param name="mat2">Second matrix</param>
            <param name="beta">Input scale factor</param>
            <param name="alpha">Matrix multiplication scale factor</param>
        </member>
        <member name="M:TorchSharp.torch.addr(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Single,System.Single)">
            <summary>
            Performs the outer-product of vectors vec1 and vec2 and adds it to the input tensor.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.addr_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Single,System.Single)">
            <summary>
            Performs the outer-product of vectors vec1 and vec2 and adds it to the input tensor.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="vec1">The first vector of the outer product</param>
            <param name="vec2">The second vector of the outer product</param>
            <param name="beta">Input scale factor</param>
            <param name="alpha">Outer-product scale factor</param>
        </member>
        <member name="M:TorchSharp.torch.baddbmm(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Single,System.Single)">
            <summary>
            Performs a batch matrix-matrix product of matrices in batch1 and batch2. input is added to the final result.
            batch1 and batch2 must be 3-D tensors each containing the same number of matrices.
            </summary>
            <param name="input">The tensor to be added</param>
            <param name="batch1">The first batch of matrices to be multiplied</param>
            <param name="batch2">The second batch of matrices to be multiplied</param>
            <param name="beta">A multiplier for input</param>
            <param name="alpha">A multiplier for batch1 @ batch2</param>
        </member>
        <member name="M:TorchSharp.torch.bmm(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Performs a batch matrix-matrix product of matrices stored in input and mat2.
            </summary>
            <param name="input">The input tensor</param>
            <param name="batch2">the second batch of matrices to be multiplied</param>
        </member>
        <member name="M:TorchSharp.torch.cholesky_inverse(TorchSharp.torch.Tensor,System.Boolean)">
            <summary>
            Computes the inverse of a symmetric positive-definite matrix AA using its Cholesky factor uu : returns matrix inv
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.cholesky_solve(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Boolean)">
            <summary>
            Solves a linear system of equations with a positive semidefinite matrix to be inverted given its Cholesky factor matrix u.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.dot(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Computes the dot product of two 1D tensors.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.geqrf(TorchSharp.torch.Tensor)">
            <summary>
            This is a low-level function for calling LAPACK’s geqrf directly.
            This function returns a namedtuple (a, tau) as defined in LAPACK documentation for geqrf.
            </summary>
            <param name="input">The input tensor.</param>
            <remarks>
            Computes a QR decomposition of input. Both Q and R matrices are stored in the same output tensor a.
            The elements of R are stored on and above the diagonal. Elementary reflectors (or Householder vectors)
            implicitly defining matrix Q are stored below the diagonal. The results of this function can be used
            together with torch.linalg.householder_product() to obtain the Q matrix or with torch.ormqr(), which
            uses an implicit representation of the Q matrix, for an efficient matrix-matrix multiplication.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.ger(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Outer product of input and vec2.
            </summary>
            <param name="input">The input vector.</param>
            <param name="vec2">1-D input vector.</param>
            <remarks>If input is a vector of size n and vec2 is a vector of size m, then out must be a matrix of size n×m.</remarks>
        </member>
        <member name="M:TorchSharp.torch.inner(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Computes the dot product for 1D tensors.
            For higher dimensions, sums the product of elements from input and other along their last dimension.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.inverse(TorchSharp.torch.Tensor)">
            <summary>
            Alias for torch.linalg.inv()
            </summary>
        </member>
        <member name="M:TorchSharp.torch.det(TorchSharp.torch.Tensor)">
            <summary>
            Computes the determinant of a square matrix.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.lstsq(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Computes the solution to the least squares and least norm problems for a full rank matrix A of size m×n and a matrix B of size m×k.
            </summary>
            <param name="A">the m by n matrix AA</param>
            <param name="B">the matrix BB</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.lu(TorchSharp.torch.Tensor,System.Boolean,System.Boolean)">
            <summary>
            Computes the LU factorization of a matrix or batches of matrices A. Returns a tuple containing the LU factorization and pivots of A. Pivoting is done if pivot is set to true.
            </summary>
            <param name="A">The tensor to factor of size (∗,m,n)</param>
            <param name="pivot">Controls whether pivoting is done. Default: true</param>
            <param name="get_infos">If set to True, returns an info IntTensor. Default: false</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.lu_solve(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Returns the LU solve of the linear system Ax = b using the partially pivoted LU factorization of A from torch.lu().
            </summary>
            <param name="b">The RHS tensor of size (∗,m,k), where *∗ is zero or more batch dimensions.</param>
            <param name="LU_data">The pivoted LU factorization of A from torch.lu() of size (∗,m,m), where *∗ is zero or more batch dimensions.</param>
            <param name="LU_pivots">
            The pivots of the LU factorization from torch.lu() of size (∗,m), where *∗ is zero or more batch dimensions.
            The batch dimensions of LU_pivots must be equal to the batch dimensions of LU_data.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.lu_unpack(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Boolean,System.Boolean)">
            <summary>
            Unpacks the data and pivots from a LU factorization of a tensor into tensors L and U and a permutation tensor P.
            </summary>
            <param name="LU_data">The packed LU factorization data</param>
            <param name="LU_pivots">The packed LU factorization pivots</param>
            <param name="unpack_data">A flag indicating if the data should be unpacked. If false, then the returned L and U are null. Default: true</param>
            <param name="unpack_pivots">A flag indicating if the pivots should be unpacked into a permutation matrix P. If false, then the returned P is null. Default: true</param>
            <returns>A tuple of three tensors to use for the outputs (P, L, U)</returns>
        </member>
        <member name="M:TorchSharp.torch.matmul(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Matrix product of two tensors.
            </summary>
            <returns></returns>
            <remarks>
            The behavior depends on the dimensionality of the tensors as follows:
            1. If both tensors are 1-dimensional, the dot product (scalar) is returned
            2. If both arguments are 2-dimensional, the matrix-matrix product is returned.
            3. If the first argument is 1-dimensional and the second argument is 2-dimensional, a 1 is prepended to its dimension for the purpose of the matrix multiply. After the matrix multiply, the prepended dimension is removed.
            4. If the first argument is 2-dimensional and the second argument is 1-dimensional, the matrix-vector product is returned.
            5. If both arguments are at least 1-dimensional and at least one argument is N-dimensional (where N > 2), then a batched matrix multiply is returned.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.matrix_power(TorchSharp.torch.Tensor,System.Int32)">
            <summary>
            Computes the n-th power of a square matrix for an integer n.
            </summary>
            <param name="input">The input square matrix.</param>
            <param name="n">The exponent</param>
            <returns></returns>
            <remarks>Input tensor must be of shape (*, m, m) where * is zero or more batch dimensions.</remarks>
        </member>
        <member name="M:TorchSharp.torch.matrix_exp(TorchSharp.torch.Tensor)">
            <summary>
            Computes the matrix exponential of a square matrix or of each square matrix in a batch.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.mm(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Performs a matrix multiplication of the matrices input and mat2.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.mv(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Performs a matrix-vector product of the matrix input and the vector vec.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.orgqr(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Computes the first n columns of a product of Householder matrices.
            </summary>
            <param name="input">tensor of shape (*, m, n) where * is zero or more batch dimensions.</param>
            <param name="tau">tensor of shape (*, k) where * is zero or more batch dimensions.</param>
        </member>
        <member name="M:TorchSharp.torch.ormqr(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Boolean,System.Boolean)">
            <summary>
            Computes the matrix-matrix multiplication of a product of Householder matrices with a general matrix.
            </summary>
            <param name="input">Tensor of shape (*, mn, k) where * is zero or more batch dimensions and mn equals to m or n depending on the left.</param>
            <param name="tau">Tensor of shape (*, min(mn, k)) where * is zero or more batch dimensions.</param>
            <param name="other">Tensor of shape (*, m, n) where * is zero or more batch dimensions.</param>
            <param name="left">Controls the order of multiplication.</param>
            <param name="transpose">Controls whether the matrix Q is conjugate transposed or not.</param>
        </member>
        <member name="M:TorchSharp.torch.outer(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Outer product of input and vec2.
            </summary>
            <param name="input">1-D input vector.</param>
            <param name="vec2">1-D input vector.</param>
            <remarks>If input is a vector of size n and vec2 is a vector of size m, then out must be a matrix of size n×m.</remarks>
        </member>
        <member name="M:TorchSharp.torch.pinverse(TorchSharp.torch.Tensor,System.Double,System.Boolean)">
            <summary>
            Computes the pseudoinverse (Moore-Penrose inverse) of a matrix.
            </summary>
            <param name="input">Tensor of shape (*, m, n) where * is zero or more batch dimensions.</param>
            <param name="rcond">The tolerance value to determine when is a singular value zero </param>
            <param name="hermitian">Indicates whether A is Hermitian if complex or symmetric if real. </param>
            <remarks>Input should be tensor of shape (*, m, n) where * is zero or more batch dimensions.</remarks>
        </member>
        <member name="M:TorchSharp.torch.softmax(TorchSharp.torch.Tensor,System.Int32,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Computes the softmax function for the input tensor.
            </summary>
            <param name="input">The input tensor</param>
            <param name="dim">A dimension along which softmax will be computed.</param>
            <param name="dtype">The desired data type of returned tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.trapz(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Int64)">
            <summary>
            Computes the trapezoidal rule along dim. By default the spacing between elements is assumed
            to be 1, but dx can be used to specify a different constant spacing, and x can be used to specify arbitrary spacing along dim.
            </summary>
            <param name="y">Values to use when computing the trapezoidal rule.</param>
            <param name="x">Defines spacing between values as specified above.</param>
            <param name="dim">The dimension along which to compute the trapezoidal rule. The last (inner-most) dimension by default.</param>
        </member>
        <member name="M:TorchSharp.torch.trapz(TorchSharp.torch.Tensor,System.Double,System.Int64)">
            <summary>
            Computes the trapezoidal rule along dim. By default the spacing between elements is assumed
            to be 1, but dx can be used to specify a different constant spacing, and x can be used to specify arbitrary spacing along dim.
            </summary>
            <param name="y">Values to use when computing the trapezoidal rule.</param>
            <param name="dx">Constant spacing between values.</param>
            <param name="dim">The dimension along which to compute the trapezoidal rule. The last (inner-most) dimension by default.</param>
        </member>
        <member name="M:TorchSharp.torch.trapezoid(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Int64)">
            <summary>
            Computes the trapezoidal rule along dim. By default the spacing between elements is assumed
            to be 1, but dx can be used to specify a different constant spacing, and x can be used to specify arbitrary spacing along dim.
            </summary>
            <param name="y">Values to use when computing the trapezoidal rule.</param>
            <param name="x">Defines spacing between values as specified above.</param>
            <param name="dim">The dimension along which to compute the trapezoidal rule. The last (inner-most) dimension by default.</param>
        </member>
        <member name="M:TorchSharp.torch.trapezoid(TorchSharp.torch.Tensor,System.Double,System.Int64)">
            <summary>
            Computes the trapezoidal rule along dim. By default the spacing between elements is assumed
            to be 1, but dx can be used to specify a different constant spacing, and x can be used to specify arbitrary spacing along dim.
            </summary>
            <param name="y">Values to use when computing the trapezoidal rule.</param>
            <param name="dx">Constant spacing between values.</param>
            <param name="dim">The dimension along which to compute the trapezoidal rule. The last (inner-most) dimension by default.</param>
        </member>
        <member name="M:TorchSharp.torch.cumulative_trapezoid(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Int64)">
            <summary>
            Cumulatively computes the trapezoidal rule along dim. By default the spacing between elements is assumed
            to be 1, but dx can be used to specify a different constant spacing, and x can be used to specify arbitrary spacing along dim.
            </summary>
            <param name="y">Values to use when computing the trapezoidal rule.</param>
            <param name="x">Defines spacing between values as specified above.</param>
            <param name="dim">The dimension along which to compute the trapezoidal rule. The last (inner-most) dimension by default.</param>
        </member>
        <member name="M:TorchSharp.torch.cumulative_trapezoid(TorchSharp.torch.Tensor,System.Double,System.Int64)">
            <summary>
            Cumulatively computes the trapezoidal rule along dim. By default the spacing between elements is assumed
            to be 1, but dx can be used to specify a different constant spacing, and x can be used to specify arbitrary spacing along dim.
            </summary>
            <param name="y">Values to use when computing the trapezoidal rule.</param>
            <param name="dx">Constant spacing between values.</param>
            <param name="dim">The dimension along which to compute the trapezoidal rule. The last (inner-most) dimension by default.</param>
        </member>
        <member name="M:TorchSharp.torch.vdot(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Computes the dot product of two 1D tensors.
            </summary>
            <param name="input"></param>
            <param name="target"></param>
            <returns></returns>
            <remarks>
            The vdot(a, b) function handles complex numbers differently than dot(a, b).
            If the first argument is complex, the complex conjugate of the first argument is used for the calculation of the dot product.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.allclose(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Double,System.Double,System.Boolean)">
            <summary>
            This function checks if all input and other lie within a certain distance from each other
            </summary>
            <param name="tensor"></param>
            <param name="target"></param>
            <param name="rtol">Relative tolerance</param>
            <param name="atol">Absolute tolerance</param>
            <param name="equal_nan">If true, then two NaN s will be considered equal</param>
        </member>
        <member name="M:TorchSharp.torch.argsort(TorchSharp.torch.Tensor,System.Int64,System.Boolean)">
            <summary>
            Returns the indices that sort a tensor along a given dimension in ascending order by value.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.eq(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Element-wise equal comparison
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="right">The right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.ge(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Element-wise greater-than-or-equal comparison
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="right">The right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.gt(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Element-wise greater-than comparison
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="right">The right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.isnan(TorchSharp.torch.Tensor)">
            <summary>
            Returns a new tensor with boolean elements representing if each element of input is <value>NaN</value> or not.
            Complex values are considered <value>NaN</value> when either their real and/or imaginary part is <value>NaN</value>.
            </summary>
            <param name="input">the input tensor</param>
            <returns>A boolean tensor that is <value>True</value> where input is <value>NaN</value> and <value>False</value> elsewhere</returns>
        </member>
        <member name="M:TorchSharp.torch.kthvalue(TorchSharp.torch.Tensor,System.Int64,System.Nullable{System.Int64},System.Boolean)">
            <summary>
            Returns a named tuple (values, indices) where values is the k th smallest element of each row of the input tensor in the given dimension dim. And indices is the index location of each element found.
            If dim is not given, the last dimension of the input is chosen.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="k">k for the k-th smallest element</param>
            <param name="dim">The dimension to find the kth value along</param>
            <param name="keepdim">Whether the output tensor has dim retained or not.</param>
        </member>
        <member name="M:TorchSharp.torch.le(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Element-wise less-than-or-equal comparison
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="right">The right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.lt(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Element-wise less-than comparison
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="right">The right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.maximum(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Computes the element-wise maximum of input and other.
            </summary>
            <param name="input">The first input tensor</param>
            <param name="other">The second input tensor</param>
        </member>
        <member name="M:TorchSharp.torch.minimum(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Computes the element-wise minimum of input and other.
            </summary>
            <param name="input">The first input tensor</param>
            <param name="other">The second input tensor</param>
        </member>
        <member name="M:TorchSharp.torch.fmax(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
             <summary>
             Computes the element-wise maximum of input and other.
            
             This is like torch.maximum() except it handles NaNs differently: if exactly one of the two elements being compared is a NaN
             then the non-NaN element is taken as the maximum.
             Only if both elements are NaN is NaN propagated.
             </summary>
             <param name="input">The first input tensor</param>
             <param name="other">The second input tensor</param>
        </member>
        <member name="M:TorchSharp.torch.fmin(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
             <summary>
             Computes the element-wise minimum of input and other.
            
             This is like torch.minimum() except it handles NaNs differently: if exactly one of the two elements being compared is a NaN
             then the non-NaN element is taken as the minimum.
             Only if both elements are NaN is NaN propagated.
             </summary>
             <param name="input">The first input tensor</param>
             <param name="other">The second input tensor</param>
        </member>
        <member name="M:TorchSharp.torch.ne(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Element-wise not-equal comparison
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="right">The right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.sort(TorchSharp.torch.Tensor,System.Int64,System.Boolean,System.Boolean)">
            <summary>
            Sorts the elements of the input tensor along a given dimension in ascending order by value.
            </summary>
            <param name="input">The input tensor</param>
            <param name="dim">The dimension to sort along. If dim is not given, the last dimension of the input is chosen.</param>
            <param name="descending">Controls the sorting order (ascending or descending)</param>
            <param name="stable">Makes the sorting routine stable, which guarantees that the order of equivalent elements is preserved.</param>
            <returns>A named tuple of (values, indices) is returned, where the values are the sorted values and indices are the indices of the elements in the original input tensor.</returns>
        </member>
        <member name="M:TorchSharp.torch.searchsorted(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Boolean,System.Boolean,TorchSharp.torch.Tensor)">
            <summary>
            Find the indices from the innermost dimension of sorted_sequence such that, if the corresponding values in values were inserted before the indices,
            when sorted, the order of the corresponding innermost dimension within sorted_sequence would be preserved.
            Return a new tensor with the same size as values.
            If right is false, then the left boundary of sorted_sequence is closed. 
            </summary>
            <param name="sorted_sequence">N-D or 1-D tensor, containing monotonically increasing sequence on the innermost dimension unless sorter is provided, in which case the sequence does not need to be sorted</param>
            <param name="values">N-D tensor or a Scalar containing the search value(s).</param>
            <param name="out_int32">Indicates the output data type. torch.int32 if true, torch.int64 otherwise. Default value is false, i.e. default output data type is torch.int64.</param>
            <param name="right">Indicates the output data type. torch.int32 if true, torch.int64 otherwise. Default value is false, i.e. default output data type is torch.int64.</param>
            <param name="sorter">If provided, a tensor matching the shape of the unsorted sorted_sequence containing a sequence of indices that sort it in the ascending order on the innermost dimension</param>
        </member>
        <member name="M:TorchSharp.torch.searchsorted(TorchSharp.torch.Tensor,TorchSharp.Scalar,System.Boolean,System.Boolean,TorchSharp.torch.Tensor)">
            <summary>
            Find the indices from the innermost dimension of sorted_sequence such that, if the corresponding values in values were inserted before the indices,
            when sorted, the order of the corresponding innermost dimension within sorted_sequence would be preserved.
            Return a new tensor with the same size as values.
            If right is false, then the left boundary of sorted_sequence is closed. 
            </summary>
            <param name="sorted_sequence">N-D or 1-D tensor, containing monotonically increasing sequence on the innermost dimension unless sorter is provided, in which case the sequence does not need to be sorted</param>
            <param name="values">A Scalar containing the search value.</param>
            <param name="out_int32">Indicates the output data type. torch.int32 if true, torch.int64 otherwise. Default value is false, i.e. default output data type is torch.int64.</param>
            <param name="right">Indicates the output data type. torch.int32 if true, torch.int64 otherwise. Default value is false, i.e. default output data type is torch.int64.</param>
            <param name="sorter">If provided, a tensor matching the shape of the unsorted sorted_sequence containing a sequence of indices that sort it in the ascending order on the innermost dimension</param>
        </member>
        <member name="M:TorchSharp.torch.histogram(TorchSharp.torch.Tensor,TorchSharp.HistogramBinSelector,System.Nullable{System.ValueTuple{System.Double,System.Double}},System.Boolean)">
            https://github.com/numpy/numpy/blob/v1.24.0/numpy/lib/histograms.py#L679
            <summary>
            Computes a histogram of the values in a tensor.
            bins can be an integer or a 1D tensor.
            If bins is an int, it specifies the number of equal-width bins. By default, the lower and upper range of the bins is determined by the minimum and maximum elements of the input tensor. The range argument can be provided to specify a range for the bins.
            If bins is a 1D tensor, it specifies the sequence of bin edges including the rightmost edge. It should contain at least 2 elements and its elements should be increasing.
            </summary>
            <param name="input"> the input tensor. </param>
            <param name="bins"> int or 1D Tensor. If int, defines the number of equal-width bins. If tensor, defines the sequence of bin edges including the rightmost edge. </param>
            <param name="range"> Defines the range of the bins. </param>
            <param name="density"> If False, the result will contain the count (or total weight) in each bin. If True, the result is the value of the probability density function over the bins, normalized such that the integral over the range of the bins is 1. </param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.histogram(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Boolean)">
            <summary>
            Computes a histogram of the values in a tensor.
            bins can be an integer or a 1D tensor.
            If bins is an int, it specifies the number of equal-width bins. By default, the lower and upper range of the bins is determined by the minimum and maximum elements of the input tensor. The range argument can be provided to specify a range for the bins.
            If bins is a 1D tensor, it specifies the sequence of bin edges including the rightmost edge. It should contain at least 2 elements and its elements should be increasing.
            </summary>
            <param name="input"> the input tensor. </param>
            <param name="bins"> int or 1D Tensor. If int, defines the number of equal-width bins. If tensor, defines the sequence of bin edges including the rightmost edge. </param>
            <param name="weight"> If provided, weight should have the same shape as input. Each value in input contributes its associated weight towards its bin’s result. </param>
            <param name="density"> If False, the result will contain the count (or total weight) in each bin. If True, the result is the value of the probability density function over the bins, normalized such that the integral over the range of the bins is 1. </param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.histogram(TorchSharp.torch.Tensor,System.Int64,System.Nullable{System.ValueTuple{System.Double,System.Double}},TorchSharp.torch.Tensor,System.Boolean)">
            <summary>
            Computes a histogram of the values in a tensor.
            bins can be an integer or a 1D tensor.
            If bins is an int, it specifies the number of equal-width bins. By default, the lower and upper range of the bins is determined by the minimum and maximum elements of the input tensor. The range argument can be provided to specify a range for the bins.
            If bins is a 1D tensor, it specifies the sequence of bin edges including the rightmost edge. It should contain at least 2 elements and its elements should be increasing.
            </summary>
            <param name="input"> the input tensor. </param>
            <param name="bins"> int or 1D Tensor. If int, defines the number of equal-width bins. If tensor, defines the sequence of bin edges including the rightmost edge. </param>
            <param name="range"> Defines the range of the bins. </param>
            <param name="weight"> If provided, weight should have the same shape as input. Each value in input contributes its associated weight towards its bin’s result. </param>
            <param name="density"> If False, the result will contain the count (or total weight) in each bin. If True, the result is the value of the probability density function over the bins, normalized such that the integral over the range of the bins is 1. </param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.histogram(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.ValueTuple{TorchSharp.torch.Tensor,TorchSharp.torch.Tensor}@)">
            <summary>
            Computes a histogram of the values in a tensor.
            bins can be an integer or a 1D tensor.
            If bins is an int, it specifies the number of equal-width bins. By default, the lower and upper range of the bins is determined by the minimum and maximum elements of the input tensor. The range argument can be provided to specify a range for the bins.
            If bins is a 1D tensor, it specifies the sequence of bin edges including the rightmost edge. It should contain at least 2 elements and its elements should be increasing.
            </summary>
            <param name="input"> the input tensor. </param>
            <param name="bins"> int or 1D Tensor. If int, defines the number of equal-width bins. If tensor, defines the sequence of bin edges including the rightmost edge. </param>
            <param name="out_tensor"> the output tensor. (tuple, optional): The result tuple of two output tensors (hist, bin_edges). </param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.histogram(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Boolean,System.ValueTuple{TorchSharp.torch.Tensor,TorchSharp.torch.Tensor}@)">
            <summary>
            Computes a histogram of the values in a tensor.
            bins can be an integer or a 1D tensor.
            If bins is an int, it specifies the number of equal-width bins. By default, the lower and upper range of the bins is determined by the minimum and maximum elements of the input tensor. The range argument can be provided to specify a range for the bins.
            If bins is a 1D tensor, it specifies the sequence of bin edges including the rightmost edge. It should contain at least 2 elements and its elements should be increasing.
            </summary>
            <param name="input"> the input tensor. </param>
            <param name="bins"> int or 1D Tensor. If int, defines the number of equal-width bins. If tensor, defines the sequence of bin edges including the rightmost edge. </param>
            <param name="weight"> If provided, weight should have the same shape as input. Each value in input contributes its associated weight towards its bin’s result. </param>
            <param name="density"> If False, the result will contain the count (or total weight) in each bin. If True, the result is the value of the probability density function over the bins, normalized such that the integral over the range of the bins is 1. </param>
            <param name="out_tensor"> the output tensor. (tuple, optional): The result tuple of two output tensors (hist, bin_edges). </param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.histogram(TorchSharp.torch.Tensor,System.Int64,System.ValueTuple{TorchSharp.torch.Tensor,TorchSharp.torch.Tensor}@)">
            <summary>
            Computes a histogram of the values in a tensor.
            bins can be an integer or a 1D tensor.
            If bins is an int, it specifies the number of equal-width bins. By default, the lower and upper range of the bins is determined by the minimum and maximum elements of the input tensor. The range argument can be provided to specify a range for the bins.
            If bins is a 1D tensor, it specifies the sequence of bin edges including the rightmost edge. It should contain at least 2 elements and its elements should be increasing.
            </summary>
            <param name="input"> the input tensor. </param>
            <param name="bins"> int or 1D Tensor. If int, defines the number of equal-width bins. If tensor, defines the sequence of bin edges including the rightmost edge. </param>
            <param name="out_tensor"> the output tensor. (tuple, optional): The result tuple of two output tensors (hist, bin_edges). </param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.histogram(TorchSharp.torch.Tensor,System.Int64,System.Nullable{System.ValueTuple{System.Double,System.Double}},System.ValueTuple{TorchSharp.torch.Tensor,TorchSharp.torch.Tensor}@)">
            <summary>
            Computes a histogram of the values in a tensor.
            bins can be an integer or a 1D tensor.
            If bins is an int, it specifies the number of equal-width bins. By default, the lower and upper range of the bins is determined by the minimum and maximum elements of the input tensor. The range argument can be provided to specify a range for the bins.
            If bins is a 1D tensor, it specifies the sequence of bin edges including the rightmost edge. It should contain at least 2 elements and its elements should be increasing.
            </summary>
            <param name="input"> the input tensor. </param>
            <param name="bins"> int or 1D Tensor. If int, defines the number of equal-width bins. If tensor, defines the sequence of bin edges including the rightmost edge. </param>
            <param name="range"> Defines the range of the bins. </param>
            <param name="out_tensor"> the output tensor. (tuple, optional): The result tuple of two output tensors (hist, bin_edges). </param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.histogram(TorchSharp.torch.Tensor,System.Int64,System.Nullable{System.ValueTuple{System.Double,System.Double}},TorchSharp.torch.Tensor,System.Boolean,System.ValueTuple{TorchSharp.torch.Tensor,TorchSharp.torch.Tensor}@)">
            <summary>
            Computes a histogram of the values in a tensor.
            bins can be an integer or a 1D tensor.
            If bins is an int, it specifies the number of equal-width bins. By default, the lower and upper range of the bins is determined by the minimum and maximum elements of the input tensor. The range argument can be provided to specify a range for the bins.
            If bins is a 1D tensor, it specifies the sequence of bin edges including the rightmost edge. It should contain at least 2 elements and its elements should be increasing.
            </summary>
            <param name="input"> the input tensor. </param>
            <param name="bins"> int or 1D Tensor. If int, defines the number of equal-width bins. If tensor, defines the sequence of bin edges including the rightmost edge. </param>
            <param name="range"> Defines the range of the bins. </param>
            <param name="weight"> If provided, weight should have the same shape as input. Each value in input contributes its associated weight towards its bin’s result. </param>
            <param name="density"> If False, the result will contain the count (or total weight) in each bin. If True, the result is the value of the probability density function over the bins, normalized such that the integral over the range of the bins is 1. </param>
            <param name="out_tensor"> the output tensor. (tuple, optional): The result tuple of two output tensors (hist, bin_edges). </param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.topk(TorchSharp.torch.Tensor,System.Int32,System.Int32,System.Boolean,System.Boolean)">
            <summary>
            Returns the k largest elements of the given input tensor along a given dimension.
            </summary>
            <param name="tensor">The input tensor</param>
            <param name="k">The 'k' in 'top-k'.</param>
            <param name="dim">The dimension to sort along. If dim is not given, the last dimension of the input is chosen.</param>
            <param name="largest">Controls whether to return largest or smallest elements</param>
            <param name="sorted">Controls whether to return the elements in sorted order</param>
        </member>
        <member name="M:TorchSharp.torch.cholesky(TorchSharp.torch.Tensor,System.Boolean)">
            <summary>
            Computes the Cholesky decomposition of a symmetric positive-definite matrix 'input' or for batches of symmetric positive-definite matrices.
            </summary>
            <param name="input">The input matrix</param>
            <param name="upper">If upper is true, the returned matrix U is upper-triangular. If upper is false, the returned matrix L is lower-triangular</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.norm(TorchSharp.torch.Tensor)">
            <summary>
            Returns the matrix norm or vector norm of a given tensor.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.concatenate(System.Collections.Generic.IList{TorchSharp.torch.Tensor},System.Int64)">
            <summary>
            Concatenates the given sequence of tensors along the given axis (dimension).
            </summary>
            <param name="tensors">A sequence of tensors of the same type. Non-empty tensors provided must have the same shape, except in the cat dimension.</param>
            <param name="axis">The dimension over which the tensors are concatenated</param>
            <returns></returns>
            <remarks> All tensors must either have the same shape (except in the concatenating dimension) or be empty.</remarks>
        </member>
        <member name="M:TorchSharp.torch.squeeze(TorchSharp.torch.Tensor,System.Nullable{System.Int64})">
            <summary>
            Returns a tensor with all the dimensions of input of size 1 removed. When dim is given, a squeeze operation is done only in the given dimension.
            </summary>
            <param name="input">The input tensor</param>
            <param name="dim">If given, the input will be squeezed only in this dimension</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.squeeze_(TorchSharp.torch.Tensor,System.Nullable{System.Int64})">
            <summary>
            Modifies (in-place) a tensor with all the dimensions of input of size 1 removed. When dim is given, a squeeze operation is done only in the given dimension.
            </summary>
            <param name="input">The input tensor</param>
            <param name="dim">If given, the input will be squeezed only in this dimension</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.column_stack(System.Collections.Generic.IList{TorchSharp.torch.Tensor})">
            <summary>
            Creates a new tensor by horizontally stacking the input tensors.
            </summary>
            <param name="tensors">A list of input tensors.</param>
            <returns></returns>
            <remarks>Equivalent to torch.hstack(tensors), except each zero or one dimensional tensor t in tensors is first reshaped into a (t.numel(), 1) column before being stacked horizontally.</remarks>
        </member>
        <member name="M:TorchSharp.torch.column_stack(TorchSharp.torch.Tensor[])">
            <summary>
            Creates a new tensor by horizontally stacking the input tensors.
            </summary>
            <param name="tensors">A list of input tensors.</param>
            <returns></returns>
            <remarks>Equivalent to torch.hstack(tensors), except each zero or one dimensional tensor t in tensors is first reshaped into a (t.numel(), 1) column before being stacked horizontally.</remarks>
        </member>
        <member name="M:TorchSharp.torch.row_stack(System.Collections.Generic.IList{TorchSharp.torch.Tensor})">
            <summary>
            Stack tensors in sequence vertically (row wise).
            </summary>
            <param name="tensors"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.row_stack(TorchSharp.torch.Tensor[])">
            <summary>
            Stack tensors in sequence vertically (row wise).
            </summary>
            <param name="tensors"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.unbind(TorchSharp.torch.Tensor,System.Int32)">
            <summary>
            Removes a tensor dimension.
            </summary>
            <param name="tensor">The input tensor</param>
            <param name="dim">The dimension to remove.</param>
            <returns>An array of all slices along a given dimension, already without it.</returns>
        </member>
        <member name="M:TorchSharp.torch.scatter_add_(TorchSharp.torch.Tensor,System.Int64,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Adds all values from the tensor other into input at the indices specified in the index tensor in a similar fashion as scatter_().
            For each value in src, it is added to an index in self which is specified by its index in src for dimension != dim and by the
            corresponding value in index for dimension = dim.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.unflatten(TorchSharp.torch.Tensor,System.Int64,System.Int64[])">
            <summary>
            Expands the dimension dim of the self tensor over multiple dimensions of sizes given by sizes.
            </summary>
            <param name="input">The input tensor</param>
            <param name="dim">Dimension to unflatten.</param>
            <param name="sizes">New shape of the unflattened dimension.</param>
        </member>
        <member name="M:TorchSharp.torch.unflatten(TorchSharp.torch.Tensor,System.Int64,TorchSharp.torch.Size)">
            <summary>
            Expands the dimension dim of the self tensor over multiple dimensions of sizes given by sizes.
            </summary>
            <param name="input">The input tensor</param>
            <param name="dim">Dimension to unflatten.</param>
            <param name="sizes">New shape of the unflattened dimension.</param>
        </member>
        <member name="M:TorchSharp.torch.index_fill(TorchSharp.torch.Tensor,System.Int64,TorchSharp.torch.Tensor,TorchSharp.Scalar)">
             <summary>
             Fills the elements of the input tensor with value value by selecting the indices in the order given in index.
            
             For example, if dim == 0, index[i] == j, and alpha=-1, then the ith row of source is subtracted from the jth row of the input tensor.
             The dimth dimension of source must have the same size as the length of index(which must be a vector), and all other dimensions must match self, or an error will be raised.
             </summary>
             <param name="input">The input tensor</param>
             <param name="dim">Dimension along which to index</param>
             <param name="index">Indices of source to select from, should have dtype either torch.int64 or torch.int32</param>
             <param name="value">The scalar multiplier for source</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.index_fill_(TorchSharp.torch.Tensor,System.Int64,TorchSharp.torch.Tensor,TorchSharp.Scalar)">
             <summary>
             Fills, in place, the elements of the input tensor with value value by selecting the indices in the order given in index.
            
             For example, if dim == 0, index[i] == j, and alpha=-1, then the ith row of source is subtracted from the jth row of the input tensor.
             The dimth dimension of source must have the same size as the length of index(which must be a vector), and all other dimensions must match self, or an error will be raised.
             </summary>
             <param name="input">The input tensor</param>
             <param name="dim">Dimension along which to index</param>
             <param name="index">Indices of source to select from, should have dtype either torch.int64 or torch.int32</param>
             <param name="value">The scalar multiplier for source</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.is_conj(TorchSharp.torch.Tensor)">
            <summary>
            Returns true if the input is a conjugated tensor, i.e. its conjugate bit is set to True.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.std_mean(TorchSharp.torch.Tensor,System.Boolean)">
            <summary>
            Calculates the standard deviation and mean of all elements in the tensor.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
        </member>
        <member name="M:TorchSharp.torch.rand_out(TorchSharp.torch.Tensor,System.Int64[])">
            <summary>
             Mutates the tensor to be filled with random values taken from a uniform distribution in [0, 1).
            </summary>
        </member>
        <member name="M:TorchSharp.torch.randint_out(TorchSharp.torch.Tensor,System.Int64,System.Int64[])">
            <summary>
             Mutates the tensor to be filled with random values taken from a normal distribution with mean 0 and variance 1.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.randn_like(TorchSharp.torch.Tensor,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Returns a tensor with the same size as input that is filled with random numbers from a normal distribution with mean 0 and variance 1.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.randint_like(TorchSharp.torch.Tensor,System.Int64,System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Returns a tensor with the same shape as Tensor input filled with random integers generated uniformly in the range [low,high).
            </summary>
        </member>
        <member name="M:TorchSharp.torch.randperm_out(TorchSharp.torch.Tensor,System.Int64)">
            <summary>
             Mutates the tensor to be a 1-D tensor of size [n] with a random permutation of [0, n).
            </summary>
        </member>
        <member name="M:TorchSharp.torch.binomial(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Draws a binomial distribution given a trial count and probabilities.
            </summary>
            <param name="count">Trial count</param>
            <param name="probs">Probability vector</param>
            <param name="generator">Optional random number generator</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.adjoint(TorchSharp.torch.Tensor)">
            <summary>
            Returns a view of the tensor conjugated and with the last two dimensions transposed.
            </summary>
            <param name="input">The input tensor</param>
        </member>
        <member name="M:TorchSharp.torch.argwhere(TorchSharp.torch.Tensor)">
            <summary>
            Returns a tensor containing the indices of all non-zero elements of input.
            Each row in the result contains the indices of a non-zero element in input.
            The result is sorted lexicographically, with the last index changing the fastest (C-style).
            If input has n dimensions, then the resulting indices tensor out is of size (z×n), where
            z is the total number of non-zero elements in the input tensor.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.cat(System.Collections.Generic.IList{TorchSharp.torch.Tensor},System.Int64)">
            <summary>
            Concatenates the given sequence of tensors in the given dimension.
            </summary>
            <param name="tensors">A sequence of tensors of the same type. Non-empty tensors provided must have the same shape, except in the cat dimension.</param>
            <param name="dim">The dimension over which the tensors are concatenated</param>
            <remarks> All tensors must either have the same shape (except in the concatenating dimension) or be empty.</remarks>
        </member>
        <member name="M:TorchSharp.torch.concat(System.Collections.Generic.IList{TorchSharp.torch.Tensor},System.Int64)">
            <summary>
            Alias of torch.cat()
            </summary>
            <param name="tensors">A sequence of tensors of the same type. Non-empty tensors provided must have the same shape, except in the cat dimension.</param>
            <param name="dim">The dimension over which the tensors are concatenated</param>
            <remarks> All tensors must either have the same shape (except in the concatenating dimension) or be empty.</remarks>
        </member>
        <member name="M:TorchSharp.torch.conj(TorchSharp.torch.Tensor)">
            <summary>
            Returns a view of input with a flipped conjugate bit. If input has a non-complex dtype, this function just returns input.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.dstack(TorchSharp.torch.Tensor[])">
            <summary>
            Stack tensors in sequence depthwise (along third axis).
            </summary>
            <param name="tensors"></param>
            <returns></returns>
            <remarks>This is equivalent to concatenation along the third axis after 1-D and 2-D tensors have been reshaped by torch.atleast_3d().</remarks>
        </member>
        <member name="M:TorchSharp.torch.dstack(System.Collections.Generic.IList{TorchSharp.torch.Tensor})">
            <summary>
            Stack tensors in sequence depthwise (along third axis).
            </summary>
            <param name="tensors"></param>
            <returns></returns>
            <remarks>This is equivalent to concatenation along the third axis after 1-D and 2-D tensors have been reshaped by torch.atleast_3d().</remarks>
        </member>
        <member name="M:TorchSharp.torch.dstack(System.Collections.Generic.IEnumerable{TorchSharp.torch.Tensor})">
            <summary>
            Stack tensors in sequence depthwise (along third axis).
            </summary>
            <param name="tensors"></param>
            <returns></returns>
            <remarks>This is equivalent to concatenation along the third axis after 1-D and 2-D tensors have been reshaped by torch.atleast_3d().</remarks>
        </member>
        <member name="M:TorchSharp.torch.gather(TorchSharp.torch.Tensor,System.Int64,TorchSharp.torch.Tensor)">
            <summary>
            Gathers values along an axis specified by dim.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.hstack(System.Collections.Generic.IList{TorchSharp.torch.Tensor})">
            <summary>
            Stack tensors in sequence horizontally (column wise).
            </summary>
            <param name="tensors"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.hstack(TorchSharp.torch.Tensor[])">
            <summary>
            Stack tensors in sequence horizontally (column wise).
            </summary>
            <param name="tensors"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.hstack(System.Collections.Generic.IEnumerable{TorchSharp.torch.Tensor})">
            <summary>
            Stack tensors in sequence horizontally (column wise).
            </summary>
            <param name="tensors"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.index_add(TorchSharp.torch.Tensor,System.Int64,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.Scalar)">
             <summary>
             Accumulate the elements of alpha times source into the input tensor by adding to the indices in the order given in index.
            
             For example, if dim == 0, index[i] == j, and alpha=-1, then the ith row of source is subtracted from the jth row of the input tensor.
             The dimth dimension of source must have the same size as the length of index(which must be a vector), and all other dimensions must match self, or an error will be raised.
             </summary>
             <param name="input">The input tensor</param>
             <param name="dim">Dimension along which to index</param>
             <param name="index">Indices of source to select from, should have dtype either torch.int64 or torch.int32</param>
             <param name="source">The tensor containing values to add</param>
             <param name="alpha">The scalar multiplier for source</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.index_add_(TorchSharp.torch.Tensor,System.Int64,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.Scalar)">
             <summary>
             Accumulate, in place, the elements of alpha times source into the input tensor by adding to the indices in the order given in index.
            
             For example, if dim == 0, index[i] == j, and alpha=-1, then the ith row of source is subtracted from the jth row of the input tensor.
             The dimth dimension of source must have the same size as the length of index(which must be a vector), and all other dimensions must match self, or an error will be raised.
             </summary>
             <param name="input">The input tensor</param>
             <param name="dim">Dimension along which to index</param>
             <param name="index">Indices of source to select from, should have dtype either torch.int64 or torch.int32</param>
             <param name="source">The tensor containing values to add</param>
             <param name="alpha">The scalar multiplier for source</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.index_copy(TorchSharp.torch.Tensor,System.Int64,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
             <summary>
             Copies the elements of the source tensor into the input tensor by selecting the indices in the order given in index.
            
             For example, if dim == 0 and index[i] == j, then the ith row of tensor is copied to the jth row of the input tensor.
             The dimth dimension of source must have the same size as the length of index(which must be a vector), and all other dimensions must match self, or an error will be raised.
             </summary>
             <param name="input">The input tensor</param>
             <param name="dim">Dimension along which to index</param>
             <param name="index">Indices of source to select from, should have dtype either torch.int64 or torch.int32</param>
             <param name="source">The tensor containing values to copy</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.index_copy_(TorchSharp.torch.Tensor,System.Int64,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
             <summary>
             Copies, in place, the elements of the source tensor into the input tensor by selecting the indices in the order given in index.
            
             For example, if dim == 0 and index[i] == j, then the ith row of tensor is copied to the jth row of the input tensor.
             The dimth dimension of source must have the same size as the length of index(which must be a vector), and all other dimensions must match self, or an error will be raised.
             </summary>
             <param name="input">The input tensor</param>
             <param name="dim">Dimension along which to index</param>
             <param name="index">Indices of source to select from, should have dtype either torch.int64 or torch.int32</param>
             <param name="source">The tensor containing values to copy</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.index_select(TorchSharp.torch.Tensor,System.Int64,TorchSharp.torch.Tensor)">
            <summary>
            Returns a new tensor which indexes the input tensor along dimension dim using the entries in index which is a LongTensor.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.nonzero(TorchSharp.torch.Tensor)">
            <summary>
            Returns a tensor containing the indices of all non-zero elements of input.
            Each row in the result contains the indices of a non-zero element in input.
            The result is sorted lexicographically, with the last index changing the fastest (C-style).
            </summary>
        </member>
        <member name="M:TorchSharp.torch.permute(TorchSharp.torch.Tensor,System.Int64[])">
            <summary>
             Returns a view of the original tensor with its dimensions permuted.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="permutation">The desired ordering of dimensions</param>
        </member>
        <member name="M:TorchSharp.torch.reshape(TorchSharp.torch.Tensor,System.Int64[])">
            <summary>
            Returns a tensor with the same data and number of elements as the input but with the specified shape.
            </summary>
            <param name="input">The input tensor</param>
            <param name="shape">The new tensor shape.</param>
        </member>
        <member name="M:TorchSharp.torch.scatter(TorchSharp.torch.Tensor,System.Int64,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
             Writes all values from the tensor src into input at the indices specified in the index tensor. For each
             value in src, its output index is specified by its index in src for dimension != dim and by the #
             corresponding value in index for dimension = dim.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.scatter_(TorchSharp.torch.Tensor,System.Int64,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
             Writes all values from the tensor src into input at the indices specified in the index tensor. For each
             value in src, its output index is specified by its index in src for dimension != dim and by the #
             corresponding value in index for dimension = dim.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.diagonal_scatter(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Int64,System.Int64,System.Int64)">
            <summary>
            Embeds the values of the src tensor into input along the diagonal elements of input, with respect to dim1 and dim2.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="src">The tensor to embed into 'this'.</param>
            <param name="offset">Which diagonal to consider. Default: main diagonal.</param>
            <param name="dim1">First dimension with respect to which to take diagonal.</param>
            <param name="dim2">Second dimension with respect to which to take diagonal.</param>
        </member>
        <member name="M:TorchSharp.torch.select_scatter(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Int64,System.Int64)">
            <summary>
            Embeds the values of the src tensor into input at the given index. This function returns a tensor with fresh storage; it does not create a view.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="src">The tensor to embed into 'this'</param>
            <param name="dim">The dimension to insert the slice into</param>
            <param name="index">The index to select with</param>
            <remarks>This function returns a tensor with fresh storage; it does not create a view.</remarks>
        </member>
        <member name="M:TorchSharp.torch.slice_scatter(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Int64,System.Nullable{System.Int64},System.Nullable{System.Int64},System.Int64)">
            <summary>
            Embeds the values of the src tensor into input at the given dimension.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="src">The tensor to embed into 'this'.</param>
            <param name="dim">The dimension to insert the slice into</param>
            <param name="start">The start index of where to insert the slice</param>
            <param name="end">The end index of where to insert the slice</param>
            <param name="step">How many elements to skip</param>
        </member>
        <member name="M:TorchSharp.torch.scatter_add(TorchSharp.torch.Tensor,System.Int64,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Adds all values from the tensor other into input at the indices specified in the index tensor in a similar fashion as scatter_().
            For each value in src, it is added to an index in self which is specified by its index in src for dimension != dim and by the
            corresponding value in index for dimension = dim.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.stack(System.Collections.Generic.IEnumerable{TorchSharp.torch.Tensor},System.Int64)">
            <summary>
            Concatenates a sequence of tensors along a new dimension.
            </summary>
            <returns></returns>
            <remarks>All tensors need to be of the same size.</remarks>
        </member>
        <member name="M:TorchSharp.torch.tile(TorchSharp.torch.Tensor,System.Int64[])">
            <summary>
            Constructs a tensor by repeating the elements of input. The dims argument specifies the number of repetitions in each dimension.
            </summary>
            <param name="input">The input tensor</param>
            <param name="dims">The number of repetitions per dimension.</param>
        </member>
        <member name="M:TorchSharp.torch.unsqueeze(TorchSharp.torch.Tensor,System.Int64)">
            <summary>
             Returns a new tensor with a dimension of size one inserted at the specified position.
             The returned tensor shares the same underlying data with this tensor.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.unsqueeze_(TorchSharp.torch.Tensor,System.Int64)">
            <summary>
             Returns a new tensor with a dimension of size one inserted at the specified position.
             The returned tensor shares the same underlying data with this tensor.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.vstack(System.Collections.Generic.IList{TorchSharp.torch.Tensor})">
            <summary>
            Stack tensors in sequence vertically (row wise).
            </summary>
            <param name="tensors"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.where(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Return a tensor of elements selected from either x or y, depending on condition.
            </summary>
            <param name="condition">When true, yield x, otherwise yield y.</param>
            <param name="x">Values selected at indices where condition is true</param>
            <param name="y">Values selected at indices where condition is false</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.where(TorchSharp.torch.Tensor)">
            <summary>
            Returns a tuple of 1-D tensors, one for each dimension in input, each containing the indices (in that dimension) of all non-zero elements of input .
            If input has nn dimensions, then the resulting tuple contains nn tensors of size zz, where zz is the total number of non-zero elements in the input tensor.
            As a special case, when input has zero dimensions and a nonzero scalar value, it is treated as a one-dimensional tensor with one element.
            </summary>
            <param name="condition">The input tensor</param>
            <returns></returns>
            <exception cref="T:System.ArgumentException"></exception>
        </member>
        <member name="M:TorchSharp.torch.no_grad">
            <summary>
            Context-manager that disables gradient calculation.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.enable_grad(System.Boolean)">
            <summary>
            Context-manager that enables gradient calculation.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.set_grad_enabled(System.Boolean)">
            <summary>
            Context-manager that sets gradient calculation to on or off.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.is_grad_enabled">
            <summary>
            Returns true if grad mode is currently enabled.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.inference_mode(System.Boolean)">
            <summary>
            Context-manager that enables inference mode.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.is_inference_mode_enabled">
            <summary>
            Returns true if inference mode mode is currently enabled.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.atleast_1d(TorchSharp.torch.Tensor[])">
            <summary>
            Returns a 1-dimensional view of each input tensor with zero dimensions. Input tensors with one or more dimensions are returned as-is.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.atleast_2d(TorchSharp.torch.Tensor[])">
            <summary>
            Returns a 2-dimensional view of each input tensor with zero or one dimensions. Input tensors with two or more dimensions are returned as-is.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.atleast_3d(TorchSharp.torch.Tensor[])">
            <summary>
            Returns a 1-dimensional view of each input tensor with fewer than three dimensions. Input tensors with three or more dimensions are returned as-is.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.bincount(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Int64)">
            <summary>
            Count the frequency of each value in an array of non-negative ints.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.block_diag(TorchSharp.torch.Tensor[])">
            <summary>
            Create a block diagonal matrix from provided tensors.
            </summary>
            <param name="tensors">One or more tensors with 0, 1, or 2 dimensions.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.broadcast_tensors(TorchSharp.torch.Tensor[])">
            <summary>
            Broadcasts the given tensors according to Torch broadcasting semantics.
            </summary>
            <param name="tensors">Any number of tensors of the same type</param>
        </member>
        <member name="M:TorchSharp.torch.broadcast_shapes(System.Int64[][])">
            <summary>
            This is equivalent to <code>torch.broadcast_tensors(*map(torch.empty, shapes))[0].shape</code>
            but avoids the need create to intermediate tensors.
            This is useful for broadcasting tensors of common batch shape but different rightmost shape,
            e.g. to broadcast mean vectors with covariance matrices.
            </summary>
            <param name="shapes">Shapes of tensors</param>
            <returns>A shape compatible with all input shapes</returns>
            <exception cref="T:System.ArgumentException">If shapes are incompatible.</exception>
        </member>
        <member name="M:TorchSharp.torch.cartesian_prod(System.Collections.Generic.IList{TorchSharp.torch.Tensor})">
            <summary>
            Do cartesian product of the given sequence of tensors.
            </summary>
            <param name="tensors"></param>
        </member>
        <member name="M:TorchSharp.torch.cartesian_prod(TorchSharp.torch.Tensor[])">
            <summary>
            Do cartesian product of the given sequence of tensors.
            </summary>
            <param name="tensors"></param>
        </member>
        <member name="M:TorchSharp.torch.cdist(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Double,TorchSharp.compute_mode)">
            <summary>
            Computes batched the p-norm distance between each pair of the two collections of row vectors.
            </summary>
            <param name="x1">Input tensor of shape BxPxM</param>
            <param name="x2">Input tensor of shape BxRxM</param>
            <param name="p">p value for the p-norm distance to calculate between each vector (p > 0)</param>
            <param name="compute_mode">
            use_mm_for_euclid_dist_if_necessary - will use matrix multiplication approach to calculate euclidean distance (p = 2) if P > 25 or R > 25
            use_mm_for_euclid_dist - will always use matrix multiplication approach to calculate euclidean distance (p = 2)
            donot_use_mm_for_euclid_dist - will never use matrix multiplication approach to calculate euclidean distance (p = 2)
            </param>
            <exception cref="T:System.ArgumentException"></exception>
        </member>
        <member name="M:TorchSharp.torch.combinations(TorchSharp.torch.Tensor,System.Int32,System.Boolean)">
            <summary>
            Compute combinations of length r of the given tensor
            </summary>
            <param name="input">1D vector.</param>
            <param name="r">Number of elements to combine</param>
            <param name="with_replacement">Whether to allow duplication in combination</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.cov(TorchSharp.torch.Tensor,System.Int64,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Estimates the covariance matrix of the variables given by the input matrix, where rows are the variables and columns are the observations.
            </summary>
            <param name="input">The input tensor</param>
            <param name="correction">
            Difference between the sample size and sample degrees of freedom.
            Defaults to Bessel’s correction, correction = 1 which returns the unbiased estimate,
            even if both fweights and aweights are specified.
            Correction = 0 will return the simple average.
            </param>
            <param name="fweights">
            A Scalar or 1D tensor of observation vector frequencies representing the number of times each observation should be repeated.
            Its numel must equal the number of columns of input.
            Must have integral dtype.</param>
            <param name="aweights">A Scalar or 1D array of observation vector weights.
            These relative weights are typically large for observations considered “important” and smaller for
            observations considered less “important”.
            Its numel must equal the number of columns of input.
            Must have floating point dtype.</param>
        </member>
        <member name="M:TorchSharp.torch.cross(TorchSharp.torch.Tensor,TorchSharp.Scalar,System.Int64)">
            <summary>
            Returns the cross product of vectors in dimension dim of input and other.
            input and other must have the same size, and the size of their dim dimension should be 3.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.cumsum(TorchSharp.torch.Tensor,System.Int64,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Returns the cumulative sum of elements of input in the dimension dim.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="dim">The dimension to do the operation over</param>
            <param name="type">The desired data type of returned tensor. If specified, the input tensor is casted to dtype before the operation is performed.
            This is useful for preventing data type overflows.</param>
        </member>
        <member name="M:TorchSharp.torch.diag(TorchSharp.torch.Tensor,System.Int64)">
            <summary>
            If input is a vector (1-D tensor), then returns a 2-D square tensor with the elements of input as the diagonal.
            If input is a matrix (2-D tensor), then returns a 1-D tensor with the diagonal elements of input.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="diagonal">
            The argument diagonal controls which diagonal to consider:
            If diagonal is 0, it is the main diagonal.
            If diagonal is greater than 0, it is above the main diagonal.
            If diagonal is less than 0, it is below the main diagonal.
            </param>
        </member>
        <member name="M:TorchSharp.torch.diag_embed(TorchSharp.torch.Tensor,System.Int64,System.Int64,System.Int64)">
             <summary>
             Creates a tensor whose diagonals of certain 2D planes (specified by dim1 and dim2) are filled by input.
             To facilitate creating batched diagonal matrices, the 2D planes formed by the last two dimensions of the returned tensor are chosen by default.
            
             The argument offset controls which diagonal to consider:
               If offset is equal to 0, it is the main diagonal.
               If offset is greater than 0, it is above the main diagonal.
               If offset is less than 0, it is below the main diagonal.
            
             The size of the new matrix will be calculated to make the specified diagonal of the size of the last input dimension.Note that for offset other than 0,
            
             the order of dim1 and dim2 matters.Exchanging them is equivalent to changing the sign of offset.
             </summary>
             <param name="input">The input tensor.</param>
             <param name="offset">Which diagonal to consider.</param>
             <param name="dim1">First dimension with respect to which to take diagonal. </param>
             <param name="dim2">Second dimension with respect to which to take diagonal</param>
        </member>
        <member name="M:TorchSharp.torch.diagflat(TorchSharp.torch.Tensor,System.Int64)">
            <summary>
            If input is a vector (1-D tensor), then returns a 2-D square tensor with the elements of input as the diagonal.
            If input is a matrix (2-D tensor), then returns a 2-D tensor with diagonal elements equal to a flattened input.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="offset">
            The argument diagonal controls which diagonal to consider:
            If diagonal is 0, it is the main diagonal.
            If diagonal is greater than 0, it is above the main diagonal.
            If diagonal is less than 0, it is below the main diagonal.
            </param>
        </member>
        <member name="M:TorchSharp.torch.diagonal(TorchSharp.torch.Tensor,System.Int64,System.Int64,System.Int64)">
             <summary>
             Returns a partial view of input with the its diagonal elements with respect to dim1 and dim2 appended as a dimension at the end of the shape.
             The argument offset controls which diagonal to consider:
            
                 If offset == 0, it is the main diagonal.
                 If offset &gt; 0, it is above the main diagonal.
                 If offset &lt; 0, it is below the main diagonal.
             </summary>
             <param name="input">The input tensor</param>
             <param name="offset">Which diagonal to consider. Default: 0 (main diagonal).</param>
             <param name="dim1">First dimension with respect to which to take diagonal. Default: 0.</param>
             <param name="dim2">Second dimension with respect to which to take diagonal. Default: 1.</param>
             <remarks>
             Applying torch.diag_embed() to the output of this function with the same arguments yields a diagonal matrix with the diagonal entries of the input.
             However, torch.diag_embed() has different default dimensions, so those need to be explicitly specified.
             </remarks>
        </member>
        <member name="M:TorchSharp.torch.diff(TorchSharp.torch.Tensor,System.Int64,System.Int64,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Computes the n-th forward difference along the given dimension.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="n">The number of times to recursively compute the difference</param>
            <param name="dim">The dimension to compute the difference along. Default is the last dimension.</param>
            <param name="prepend">
            Values to prepend or append to input along dim before computing the difference.
            Their dimensions must be equivalent to that of input, and their shapes must match input’s shape except on dim.
            </param>
            <param name="append">
            Values to prepend or append to input along dim before computing the difference.
            Their dimensions must be equivalent to that of input, and their shapes must match input’s shape except on dim.
            </param>
        </member>
        <member name="M:TorchSharp.torch.einsum(System.String,TorchSharp.torch.Tensor[])">
            <summary>
            Sums the product of the elements of the input operands along dimensions specified using a notation based on the Einstein summation convention.
            </summary>
            <param name="equation">The subscripts for the Einstein summation.</param>
            <param name="tensors">The operands to compute the Einstein sum of.</param>
            <remarks>
            Einsum allows computing many common multi-dimensional linear algebraic array operations by representing them in a short-hand format based on the
            Einstein summation convention, given by equation.The details of this format are described below, but the general idea is to label every dimension
            of the input operands with some subscript and define which subscripts are part of the output. The output is then computed by summing the product
            of the elements of the operands along the dimensions whose subscripts are not part of the output.For example, matrix multiplication can be computed
            using einsum as torch.einsum(“ij,jk->ik”, A, B). Here, j is the summation subscript and i and k the output subscripts(see section below for more details on why).
            </remarks>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.flatten(TorchSharp.torch.Tensor,System.Int64,System.Int64)">
            <summary>
            Flattens input by reshaping it into a one-dimensional tensor.
            </summary>
            <param name="input">The input tensor</param>
            <param name="start_dim">The first dim to flatten</param>
            <param name="end_dim">The last dim to flatten.</param>
            <remarks>Flattening a zero-dimensional tensor will return a one-dimensional view.</remarks>
        </member>
        <member name="M:TorchSharp.torch.kron(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Computes the Kronecker product of input and other.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="other">The second tensor</param>
        </member>
        <member name="M:TorchSharp.torch.rot90(TorchSharp.torch.Tensor,System.Int64,System.Nullable{System.ValueTuple{System.Int64,System.Int64}})">
            <summary>
            Rotate a n-D tensor by 90 degrees in the plane specified by dims axis.
            Rotation direction is from the first towards the second axis if k is greater than 0,
            and from the second towards the first for k less than 0.
            </summary>
            <param name="input">The input tensor</param>
            <param name="k">The number of times to rotate.</param>
            <param name="dims">Axes to rotate</param>
        </member>
        <member name="M:TorchSharp.torch.gcd(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Computes the element-wise greatest common divisor (GCD) of input and other.
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="right">The right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.gcd_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Computes the element-wise greatest common divisor (GCD) of input and other.
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="right">The right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.histc(TorchSharp.torch.Tensor,System.Int64,System.Int64,System.Int64)">
            <summary>
            Computes the histogram of a tensor.
            The elements are sorted into equal width bins between min and max.If min and max are both zero, the minimum and maximum values of the data are used.
            Elements lower than min and higher than max are ignored.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="bins">Number of histogram bins</param>
            <param name="min">Lower end of the range (inclusive)</param>
            <param name="max">Upper end of the range (inclusive)</param>
        </member>
        <member name="M:TorchSharp.torch.meshgrid(System.Collections.Generic.IEnumerable{TorchSharp.torch.Tensor},TorchSharp.indexing)">
            <summary>
            Creates grids of coordinates specified by the 1D inputs in tensors.
            This is helpful when you want to visualize data over some range of inputs.
            </summary>
            <returns></returns>
            <remarks>All tensors need to be of the same size.</remarks>
        </member>
        <member name="M:TorchSharp.torch.meshgrid(System.Collections.Generic.IEnumerable{TorchSharp.torch.Tensor},System.String)">
            <summary>
            Creates grids of coordinates specified by the 1D inputs in tensors.
            This is helpful when you want to visualize data over some range of inputs.
            </summary>
            <returns></returns>
            <remarks>All tensors need to be of the same size.</remarks>
        </member>
        <member name="M:TorchSharp.torch.lcm(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Computes the element-wise least common multiple (LCM) of input and other.
            </summary>
            <param name="input">The first input tensor.</param>
            <param name="other">The second input tensor.</param>
            <remarks>Both input and other must have integer types.</remarks>
        </member>
        <member name="M:TorchSharp.torch.lcm_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Computes the element-wise least common multiple (LCM) of input and other in place.
            </summary>
            <param name="input">The first input tensor.</param>
            <param name="other">The second input tensor.</param>
            <remarks>Both input and other must have integer types.</remarks>
        </member>
        <member name="M:TorchSharp.torch.logcumsumexp(TorchSharp.torch.Tensor,System.Int64)">
            <summary>
            Returns the logarithm of the cumulative summation of the exponentiation of elements of input in the dimension dim.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="dim">The dimension to do the operation over</param>
        </member>
        <member name="M:TorchSharp.torch.renorm(TorchSharp.torch.Tensor,System.Single,System.Int64,System.Single)">
            <summary>
            Returns a tensor where each sub-tensor of input along dimension dim is normalized such that the p-norm of the sub-tensor is lower than the value maxnorm
            </summary>
            <param name="input">The input tensor.</param>
            <param name="p">The power for the norm computation</param>
            <param name="dim">The dimension to slice over to get the sub-tensors</param>
            <param name="maxnorm">The maximum norm to keep each sub-tensor under</param>
        </member>
        <member name="M:TorchSharp.torch.repeat_interleave(TorchSharp.torch.Tensor,System.Int64,System.Nullable{System.Int64},System.Nullable{System.Int64})">
            <summary>
            Repeat elements of a tensor.
            </summary>
            <param name="input">The input tensor</param>
            <param name="repeats">The number of repeats</param>
            <param name="dim">The dimension to repeat</param>
            <param name="output_size">The size of output</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.repeat_interleave(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Nullable{System.Int64},System.Nullable{System.Int64})">
            <summary>
            Repeat elements of a tensor.
            </summary>
            <param name="input">The input tensor</param>
            <param name="repeats">The number of repeats</param>
            <param name="dim">The dimension to repeat</param>
            <param name="output_size">The size of output</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.roll(TorchSharp.torch.Tensor,System.Int64,System.Nullable{System.Int64})">
            <summary>
            Roll the tensor along the given dimension(s).
            Elements that are shifted beyond the last position are re-introduced at the first position.
            If a dimension is not specified, the tensor will be flattened before rolling and then restored to the original shape.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.roll(TorchSharp.torch.Tensor,System.ValueTuple{System.Int64,System.Int64},System.ValueTuple{System.Int64,System.Int64})">
            <summary>
            Roll the tensor along the given dimension(s).
            Elements that are shifted beyond the last position are re-introduced at the first position.
            If a dimension is not specified, the tensor will be flattened before rolling and then restored to the original shape.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.roll(TorchSharp.torch.Tensor,System.ValueTuple{System.Int64,System.Int64,System.Int64},System.ValueTuple{System.Int64,System.Int64,System.Int64})">
            <summary>
            Roll the tensor along the given dimension(s).
            Elements that are shifted beyond the last position are re-introduced at the first position.
            If a dimension is not specified, the tensor will be flattened before rolling and then restored to the original shape.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.roll(TorchSharp.torch.Tensor,System.Int64[],System.Int64[])">
            <summary>
            Roll the tensor along the given dimension(s).
            Elements that are shifted beyond the last position are re-introduced at the first position.
            If a dimension is not specified, the tensor will be flattened before rolling and then restored to the original shape.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.roll(TorchSharp.torch.Tensor,System.Int64[])">
            <summary>
            Roll the tensor along the given dimension(s).
            Elements that are shifted beyond the last position are re-introduced at the first position.
            If a dimension is not specified, the tensor will be flattened before rolling and then restored to the original shape.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.roll(TorchSharp.torch.Tensor,System.ReadOnlySpan{System.Int64},System.ReadOnlySpan{System.Int64})">
            <summary>
            Roll the tensor along the given dimension(s).
            Elements that are shifted beyond the last position are re-introduced at the first position.
            If a dimension is not specified, the tensor will be flattened before rolling and then restored to the original shape.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.tensordot(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Int64)">
            <summary>
            Returns a contraction of <paramref name="a"/> and <paramref name="b"/> over multiple dimensions.
            tensordot implements a generalized matrix product.
            </summary>
            <param name="a">Left tensor to contract</param>
            <param name="b">Right tensor to contract</param>
            <param name="dims">number of dimensions to contract for <paramref name="a"/> and <paramref name="b"/></param>
            <returns>contraction</returns>
        </member>
        <member name="M:TorchSharp.torch.tensordot(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Int64[],System.Int64[])">
            <summary>
            Returns a contraction of <paramref name="a"/> and <paramref name="b"/> over multiple dimensions.
            tensordot implements a generalized matrix product.
            </summary>
            <param name="a">Left tensor to contract</param>
            <param name="b">Right tensor to contract</param>
            <param name="dims1">dimensions to contract for <paramref name="a"/></param>
            <param name="dims2">dimensions to contract for <paramref name="b"/></param>
            <returns>contraction</returns>
        </member>
        <member name="M:TorchSharp.torch.tensordot(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.ValueTuple{System.Int64,System.Int64}[])">
            <summary>
            Returns a contraction of <paramref name="a"/> and <paramref name="b"/> over multiple dimensions.
            tensordot implements a generalized matrix product.
            </summary>
            <param name="a">Left tensor to contract</param>
            <param name="b">Right tensor to contract</param>
            <param name="dims">dimensions to contract for <paramref name="a"/> and <paramref name="b"/> respectively</param>
            <returns>contraction</returns>
        </member>
        <member name="M:TorchSharp.torch.trace(TorchSharp.torch.Tensor)">
            <summary>
            Returns the sum of the elements of the diagonal of the input 2-D matrix.
            </summary>
            <param name="input">The input tensor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.view_as_real(TorchSharp.torch.Tensor)">
            <summary>
            Returns a view of input as a real tensor.
            For an input complex tensor of size m1, m2, …, mi, this function returns a new real tensor of size m1, m2, …, mi, 2, where the last dimension of size 2 represents the real and imaginary components of complex numbers.
            </summary>
            <param name="input">The input tensor</param>
        </member>
        <member name="M:TorchSharp.torch.view_as_complex(TorchSharp.torch.Tensor)">
            <summary>
            Returns a view of input as a complex tensor.
            For an input complex tensor of size m1, m2, …, mi, 2, this function returns a new complex tensor of size m1, m2, …, mi where the last dimension of the input tensor is expected to represent the real and imaginary components of complex numbers.
            </summary>
            <param name="input">The input tensor</param>
        </member>
        <member name="M:TorchSharp.torch.resolve_conj(TorchSharp.torch.Tensor)">
            <summary>
            Returns a new tensor with materialized conjugation if input’s conjugate bit is set to True, else returns input.
            The output tensor will always have its conjugate bit set to False.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.resolve_neg(TorchSharp.torch.Tensor)">
            <summary>
            Returns a new tensor with materialized negation if input’s negative bit is set to True, else returns input.
            The output tensor will always have its negative bit set to False.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.is_neg(TorchSharp.torch.Tensor)">
            <summary>
            Returns true if the input's negative bit is set to True.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.get_num_threads">
            <summary>
            Returns the number of threads used for parallelizing CPU operations
            </summary>
        </member>
        <member name="M:TorchSharp.torch.set_num_threads(System.Int32)">
            <summary>
            Sets the number of threads used for parallelizing CPU operations
            </summary>
            <param name="num">The number of threads to use.</param>
        </member>
        <member name="M:TorchSharp.torch.get_num_interop_threads">
            <summary>
            Returns the number of threads used for inter-op parallelism on CPU (e.g. in JIT interpreter)
            </summary>
        </member>
        <member name="M:TorchSharp.torch.set_num_interop_threads(System.Int32)">
            <summary>
            Sets the number of threads used for inter-op parallelism on CPU (e.g. in JIT interpreter)
            </summary>
            <param name="num">The number of threads to use.</param>
        </member>
        <member name="M:TorchSharp.torch.abs(TorchSharp.torch.Tensor)">
            <summary>
            Compute the absolute value of each element in the tensor
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.abs_(TorchSharp.torch.Tensor)">
            <summary>
            Compute the absolute value of each element in the tensor, in-place
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.absolute(TorchSharp.torch.Tensor)">
            <summary>
            Compute the absolute value of each element in the tensor
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.absolute_(TorchSharp.torch.Tensor)">
            <summary>
            Compute the absolute value of each element in the tensor, in-place
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.acos(TorchSharp.torch.Tensor)">
            <summary>
            Computes the arccosine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.acos_(TorchSharp.torch.Tensor)">
            <summary>
            Computes the arccosine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.arccos(TorchSharp.torch.Tensor)">
            <summary>
            Computes the arccosine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.arccos_(TorchSharp.torch.Tensor)">
            <summary>
            Computes the arccosine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.acosh(TorchSharp.torch.Tensor)">
            <summary>
            Computes the hyperbolic arccosine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.acosh_(TorchSharp.torch.Tensor)">
            <summary>
            Computes the hyperbolic arccosine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.arccosh(TorchSharp.torch.Tensor)">
            <summary>
            Computes the hyperbolic arccosine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.arccosh_(TorchSharp.torch.Tensor)">
            <summary>
            Computes the hyperbolic arccosine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.add(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Add two tensors, element-wise
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="right">The right-hand operand.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.add(TorchSharp.torch.Tensor,TorchSharp.Scalar)">
            <summary>
            Add a scalar value to each element in the target tensor.
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="right">The right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.add(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.Scalar)">
            <summary>
            Add two tensors, element-wise, scaling the second operator by 'alpha'
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="right">The right-hand operand.</param>
            <param name="alpha">RHS scale factor.</param>
        </member>
        <member name="M:TorchSharp.torch.add(TorchSharp.torch.Tensor,TorchSharp.Scalar,TorchSharp.Scalar)">
            <summary>
            Add a scalar value to each element in the target tensor, scaled by 'alpha'
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="right">The right-hand operand.</param>
            <param name="alpha">RHS scale factor.</param>
        </member>
        <member name="M:TorchSharp.torch.add_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Add two tensors, element-wise, in place
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="right">The right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.add_(TorchSharp.torch.Tensor,TorchSharp.Scalar)">
            <summary>
            Add a scalar value to each element in the target tensor, in place.
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="right">The right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.add_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.Scalar)">
            <summary>
            Add two tensors, element-wise, scaling the second operator by 'alpha', in place
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="right">The right-hand operand.</param>
            <param name="alpha">RHS scale factor.</param>
        </member>
        <member name="M:TorchSharp.torch.add_(TorchSharp.torch.Tensor,TorchSharp.Scalar,TorchSharp.Scalar)">
            <summary>
            Add a scalar value to each element in the target tensor, scaled by 'alpha', in place
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="right">The right-hand operand.</param>
            <param name="alpha">RHS scale factor.</param>
        </member>
        <member name="M:TorchSharp.torch.addcdiv(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.Scalar)">
            <summary>
            Performs the element-wise division of tensor1 by tensor2, multiply the result by the scalar value and add it to input.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="tensor1">First tensor</param>
            <param name="tensor2">Second tensor</param>
            <param name="value">Scale factor</param>
        </member>
        <member name="M:TorchSharp.torch.addcdiv_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.Scalar)">
            <summary>
            Performs the element-wise division of tensor1 by tensor2, multiply the result by the scalar value and add it to input.
            In-place version of <see cref="M:TorchSharp.torch.addcdiv(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.Scalar)"/>.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="tensor1">First tensor</param>
            <param name="tensor2">Second tensor</param>
            <param name="value">Scale factor</param>
        </member>
        <member name="M:TorchSharp.torch.addcmul(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.Scalar)">
            <summary>
            Performs the element-wise multiplication of tensor1 by tensor2, multiply the result by the scalar value and add it to input.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="tensor1">First tensor</param>
            <param name="tensor2">Second tensor</param>
            <param name="value">Scale factor</param>
        </member>
        <member name="M:TorchSharp.torch.addcmul_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.Scalar)">
            <summary>
            Performs the element-wise divismultiplicationion of tensor1 by tensor2, multiply the result by the scalar value and add it to input.
            In-place version of <see cref="M:TorchSharp.torch.addcmul(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.Scalar)"/>.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="tensor1">First tensor</param>
            <param name="tensor2">Second tensor</param>
            <param name="value">Scale factor</param>
        </member>
        <member name="M:TorchSharp.torch.angle(TorchSharp.torch.Tensor)">
            <summary>
            Computes the element-wise angle (in radians) of the given input tensor.
            </summary>
            <returns></returns>
            <remarks>
            Starting in Torch 1.8, angle returns pi for negative real numbers, zero for non-negative real numbers, and propagates NaNs.
            Previously the function would return zero for all real numbers and not propagate floating-point NaNs.
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.asin(TorchSharp.torch.Tensor)">
            <summary>
            Computes the arcsine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.asin_(TorchSharp.torch.Tensor)">
            <summary>
            Computes the arcsine of the elements of input, in place.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.arcsin(TorchSharp.torch.Tensor)">
            <summary>
            Computes the arcsine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.arcsin_(TorchSharp.torch.Tensor)">
            <summary>
            Computes the arcsine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.asinh(TorchSharp.torch.Tensor)">
            <summary>
            Computes the hyperbolic arcsine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.asinh_(TorchSharp.torch.Tensor)">
            <summary>
            Computes the hyperbolic arcsine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.arcsinh(TorchSharp.torch.Tensor)">
            <summary>
            Computes the hyperbolic arcsine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.arcsinh_(TorchSharp.torch.Tensor)">
            <summary>
            Computes the hyperbolic arcsine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.atan(TorchSharp.torch.Tensor)">
            <summary>
            Computes the arctangent of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.atan_(TorchSharp.torch.Tensor)">
            <summary>
            Computes the arctangent of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.arctan(TorchSharp.torch.Tensor)">
            <summary>
            Computes the arctangent of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.arctan_(TorchSharp.torch.Tensor)">
            <summary>
            Computes the arctangent of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.atanh(TorchSharp.torch.Tensor)">
            <summary>
            Computes the hyperbolic arctangent of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.atanh_(TorchSharp.torch.Tensor)">
            <summary>
            Computes the hyperbolic arctangent of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.arctanh(TorchSharp.torch.Tensor)">
            <summary>
            Computes the hyperbolic arctangent of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.arctanh_(TorchSharp.torch.Tensor)">
            <summary>
            Computes the hyperbolic arctangent of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.atan2(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Element-wise arctangent of input / other with consideration of the quadrant.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.atan2_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Element-wise arctangent of input / other with consideration of the quadrant.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.arctan2(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Element-wise arctangent of input / other with consideration of the quadrant.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.arctan2_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Element-wise arctangent of input / other with consideration of the quadrant.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.arctan(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Element-wise arctangent of input / other with consideration of the quadrant.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.arctan_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Element-wise arctangent of input / other with consideration of the quadrant.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.bitwise_not(TorchSharp.torch.Tensor)">
            <summary>
            Element-wise bitwise NOT
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.bitwise_not_(TorchSharp.torch.Tensor)">
            <summary>
            Element-wise bitwise NOT, in place.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.bitwise_and(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Element-wise bitwise AND
            </summary>
            <param name="left">Left-hand operand.</param>
            <param name="right">Right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.bitwise_and_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Element-wise bitwise AND, in place.
            </summary>
            <param name="left">Left-hand operand.</param>
            <param name="right">Right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.bitwise_or(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Element-wise bitwise OR
            </summary>
            <param name="left">Left-hand operand.</param>
            <param name="right">Right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.bitwise_or_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Element-wise bitwiseXOR, in place.
            </summary>
            <param name="left">Left-hand operand.</param>
            <param name="right">Right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.bitwise_xor(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Element-wise bitwise XOR
            </summary>
            <param name="left">Left-hand operand.</param>
            <param name="right">Right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.bitwise_xor_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Element-wise bitwise XOR, in place.
            </summary>
            <param name="left">Left-hand operand.</param>
            <param name="right">Right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.bitwise_left_shift(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Element-wise bitwise left shift
            </summary>
            <param name="left">Left-hand operand.</param>
            <param name="right">Right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.bitwise_left_shift_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Element-wise bitwise left shift, in place.
            </summary>
            <param name="left">Left-hand operand.</param>
            <param name="right">Right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.bitwise_right_shift(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Element-wise bitwise right shift
            </summary>
            <param name="left">Left-hand operand.</param>
            <param name="right">Right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.bitwise_right_shift_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Element-wise bitwise right shift, in place.
            </summary>
            <param name="left">Left-hand operand.</param>
            <param name="right">Right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.ceil(TorchSharp.torch.Tensor)">
            <summary>
            Returns a new tensor with the ceil of the elements of input, the smallest integer greater than or equal to each element.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.ceil_(TorchSharp.torch.Tensor)">
            <summary>
            Replaces each element of the input with the smallest integer greater than or equal to the element.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.clamp(TorchSharp.torch.Tensor,TorchSharp.Scalar,TorchSharp.Scalar)">
            <summary>
            Clamps all elements in input into the range [ min, max ].
            </summary>
            <param name="input">The input tensor</param>
            <param name="min">The minimum value</param>
            <param name="max">The maximum value</param>
        </member>
        <member name="M:TorchSharp.torch.clamp_(TorchSharp.torch.Tensor,TorchSharp.Scalar,TorchSharp.Scalar)">
            <summary>
            Clamps all elements in input into the range [ min, max ] in place.
            </summary>
            <param name="input">The input tensor</param>
            <param name="min">The minimum value</param>
            <param name="max">The maximum value</param>
        </member>
        <member name="M:TorchSharp.torch.clamp(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Clamps all elements in input into the range [ min, max ].
            </summary>
            <param name="input">The input tensor</param>
            <param name="min">The minimum value</param>
            <param name="max">The maximum value</param>
        </member>
        <member name="M:TorchSharp.torch.clamp_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Clamps all elements in input into the range [ min, max ] in place.
            </summary>
            <param name="input">The input tensor</param>
            <param name="min">The minimum value</param>
            <param name="max">The maximum value</param>
        </member>
        <member name="M:TorchSharp.torch.conj_physical(TorchSharp.torch.Tensor)">
            <summary>
            Computes the element-wise conjugate of the given input tensor. If input has a non-complex <see cref="T:TorchSharp.DeviceType">dtype</see>, this function just returns input.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.conj_physical_(TorchSharp.torch.Tensor)">
            <summary>
            In-place version of conj_physical
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.copysign(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Create a new floating-point tensor with the magnitude of input and the sign of other, elementwise.
            Supports broadcasting to a common shape, and integer and float inputs.
            </summary>
            <param name="input">magnitudes</param>
            <param name="other">contains value(s) whose signbit(s) are applied to the magnitudes in <paramref name="input"/>.</param>
            <returns>the output tensor</returns>
        </member>
        <member name="M:TorchSharp.torch.cos(TorchSharp.torch.Tensor)">
            <summary>
            Computes the cosine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.cos_(TorchSharp.torch.Tensor)">
            <summary>
            Computes the cosine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.cosh(TorchSharp.torch.Tensor)">
            <summary>
            Computes the hyperbolic cosine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.cosh_(TorchSharp.torch.Tensor)">
            <summary>
            Computes the hyperbolic cosine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.div(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.RoundingMode)">
            <summary>
            Divides each element of the input by the corresponding element of other.
            </summary>
            <param name="left">Numerator</param>
            <param name="right">Denominator</param>
            <param name="rounding_mode">Rounding mode.</param>
        </member>
        <member name="M:TorchSharp.torch.div(TorchSharp.torch.Tensor,TorchSharp.Scalar,TorchSharp.torch.RoundingMode)">
            <summary>
            Divides each element of the input by a scalar value.
            </summary>
            <param name="left">Numerator</param>
            <param name="right">Denominator</param>
            <param name="rounding_mode">Rounding mode.</param>
        </member>
        <member name="M:TorchSharp.torch.div_(TorchSharp.torch.Tensor,TorchSharp.Scalar,TorchSharp.torch.RoundingMode)">
            <summary>
            Divides each element of the input by the corresponding element of other.
            </summary>
            <param name="left">Numerator</param>
            <param name="right">Denominator</param>
            <param name="rounding_mode">Rounding mode.</param>
        </member>
        <member name="M:TorchSharp.torch.div_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.RoundingMode)">
            <summary>
            Divides each element of the input by the corresponding element of other.
            </summary>
            <param name="left">Numerator</param>
            <param name="right">Denominator</param>
            <param name="rounding_mode">Rounding mode.</param>
        </member>
        <member name="M:TorchSharp.torch.divide(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.RoundingMode)">
            <summary>
            Divides each element of the input by the corresponding element of other.
            </summary>
            <param name="left">Numerator</param>
            <param name="right">Denominator</param>
            <param name="rounding_mode">Rounding mode.</param>
        </member>
        <member name="M:TorchSharp.torch.divide(TorchSharp.torch.Tensor,TorchSharp.Scalar,TorchSharp.torch.RoundingMode)">
            <summary>
            Divides each element of the input by a scalar value.
            </summary>
            <param name="left">Numerator</param>
            <param name="right">Denominator</param>
            <param name="rounding_mode">Rounding mode.</param>
        </member>
        <member name="M:TorchSharp.torch.divide_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.RoundingMode)">
            <summary>
            Divides each element of the input by the corresponding element of other.
            </summary>
            <param name="left">Numerator</param>
            <param name="right">Denominator</param>
            <param name="rounding_mode">Rounding mode.</param>
        </member>
        <member name="M:TorchSharp.torch.divide_(TorchSharp.torch.Tensor,TorchSharp.Scalar)">
            <summary>
            Divides each element of the input by the corresponding element of other.
            </summary>
            <param name="left">Numerator</param>
            <param name="right">Denominator</param>
        </member>
        <member name="M:TorchSharp.torch.digamma(TorchSharp.torch.Tensor)">
            <summary>
            Computes the logarithmic derivative of the gamma function on input.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.digamma_(TorchSharp.torch.Tensor)">
            <summary>
            Computes the logarithmic derivative of the gamma function on input, in place.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.erf(TorchSharp.torch.Tensor)">
            <summary>
            Computes the error function of the input.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.erf_(TorchSharp.torch.Tensor)">
            <summary>
            Computes the error function of the input in place.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.erfc(TorchSharp.torch.Tensor)">
            <summary>
            Computes the error function of the input.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.erfc_(TorchSharp.torch.Tensor)">
            <summary>
            Computes the error function of the input in place.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.erfinv(TorchSharp.torch.Tensor)">
            <summary>
            Computes the error function of the input.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.erfinv_(TorchSharp.torch.Tensor)">
            <summary>
            Computes the error function of the input in place.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.exp(TorchSharp.torch.Tensor)">
            <summary>
            Returns a new tensor with the exponential of the elements of the input tensor input.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.exp_(TorchSharp.torch.Tensor)">
            <summary>
            Replaces each element of the input with the exponential of the elements of the input tensor input.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.exp2(TorchSharp.torch.Tensor)">
            <summary>
            Computes the base 2 exponential function of input.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.expm1(TorchSharp.torch.Tensor)">
            <summary>
            Returns a new tensor with the exponential of the elements minus 1 of input.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.expm1_(TorchSharp.torch.Tensor)">
            <summary>
            Replaces each element with the exponential of the element minus 1 of input.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.fake_quantize_per_channel_affine(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Int32,System.Int64,System.Int64)">
            <summary>
            Returns a new tensor with the data in <paramref name="input"/> fake quantized per channel using
            <paramref name="scale"/>, <paramref name="zero_point"/>, <paramref name="quant_min"/> and <paramref name="quant_max"/>,
            across the channel specified by <paramref name="axis"/>.
            </summary>
            <param name="input">the input value(s) (float32)</param>
            <param name="scale">quantization scale, per channel (float32)</param>
            <param name="zero_point">quantization zero_point, per channel (torch.int32, torch.half, or torch.float32)</param>
            <param name="axis">channel axis</param>
            <param name="quant_min">lower bound of the quantized domain</param>
            <param name="quant_max">upper bound of the quantized domain</param>
            <returns>A newly fake_quantized per channel torch.float32 tensor</returns>
        </member>
        <member name="M:TorchSharp.torch.fake_quantize_per_tensor_affine(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Int64,System.Int64)">
            <summary>
            Returns a new tensor with the data in <paramref name="input"/> fake quantized per channel using
            <paramref name="scale"/>, <paramref name="zero_point"/>, <paramref name="quant_min"/> and <paramref name="quant_max"/>,
            across the channel specified by axis.
            </summary>
            <param name="input">the input value(s) (float32)</param>
            <param name="scale">quantization scale, per channel (float32)</param>
            <param name="zero_point">quantization zero_point, per channel (torch.int32, torch.half, or torch.float32)</param>
            <param name="quant_min">lower bound of the quantized domain</param>
            <param name="quant_max">upper bound of the quantized domain</param>
            <returns>A newly fake_quantized per channel torch.float32 tensor</returns>
        </member>
        <member name="M:TorchSharp.torch.fix(TorchSharp.torch.Tensor)">
            <summary>
            Returns a new tensor with the truncated integer values of the elements of input.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.fix_(TorchSharp.torch.Tensor)">
            <summary>
            Replaces each element with the truncated integer values of the elements of input.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.float_power(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Raises input to the power of exponent, elementwise, in double precision.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="target">The exponent.</param>
            <remarks> If neither input is complex returns a torch.float64 tensor, and if one or more inputs is complex returns a torch.complex128 tensor.</remarks>
        </member>
        <member name="M:TorchSharp.torch.floor(TorchSharp.torch.Tensor)">
            <summary>
            Returns a new tensor with the floor of the elements of input, the largest integer less than or equal to each element.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.floor_(TorchSharp.torch.Tensor)">
            <summary>
            Replaces each element with the floor of the input, the largest integer less than or equal to each element.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.floor_divide(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Computes input divided by other, elementwise, and floors the result.
            Supports broadcasting to a common shape, type promotion, and integer and float inputs.
            </summary>
            <param name="input">the dividend</param>
            <param name="other">the divisor</param>
            <returns>the output tensor</returns>
        </member>
        <member name="M:TorchSharp.torch.floor_divide_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Computes input divided by other, elementwise, and floors the result.
            Supports broadcasting to a common shape, type promotion, and integer and float inputs.
            </summary>
            <param name="input">the dividend</param>
            <param name="other">the divisor</param>
            <returns>the output tensor</returns>
        </member>
        <member name="M:TorchSharp.torch.fmod(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Computes the element-wise remainder of division.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.fmod_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Computes the element-wise remainder of division, in place.
            </summary>
            <param name="left">Numerator</param>
            <param name="right">Denominator</param>
        </member>
        <member name="M:TorchSharp.torch.fmod(TorchSharp.torch.Tensor,TorchSharp.Scalar)">
            <summary>
            Computes the element-wise remainder of division.
            </summary>
            <param name="left">Numerator</param>
            <param name="right">Denominator</param>
        </member>
        <member name="M:TorchSharp.torch.fmod_(TorchSharp.torch.Tensor,TorchSharp.Scalar)">
            <summary>
            Computes the element-wise remainder of division, in place.
            </summary>
            <param name="left">Numerator</param>
            <param name="right">Denominator</param>
        </member>
        <member name="M:TorchSharp.torch.frac(TorchSharp.torch.Tensor)">
            <summary>
            Computes the fractional portion of each element in input.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.frac_(TorchSharp.torch.Tensor)">
            <summary>
            Computes the fractional portion of each element in input, in-place.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.frexp(TorchSharp.torch.Tensor)">
            <summary>
            Decomposes input into mantissa and exponent tensors
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.ldexp(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Multiplies input by pow(2,other).
            </summary>
            <param name="input">The input tensor.</param>
            <param name="other">A tensor of exponents, typically integers</param>
            <remarks>Typically this function is used to construct floating point numbers by multiplying mantissas in input with integral powers of two created from the exponents in other.</remarks>
        </member>
        <member name="M:TorchSharp.torch.ldexp_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Multiplies input by pow(2,other) in place.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="other">A tensor of exponents, typically integers</param>
            <remarks>Typically this function is used to construct floating point numbers by multiplying mantissas in input with integral powers of two created from the exponents in other.</remarks>
        </member>
        <member name="M:TorchSharp.torch.lerp(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Does a linear interpolation of two tensors start (given by input)
            and end based on a scalar or tensor weight and returns the resulting out tensor.
            </summary>
            <remarks>
            The shapes of start and end must be broadcastable.
            If weight is a tensor, then the shapes of weight, start, and end must be broadcastable.
            </remarks>
            <param name="input">the tensor with the starting points</param>
            <param name="end">the tensor with the ending points</param>
            <param name="weight">the weight for the interpolation formula</param>
            <returns>the output tensor</returns>
        </member>
        <member name="M:TorchSharp.torch.lgamma(TorchSharp.torch.Tensor)">
            <summary>
            Computes the logarithm of the gamma function on input.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.lgamma_(TorchSharp.torch.Tensor)">
            <summary>
            Computes the logarithm of the gamma function on input, in place.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.log(TorchSharp.torch.Tensor)">
            <summary>
            Returns a new tensor with the natural logarithm of the input elements.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.log_(TorchSharp.torch.Tensor)">
            <summary>
            Replaces each elements with the natural logarithm of the input.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.log10(TorchSharp.torch.Tensor)">
            <summary>
            Returns a new tensor with the logarithm to the base 10 of the elements of input.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.log10_(TorchSharp.torch.Tensor)">
            <summary>
            Replaces each elements with the logarithm to the base 10 of the elements of input.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.log1p(TorchSharp.torch.Tensor)">
            <summary>
            Returns a new tensor with the natural logarithm of (1 + input).
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.log1p_(TorchSharp.torch.Tensor)">
            <summary>
            Replaces each elements with the natural logarithm of (1 + input), in place.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.log2(TorchSharp.torch.Tensor)">
            <summary>
            Returns a new tensor with the logarithm to the base 10 of the elements of input.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.log2_(TorchSharp.torch.Tensor)">
            <summary>
            Replaces each elements with the logarithm to the base 10 of the elements of input.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.logaddexp(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Logarithm of the sum of exponentiations of the inputs.
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="right">The right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.logaddexp2(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Logarithm of the sum of exponentiations of the inputs in base-2.
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="right">The right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.logical_and(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Element-wise logical AND
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="right">The right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.logical_and_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Element-wise logical AND, in place.
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="right">The right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.logical_not(TorchSharp.torch.Tensor)">
            <summary>
            Element-wise logical NOT
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.logical_or(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Element-wise logical OR
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="right">The right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.logical_or_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Element-wise logicalXOR, in place.
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="right">The right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.logical_xor(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Element-wise logical XOR
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="right">The right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.logical_xor_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Element-wise logical XOR
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="right">The right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.logit(TorchSharp.torch.Tensor,System.Nullable{System.Double})">
            <summary>
            Returns a new tensor with the logit of the elements of input.
            input is clamped to [eps, 1 - eps] when eps is not null
            </summary>
            <param name="input">The input tensor.</param>
            <param name="eps">The epsilon for input clamp bound.</param>
        </member>
        <member name="M:TorchSharp.torch.hypot(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Element-wise: given the legs of a right triangle, return its hypotenuse.
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="right">The right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.i0(TorchSharp.torch.Tensor)">
            <summary>
            Alias for <see cref="M:TorchSharp.torch.special.i0(TorchSharp.torch.Tensor)"/>.
            </summary>
            <param name="input"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.igamma(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Alias for <see cref="M:TorchSharp.torch.special.gammainc(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)"/>.
            </summary>
            <param name="input"></param>
            <param name="other"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.igammac(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Alias for <see cref="M:TorchSharp.torch.special.gammaincc(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)"/>".
            </summary>
            <param name="input"></param>
            <param name="other"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.mul(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Multiplies each element of the input by the corresponding element of other.
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="right">The right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.mul(TorchSharp.torch.Tensor,TorchSharp.Scalar)">
            <summary>
            Divides each element of the input by a scalar value.
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="right">The right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.mul_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Divides each element of the input by the corresponding element of other.
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="right">The right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.mul_(TorchSharp.torch.Tensor,TorchSharp.Scalar)">
            <summary>
            Divides each element of the input by the corresponding element of other.
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="right">The right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.multiply(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Multiplies each element of the input by the corresponding element of other.
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="right">The right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.multiply(TorchSharp.torch.Tensor,TorchSharp.Scalar)">
            <summary>
            Divides each element of the input by a scalar value.
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="right">The right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.multiply_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Divides each element of the input by the corresponding element of other.
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="right">The right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.multiply_(TorchSharp.torch.Tensor,TorchSharp.Scalar)">
            <summary>
            Divides each element of the input by the corresponding element of other.
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="right">The right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.mvlgamma(TorchSharp.torch.Tensor,System.Int64)">
            <summary>
            Computes the multivariate log-gamma function) with dimension pp element-wise
            </summary>
            <param name="input">The input tensor.</param>
            <param name="p">The number of dimensions</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.mvlgamma_(TorchSharp.torch.Tensor,System.Int64)">
            <summary>
            Computes the multivariate log-gamma function) with dimension pp element-wise, in place.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="p">The number of dimensions</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.nan_to_num(TorchSharp.torch.Tensor,System.Double,System.Nullable{System.Double},System.Nullable{System.Double})">
            <summary>
            Replaces NaN, positive infinity, and negative infinity values in input with the values specified by nan,
            posinf, and neginf, respectively. By default, NaNs are replaced with zero,
            positive infinity is replaced with the greatest finite value representable by input’s dtype,
            and negative infinity is replaced with the least finite value representable by input’s dtype.
            </summary>
            <param name="input">the input tensor</param>
            <param name="nan">the value to replace NaNs with. Default is zero.</param>
            <param name="posinf">
            if a Number, the value to replace positive infinity values with.
            If None, positive infinity values are replaced with the greatest finite value representable by input’s dtype.
            Default is null.
            </param>
            <param name="neginf">
            if a Number, the value to replace negative infinity values with.
            If None, negative infinity values are replaced with the lowest finite value representable by input’s dtype.
            Default is null.
            </param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.neg(TorchSharp.torch.Tensor)">
            <summary>
            Negation
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.neg_(TorchSharp.torch.Tensor)">
            <summary>
            In-place negation
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.negative(TorchSharp.torch.Tensor)">
            <summary>
            Negation
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.negative_(TorchSharp.torch.Tensor)">
            <summary>
            In-place negation
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.polygamma(TorchSharp.torch.Tensor,System.Int64)">
            <summary>
            Computes the Nth derivative of the digamma function on input.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="p">The number of dimensions</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.polygamma_(TorchSharp.torch.Tensor,System.Int64)">
            <summary>
            Computes the Nth derivative of the digamma function on input, in-place.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="p">The number of dimensions</param>
        </member>
        <member name="M:TorchSharp.torch.pow(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Takes the power of each element in input with exponent and returns a tensor with the result.
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="exponent">The right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.pow(TorchSharp.torch.Tensor,TorchSharp.Scalar)">
            <summary>
            Takes the power of each element in input with exponent and returns a tensor with the result.
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="exponent">The right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.pow_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Replaces each element in input with the power of the element and the exponent.
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="exponent">The right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.pow_(TorchSharp.torch.Tensor,TorchSharp.Scalar)">
            <summary>
            Replaces each element in input with the power of the element and the exponent.
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="exponent">The right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.quantized_batch_norm(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Double,System.Double,System.Int64)">
            <summary>
            Applies batch normalization on a 4D (NCHW) quantized tensor.
            </summary>
            <param name="input">quantized tensor</param>
            <param name="weight">float tensor that corresponds to the gamma, size C</param>
            <param name="bias">float tensor that corresponds to the beta, size C</param>
            <param name="mean">float mean value in batch normalization, size C</param>
            <param name="var">float tensor for variance, size C</param>
            <param name="eps">a value added to the denominator for numerical stability.</param>
            <param name="output_scale">output quantized tensor scale</param>
            <param name="output_zero_point">output quantized tensor zero_point</param>
            <returns>A quantized tensor with batch normalization applied.</returns>
        </member>
        <member name="M:TorchSharp.torch.quantized_max_pool1d(TorchSharp.torch.Tensor,System.Int64[],System.Int64[],System.Int64[],System.Int64,System.Boolean)">
            <summary>
            Applies a 1D max pooling over an input quantized tensor composed of several input planes.
            </summary>
            <param name="input">quantized tensor</param>
            <param name="kernel_size">the size of the sliding window</param>
            <param name="stride">the stride of the sliding window</param>
            <param name="padding">padding to be added on both sides, must be &gt;= 0 and &lt;= kernel_size / 2</param>
            <param name="dilation">the stride between elements within a sliding window, must be &gt; 0. Default 1</param>
            <param name="ceil_mode">If <value>true</value>, will use ceil instead of floor to compute the output shape. Defaults to <value>false</value>.</param>
            <returns>A quantized tensor with max_pool1d applied.</returns>
        </member>
        <member name="M:TorchSharp.torch.quantized_max_pool2d(TorchSharp.torch.Tensor,System.Int64[],System.Int64[],System.Int64[],System.Int64,System.Boolean)">
            <summary>
            Applies a 2D max pooling over an input quantized tensor composed of several input planes.
            </summary>
            <param name="input">quantized tensor</param>
            <param name="kernel_size">the size of the sliding window</param>
            <param name="stride">the stride of the sliding window</param>
            <param name="padding">padding to be added on both sides, must be &gt;= 0 and &lt;= kernel_size / 2</param>
            <param name="dilation">The stride between elements within a sliding window, must be > 0. Default 1</param>
            <param name="ceil_mode">If <value>true</value>, will use ceil instead of floor to compute the output shape. Defaults to <value>false</value>.</param>
            <returns>A quantized tensor with max_pool2d applied.</returns>
        </member>
        <member name="M:TorchSharp.torch.rad2deg(TorchSharp.torch.Tensor)">
            <summary>
            Returns a new tensor with each of the elements of input converted from angles in radians to degrees.
            </summary>
            <param name="input">The input tensor.</param>
            <returns>tensor with angles in radians</returns>
        </member>
        <member name="M:TorchSharp.torch.real(TorchSharp.torch.Tensor)">
            <summary>
            Returns a new tensor containing real values of the self tensor.
            The returned tensor and self share the same underlying storage.
            </summary>
            <param name="input">the input tensor.</param>
            <returns>tensor containing real values</returns>
        </member>
        <member name="M:TorchSharp.torch.reciprocal(TorchSharp.torch.Tensor)">
            <summary>
            Returns a new tensor with the reciprocal of the elements of input
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.reciprocal_(TorchSharp.torch.Tensor)">
            <summary>
            Replaces each element with the reciprocal of the input
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.remainder(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Computes the element-wise remainder of division.
            </summary>
            <param name="left">Numerator</param>
            <param name="right">Denominator</param>
        </member>
        <member name="M:TorchSharp.torch.remainder(TorchSharp.torch.Tensor,TorchSharp.Scalar)">
            <summary>
            Computes the element-wise remainder of division.
            </summary>
            <param name="left">Numerator</param>
            <param name="right">Denominator</param>
        </member>
        <member name="M:TorchSharp.torch.remainder_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Computes the element-wise remainder of division, in place
            </summary>
            <param name="left">Numerator</param>
            <param name="right">Denominator</param>
        </member>
        <member name="M:TorchSharp.torch.remainder_(TorchSharp.torch.Tensor,TorchSharp.Scalar)">
            <summary>
            Computes the element-wise remainder of division, in place
            </summary>
            <param name="left">Numerator</param>
            <param name="right">Denominator</param>
        </member>
        <member name="M:TorchSharp.torch.round(TorchSharp.torch.Tensor,System.Int64)">
            <summary>
            Returns a new tensor with each of the elements of input rounded to the closest value with the given number of decimals.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="decimals">Number of decimal places to round to (default: 0). If decimals is negative, it specifies the number of positions to the left of the decimal point.</param>
        </member>
        <member name="M:TorchSharp.torch.round_(TorchSharp.torch.Tensor,System.Int64)">
            <summary>
            Replaces each of the elements of input with the element rounded to the closest  value with the given number of decimals.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="decimals">Number of decimal places to round to (default: 0). If decimals is negative, it specifies the number of positions to the left of the decimal point.</param>
        </member>
        <member name="M:TorchSharp.torch.rsqrt(TorchSharp.torch.Tensor)">
            <summary>
            Returns a new tensor with the reciprocal of the square-root of each of the elements of input.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.rsqrt_(TorchSharp.torch.Tensor)">
            <summary>
            Replaces each of the elements of input with  the reciprocal of the square-root of each of the elements of input.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.sigmoid(TorchSharp.torch.Tensor)">
            <summary>
            Computes the logistic sigmoid function of the elements of input.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.sigmoid_(TorchSharp.torch.Tensor)">
            <summary>
            Computes the logistic sigmoid function of the elements of input.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.sign(TorchSharp.torch.Tensor)">
            <summary>
            Returns a new tensor with the signs (-1, 0, 1) of the elements of input.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.sign_(TorchSharp.torch.Tensor)">
            <summary>
            Returns a new tensor with the signs (-1, 0, 1) of the elements of input.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.sgn(TorchSharp.torch.Tensor)">
            <summary>
            This function is an extension of torch.sign() to complex tensors.
            It computes a new tensor whose elements have the same angles as the corresponding
            elements of input and absolute values (i.e. magnitudes) of one for complex tensors
            and is equivalent to torch.sign() for non-complex tensors.
            </summary>
            <param name="input">the input tensor.</param>
            <returns>the output tensor.</returns>
        </member>
        <member name="M:TorchSharp.torch.sgn_(TorchSharp.torch.Tensor)">
            <summary>
            This function is an extension of torch.sign() to complex tensors.
            It computes a new tensor whose elements have the same angles as the corresponding
            elements of input and absolute values (i.e. magnitudes) of one for complex tensors
            and is equivalent to torch.sign() for non-complex tensors.
            </summary>
            <param name="input">the input tensor.</param>
            <returns>the output tensor.</returns>
        </member>
        <member name="M:TorchSharp.torch.signbit(TorchSharp.torch.Tensor)">
            <summary>
            Tests whether each element of input has its sign bit set (is less than zero) or not.
            </summary>
            <param name="input">The input tensor.</param>
            <returns>A boolean tensor of the same shape as the input.</returns>
        </member>
        <member name="M:TorchSharp.torch.sin(TorchSharp.torch.Tensor)">
            <summary>
            Computes the sine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.sin_(TorchSharp.torch.Tensor)">
            <summary>
            Computes the sine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.sinc(TorchSharp.torch.Tensor)">
            <summary>
            Computes the normalized sinc of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.sinc_(TorchSharp.torch.Tensor)">
            <summary>
            Computes the normalized sinc of input, in place.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.sinh(TorchSharp.torch.Tensor)">
            <summary>
            Computes the hyperbolic sine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.sinh_(TorchSharp.torch.Tensor)">
            <summary>
            Computes the hyperbolic sine of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.sqrt(TorchSharp.torch.Tensor)">
            <summary>
            Computes the element-wise square root
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.sqrt_(TorchSharp.torch.Tensor)">
            <summary>
            Computes the element-wise square root, in place
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.square(TorchSharp.torch.Tensor)">
            <summary>
            Computes the element-wise square
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.sub(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Element-wise subtraction
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="right">The right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.sub(TorchSharp.torch.Tensor,TorchSharp.Scalar)">
            <summary>
            Element-wise subtraction
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="right">The right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.sub_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Element-wise subtraction
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="right">The right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.sub_(TorchSharp.torch.Tensor,TorchSharp.Scalar)">
            <summary>
            Element-wise subtraction
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="right">The right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.subtract(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Element-wise subtraction
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="right">The right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.subtract(TorchSharp.torch.Tensor,TorchSharp.Scalar)">
            <summary>
            Element-wise subtraction
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="right">The right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.subtract_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Element-wise subtraction
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.subtract_(TorchSharp.torch.Tensor,TorchSharp.Scalar)">
            <summary>
            Element-wise subtraction
            </summary>
            <param name="left">The left-hand operand.</param>
            <param name="right">The right-hand operand.</param>
        </member>
        <member name="M:TorchSharp.torch.tan(TorchSharp.torch.Tensor)">
            <summary>
            Computes the tangent of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.tan_(TorchSharp.torch.Tensor)">
            <summary>
            Computes the tangent of the elements of input. In-place version.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.tanh(TorchSharp.torch.Tensor)">
            <summary>
            Computes the hyperbolic tangent of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.tanh_(TorchSharp.torch.Tensor)">
            <summary>
            Computes the hyperbolic tangent of the elements of input.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.true_divide(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Alias for torch.div() with rounding_mode=None.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.true_divide_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Alias for torch.div_() with rounding_mode=None.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.trunc(TorchSharp.torch.Tensor)">
            <summary>
            Returns a new tensor with the truncated integer values of the elements of input.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.trunc_(TorchSharp.torch.Tensor)">
            <summary>
            Replaces each element with the truncated integer values of the elements of input.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.xlogy(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Computes x * log(y)
            </summary>
            <param name="x">The 'x' operand.</param>
            <param name="y">The 'y' operand.</param>
        </member>
        <member name="M:TorchSharp.torch.xlogy_(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Computes x * log(y) in place
            </summary>
            <param name="x">The 'x' operand.</param>
            <param name="y">The 'y' operand.</param>
        </member>
        <member name="M:TorchSharp.torch.xlogy(TorchSharp.torch.Tensor,TorchSharp.Scalar)">
            <summary>
            Computes x * log(y)
            </summary>
            <param name="x">The 'x' operand.</param>
            <param name="y">The 'y' operand.</param>
        </member>
        <member name="M:TorchSharp.torch.xlogy_(TorchSharp.torch.Tensor,TorchSharp.Scalar)">
            <summary>
            Computes x * log(y) in place
            </summary>
            <param name="x">The 'x' operand.</param>
            <param name="y">The 'y' operand.</param>
        </member>
        <member name="M:TorchSharp.torch.seed">
            <summary>
            Sets the seed for generating random numbers to a non-deterministic random number. Returns a 64 bit number used to seed the RNG.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.manual_seed(System.Int64)">
            <summary>
            Sets the seed for generating random numbers. Returns a torch.Generator object.
            </summary>
            <param name="seed">The desired seed.</param>
        </member>
        <member name="M:TorchSharp.torch.initial_seed">
            <summary>
            Returns the initial seed for generating random numbers.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.get_rng_state">
            <summary>
            Returns the random number generator state as a torch.ByteTensor.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.set_rng_state(TorchSharp.torch.Tensor)">
            <summary>
            Sets the random number generator state.
            </summary>
            <param name="new_state">The desired state</param>
        </member>
        <member name="M:TorchSharp.torch.bernoulli(TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Draws binary random numbers (0 or 1) from a Bernoulli distribution.
            </summary>
            <param name="input">The input tensor of probability values for the Bernoulli distribution</param>
            <param name="generator">Optional random number generator</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.multinomial(TorchSharp.torch.Tensor,System.Int64,System.Boolean,TorchSharp.torch.Generator)">
            <summary>
            Returns a tensor where each row contains num_samples indices sampled from the multinomial probability distribution located in the corresponding row of tensor input.
            </summary>
            <param name="input">A probabilities tensor</param>
            <param name="num_samples">Number of samples to draw</param>
            <param name="replacement">Whether to draw with replacement or not</param>
            <param name="generator">Optional random number generator</param>
        </member>
        <member name="M:TorchSharp.torch.normal(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Returns a tensor of random numbers drawn from separate normal distributions whose mean and standard deviation are given.
            </summary>
            <param name="mean">The tensor of per-element means</param>
            <param name="std">The tensor of per-element standard deviations</param>
            <param name="generator">An optional random number generator</param>
            <returns></returns>
            <exception cref="T:System.ArgumentException"></exception>
        </member>
        <member name="M:TorchSharp.torch.poisson(TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Returns a tensor of the same size as input with each element sampled from a Poisson distribution with rate parameter given by the corresponding element in input
            </summary>
            <param name="input">Input tensor.</param>
            <param name="generator">Optional random number generator</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.randn_like(TorchSharp.torch.Tensor,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.layout,TorchSharp.torch.Device,System.Boolean,TorchSharp.memory_format)">
            <summary>
            Returns a tensor with the same size as input that is filled with random numbers from a uniform distribution on the interval [0,1) .
            </summary>
        </member>
        <member name="M:TorchSharp.torch.rand_like(TorchSharp.torch.Tensor,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Returns a tensor with the same size as input that is filled with random numbers from a uniform distribution on the interval [0,1) .
            </summary>
        </member>
        <member name="M:TorchSharp.torch.randperm(System.Int64,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean,TorchSharp.torch.Generator)">
            <summary>
            Creates 1-D tensor of size [n] with a random permutation of [0, n).
            </summary>
        </member>
        <member name="M:TorchSharp.torch.randperm(System.Int64,TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Mutates the existing tensor to be a 1-D tensor of size [n] with a random permutation of [0, n).
            </summary>
        </member>
        <member name="M:TorchSharp.torch.randperm(System.Int64,TorchSharp.torch.Generator,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.layout,TorchSharp.torch.Device,System.Boolean,System.Boolean)">
            <summary>
            Creates 1-D tensor of size [n] with a random permutation of [0, n).
            </summary>
        </member>
        <member name="M:TorchSharp.torch.argmax(TorchSharp.torch.Tensor)">
            <summary>
            Returns the indices of the maximum value of all elements in the input tensor.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.argmax(TorchSharp.torch.Tensor,System.Int64,System.Boolean)">
            <summary>
            Returns the indices of the maximum value of all elements in the input tensor.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.argmin(TorchSharp.torch.Tensor)">
            <summary>
            Returns the indices of the minimum value of all elements in the input tensor.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.argmin(TorchSharp.torch.Tensor,System.Int64,System.Boolean)">
            <summary>
            Returns the indices of the minimum value of all elements in the input tensor.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.amax(TorchSharp.torch.Tensor,System.Int64[],System.Boolean,TorchSharp.torch.Tensor)">
            <summary>
            Returns the maximum value of each slice of the input tensor in the given dimension(s) dim.
            </summary>
            <param name="input">The input tensor</param>
            <param name="dims">The dimension or dimensions to reduce.</param>
            <param name="keepdim">Whether the output tensor has dim retained or not.</param>
            <param name="out">The output tensor -- optional.</param>
        </member>
        <member name="M:TorchSharp.torch.amin(TorchSharp.torch.Tensor,System.Int64[],System.Boolean,TorchSharp.torch.Tensor)">
            <summary>
            Returns the minimum value of each slice of the input tensor in the given dimension(s) dim.
            </summary>
            <param name="input">The input tensor</param>
            <param name="dims">The dimension or dimensions to reduce.</param>
            <param name="keepdim">Whether the output tensor has dim retained or not.</param>
            <param name="out">The output tensor -- optional.</param>
        </member>
        <member name="M:TorchSharp.torch.amin(TorchSharp.torch.Tensor,System.ReadOnlySpan{System.Int64},System.Boolean,TorchSharp.torch.Tensor)">
            <summary>
            Returns the minimum value of each slice of the input tensor in the given dimension(s) dim.
            </summary>
            <param name="input">The input tensor</param>
            <param name="dims">The dimension or dimensions to reduce.</param>
            <param name="keepdim">Whether the output tensor has dim retained or not.</param>
            <param name="out">The output tensor -- optional.</param>
        </member>
        <member name="M:TorchSharp.torch.all(TorchSharp.torch.Tensor)">
            <summary>
            Tests if all elements in input evaluate to true.
            <param name="input">The input tensor</param>
            </summary>
        </member>
        <member name="M:TorchSharp.torch.all(TorchSharp.torch.Tensor,System.Int64,System.Boolean)">
            <summary>
            Tests if all elements in input evaluate to true.
            <param name="input">The input tensor</param>
            <param name="dim">The dimension to reduce</param>
            <param name="keepdim">Keep the dimension to reduce</param>
            </summary>
        </member>
        <member name="M:TorchSharp.torch.any(TorchSharp.torch.Tensor)">
            <summary>
            Tests if all elements in input evaluate to true.
            <param name="input">The input tensor</param>
            </summary>
        </member>
        <member name="M:TorchSharp.torch.any(TorchSharp.torch.Tensor,System.Int64,System.Boolean)">
            <summary>
            Tests if any element in input evaluate to true.
            <param name="input">The input tensor</param>
            <param name="dim">The dimension to reduce</param>
            <param name="keepdim">Keep the dimension to reduce</param>
            </summary>
        </member>
        <member name="M:TorchSharp.torch.max(TorchSharp.torch.Tensor)">
            <summary>
            Returns the maximum value of all elements in the input tensor.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.max(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Computes the element-wise maximum of input and other.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="other">The second tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.max(TorchSharp.torch.Tensor,System.Int64,System.Boolean)">
            <summary>
            Returns a named tuple (values, indexes) where values is the maximum value of each row of the input tensor in the given dimension dim.
            And indices is the index location of each maximum value found (argmax).
            </summary>
            <param name="input">The input tensor</param>
            <param name="dim">the dimension to reduce.</param>
            <param name="keepdim">whether the output tensor has dim retained or not. Default: false.</param>
            <remarks>If keepdim is true, the output tensors are of the same size as input except in the dimension dim where they are of size 1.
            Otherwise, dim is squeezed(see torch.squeeze()), resulting in the output tensors having 1 fewer dimension than input.</remarks>
        </member>
        <member name="M:TorchSharp.torch.min(TorchSharp.torch.Tensor)">
            <summary>
            Returns the minimum value of all elements in the input tensor.
            </summary>
            <param name="input">The input tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.min(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Computes the element-wise minimum of input and other.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="other">The second tensor.</param>
        </member>
        <member name="M:TorchSharp.torch.min(TorchSharp.torch.Tensor,System.Int64,System.Boolean)">
            <summary>
            Returns a named tuple (values, indexes) where values is the minimum value of each row of the input tensor in the given dimension dim.
            And indices is the index location of each minimum value found (argmin).
            </summary>
            <param name="input">The input tensor</param>
            <param name="dim">the dimension to reduce.</param>
            <param name="keepdim">whether the output tensor has dim retained or not. Default: false.</param>
            <remarks>If keepdim is true, the output tensors are of the same size as input except in the dimension dim where they are of size 1.
            Otherwise, dim is squeezed(see torch.squeeze()), resulting in the output tensors having 1 fewer dimension than input.</remarks>
        </member>
        <member name="M:TorchSharp.torch.dist(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Single)">
            <summary>
            Returns the p-norm of (input - other).
            The shapes of input and other must be broadcastable.
            </summary>
            <param name="input">Left-hand side input tensor.</param>
            <param name="other">Right-hand side input tensor</param>
            <param name="p">The norm to be computed.</param>
        </member>
        <member name="M:TorchSharp.torch.logsumexp(TorchSharp.torch.Tensor,System.Int64,System.Boolean)">
            <summary>
            Returns the log of summed exponentials of each row of the input tensor in the given dimension dim.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="dim">The dimension to do the operation over</param>
            <param name="keepdim">Thether the output tensor has dim retained or not.</param>
        </member>
        <member name="M:TorchSharp.torch.mean(TorchSharp.torch.Tensor)">
            <summary>
            Returns the mean value of all elements in the input tensor.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.mean(TorchSharp.torch.Tensor,System.Int64[],System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Returns the mean value of each row of the input tensor in the given dimension dim. If dim is a list of dimensions, reduce over all of them.
            </summary>
            <param name="input">The input tensor</param>
            <param name="dimensions">The dimension or dimensions to reduce.</param>
            <param name="keepdim">Whether the output tensor has dim retained or not.</param>
            <param name="type">The desired data type of returned tensor. If specified, the input tensor is cast to dtype before the operation is performed. This is useful for preventing data type overflows.</param>
            <remarks>
            If keepdim is True, the output tensor is of the same size as input except in the dimension(s) dim where it is of size 1.
            Otherwise, dim is squeezed(see torch.squeeze()), resulting in the output tensor having 1 (or len(dim)) fewer dimension(s).
            </remarks>
        </member>
        <member name="M:TorchSharp.torch.prod(TorchSharp.torch.Tensor,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
             Returns the product of each row of the input tensor in the given dimensions.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.prod(TorchSharp.torch.Tensor,System.Int64,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Returns the product of each row of the input tensor in the given dimension.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.std(TorchSharp.torch.Tensor,System.Boolean)">
            <summary>
            Calculates the standard deviation of all elements in the tensor.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
        </member>
        <member name="M:TorchSharp.torch.std(TorchSharp.torch.Tensor,System.Int64[],System.Boolean,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>Calculates the standard deviation of all elements in the tensor.</summary>
            <remarks>
            If <paramref name="unbiased" /> is <value>true</value>, Bessel’s correction will be used.
            Otherwise, the sample deviation is calculated, without any correction.
            </remarks>
            <param name="input">The input tensor.</param>
            <param name="dimensions">The dimensions to reduce.</param>
            <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
            <param name="keepdim">Whether the <see cref="T:TorchSharp.torch.Tensor">output tensor</see> has dim retained or not.</param>
            <param name="type"></param>
            <returns>The <see cref="T:TorchSharp.torch.Tensor">output tensor</see>.</returns>
        </member>
        <member name="M:TorchSharp.torch.std(TorchSharp.torch.Tensor,System.Int64,System.Boolean,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>Calculates the standard deviation of all elements in the tensor.</summary>
            <remarks>
            If <paramref name="unbiased" /> is <value>true</value>, Bessel’s correction will be used.
            Otherwise, the sample deviation is calculated, without any correction.
            </remarks>
            <param name="input">The input tensor.</param>
            <param name="dimensions">The dimensions to reduce.</param>
            <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
            <param name="keepdim">Whether the <see cref="T:TorchSharp.torch.Tensor">output tensor</see> has dim retained or not.</param>
            <param name="type"></param>
            <returns>The <see cref="T:TorchSharp.torch.Tensor">output tensor</see>.</returns>
        </member>
        <member name="M:TorchSharp.torch.std(TorchSharp.torch.Tensor,System.ValueTuple{System.Int64,System.Int64},System.Boolean,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>Calculates the standard deviation of all elements in the tensor.</summary>
            <remarks>
            If <paramref name="unbiased" /> is <value>true</value>, Bessel’s correction will be used.
            Otherwise, the sample deviation is calculated, without any correction.
            </remarks>
            <param name="input">The input tensor.</param>
            <param name="dimensions">The dimensions to reduce.</param>
            <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
            <param name="keepdim">Whether the <see cref="T:TorchSharp.torch.Tensor">output tensor</see> has dim retained or not.</param>
            <param name="type"></param>
            <returns>The <see cref="T:TorchSharp.torch.Tensor">output tensor</see>.</returns>
        </member>
        <member name="M:TorchSharp.torch.std(TorchSharp.torch.Tensor,System.ValueTuple{System.Int64,System.Int64,System.Int64},System.Boolean,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>Calculates the standard deviation of all elements in the tensor.</summary>
            <remarks>
            If <paramref name="unbiased" /> is <value>true</value>, Bessel’s correction will be used.
            Otherwise, the sample deviation is calculated, without any correction.
            </remarks>
            <param name="input">The input tensor.</param>
            <param name="dimensions">The dimensions to reduce.</param>
            <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
            <param name="keepdim">Whether the <see cref="T:TorchSharp.torch.Tensor">output tensor</see> has dim retained or not.</param>
            <param name="type"></param>
            <returns>The <see cref="T:TorchSharp.torch.Tensor">output tensor</see>.</returns>
        </member>
        <member name="M:TorchSharp.torch.std_mean(TorchSharp.torch.Tensor,System.Int64[],System.Boolean,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>Calculates the standard deviation and mean of all elements in the tensor.</summary>
            <remarks>
            If <paramref name="unbiased" /> is <value>true</value>, Bessel’s correction will be used.
            Otherwise, the sample deviation is calculated, without any correction.
            </remarks>
            <param name="input">The input tensor.</param>
            <param name="dimensions">The dimensions to reduce.</param>
            <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
            <param name="keepdim">Whether the <see cref="T:TorchSharp.torch.Tensor">output tensor</see> has dim retained or not.</param>
            <param name="type"></param>
            <returns>A <see cref="T:TorchSharp.torch.Tensor">tensor</see> tuple of the standard deviation and the mean.</returns>
        </member>
        <member name="M:TorchSharp.torch.std_mean(TorchSharp.torch.Tensor,System.ReadOnlySpan{System.Int64},System.Boolean,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>Calculates the standard deviation and mean of all elements in the tensor.</summary>
            <remarks>
            If <paramref name="unbiased" /> is <value>true</value>, Bessel’s correction will be used.
            Otherwise, the sample deviation is calculated, without any correction.
            </remarks>
            <param name="input">The input tensor.</param>
            <param name="dimensions">The dimensions to reduce.</param>
            <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
            <param name="keepdim">Whether the <see cref="T:TorchSharp.torch.Tensor">output tensor</see> has dim retained or not.</param>
            <param name="type"></param>
            <returns>A <see cref="T:TorchSharp.torch.Tensor">tensor</see> tuple of the standard deviation and the mean.</returns>
        </member>
        <member name="M:TorchSharp.torch.std_mean(TorchSharp.torch.Tensor,System.Int64,System.Boolean,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>Calculates the standard deviation and mean of all elements in the tensor.</summary>
            <remarks>
            If <paramref name="unbiased" /> is <value>true</value>, Bessel’s correction will be used.
            Otherwise, the sample deviation is calculated, without any correction.
            </remarks>
            <param name="input">The input tensor.</param>
            <param name="dimensions">The dimensions to reduce.</param>
            <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
            <param name="keepdim">Whether the <see cref="T:TorchSharp.torch.Tensor">output tensor</see> has dim retained or not.</param>
            <param name="type"></param>
            <returns>A <see cref="T:TorchSharp.torch.Tensor">tensor</see> tuple of the standard deviation and the mean.</returns>
        </member>
        <member name="M:TorchSharp.torch.std_mean(TorchSharp.torch.Tensor,System.ValueTuple{System.Int64,System.Int64},System.Boolean,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>Calculates the standard deviation and mean of all elements in the tensor.</summary>
            <remarks>
            If <paramref name="unbiased" /> is <value>true</value>, Bessel’s correction will be used.
            Otherwise, the sample deviation is calculated, without any correction.
            </remarks>
            <param name="input">The input tensor.</param>
            <param name="dimensions">The dimensions to reduce.</param>
            <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
            <param name="keepdim">Whether the <see cref="T:TorchSharp.torch.Tensor">output tensor</see> has dim retained or not.</param>
            <param name="type"></param>
            <returns>A <see cref="T:TorchSharp.torch.Tensor">tensor</see> tuple of the standard deviation and the mean.</returns>
        </member>
        <member name="M:TorchSharp.torch.std_mean(TorchSharp.torch.Tensor,System.ValueTuple{System.Int64,System.Int64,System.Int64},System.Boolean,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>Calculates the standard deviation and mean of all elements in the tensor.</summary>
            <remarks>
            If <paramref name="unbiased" /> is <value>true</value>, Bessel’s correction will be used.
            Otherwise, the sample deviation is calculated, without any correction.
            </remarks>
            <param name="input">The input tensor.</param>
            <param name="dimensions">The dimensions to reduce.</param>
            <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
            <param name="keepdim">Whether the <see cref="T:TorchSharp.torch.Tensor">output tensor</see> has dim retained or not.</param>
            <param name="type"></param>
            <returns>A <see cref="T:TorchSharp.torch.Tensor">tensor</see> tuple of the standard deviation and the mean.</returns>
        </member>
        <member name="M:TorchSharp.torch.sum(TorchSharp.torch.Tensor,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
             Returns the sum of each row of the input tensor in the given dimensions.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.sum(TorchSharp.torch.Tensor,System.ReadOnlySpan{System.Int64},System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Returns the sum of each row of the input tensor in the given dimensions.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.sum(TorchSharp.torch.Tensor,System.Int64,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>
            Returns the sum of each row of the input tensor in the given dimension.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.unique(TorchSharp.torch.Tensor,System.Boolean,System.Boolean,System.Boolean,System.Nullable{System.Int32})">
            <summary>
            Returns the unique elements of the input tensor.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.unique_consecutive(TorchSharp.torch.Tensor,System.Boolean,System.Boolean,System.Nullable{System.Int32})">
            <summary>
            Eliminates all but the first element from every consecutive group of equivalent elements.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.var(TorchSharp.torch.Tensor,System.Boolean)">
            <summary>
            Calculates the variance of all elements in the tensor.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
        </member>
        <member name="M:TorchSharp.torch.var(TorchSharp.torch.Tensor,System.Int64[],System.Boolean,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>Calculates the variance of all elements in the tensor.</summary>
            <remarks>
            If <paramref name="unbiased" /> is <value>true</value>, Bessel’s correction will be used.
            Otherwise, the sample variance is calculated, without any correction.
            </remarks>
            <param name="input">The input tensor.</param>
            <param name="dimensions">The dimensions to reduce.</param>
            <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
            <param name="keepdim">Whether the <see cref="T:TorchSharp.torch.Tensor">output tensor</see> has dim retained or not.</param>
            <param name="type"></param>
            <returns>The <see cref="T:TorchSharp.torch.Tensor">output tensor</see>.</returns>
        </member>
        <member name="M:TorchSharp.torch.var(TorchSharp.torch.Tensor,System.Int64,System.Boolean,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>Calculates the variance of all elements in the tensor.</summary>
            <remarks>
            If <paramref name="unbiased" /> is <value>true</value>, Bessel’s correction will be used.
            Otherwise, the sample variance is calculated, without any correction.
            </remarks>
            <param name="input">The input tensor.</param>
            <param name="dimensions">The dimensions to reduce.</param>
            <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
            <param name="keepdim">Whether the <see cref="T:TorchSharp.torch.Tensor">output tensor</see> has dim retained or not.</param>
            <param name="type"></param>
            <returns>The <see cref="T:TorchSharp.torch.Tensor">output tensor</see>.</returns>
        </member>
        <member name="M:TorchSharp.torch.var(TorchSharp.torch.Tensor,System.ValueTuple{System.Int64,System.Int64},System.Boolean,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>Calculates the variance of all elements in the tensor.</summary>
            <remarks>
            If <paramref name="unbiased" /> is <value>true</value>, Bessel’s correction will be used.
            Otherwise, the sample variance is calculated, without any correction.
            </remarks>
            <param name="input">The input tensor.</param>
            <param name="dimensions">The dimensions to reduce.</param>
            <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
            <param name="keepdim">Whether the <see cref="T:TorchSharp.torch.Tensor">output tensor</see> has dim retained or not.</param>
            <param name="type"></param>
            <returns>The <see cref="T:TorchSharp.torch.Tensor">output tensor</see>.</returns>
        </member>
        <member name="M:TorchSharp.torch.var(TorchSharp.torch.Tensor,System.ValueTuple{System.Int64,System.Int64,System.Int64},System.Boolean,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>Calculates the variance of all elements in the tensor.</summary>
            <remarks>
            If <paramref name="unbiased" /> is <value>true</value>, Bessel’s correction will be used.
            Otherwise, the sample variance is calculated, without any correction.
            </remarks>
            <param name="input">The input tensor.</param>
            <param name="dimensions">The dimensions to reduce.</param>
            <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
            <param name="keepdim">Whether the <see cref="T:TorchSharp.torch.Tensor">output tensor</see> has dim retained or not.</param>
            <param name="type"></param>
            <returns>The <see cref="T:TorchSharp.torch.Tensor">output tensor</see>.</returns>
        </member>
        <member name="M:TorchSharp.torch.var_mean(TorchSharp.torch.Tensor,System.Boolean)">
            <summary>
            Calculates the variance and mean of all elements in the tensor.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
        </member>
        <member name="M:TorchSharp.torch.var_mean(TorchSharp.torch.Tensor,System.Int64[],System.Boolean,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>Calculates the variance and mean of all elements in the tensor.</summary>
            <remarks>
            If <paramref name="unbiased" /> is <value>true</value>, Bessel’s correction will be used.
            Otherwise, the sample variance is calculated, without any correction.
            </remarks>
            <param name="input">The input tensor.</param>
            <param name="dimensions">The dimensions to reduce.</param>
            <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
            <param name="keepdim">Whether the <see cref="T:TorchSharp.torch.Tensor">output tensor</see> has dim retained or not.</param>
            <param name="type"></param>
            <returns>A <see cref="T:TorchSharp.torch.Tensor">tensor</see> tuple of the variance and the mean.</returns>
        </member>
        <member name="M:TorchSharp.torch.var_mean(TorchSharp.torch.Tensor,System.ReadOnlySpan{System.Int64},System.Boolean,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>Calculates the variance and mean of all elements in the tensor.</summary>
            <remarks>
            If <paramref name="unbiased" /> is <value>true</value>, Bessel’s correction will be used.
            Otherwise, the sample variance is calculated, without any correction.
            </remarks>
            <param name="input">The input tensor.</param>
            <param name="dimensions">The dimensions to reduce.</param>
            <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
            <param name="keepdim">Whether the <see cref="T:TorchSharp.torch.Tensor">output tensor</see> has dim retained or not.</param>
            <param name="type"></param>
            <returns>A <see cref="T:TorchSharp.torch.Tensor">tensor</see> tuple of the variance and the mean.</returns>
        </member>
        <member name="M:TorchSharp.torch.var_mean(TorchSharp.torch.Tensor,System.Int64,System.Boolean,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>Calculates the variance and mean of all elements in the tensor.</summary>
            <remarks>
            If <paramref name="unbiased" /> is <value>true</value>, Bessel’s correction will be used.
            Otherwise, the sample variance is calculated, without any correction.
            </remarks>
            <param name="input">The input tensor.</param>
            <param name="dimensions">The dimensions to reduce.</param>
            <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
            <param name="keepdim">Whether the <see cref="T:TorchSharp.torch.Tensor">output tensor</see> has dim retained or not.</param>
            <param name="type"></param>
            <returns>A <see cref="T:TorchSharp.torch.Tensor">tensor</see> tuple of the variance and the mean.</returns>
        </member>
        <member name="M:TorchSharp.torch.var_mean(TorchSharp.torch.Tensor,System.ValueTuple{System.Int64,System.Int64},System.Boolean,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>Calculates the variance and mean of all elements in the tensor.</summary>
            <remarks>
            If <paramref name="unbiased" /> is <value>true</value>, Bessel’s correction will be used.
            Otherwise, the sample variance is calculated, without any correction.
            </remarks>
            <param name="input">The input tensor.</param>
            <param name="dimensions">The dimensions to reduce.</param>
            <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
            <param name="keepdim">Whether the <see cref="T:TorchSharp.torch.Tensor">output tensor</see> has dim retained or not.</param>
            <param name="type"></param>
            <returns>A <see cref="T:TorchSharp.torch.Tensor">tensor</see> tuple of the variance and the mean.</returns>
        </member>
        <member name="M:TorchSharp.torch.var_mean(TorchSharp.torch.Tensor,System.ValueTuple{System.Int64,System.Int64,System.Int64},System.Boolean,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType})">
            <summary>Calculates the variance and mean of all elements in the tensor.</summary>
            <remarks>
            If <paramref name="unbiased" /> is <value>true</value>, Bessel’s correction will be used.
            Otherwise, the sample variance is calculated, without any correction.
            </remarks>
            <param name="input">The input tensor.</param>
            <param name="dimensions">The dimensions to reduce.</param>
            <param name="unbiased">Whether to use Bessel’s correction (δN=1).</param>
            <param name="keepdim">Whether the <see cref="T:TorchSharp.torch.Tensor">output tensor</see> has dim retained or not.</param>
            <param name="type"></param>
            <returns>A <see cref="T:TorchSharp.torch.Tensor">tensor</see> tuple of the variance and the mean.</returns>
        </member>
        <member name="M:TorchSharp.torch.count_nonzero(TorchSharp.torch.Tensor,System.Int64[])">
            <summary>
            Counts the number of non-zero values in the tensor input along the given dim. If no dim is specified then all non-zeros in the tensor are counted.
            </summary>
            <param name="input">The input tensor.</param>
            <param name="dims">List of dims along which to count non-zeros.</param>
        </member>
        <member name="M:TorchSharp.torch.stft(TorchSharp.torch.Tensor,System.Int64,System.Int64,System.Int64,TorchSharp.torch.Tensor,System.Boolean,TorchSharp.PaddingModes,System.Boolean,System.Nullable{System.Boolean},System.Nullable{System.Boolean})">
            <summary>
            Returns a tensor containing the result of Short-time Fourier transform (STFT).
            </summary>
            <param name="input">The input tensor</param>
            <param name="n_fft">The size of Fourier transform</param>
            <param name="hop_length">The hop length</param>
            <param name="win_length">The window length</param>
            <param name="window">The window function</param>
            <param name="center">Whether the t-th frame is centered around t * hop_window, or not.</param>
            <param name="pad_mode">The padding mode used when center is true.</param>
            <param name="normalized">Whether the output is normalized, or not.</param>
            <param name="onesided">Whether the output is onesided or not.</param>
            <param name="return_complex">Whether a complex tensor is returned, or not.</param>
            <returns>A tensor containing the result of Short-time Fourier transform (STFT).</returns>
        </member>
        <member name="M:TorchSharp.torch.istft(TorchSharp.torch.Tensor,System.Int64,System.Int64,System.Int64,TorchSharp.torch.Tensor,System.Boolean,System.Boolean,System.Nullable{System.Boolean},System.Int64,System.Boolean)">
            <summary>
            Returns a tensor containing the result of Inverse Short-time Fourier transform.
            </summary>
            <param name="input">The input tensor</param>
            <param name="n_fft">The size of Fourier transform</param>
            <param name="hop_length">The hop length</param>
            <param name="win_length">The window length</param>
            <param name="window">The window function</param>
            <param name="center">Whether the t-th frame is centered around t * hop_window, or not.</param>
            <param name="normalized">Whether the output is normalized, or not.</param>
            <param name="onesided">Whether the output is onesided or not.</param>
            <param name="length">The length of the output tensor.</param>
            <param name="return_complex">Whether a complex tensor is returned, or not.</param>
            <returns>A tensor containing the result of Inverse Short-time Fourier transform</returns>
        </member>
        <member name="M:TorchSharp.torch.bartlett_window(System.Int64,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Bartlett window function.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.blackman_window(System.Int64,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Blackman window function.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.hamming_window(System.Int64,System.Boolean,System.Single,System.Single,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Hamming window function.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.hann_window(System.Int64,System.Boolean,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Hann window function.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.kaiser_window(System.Int64,System.Boolean,System.Single,System.Nullable{TorchSharp.torch.ScalarType},TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Computes the Kaiser window with window length window_length and shape parameter beta.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.is_complex(TorchSharp.torch.Tensor)">
            <summary>
            Returns True if the data type of input is a complex data type i.e., one of torch.complex64, and torch.complex128.
            </summary>
            <param name="input">The input tensor</param>
        </member>
        <member name="M:TorchSharp.torch.is_floating_point(TorchSharp.torch.Tensor)">
            <summary>
            Returns True if the data type of input is a floating point data type.
            </summary>
            <param name="input">The input tensor</param>
        </member>
        <member name="M:TorchSharp.torch.is_nonzero(TorchSharp.torch.Tensor)">
            <summary>
            Returns True if the input is a single element tensor which is not equal to zero after type conversions,
            i.e. not equal to torch.tensor([0.]) or torch.tensor([0]) or torch.tensor([False]).
            Throws an InvalidOperationException if torch.numel() != 1.
            </summary>
            <param name="input">The input tensor</param>
        </member>
        <member name="M:TorchSharp.torch.set_default_dtype(TorchSharp.torch.ScalarType)">
            <summary>
            Sets the default floating point dtype to d. This dtype is:
            1. The inferred dtype for python floats in torch.tensor().
            2. Used to infer dtype for python complex numbers.
            The default complex dtype is set to torch.complex128 if default floating point dtype is torch.float64, otherwise it’s set to torch.complex64
            The default floating point dtype is initially torch.float32.
            </summary>
            <param name="dtype"></param>
        </member>
        <member name="M:TorchSharp.torch.get_default_dtype">
            <summary>
            Get the current default floating point torch.dtype.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.numel(TorchSharp.torch.Tensor)">
            <summary>
            Get the number of elements in the input tensor.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.CopyNativeComponentsIntoSingleDirectory(System.String,System.String,System.String,System.String,System.Text.StringBuilder)">
            Copy all native runtime DLLs into single directory if it hasn't been done already
        </member>
        <member name="M:TorchSharp.torch.random.seed">
            <summary>
            Sets the seed for generating random numbers to a non-deterministic random number. Returns a 64 bit number used to seed the RNG.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.random.initial_seed">
            <summary>
            Returns the initial seed for generating random numbers.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.random.manual_seed(System.Int64)">
            <summary>
            Sets the seed for generating random numbers. Returns a torch.Generator object.
            </summary>
            <param name="seed">The desired seed.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.random.get_rng_state">
            <summary>
            Returns the random number generator state as a torch.ByteTensor.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.random.set_rng_state(TorchSharp.torch.Tensor)">
            <summary>
            Sets the random number generator state.
            </summary>
            <param name="new_state">The desired state</param>
        </member>
        <member name="M:TorchSharp.torch.cuda.CallTorchCudaIsAvailable">
            This must be a separate method to the failure to bind DllImport THSTorchCuda_is_available
            is not raised as early as a DllImportException
        </member>
        <member name="M:TorchSharp.torch.cuda.is_available">
            <summary>
            Returns a bool indicating if CUDA is currently available.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.cuda.is_cudnn_available">
            <summary>
            Returns a bool indicating if CUDNN is currently available.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.cuda.device_count">
            <summary>
            Returns the number of GPUs available.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.torch.cuda.manual_seed(System.Int64)">
            <summary>
            Sets the seed for generating random numbers for the current GPU.
            It’s safe to call this function if CUDA is not available; in that case, it is silently ignored.
            </summary>
            <param name="seed">The desired seed.</param>
        </member>
        <member name="M:TorchSharp.torch.cuda.manual_seed_all(System.Int64)">
            <summary>
            Sets the seed for generating random numbers on all GPUs.
            It’s safe to call this function if CUDA is not available; in that case, it is silently ignored.
            </summary>
            <param name="seed"></param>
        </member>
        <member name="M:TorchSharp.torch.cuda.synchronize(TorchSharp.torch.Device)">
            <summary>
            Waits for all kernels in all streams on a CUDA device to complete.
            </summary>
            <param name="device">Device for which to synchronize.
            It uses the current device, given by current_device(), if a device is not provided.</param>
        </member>
        <member name="M:TorchSharp.torch.cuda_is_available">
            <summary>
            Workaround for F# issue.
            </summary>
        </member>
        <member name="M:TorchSharp.torch.mps_is_available">
            <summary>
            Check whether MPS is available
            </summary>
        </member>
        <member name="T:TorchSharp.Data.DataIterator">
            <summary>
            Class implementing enumerable over PyTorch's iterator.
            </summary>
        </member>
        <member name="T:TorchSharp.Data.DataIterator.HType">
            <summary>
               Class wrapping PyTorch's iterator object reference.
            </summary>
        </member>
        <member name="M:TorchSharp.Data.DataIterator.#ctor(System.IntPtr)">
            <summary>
            Constructor.
            </summary>
            <param name="handle"></param>
        </member>
        <member name="M:TorchSharp.Data.DataIterator.Dispose">
            <summary>
            Releases the storage.
            </summary>
        </member>
        <member name="M:TorchSharp.Data.DataIterator.Dispose(System.Boolean)">
            <summary>
            Implements the .NET Dispose pattern.
            </summary>
        </member>
        <member name="M:TorchSharp.Data.DataIterator.Size">
            <summary>
            Return the total size in Bytes of the input dataset.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Data.DataIterator.GetEnumerator">
            <summary>
            Get the enumerator for this iterator.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Data.Loader.MNIST(System.String,System.Int64,System.Boolean)">
            <summary>
            Create an iterator scanning the MNIST dataset.
            </summary>
            <param name="filename">The position of the MNIST dataset</param>
            <param name="batchSize">The required batch size</param>
            <param name="isTrain">Wheter the iterator is for training or testing</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Data.Loader.CIFAR10(System.String,System.Int64,System.Boolean)">
            <summary>
            Create an iterator scanning the CIFAR10 dataset.
            </summary>
            <param name="path">The position of the CIFAR10 dataset</param>
            <param name="batchSize">The required batch size</param>
            <param name="isTrain">Wheter the iterator is for training or testing</param>
            <returns></returns>
        </member>
        <member name="T:TorchSharp.Modules.DataLoader">
            <summary>
            Data loader. Combines a dataset and a sampler, and provides an enumerator over the given dataset.
            </summary>
            <remarks>This class is used for map-style data sets</remarks>
        </member>
        <member name="M:TorchSharp.Modules.DataLoader.#ctor(TorchSharp.torch.utils.data.Dataset,System.Int32,System.Collections.Generic.IEnumerable{System.Int64},TorchSharp.torch.Device,System.Int32,System.Boolean,System.Boolean,System.Boolean)">
            <summary>
            Pytorch style dataloader
            </summary>
            <param name="dataset">Dataset for create batch</param>
            <param name="batchSize">Size of batch</param>
            <param name="device">device for output tensor</param>
            <param name="shuffler">Shuffler for dataloader</param>
            <param name="num_worker">Count of worker</param>
            <param name="drop_last">
            Set to true to drop the last incomplete batch, if the dataset size is not divisible by the batch size.
            If alse and the size of dataset is not divisible by the batch size, then the last batch will be smaller.
            </param>
            <param name="disposeBatch">
            Indicates whether to automatically dispose the collated tensors after an iteration.
            </param>
            <param name="disposeDataset">
            Indicates whether to dispose the dataset when being disposed.
            </param>
        </member>
        <member name="M:TorchSharp.Modules.DataLoader.#ctor(TorchSharp.torch.utils.data.Dataset,System.Int32,System.Boolean,TorchSharp.torch.Device,System.Nullable{System.Int32},System.Int32,System.Boolean,System.Boolean,System.Boolean)">
            <summary>
            Pytorch style dataloader
            </summary>
            <param name="dataset">Dataset for create batch</param>
            <param name="batchSize">Size of batch</param>
            <param name="shuffle">true if shuffle dataset, false for not</param>
            <param name="device">device for output tensor</param>
            <param name="seed">Seed for generating shuffle</param>
            <param name="num_worker">Count of worker</param>
            <param name="drop_last">
            Set to true to drop the last incomplete batch, if the dataset size is not divisible by the batch size.
            If alse and the size of dataset is not divisible by the batch size, then the last batch will be smaller.
            </param>
            <param name="disposeBatch">
            Indicates whether to automatically dispose the collated tensors after an iteration.
            </param>
            <param name="disposeDataset">
            Indicates whether to dispose the dataset when being disposed.
            </param>
        </member>
        <member name="T:TorchSharp.Modules.IterableDataLoader">
            <summary>
            Data loader. Combines a dataset and a sampler, and provides an enumerator over the given dataset.
            </summary>
            <remarks>This class is used for list-style data sets</remarks>
        </member>
        <member name="M:TorchSharp.Modules.IterableDataLoader.#ctor(TorchSharp.torch.utils.data.IterableDataset,System.Int32,System.Collections.Generic.IEnumerable{System.Int64},TorchSharp.torch.Device,System.Int32,System.Boolean,System.Boolean,System.Boolean)">
            <summary>
            Pytorch style dataloader
            </summary>
            <param name="dataset">Dataset for create batch</param>
            <param name="batchSize">Size of batch</param>
            <param name="device">device for output tensor</param>
            <param name="shuffler">Shuffler for dataloader</param>
            <param name="num_worker">Count of worker</param>
            <param name="drop_last">
            Set to true to drop the last incomplete batch, if the dataset size is not divisible by the batch size.
            If alse and the size of dataset is not divisible by the batch size, then the last batch will be smaller.
            </param>
            <param name="disposeBatch">
            Indicates whether to automatically dispose the collated tensors after an iteration.
            </param>
            <param name="disposeDataset">
            Indicates whether to dispose the dataset when being disposed.
            </param>
        </member>
        <member name="M:TorchSharp.Modules.IterableDataLoader.#ctor(TorchSharp.torch.utils.data.IterableDataset,System.Int32,System.Boolean,TorchSharp.torch.Device,System.Nullable{System.Int32},System.Int32,System.Boolean,System.Boolean,System.Boolean)">
            <summary>
            Pytorch style dataloader
            </summary>
            <param name="dataset">Dataset for create batch</param>
            <param name="batchSize">Size of batch</param>
            <param name="shuffle">true if shuffle dataset, false for not</param>
            <param name="device">device for output tensor</param>
            <param name="seed">Seed for generating shuffle</param>
            <param name="num_worker">Count of worker</param>
            <param name="drop_last">
            Set to true to drop the last incomplete batch, if the dataset size is not divisible by the batch size.
            If alse and the size of dataset is not divisible by the batch size, then the last batch will be smaller.
            </param>
            <param name="disposeBatch">
            Indicates whether to automatically dispose the collated tensors after an iteration.
            </param>
            <param name="disposeDataset">
            Indicates whether to dispose the dataset when being disposed.
            </param>
        </member>
        <member name="T:TorchSharp.Modules.DataLoader`2">
            <summary>
            This class supports creating batches from data sets.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.DataLoader`2.#ctor(TorchSharp.torch.utils.data.Dataset{`0},System.Int32,System.Func{System.Collections.Generic.IEnumerable{`0},TorchSharp.torch.Device,`1},System.Collections.Generic.IEnumerable{System.Int64},TorchSharp.torch.Device,System.Int32,System.Boolean,System.Boolean,System.Boolean)">
            <summary>
            Pytorch style dataloader
            </summary>
            <param name="dataset">Dataset for create batch</param>
            <param name="batchSize">Size of batch</param>
            <param name="collate_fn">Callback to merge items make to a batch</param>
            <param name="device">device for output tensor</param>
            <param name="shuffler">Shuffler for dataloader</param>
            <param name="num_worker">Count of worker</param>
            <param name="drop_last">
            Set to true to drop the last incomplete batch, if the dataset size is not divisible by the batch size.
            If alse and the size of dataset is not divisible by the batch size, then the last batch will be smaller.
            </param>
            <param name="disposeBatch">
            Indicates whether to automatically dispose the collated tensors after an iteration.
            </param>
            <param name="disposeDataset">
            Indicates whether to dispose the dataset when being disposed.
            </param>
        </member>
        <member name="M:TorchSharp.Modules.DataLoader`2.#ctor(TorchSharp.torch.utils.data.Dataset{`0},System.Int32,System.Func{System.Collections.Generic.IEnumerable{`0},TorchSharp.torch.Device,`1},System.Boolean,TorchSharp.torch.Device,System.Nullable{System.Int32},System.Int32,System.Boolean,System.Boolean,System.Boolean)">
            <summary>
            Pytorch style dataloader
            </summary>
            <param name="dataset">Dataset for create batch</param>
            <param name="batchSize">Size of batch</param>
            <param name="collate_fn">Callback to merge items to make a batch</param>
            <param name="shuffle">true if shuffle dataset, false for not</param>
            <param name="device">device for output tensor</param>
            <param name="seed">Seed for generating shuffle</param>
            <param name="num_worker">Count of worker</param>
            <param name="drop_last">
            Set to true to drop the last incomplete batch, if the dataset size is not divisible by the batch size.
            If alse and the size of dataset is not divisible by the batch size, then the last batch will be smaller.
            </param>
            <param name="disposeBatch">
            Indicates whether to automatically dispose the collated tensors (a batch) after an iteration.
            </param>
            <param name="disposeDataset">
            Indicates whether to dispose the dataset when being disposed.
            </param>
        </member>
        <member name="M:TorchSharp.Modules.DataLoader`2.GetEnumerator">
            <summary>
            Generate enumerator
            </summary>
            <returns>Enumerator for batch</returns>
        </member>
        <member name="P:TorchSharp.Modules.DataLoader`2.Count">
            <summary>
            Size of batch
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.DataLoader`2.DataLoaderEnumerator.MoveNext">
            <summary>
            Get next batch
            </summary>
            <returns>true if batch created, false if batch has finished</returns>
        </member>
        <member name="M:TorchSharp.Modules.DataLoader`2.DataLoaderEnumerator.Reset">
            <summary>
            Reset enumerator
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.DataLoader`2.DataLoaderEnumerator.Current">
            <summary>
            Current tensor
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.Bernoulli">
            <summary>
            A Bernoulli distribution parameterized by `probs` or `logits` (but not both).
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Bernoulli.mean">
            <summary>
            The mean of the distribution.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Bernoulli.variance">
            <summary>
            The variance of the distribution
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Bernoulli.#ctor(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Constructor
            </summary>
            <param name="p"></param>
            <param name="l"></param>
            <param name="generator"></param>
        </member>
        <member name="P:TorchSharp.Modules.Bernoulli.probs">
            <summary>
            The probability of sampling 1
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Bernoulli.logits">
            <summary>
            The log-odds of sampling 1
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Bernoulli.rsample(System.Int64[])">
            <summary>
             Generates a sample_shape shaped reparameterized sample or sample_shape shaped batch of reparameterized samples
             if the distribution parameters are batched.
            </summary>
            <param name="sample_shape">The sample shape.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.Bernoulli.log_prob(TorchSharp.torch.Tensor)">
            <summary>
            Returns the log of the probability density/mass function evaluated at `value`.
            </summary>
            <param name="value"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.Bernoulli.entropy">
            <summary>
            Returns entropy of distribution, batched over batch_shape.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Bernoulli.expand(TorchSharp.torch.Size,TorchSharp.torch.distributions.Distribution)">
            <summary>
            Returns a new distribution instance (or populates an existing instance provided by a derived class) with batch dimensions expanded to
            `batch_shape`. This method calls `torch.Tensor.expand()` on the distribution's parameters. As such, this does not allocate new
            memory for the expanded distribution instance.
            </summary>
            <param name="batch_shape">Tthe desired expanded size.</param>
            <param name="instance">new instance provided by subclasses that need to override `.expand`.</param>
            <returns></returns>
        </member>
        <member name="T:TorchSharp.Modules.Beta">
            <summary>
            A Beta distribution parameterized by concentration1 and concentration0.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Beta.mean">
            <summary>
            The mean of the distribution.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Beta.variance">
            <summary>
            The variance of the distribution
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Beta.rsample(System.Int64[])">
            <summary>
             Generates a sample_shape shaped reparameterized sample or sample_shape shaped batch of reparameterized samples
             if the distribution parameters are batched.
            </summary>
            <param name="sample_shape">The sample shape.</param>
        </member>
        <member name="M:TorchSharp.Modules.Beta.log_prob(TorchSharp.torch.Tensor)">
            <summary>
            Returns the log of the probability density/mass function evaluated at `value`.
            </summary>
            <param name="value"></param>
        </member>
        <member name="M:TorchSharp.Modules.Beta.entropy">
            <summary>
            Returns entropy of distribution, batched over batch_shape.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Beta.expand(TorchSharp.torch.Size,TorchSharp.torch.distributions.Distribution)">
            <summary>
            Returns a new distribution instance (or populates an existing instance provided by a derived class) with batch dimensions expanded to
            `batch_shape`. This method calls `torch.Tensor.expand()` on the distribution's parameters. As such, this does not allocate new
            memory for the expanded distribution instance.
            </summary>
            <param name="batch_shape">Tthe desired expanded size.</param>
            <param name="instance">new instance provided by subclasses that need to override `.expand`.</param>
        </member>
        <member name="T:TorchSharp.Modules.Binomial">
            <summary>
            A Binomial distribution parameterized by total_count and either probs or logits (but not both).
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Binomial.mean">
            <summary>
            The mean of the distribution.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Binomial.variance">
            <summary>
            The variance of the distribution
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Binomial.mode">
            <summary>
            Mode of the negative binomial distribution.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Binomial.probs">
            <summary>
            Event probabilities
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Binomial.logits">
            <summary>
            Event log-odds
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Binomial.rsample(System.Int64[])">
            <summary>
             Generates a sample_shape shaped reparameterized sample or sample_shape shaped batch of reparameterized samples
             if the distribution parameters are batched.
            </summary>
            <param name="sample_shape">The sample shape.</param>
        </member>
        <member name="M:TorchSharp.Modules.Binomial.log_prob(TorchSharp.torch.Tensor)">
            <summary>
            Returns the log of the probability density/mass function evaluated at `value`.
            </summary>
            <param name="value"></param>
        </member>
        <member name="M:TorchSharp.Modules.Binomial.entropy">
            <summary>
            Returns entropy of distribution, batched over batch_shape.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Binomial.expand(TorchSharp.torch.Size,TorchSharp.torch.distributions.Distribution)">
            <summary>
            Returns a new distribution instance (or populates an existing instance provided by a derived class) with batch dimensions expanded to
            `batch_shape`. This method calls `torch.Tensor.expand()` on the distribution's parameters. As such, this does not allocate new
            memory for the expanded distribution instance.
            </summary>
            <param name="batch_shape">Tthe desired expanded size.</param>
            <param name="instance">new instance provided by subclasses that need to override `.expand`.</param>
        </member>
        <member name="P:TorchSharp.Modules.Categorical.mean">
            <summary>
            The mean of the distribution.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Categorical.variance">
            <summary>
            The variance of the distribution
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Categorical.#ctor(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Constructor
            </summary>
            <param name="probs">Event probabilities</param>
            <param name="logits">Even log-odds</param>
            <param name="generator">An optional random number generator object.</param>
        </member>
        <member name="P:TorchSharp.Modules.Categorical.probs">
            <summary>
            Event probabilities
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Categorical.logits">
            <summary>
            Event log-odds
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Categorical.param_shape">
            <summary>
             The shape of the input parameter.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Categorical.rsample(System.Int64[])">
            <summary>
             Generates a sample_shape shaped reparameterized sample or sample_shape shaped batch of reparameterized samples
             if the distribution parameters are batched.
            </summary>
            <param name="sample_shape">The sample shape.</param>
        </member>
        <member name="M:TorchSharp.Modules.Categorical.log_prob(TorchSharp.torch.Tensor)">
            <summary>
            Returns the log of the probability density/mass function evaluated at `value`.
            </summary>
            <param name="value"></param>
        </member>
        <member name="M:TorchSharp.Modules.Categorical.entropy">
            <summary>
            Returns entropy of distribution, batched over batch_shape.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Categorical.expand(TorchSharp.torch.Size,TorchSharp.torch.distributions.Distribution)">
            <summary>
            Returns a new distribution instance (or populates an existing instance provided by a derived class) with batch dimensions expanded to
            `batch_shape`. This method calls `torch.Tensor.expand()` on the distribution's parameters. As such, this does not allocate new
            memory for the expanded distribution instance.
            </summary>
            <param name="batch_shape">Tthe desired expanded size.</param>
            <param name="instance">new instance provided by subclasses that need to override `.expand`.</param>
            <returns></returns>
        </member>
        <member name="T:TorchSharp.Modules.Cauchy">
            <summary>
            A Cauchy (Lorentz) distribution. The distribution of the ratio of
            independent normally distributed random variables with means `0` follows a Cauchy distribution.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Cauchy.mode">
            <summary>
            The mode of the distribution.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Cauchy.mean">
            <summary>
            The mean of the distribution.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Cauchy.variance">
            <summary>
            The variance of the distribution
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Cauchy.#ctor(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Constructor
            </summary>
            <param name="loc">Mode or median of the distribution.</param>
            <param name="scale">Half width at half maximum.</param>
            <param name="generator">An optional random number generator object.</param>
        </member>
        <member name="M:TorchSharp.Modules.Cauchy.rsample(System.Int64[])">
            <summary>
             Generates a sample_shape shaped reparameterized sample or sample_shape shaped batch of reparameterized samples
             if the distribution parameters are batched.
            </summary>
            <param name="sample_shape">The sample shape.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.Cauchy.log_prob(TorchSharp.torch.Tensor)">
            <summary>
            Returns the log of the probability density/mass function evaluated at `value`.
            </summary>
            <param name="value"></param>
        </member>
        <member name="M:TorchSharp.Modules.Cauchy.entropy">
            <summary>
            Returns entropy of distribution, batched over batch_shape.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.Cauchy.cdf(TorchSharp.torch.Tensor)">
            <summary>
            Returns the cumulative density/mass function evaluated at `value`.
            </summary>
            <param name="value"></param>
        </member>
        <member name="M:TorchSharp.Modules.Cauchy.icdf(TorchSharp.torch.Tensor)">
            <summary>
            Returns the inverse cumulative density/mass function evaluated at `value`.
            </summary>
            <param name="value"></param>
        </member>
        <member name="M:TorchSharp.Modules.Cauchy.expand(TorchSharp.torch.Size,TorchSharp.torch.distributions.Distribution)">
            <summary>
            Returns a new distribution instance (or populates an existing instance provided by a derived class) with batch dimensions expanded to
            `batch_shape`. This method calls `torch.Tensor.expand()` on the distribution's parameters. As such, this does not allocate new
            memory for the expanded distribution instance.
            </summary>
            <param name="batch_shape">Tthe desired expanded size.</param>
            <param name="instance">new instance provided by subclasses that need to override `.expand`.</param>
        </member>
        <member name="T:TorchSharp.Modules.Chi2">
            <summary>
            A Gamma distribution parameterized by a single shape parameter.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Chi2.#ctor(TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Constructor
            </summary>
            <param name="df">Shape parameter of the distribution</param>
            <param name="generator">An optional random number generator object.</param>
        </member>
        <member name="M:TorchSharp.Modules.Chi2.expand(TorchSharp.torch.Size,TorchSharp.torch.distributions.Distribution)">
            <summary>
            Returns a new distribution instance (or populates an existing instance provided by a derived class) with batch dimensions expanded to
            `batch_shape`. This method calls `torch.Tensor.expand()` on the distribution's parameters. As such, this does not allocate new
            memory for the expanded distribution instance.
            </summary>
            <param name="batch_shape">Tthe desired expanded size.</param>
            <param name="instance">new instance provided by subclasses that need to override `.expand`.</param>
        </member>
        <member name="T:TorchSharp.Modules.Dirichlet">
            <summary>
            A Dirichlet distribution parameterized by shape `concentration` and `rate`.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Dirichlet.mean">
            <summary>
            The mean of the distribution.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Dirichlet.variance">
            <summary>
            The variance of the distribution
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Dirichlet.#ctor(TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Constructor
            </summary>
            <param name="concentration">Shape parameter of the distribution (often referred to as 'α')</param>
            <param name="generator">An optional random number generator object.</param>
        </member>
        <member name="M:TorchSharp.Modules.Dirichlet.rsample(System.Int64[])">
            <summary>
             Generates a sample_shape shaped reparameterized sample or sample_shape shaped batch of reparameterized samples
             if the distribution parameters are batched.
            </summary>
            <param name="sample_shape">The sample shape.</param>
        </member>
        <member name="M:TorchSharp.Modules.Dirichlet.log_prob(TorchSharp.torch.Tensor)">
            <summary>
            Returns the log of the probability density/mass function evaluated at `value`.
            </summary>
            <param name="value"></param>
        </member>
        <member name="M:TorchSharp.Modules.Dirichlet.entropy">
            <summary>
            Returns entropy of distribution, batched over batch_shape.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.Dirichlet.expand(TorchSharp.torch.Size,TorchSharp.torch.distributions.Distribution)">
            <summary>
            Returns a new distribution instance (or populates an existing instance provided by a derived class) with batch dimensions expanded to
            `batch_shape`. This method calls `torch.Tensor.expand()` on the distribution's parameters. As such, this does not allocate new
            memory for the expanded distribution instance.
            </summary>
            <param name="batch_shape">Tthe desired expanded size.</param>
            <param name="instance">new instance provided by subclasses that need to override `.expand`.</param>
            <returns></returns>
        </member>
        <member name="T:TorchSharp.Modules.Exponential">
            <summary>
            An Exponential distribution parameterized by `rate`.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Exponential.mean">
            <summary>
            The mean of the distribution.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Exponential.variance">
            <summary>
            The variance of the distribution
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Exponential.stddev">
            <summary>
            The standard deviation of the distribution
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Exponential.#ctor(TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Constructor
            </summary>
            <param name="rate">rate = 1 / scale of the distribution (often referred to as 'β')</param>
            <param name="generator">An optional random number generator object.</param>
        </member>
        <member name="M:TorchSharp.Modules.Exponential.rsample(System.Int64[])">
            <summary>
             Generates a sample_shape shaped reparameterized sample or sample_shape shaped batch of reparameterized samples
             if the distribution parameters are batched.
            </summary>
            <param name="sample_shape">The sample shape.</param>
        </member>
        <member name="M:TorchSharp.Modules.Exponential.log_prob(TorchSharp.torch.Tensor)">
            <summary>
            Returns the log of the probability density/mass function evaluated at `value`.
            </summary>
            <param name="value"></param>
        </member>
        <member name="M:TorchSharp.Modules.Exponential.entropy">
            <summary>
            Returns entropy of distribution, batched over batch_shape.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.Exponential.cdf(TorchSharp.torch.Tensor)">
            <summary>
            Returns the cumulative density/mass function evaluated at `value`.
            </summary>
            <param name="value"></param>
        </member>
        <member name="M:TorchSharp.Modules.Exponential.icdf(TorchSharp.torch.Tensor)">
            <summary>
            Returns the inverse cumulative density/mass function evaluated at `value`.
            </summary>
            <param name="value"></param>
        </member>
        <member name="M:TorchSharp.Modules.Exponential.expand(TorchSharp.torch.Size,TorchSharp.torch.distributions.Distribution)">
            <summary>
            Returns a new distribution instance (or populates an existing instance provided by a derived class) with batch dimensions expanded to
            `batch_shape`. This method calls `torch.Tensor.expand()` on the distribution's parameters. As such, this does not allocate new
            memory for the expanded distribution instance.
            </summary>
            <param name="batch_shape">Tthe desired expanded size.</param>
            <param name="instance">new instance provided by subclasses that need to override `.expand`.</param>
        </member>
        <member name="T:TorchSharp.Modules.ExpRelaxedCategorical">
            <summary>
            Creates a ExpRelaxedCategorical parameterized by `temperature`, and either `probs` or `logits` (but not both).
            Returns the log of a point in the simplex.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.ExpRelaxedCategorical.#ctor(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Constructor
            </summary>
            <param name="temperature">Relaxation temperature</param>
            <param name="probs">the probability of sampling `1`</param>
            <param name="logits">the log-odds of sampling `1`</param>
            <param name="generator"></param>
        </member>
        <member name="P:TorchSharp.Modules.ExpRelaxedCategorical.probs">
            <summary>
            The probability of sampling 1
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.ExpRelaxedCategorical.logits">
            <summary>
            The log-odds of sampling 1
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.ExpRelaxedCategorical.expand(TorchSharp.torch.Size,TorchSharp.torch.distributions.Distribution)">
            <summary>
            Returns a new distribution instance (or populates an existing instance provided by a derived class) with batch dimensions expanded to
            `batch_shape`. This method calls `torch.Tensor.expand()` on the distribution's parameters. As such, this does not allocate new
            memory for the expanded distribution instance.
            </summary>
            <param name="batch_shape">Tthe desired expanded size.</param>
            <param name="instance">new instance provided by subclasses that need to override `.expand`.</param>
            <returns></returns>
        </member>
        <member name="P:TorchSharp.Modules.ExpRelaxedCategorical.param_shape">
            <summary>
             The shape of the input parameter.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.FisherSnedecor">
            <summary>
            A Fisher-Snedecor distribution parameterized by `df1` and `df2`.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.FisherSnedecor.mean">
            <summary>
            The mean of the distribution.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.FisherSnedecor.variance">
            <summary>
            The variance of the distribution
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.FisherSnedecor.#ctor(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Constructor
            </summary>
            <param name="df1">Degrees of freedom parameter 1</param>
            <param name="df2">Degrees of freedom parameter 2</param>
            <param name="generator">An optional random number generator object.</param>
        </member>
        <member name="M:TorchSharp.Modules.FisherSnedecor.rsample(System.Int64[])">
            <summary>
             Generates a sample_shape shaped reparameterized sample or sample_shape shaped batch of reparameterized samples
             if the distribution parameters are batched.
            </summary>
            <param name="sample_shape">The sample shape.</param>
        </member>
        <member name="M:TorchSharp.Modules.FisherSnedecor.log_prob(TorchSharp.torch.Tensor)">
            <summary>
            Returns the log of the probability density/mass function evaluated at `value`.
            </summary>
            <param name="value"></param>
        </member>
        <member name="M:TorchSharp.Modules.FisherSnedecor.expand(TorchSharp.torch.Size,TorchSharp.torch.distributions.Distribution)">
            <summary>
            Returns a new distribution instance (or populates an existing instance provided by a derived class) with batch dimensions expanded to
            `batch_shape`. This method calls `torch.Tensor.expand()` on the distribution's parameters. As such, this does not allocate new
            memory for the expanded distribution instance.
            </summary>
            <param name="batch_shape">Tthe desired expanded size.</param>
            <param name="instance">new instance provided by subclasses that need to override `.expand`.</param>
        </member>
        <member name="M:TorchSharp.Modules.FisherSnedecor.entropy">
            <summary>
            Returns entropy of distribution, batched over batch_shape.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.Gamma">
            <summary>
            A Gamma distribution parameterized by shape `concentration` and `rate`.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Gamma.mean">
            <summary>
            The mean of the distribution.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Gamma.variance">
            <summary>
            The variance of the distribution
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Gamma.#ctor(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Constructor
            </summary>
            <param name="concentration">Shape parameter of the distribution (often referred to as 'α')</param>
            <param name="rate">rate = 1 / scale of the distribution (often referred to as 'β')</param>
            <param name="generator">An optional random number generator object.</param>
        </member>
        <member name="M:TorchSharp.Modules.Gamma.rsample(System.Int64[])">
            <summary>
             Generates a sample_shape shaped reparameterized sample or sample_shape shaped batch of reparameterized samples
             if the distribution parameters are batched.
            </summary>
            <param name="sample_shape">The sample shape.</param>
        </member>
        <member name="M:TorchSharp.Modules.Gamma.log_prob(TorchSharp.torch.Tensor)">
            <summary>
            Returns the log of the probability density/mass function evaluated at `value`.
            </summary>
            <param name="value"></param>
        </member>
        <member name="M:TorchSharp.Modules.Gamma.entropy">
            <summary>
            Returns entropy of distribution, batched over batch_shape.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Gamma.expand(TorchSharp.torch.Size,TorchSharp.torch.distributions.Distribution)">
            <summary>
            Returns a new distribution instance (or populates an existing instance provided by a derived class) with batch dimensions expanded to
            `batch_shape`. This method calls `torch.Tensor.expand()` on the distribution's parameters. As such, this does not allocate new
            memory for the expanded distribution instance.
            </summary>
            <param name="batch_shape">Tthe desired expanded size.</param>
            <param name="instance">new instance provided by subclasses that need to override `.expand`.</param>
        </member>
        <member name="T:TorchSharp.Modules.Geometric">
             <summary>
             A Geometric distribution parameterized by probs,
             where probs is the probability of success of Bernoulli trials.
            
             It represents the probability that in k+1 Bernoulli trials, the
             first k trials failed, before seeing a success.
             </summary>
        </member>
        <member name="P:TorchSharp.Modules.Geometric.mean">
            <summary>
            The mean of the distribution.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Geometric.variance">
            <summary>
            The variance of the distribution
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Geometric.#ctor(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Constructor
            </summary>
            <param name="probs">The probability of sampling '1'. Must be in range (0, 1]</param>
            <param name="logits">The log-odds of sampling '1'</param>
            <param name="generator">An optional random number generator object.</param>
        </member>
        <member name="P:TorchSharp.Modules.Geometric.probs">
            <summary>
            Event probabilities
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Geometric.logits">
            <summary>
            Event log-odds
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Geometric.rsample(System.Int64[])">
            <summary>
             Generates a sample_shape shaped reparameterized sample or sample_shape shaped batch of reparameterized samples
             if the distribution parameters are batched.
            </summary>
            <param name="sample_shape">The sample shape.</param>
        </member>
        <member name="M:TorchSharp.Modules.Geometric.log_prob(TorchSharp.torch.Tensor)">
            <summary>
            Returns the log of the probability density/mass function evaluated at `value`.
            </summary>
            <param name="value"></param>
        </member>
        <member name="M:TorchSharp.Modules.Geometric.entropy">
            <summary>
            Returns entropy of distribution, batched over batch_shape.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.Geometric.expand(TorchSharp.torch.Size,TorchSharp.torch.distributions.Distribution)">
            <summary>
            Returns a new distribution instance (or populates an existing instance provided by a derived class) with batch dimensions expanded to
            `batch_shape`. This method calls `torch.Tensor.expand()` on the distribution's parameters. As such, this does not allocate new
            memory for the expanded distribution instance.
            </summary>
            <param name="batch_shape">Tthe desired expanded size.</param>
            <param name="instance">new instance provided by subclasses that need to override `.expand`.</param>
        </member>
        <member name="T:TorchSharp.Modules.Gumbel">
            <summary>
            Samples from a Gumbel Distribution.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Gumbel.entropy">
            <summary>
            Returns entropy of distribution, batched over batch_shape.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.HalfCauchy">
            <summary>
            Creates a half-Cauchy distribution parameterized by `scale`
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.HalfCauchy.entropy">
            <summary>
            Returns entropy of distribution, batched over batch_shape.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.HalfCauchy.expand(TorchSharp.torch.Size,TorchSharp.torch.distributions.Distribution)">
            <summary>
            Returns a new distribution instance (or populates an existing instance provided by a derived class) with batch dimensions expanded to
            `batch_shape`. This method calls `torch.Tensor.expand()` on the distribution's parameters. As such, this does not allocate new
            memory for the expanded distribution instance.
            </summary>
            <param name="batch_shape">Tthe desired expanded size.</param>
            <param name="instance">new instance provided by subclasses that need to override `.expand`.</param>
        </member>
        <member name="T:TorchSharp.Modules.HalfNormal">
            <summary>
            Creates a half-normal distribution parameterized by `scale`
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.HalfNormal.expand(TorchSharp.torch.Size,TorchSharp.torch.distributions.Distribution)">
            <summary>
            Returns a new distribution instance (or populates an existing instance provided by a derived class) with batch dimensions expanded to
            `batch_shape`. This method calls `torch.Tensor.expand()` on the distribution's parameters. As such, this does not allocate new
            memory for the expanded distribution instance.
            </summary>
            <param name="batch_shape">Tthe desired expanded size.</param>
            <param name="instance">new instance provided by subclasses that need to override `.expand`.</param>
        </member>
        <member name="T:TorchSharp.Modules.Independent">
            <summary>
            Reinterprets some of the batch dims of a distribution as event dims.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Independent.mean">
            <summary>
            The mean of the distribution.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Independent.variance">
            <summary>
            The variance of the distribution
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Independent.#ctor(TorchSharp.torch.distributions.Distribution,System.Int32,TorchSharp.torch.Generator)">
            <summary>
            Constructor
            </summary>
            <param name="base_distribution">A base distribution.</param>
            <param name="reinterpreted_batch_ndims">the number of batch dims to reinterpret as event dims</param>
            <param name="generator">An optional random number generator object.</param>
        </member>
        <member name="M:TorchSharp.Modules.Independent.sample(System.Int64[])">
            <summary>
            Generates a sample_shape shaped sample or sample_shape shaped batch of samples if the distribution parameters are batched.
            </summary>
            <param name="sample_shape"></param>
        </member>
        <member name="M:TorchSharp.Modules.Independent.rsample(System.Int64[])">
            <summary>
             Generates a sample_shape shaped reparameterized sample or sample_shape shaped batch of reparameterized samples
             if the distribution parameters are batched.
            </summary>
            <param name="sample_shape">The sample shape.</param>
        </member>
        <member name="M:TorchSharp.Modules.Independent.log_prob(TorchSharp.torch.Tensor)">
            <summary>
            Returns the log of the probability density/mass function evaluated at `value`.
            </summary>
            <param name="value"></param>
        </member>
        <member name="M:TorchSharp.Modules.Independent.entropy">
            <summary>
            Returns entropy of distribution, batched over batch_shape.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Independent.expand(TorchSharp.torch.Size,TorchSharp.torch.distributions.Distribution)">
            <summary>
            Returns a new distribution instance (or populates an existing instance provided by a derived class) with batch dimensions expanded to
            `batch_shape`. This method calls `torch.Tensor.expand()` on the distribution's parameters. As such, this does not allocate new
            memory for the expanded distribution instance.
            </summary>
            <param name="batch_shape">Tthe desired expanded size.</param>
            <param name="instance">new instance provided by subclasses that need to override `.expand`.</param>
        </member>
        <member name="T:TorchSharp.Modules.Laplace">
            <summary>
            A Laplace distribution.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Laplace.mean">
            <summary>
            The mean of the distribution.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Laplace.mode">
            <summary>
            The mode of the distribution.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Laplace.stddev">
            <summary>
            The standard deviation of the distribution
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Laplace.variance">
            <summary>
            The variance of the distribution
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Laplace.#ctor(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Constructor
            </summary>
            <param name="loc">Mode or median of the distribution.</param>
            <param name="scale">Standard deviation.</param>
            <param name="generator">An optional random number generator object.</param>
        </member>
        <member name="M:TorchSharp.Modules.Laplace.rsample(System.Int64[])">
            <summary>
             Generates a sample_shape shaped reparameterized sample or sample_shape shaped batch of reparameterized samples
             if the distribution parameters are batched.
            </summary>
            <param name="sample_shape">The sample shape.</param>
        </member>
        <member name="M:TorchSharp.Modules.Laplace.log_prob(TorchSharp.torch.Tensor)">
            <summary>
            Returns the log of the probability density/mass function evaluated at `value`.
            </summary>
            <param name="value"></param>
        </member>
        <member name="M:TorchSharp.Modules.Laplace.entropy">
            <summary>
            Returns entropy of distribution, batched over batch_shape.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Laplace.cdf(TorchSharp.torch.Tensor)">
            <summary>
            Returns the cumulative density/mass function evaluated at `value`.
            </summary>
            <param name="value"></param>
        </member>
        <member name="M:TorchSharp.Modules.Laplace.icdf(TorchSharp.torch.Tensor)">
            <summary>
            Returns the inverse cumulative density/mass function evaluated at `value`.
            </summary>
            <param name="value"></param>
        </member>
        <member name="M:TorchSharp.Modules.Laplace.expand(TorchSharp.torch.Size,TorchSharp.torch.distributions.Distribution)">
            <summary>
            Returns a new distribution instance (or populates an existing instance provided by a derived class) with batch dimensions expanded to
            `batch_shape`. This method calls `torch.Tensor.expand()` on the distribution's parameters. As such, this does not allocate new
            memory for the expanded distribution instance.
            </summary>
            <param name="batch_shape">Tthe desired expanded size.</param>
            <param name="instance">new instance provided by subclasses that need to override `.expand`.</param>
        </member>
        <member name="T:TorchSharp.Modules.LogitRelaxedBernoulli">
            <summary>
            Creates a LogitRelaxedBernoulli distribution parameterized by `probs` or 'logits` (but not both),
            which is the logit of a RelaxedBernoulli distribution.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.LogitRelaxedBernoulli.mean">
            <summary>
            The mean of the distribution.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.LogitRelaxedBernoulli.variance">
            <summary>
            The variance of the distribution
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.LogitRelaxedBernoulli.#ctor(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Constructor
            </summary>
            <param name="temperature">Relaxation temperature</param>
            <param name="probs"></param>
            <param name="logits"></param>
            <param name="generator"></param>
        </member>
        <member name="P:TorchSharp.Modules.LogitRelaxedBernoulli.probs">
            <summary>
            The probability of sampling 1
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.LogitRelaxedBernoulli.logits">
            <summary>
            The log-odds of sampling 1
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.LogitRelaxedBernoulli.rsample(System.Int64[])">
            <summary>
             Generates a sample_shape shaped reparameterized sample or sample_shape shaped batch of reparameterized samples
             if the distribution parameters are batched.
            </summary>
            <param name="sample_shape">The sample shape.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.LogitRelaxedBernoulli.log_prob(TorchSharp.torch.Tensor)">
            <summary>
            Returns the log of the probability density/mass function evaluated at `value`.
            </summary>
            <param name="value"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.LogitRelaxedBernoulli.entropy">
            <summary>
            Returns entropy of distribution, batched over batch_shape.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.LogitRelaxedBernoulli.expand(TorchSharp.torch.Size,TorchSharp.torch.distributions.Distribution)">
            <summary>
            Returns a new distribution instance (or populates an existing instance provided by a derived class) with batch dimensions expanded to
            `batch_shape`. This method calls `torch.Tensor.expand()` on the distribution's parameters. As such, this does not allocate new
            memory for the expanded distribution instance.
            </summary>
            <param name="batch_shape">Tthe desired expanded size.</param>
            <param name="instance">new instance provided by subclasses that need to override `.expand`.</param>
            <returns></returns>
        </member>
        <member name="T:TorchSharp.Modules.Multinomial">
            <summary>
            A Multinomial distribution parameterized by `probs` or `logits` (but not both).
            `total_count` must be broadcastable with `probs`/`logits`.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Multinomial.mean">
            <summary>
            The mean of the distribution.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Multinomial.variance">
            <summary>
            The variance of the distribution
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Multinomial.#ctor(System.Int32,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Constructor
            </summary>
            <param name="total_count">Number of Bernoulli trials</param>
            <param name="probs">The probability of sampling '1'</param>
            <param name="logits">The log-odds of sampling '1'</param>
            <param name="generator">An optional random number generator object.</param>
        </member>
        <member name="P:TorchSharp.Modules.Multinomial.probs">
            <summary>
            Event probabilities
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Multinomial.logits">
            <summary>
            Event log-odds
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Multinomial.rsample(System.Int64[])">
            <summary>
             Generates a sample_shape shaped reparameterized sample or sample_shape shaped batch of reparameterized samples
             if the distribution parameters are batched.
            </summary>
            <param name="sample_shape">The sample shape.</param>
        </member>
        <member name="M:TorchSharp.Modules.Multinomial.log_prob(TorchSharp.torch.Tensor)">
            <summary>
            Returns the log of the probability density/mass function evaluated at `value`.
            </summary>
            <param name="value"></param>
        </member>
        <member name="M:TorchSharp.Modules.Multinomial.expand(TorchSharp.torch.Size,TorchSharp.torch.distributions.Distribution)">
            <summary>
            Returns a new distribution instance (or populates an existing instance provided by a derived class) with batch dimensions expanded to
            `batch_shape`. This method calls `torch.Tensor.expand()` on the distribution's parameters. As such, this does not allocate new
            memory for the expanded distribution instance.
            </summary>
            <param name="batch_shape">Tthe desired expanded size.</param>
            <param name="instance">new instance provided by subclasses that need to override `.expand`.</param>
        </member>
        <member name="M:TorchSharp.Modules.Multinomial.entropy">
            <summary>
            Returns entropy of distribution, batched over batch_shape.
            </summary>
            <returns></returns>
        </member>
        <member name="T:TorchSharp.Modules.MultivariateNormal">
             <summary>
             A multivariate normal (also called Gaussian) distribution parameterized by a mean vector and a covariance matrix.
            
             The multivariate normal distribution can be parameterized either in terms of a positive definite covariance matrix
             or a positive definite precision matrix or a lower-triangular matrix with positive-valued diagonal entries. This triangular matrix
             can be obtained via Cholesky decomposition of the covariance.
             </summary>
        </member>
        <member name="P:TorchSharp.Modules.MultivariateNormal.mean">
            <summary>
            The mean of the distribution.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.MultivariateNormal.mode">
            <summary>
            The mode of the distribution.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.MultivariateNormal.variance">
            <summary>
            The variance of the distribution
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.MultivariateNormal.#ctor(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
             <summary>
             Constructor
             </summary>
             <param name="loc"></param>
             <param name="covariance_matrix">Positive-definite covariance matrix</param>
             <param name="precision_matrix">Positive-definite precision matrix</param>
             <param name="scale_tril">The lower-triangular factor of covariance, with positive-valued diagonal</param>
             <param name="generator">An optional random number generator object.</param>
             <remarks>
             Only one of `covariance_matrix` or `precision_matrix` or `scale_tril` may be specified.
            
             Using `scale_tril` will be more efficient: all computations internally are based on `scale_tril`.
             If `covariance_matrix` or `precision_matrix` is passed instead, it is only used to compute
             the corresponding lower triangular matrices using a Cholesky decomposition.
             </remarks>
        </member>
        <member name="M:TorchSharp.Modules.MultivariateNormal.rsample(System.Int64[])">
            <summary>
             Generates a sample_shape shaped reparameterized sample or sample_shape shaped batch of reparameterized samples
             if the distribution parameters are batched.
            </summary>
            <param name="sample_shape">The sample shape.</param>
        </member>
        <member name="M:TorchSharp.Modules.MultivariateNormal.log_prob(TorchSharp.torch.Tensor)">
            <summary>
            Returns the log of the probability density/mass function evaluated at `value`.
            </summary>
            <param name="value"></param>
        </member>
        <member name="M:TorchSharp.Modules.MultivariateNormal.expand(TorchSharp.torch.Size,TorchSharp.torch.distributions.Distribution)">
            <summary>
            Returns a new distribution instance (or populates an existing instance provided by a derived class) with batch dimensions expanded to
            `batch_shape`. This method calls `torch.Tensor.expand()` on the distribution's parameters. As such, this does not allocate new
            memory for the expanded distribution instance.
            </summary>
            <param name="batch_shape">Tthe desired expanded size.</param>
            <param name="instance">new instance provided by subclasses that need to override `.expand`.</param>
        </member>
        <member name="M:TorchSharp.Modules.MultivariateNormal.entropy">
            <summary>
            Returns entropy of distribution, batched over batch_shape.
            </summary>
            <returns></returns>
        </member>
        <member name="T:TorchSharp.Modules.NegativeBinomial">
             <summary>
             A NegativeBinomial distribution parameterized by total_count and either probs or logits (but not both).
            
             This is a distribution of the number of successful independent and identical Bernoulli trials
             before `total_count` failures are achieved. The probability of success of each Bernoulli trial is `probs`.
             </summary>
        </member>
        <member name="P:TorchSharp.Modules.NegativeBinomial.mean">
            <summary>
            The mean of the distribution.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.NegativeBinomial.mode">
            <summary>
            Mode of the negative binomial distribution.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.NegativeBinomial.variance">
            <summary>
            The variance of the distribution
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.NegativeBinomial.probs">
            <summary>
            Event probabilities
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.NegativeBinomial.logits">
            <summary>
            Event log-odds
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.NegativeBinomial.rsample(System.Int64[])">
            <summary>
             Generates a sample_shape shaped reparameterized sample or sample_shape shaped batch of reparameterized samples
             if the distribution parameters are batched.
            </summary>
            <param name="sample_shape">The sample shape.</param>
        </member>
        <member name="M:TorchSharp.Modules.NegativeBinomial.log_prob(TorchSharp.torch.Tensor)">
            <summary>
            Returns the log of the probability density/mass function evaluated at `value`.
            </summary>
            <param name="value"></param>
        </member>
        <member name="M:TorchSharp.Modules.NegativeBinomial.entropy">
            <summary>
            Returns entropy of distribution, batched over batch_shape.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.NegativeBinomial.expand(TorchSharp.torch.Size,TorchSharp.torch.distributions.Distribution)">
            <summary>
            Returns a new distribution instance (or populates an existing instance provided by a derived class) with batch dimensions expanded to
            `batch_shape`. This method calls `torch.Tensor.expand()` on the distribution's parameters. As such, this does not allocate new
            memory for the expanded distribution instance.
            </summary>
            <param name="batch_shape">Tthe desired expanded size.</param>
            <param name="instance">new instance provided by subclasses that need to override `.expand`.</param>
        </member>
        <member name="T:TorchSharp.Modules.Normal">
            <summary>
            A Normal (Gaussian) distribution.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Normal.mean">
            <summary>
            The mean of the distribution.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Normal.mode">
            <summary>
            The mode of the distribution.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Normal.stddev">
            <summary>
            The standard deviation of the distribution
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Normal.variance">
            <summary>
            The variance of the distribution
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Normal.#ctor(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Constructor
            </summary>
            <param name="loc">Mode or median of the distribution.</param>
            <param name="scale">Standard deviation.</param>
            <param name="generator">An optional random number generator object.</param>
        </member>
        <member name="M:TorchSharp.Modules.Normal.sample(System.Int64[])">
            <summary>
            Generates a sample_shape shaped sample or sample_shape shaped batch of samples if the distribution parameters are batched.
            </summary>
            <param name="sample_shape"></param>
        </member>
        <member name="M:TorchSharp.Modules.Normal.rsample(System.Int64[])">
            <summary>
             Generates a sample_shape shaped reparameterized sample or sample_shape shaped batch of reparameterized samples
             if the distribution parameters are batched.
            </summary>
            <param name="sample_shape">The sample shape.</param>
        </member>
        <member name="M:TorchSharp.Modules.Normal.log_prob(TorchSharp.torch.Tensor)">
            <summary>
            Returns the log of the probability density/mass function evaluated at `value`.
            </summary>
            <param name="value"></param>
        </member>
        <member name="M:TorchSharp.Modules.Normal.entropy">
            <summary>
            Returns entropy of distribution, batched over batch_shape.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Normal.cdf(TorchSharp.torch.Tensor)">
            <summary>
            Returns the cumulative density/mass function evaluated at `value`.
            </summary>
            <param name="value"></param>
        </member>
        <member name="M:TorchSharp.Modules.Normal.icdf(TorchSharp.torch.Tensor)">
            <summary>
            Returns the inverse cumulative density/mass function evaluated at `value`.
            </summary>
            <param name="value"></param>
        </member>
        <member name="M:TorchSharp.Modules.Normal.expand(TorchSharp.torch.Size,TorchSharp.torch.distributions.Distribution)">
            <summary>
            Returns a new distribution instance (or populates an existing instance provided by a derived class) with batch dimensions expanded to
            `batch_shape`. This method calls `torch.Tensor.expand()` on the distribution's parameters. As such, this does not allocate new
            memory for the expanded distribution instance.
            </summary>
            <param name="batch_shape">Tthe desired expanded size.</param>
            <param name="instance">new instance provided by subclasses that need to override `.expand`.</param>
        </member>
        <member name="T:TorchSharp.Modules.OneHotCategorical">
            <summary>
            A Bernoulli distribution parameterized by `probs` or `logits` (but not both).
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.OneHotCategorical.mean">
            <summary>
            The mean of the distribution.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.OneHotCategorical.mode">
            <summary>
            The mode of the distribution.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.OneHotCategorical.variance">
            <summary>
            The variance of the distribution
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.OneHotCategorical.#ctor(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Constructor
            </summary>
            <param name="p"></param>
            <param name="l"></param>
            <param name="generator"></param>
        </member>
        <member name="P:TorchSharp.Modules.OneHotCategorical.probs">
            <summary>
            The probability of sampling 1
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.OneHotCategorical.logits">
            <summary>
            The log-odds of sampling 1
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.OneHotCategorical.rsample(System.Int64[])">
            <summary>
             Generates a sample_shape shaped reparameterized sample or sample_shape shaped batch of reparameterized samples
             if the distribution parameters are batched.
            </summary>
            <param name="sample_shape">The sample shape.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.OneHotCategorical.log_prob(TorchSharp.torch.Tensor)">
            <summary>
            Returns the log of the probability density/mass function evaluated at `value`.
            </summary>
            <param name="value"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.OneHotCategorical.entropy">
            <summary>
            Returns entropy of distribution, batched over batch_shape.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.OneHotCategorical.expand(TorchSharp.torch.Size,TorchSharp.torch.distributions.Distribution)">
            <summary>
            Returns a new distribution instance (or populates an existing instance provided by a derived class) with batch dimensions expanded to
            `batch_shape`. This method calls `torch.Tensor.expand()` on the distribution's parameters. As such, this does not allocate new
            memory for the expanded distribution instance.
            </summary>
            <param name="batch_shape">Tthe desired expanded size.</param>
            <param name="instance">new instance provided by subclasses that need to override `.expand`.</param>
            <returns></returns>
        </member>
        <member name="T:TorchSharp.Modules.Poisson">
            <summary>
            A Poisson distribution parameterized by `rate`.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Poisson.#ctor(TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Constructor
            </summary>
            <param name="rate">rate = 1 / scale of the distribution (often referred to as 'β')</param>
            <param name="generator">An optional random number generator object.</param>
        </member>
        <member name="M:TorchSharp.Modules.Poisson.rsample(System.Int64[])">
            <summary>
             Generates a sample_shape shaped reparameterized sample or sample_shape shaped batch of reparameterized samples
             if the distribution parameters are batched.
            </summary>
            <param name="sample_shape">The sample shape.</param>
        </member>
        <member name="M:TorchSharp.Modules.Poisson.log_prob(TorchSharp.torch.Tensor)">
            <summary>
            Returns the log of the probability density/mass function evaluated at `value`.
            </summary>
            <param name="value"></param>
        </member>
        <member name="M:TorchSharp.Modules.Poisson.cdf(TorchSharp.torch.Tensor)">
            <summary>
            Returns the cumulative density/mass function evaluated at `value`.
            </summary>
            <param name="value"></param>
        </member>
        <member name="M:TorchSharp.Modules.Poisson.icdf(TorchSharp.torch.Tensor)">
            <summary>
            Returns the inverse cumulative density/mass function evaluated at `value`.
            </summary>
            <param name="value"></param>
        </member>
        <member name="M:TorchSharp.Modules.Poisson.expand(TorchSharp.torch.Size,TorchSharp.torch.distributions.Distribution)">
             <summary>
             Returns tensor containing all values supported by a discrete distribution. The result will enumerate over dimension 0, so the shape
             of the result will be `(cardinality,) + batch_shape + event_shape` (where `event_shape = ()` for univariate distributions).
            
             Note that this enumerates over all batched tensors in lock-step `[[0, 0], [1, 1], ...]`. With `expand=False`, enumeration happens
             along dim 0, but with the remaining batch dimensions being singleton dimensions, `[[0], [1], ..`
             </summary>
        </member>
        <member name="T:TorchSharp.Modules.RelaxedBernoulli">
            <summary>
            Creates a RelaxedBernoulli distribution, parametrized by `temperature`, and either `probs` or `logits` (but not both).
            This is a relaxed version of the `Bernoulli` distribution, so the values are in (0, 1), and has reparametrizable samples.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.RelaxedBernoulli.#ctor(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Constructor
            </summary>
            <param name="temperature">Relaxation temperature</param>
            <param name="probs">the probability of sampling `1`</param>
            <param name="logits">the log-odds of sampling `1`</param>
            <param name="generator"></param>
        </member>
        <member name="P:TorchSharp.Modules.RelaxedBernoulli.probs">
            <summary>
            The probability of sampling 1
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.RelaxedBernoulli.logits">
            <summary>
            The log-odds of sampling 1
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.RelaxedBernoulli.expand(TorchSharp.torch.Size,TorchSharp.torch.distributions.Distribution)">
            <summary>
            Returns a new distribution instance (or populates an existing instance provided by a derived class) with batch dimensions expanded to
            `batch_shape`. This method calls `torch.Tensor.expand()` on the distribution's parameters. As such, this does not allocate new
            memory for the expanded distribution instance.
            </summary>
            <param name="batch_shape">Tthe desired expanded size.</param>
            <param name="instance">new instance provided by subclasses that need to override `.expand`.</param>
            <returns></returns>
        </member>
        <member name="T:TorchSharp.Modules.RelaxedOneHotCategorical">
            <summary>
            Creates a RelaxedOneHotCategorical distribution, parametrized by `temperature`, and either `probs` or `logits` (but not both).
            This is a relaxed version of the `OneHotCategorical` distribution, so its samples are on simplex, and are reparametrizable..
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.RelaxedOneHotCategorical.#ctor(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Constructor
            </summary>
            <param name="temperature">Relaxation temperature</param>
            <param name="probs">the probability of sampling `1`</param>
            <param name="logits">the log-odds of sampling `1`</param>
            <param name="generator"></param>
        </member>
        <member name="P:TorchSharp.Modules.RelaxedOneHotCategorical.probs">
            <summary>
            The probability of sampling 1
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.RelaxedOneHotCategorical.logits">
            <summary>
            The log-odds of sampling 1
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.RelaxedOneHotCategorical.expand(TorchSharp.torch.Size,TorchSharp.torch.distributions.Distribution)">
            <summary>
            Returns a new distribution instance (or populates an existing instance provided by a derived class) with batch dimensions expanded to
            `batch_shape`. This method calls `torch.Tensor.expand()` on the distribution's parameters. As such, this does not allocate new
            memory for the expanded distribution instance.
            </summary>
            <param name="batch_shape">Tthe desired expanded size.</param>
            <param name="instance">new instance provided by subclasses that need to override `.expand`.</param>
            <returns></returns>
        </member>
        <member name="T:TorchSharp.Modules.TransformedDistribution">
            <summary>
            Extension of the Distribution class, which applies a sequence of Transforms to a base distribution.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.Uniform">
            <summary>
            Generates uniformly distributed random samples from the half-open interval [low, high[.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Uniform.mean">
            <summary>
            The mean of the distribution.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Uniform.variance">
            <summary>
            The variance of the distribution
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Uniform.#ctor(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Generator)">
            <summary>
            Constructor
            </summary>
            <param name="low">Lower bound (inclusive)</param>
            <param name="high">Upper bound (exclusive)</param>
            <param name="generator">An optional random number generator object.</param>
        </member>
        <member name="M:TorchSharp.Modules.Uniform.rsample(System.Int64[])">
            <summary>
             Generates a sample_shape shaped reparameterized sample or sample_shape shaped batch of reparameterized samples
             if the distribution parameters are batched.
            </summary>
            <param name="sample_shape">The sample shape.</param>
        </member>
        <member name="M:TorchSharp.Modules.Uniform.log_prob(TorchSharp.torch.Tensor)">
            <summary>
            Returns the log of the probability density/mass function evaluated at `value`.
            </summary>
            <param name="value"></param>
        </member>
        <member name="M:TorchSharp.Modules.Uniform.cdf(TorchSharp.torch.Tensor)">
            <summary>
            Returns the cumulative density/mass function evaluated at `value`.
            </summary>
            <param name="value"></param>
        </member>
        <member name="M:TorchSharp.Modules.Uniform.icdf(TorchSharp.torch.Tensor)">
            <summary>
            Returns the inverse cumulative density/mass function evaluated at `value`.
            </summary>
            <param name="value"></param>
        </member>
        <member name="M:TorchSharp.Modules.Uniform.entropy">
            <summary>
            Returns entropy of distribution, batched over batch_shape.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Uniform.expand(TorchSharp.torch.Size,TorchSharp.torch.distributions.Distribution)">
            <summary>
            Returns a new distribution instance (or populates an existing instance provided by a derived class) with batch dimensions expanded to
            `batch_shape`. This method calls `torch.Tensor.expand()` on the distribution's parameters. As such, this does not allocate new
            memory for the expanded distribution instance.
            </summary>
            <param name="batch_shape">Tthe desired expanded size.</param>
            <param name="instance">new instance provided by subclasses that need to override `.expand`.</param>
        </member>
        <member name="T:TorchSharp.Modules.Weibull">
            <summary>
            Samples from a two-parameter Weibull distribution.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Weibull.entropy">
            <summary>
            Returns entropy of distribution, batched over batch_shape.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Weibull.expand(TorchSharp.torch.Size,TorchSharp.torch.distributions.Distribution)">
            <summary>
            Returns a new distribution instance (or populates an existing instance provided by a derived class) with batch dimensions expanded to
            `batch_shape`. This method calls `torch.Tensor.expand()` on the distribution's parameters. As such, this does not allocate new
            memory for the expanded distribution instance.
            </summary>
            <param name="batch_shape">Tthe desired expanded size.</param>
            <param name="instance">new instance provided by subclasses that need to override `.expand`.</param>
        </member>
        <member name="T:TorchSharp.Modules.CELU">
            <summary>
            This class is used to represent a CELU module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.ELU">
            <summary>
            This class is used to represent a ELU module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.GELU">
            <summary>
            This class is used to represent a GELU module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.GLU">
            <summary>
            This class is used to represent a GLU (gated linear unit) module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.Hardshrink">
            <summary>
            This class is used to represent a Hardshrink module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.Hardsigmoid">
            <summary>
            This class is used to represent a Hardsigmoid module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.Hardswish">
            <summary>
            This class is used to represent a Hardswish module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.Hardtanh">
            <summary>
            This class is used to represent a Hardtanh module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.LeakyReLU">
            <summary>
            This class is used to represent a LeakyReLU module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.LogSigmoid">
            <summary>
            This class is used to represent a LogSigmoid module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.LogSoftmax">
            <summary>
            This class is used to represent a log softmax module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.Mish">
            <summary>
            This class is used to represent a Mish module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.PReLU">
            <summary>
            This class is used to represent a PReLU module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.ReLU">
            <summary>
            This class is used to represent a ReLU module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.ReLU6">
            <summary>
            This class is used to represent a ReLU6 module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.RReLU">
            <summary>
            This class is used to represent a RReLU module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.SELU">
            <summary>
            This class is used to represent a SELU module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.Sigmoid">
            <summary>
            This class is used to represent a Sigmoid module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.SiLU">
            <summary>
            This class is used to represent a SiLU module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.Softmax">
            <summary>
            This class is used to represent a Softmax module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.Softmax2d">
            <summary>
            This class is used to represent a Softmax2d module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.Softmin">
            <summary>
            This class is used to represent a Softmin module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.Softplus">
            <summary>
            This class is used to represent a Softplus module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.Softshrink">
            <summary>
            This class is used to represent a Softshrink module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.Softsign">
            <summary>
            This class is used to represent a Softsign module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.Tanh">
            <summary>
            This class is used to represent a Tanh module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.Tanhshrink">
            <summary>
            This class is used to represent a Tanhshrink module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.Threshold">
            <summary>
            This class is used to represent a Threshold module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.AlphaDropout">
            <summary>
            Alpha Dropout is a type of Dropout that maintains the self-normalizing property. For an input with zero mean and unit standard deviation,
            the output of Alpha Dropout maintains the original mean and standard deviation of the input.
            Alpha Dropout goes hand-in-hand with SELU activation function, which ensures that the outputs have zero mean and unit standard deviation.
            During training, it randomly masks some of the elements of the input tensor with probability p using samples from a bernoulli distribution.
            The elements to masked are randomized on every forward call, and scaled and shifted to maintain zero mean and unit standard deviation.
            During evaluation the module simply computes an identity function.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.AlphaDropout.forward(TorchSharp.torch.Tensor)">
            <summary>
            Forward pass.
            </summary>
            <param name="tensor">Input tensor</param>
            <returns></returns>
        </member>
        <member name="T:TorchSharp.Modules.CosineSimilarity">
            <summary>
            A cosine similarity module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.Dropout">
            <summary>
            This class is used to represent a dropout module.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Dropout.forward(TorchSharp.torch.Tensor)">
            <summary>
            Forward pass.
            </summary>
            <param name="tensor">Input tensor</param>
            <returns></returns>
        </member>
        <member name="T:TorchSharp.Modules.Dropout1d">
            <summary>
            This class is used to represent a Dropout2d module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.Dropout2d">
            <summary>
            This class is used to represent a Dropout2d module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.Dropout3d">
            <summary>
            This class is used to represent a Dropout3d module.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.EmbeddingBag.forward(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Forward pass of EmbeddingBag.
            </summary>
            <param name="input">Tensor containing bags of indices into the embedding matrix.</param>
            <param name="offsets">Only used when input is 1D. offsets determines the starting index position of each bag (sequence) in input.</param>
            <param name="perSampleWeights">a tensor of float / double weights, or None to indicate all weights should be taken to be 1.
            If specified, per_sample_weights must have exactly the same shape as input and is treated as having the same offsets, if those are not None.
            Only supported for mode='sum'.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.EmbeddingBag.call(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Forward pass of EmbeddingBag.
            </summary>
            <param name="input">Tensor containing bags of indices into the embedding matrix.</param>
            <param name="offsets">Only used when input is 1D. offsets determines the starting index position of each bag (sequence) in input.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.EmbeddingBag.call(TorchSharp.torch.Tensor)">
            <summary>
            Forward pass of EmbeddingBag.
            </summary>
            <param name="input">Tensor containing bags of indices into the embedding matrix.</param>
            <returns></returns>
        </member>
        <member name="T:TorchSharp.Modules.FeatureAlphaDropout">
            <summary>
            This class is used to represent a dropout module for 2d/3d convolutational layers.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.Flatten">
            <summary>
            This class is used to represent a flattening of the input tensors.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.Sequential`2">
             <summary>
             This class is used to represent a Sequential module.
             </summary>
             <remarks>
             This version of Sequential accepts modules of any type.
             The submodules are not statically typed, so any `forward` implementation will have to validate the module
             types dynamically and cast to the right type in order to invoke them.
             The constructor of a derived type should validate that the entered modules are of the expected types, as should
             the `forward` implementation. Without dynamic type validation, there is a significant risk of silent failure.
            
             Please note that if all submodules have forward methods taking a single Tensor and returning a single Tensor, then
             using the non-generic Sequential will be better -- it means not having to derive a class or implement the forward
             method, and the implementation is more efficient since there is no need for dynamic type checking of the submodules.
             </remarks>
        </member>
        <member name="M:TorchSharp.Modules.Sequential`2.#ctor(System.ValueTuple{System.String,TorchSharp.torch.nn.Module}[])">
            <summary>
            Constructor, intended for derived modules.
            </summary>
            <param name="modules">An ordered list of the contained modules.</param>
        </member>
        <member name="M:TorchSharp.Modules.Sequential`2.#ctor(TorchSharp.torch.nn.Module[])">
            <summary>
            Constructor, intended for derived modules.
            </summary>
            <param name="modules">An ordered list of the contained modules.</param>
        </member>
        <member name="P:TorchSharp.Modules.Sequential`2.Count">
            <summary>
            The number of modules in the SequentialAbstractBase collection.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Sequential`2.SequentialItems(System.Int32)">
            <summary>
            Module indexer.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Sequential`2.SequentialItems(System.ValueTuple{System.Nullable{System.Int32},System.Nullable{System.Int32}})">
            <summary>
            Module indexer.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Sequential`2.Slice(System.Int32,System.Int32)">
            <summary>
            Slicing the Sequential from `start` to `end'
            </summary>
            <remarks>
            Any implementation of `Slice` must take into consideration that the first layer
            in the slice must adhere to the same forward semantics as the containing class itself.
            </remarks>
        </member>
        <member name="P:TorchSharp.Modules.Sequential`2.SequentialItems(System.Range)">
            <summary>
            Module indexer.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Sequential`2.train(System.Boolean)">
            <summary>
            Sets the module in training mode.
            </summary>
            <remarks>
            This has any effect only on certain modules.See documentations of particular modules for details of their behaviors in training/evaluation mode, if they are affected, e.g.Dropout, BatchNorm, etc.
            </remarks>
        </member>
        <member name="M:TorchSharp.Modules.Sequential`2.eval">
            <summary>
            Sets the module in evaluation mode.
            </summary>
            <remarks>
            This has any effect only on certain modules.See documentations of particular modules for details of their behaviors in training/evaluation mode, if they are affected, e.g.Dropout, BatchNorm, etc.
            </remarks>
        </member>
        <member name="T:TorchSharp.Modules.Sequential`3">
            <summary>
            This class is used to represent a Sequential module.
            </summary>
            <remarks>
            This version of Sequential accepts modules of any type.
            The submodules are not statically typed, so any `forward` implementation will have to validate the module
            types dynamically and cast to the right type in order to invoke them.
            The constructor of a derived type should validate that the entered modules are of the expected types, as should
            the `forward` implementation. Without dynamic type validation, there is a significant risk of silent failure.
            </remarks>
        </member>
        <member name="M:TorchSharp.Modules.Sequential`3.#ctor(System.ValueTuple{System.String,TorchSharp.torch.nn.Module}[])">
            <summary>
            Constructor, intended for derived modules.
            </summary>
            <param name="modules">An ordered list of the contained modules.</param>
        </member>
        <member name="M:TorchSharp.Modules.Sequential`3.#ctor(TorchSharp.torch.nn.Module[])">
            <summary>
            Constructor, intended for derived modules.
            </summary>
            <param name="modules">An ordered list of the contained modules.</param>
        </member>
        <member name="P:TorchSharp.Modules.Sequential`3.Count">
            <summary>
            The number of modules in the SequentialAbstractBase collection.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Sequential`3.SequentialItems(System.Int32)">
            <summary>
            Module indexer.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Sequential`3.SequentialItems(System.ValueTuple{System.Nullable{System.Int32},System.Nullable{System.Int32}})">
            <summary>
            Module indexer.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Sequential`3.Slice(System.Int32,System.Int32)">
            <summary>
            Slicing the Sequential from `start` to `end'
            </summary>
            <remarks>
            Any implementation of `Slice` must take into consideration that the first layer
            in the slice must adhere to the same forward semantics as the containing class itself.
            </remarks>
        </member>
        <member name="P:TorchSharp.Modules.Sequential`3.SequentialItems(System.Range)">
            <summary>
            Module indexer.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Sequential`3.train(System.Boolean)">
            <summary>
            Sets the module in training mode.
            </summary>
            <remarks>
            This has any effect only on certain modules.See documentations of particular modules for details of their behaviors in training/evaluation mode, if they are affected, e.g.Dropout, BatchNorm, etc.
            </remarks>
        </member>
        <member name="M:TorchSharp.Modules.Sequential`3.eval">
            <summary>
            Sets the module in evaluation mode.
            </summary>
            <remarks>
            This has any effect only on certain modules.See documentations of particular modules for details of their behaviors in training/evaluation mode, if they are affected, e.g.Dropout, BatchNorm, etc.
            </remarks>
        </member>
        <member name="T:TorchSharp.Modules.Sequential`4">
            <summary>
            This class is used to represent a Sequential module.
            </summary>
            <remarks>
            This version of Sequential accepts modules of any type.
            The submodules are not statically typed, so any `forward` implementation will have to validate the module
            types dynamically and cast to the right type in order to invoke them.
            The constructor of a derived type should validate that the entered modules are of the expected types, as should
            the `forward` implementation. Without dynamic type validation, there is a significant risk of silent failure.
            </remarks>
        </member>
        <member name="M:TorchSharp.Modules.Sequential`4.#ctor(System.ValueTuple{System.String,TorchSharp.torch.nn.Module}[])">
            <summary>
            Constructor, intended for derived modules.
            </summary>
            <param name="modules">An ordered list of the contained modules.</param>
        </member>
        <member name="M:TorchSharp.Modules.Sequential`4.#ctor(TorchSharp.torch.nn.Module[])">
            <summary>
            Constructor, intended for derived modules.
            </summary>
            <param name="modules">An ordered list of the contained modules.</param>
        </member>
        <member name="P:TorchSharp.Modules.Sequential`4.Count">
            <summary>
            The number of modules in the SequentialAbstractBase collection.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Sequential`4.SequentialItems(System.Int32)">
            <summary>
            Module indexer.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Sequential`4.SequentialItems(System.ValueTuple{System.Nullable{System.Int32},System.Nullable{System.Int32}})">
            <summary>
            Module indexer.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Sequential`4.SequentialItems(System.Range)">
            <summary>
            Module indexer.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Sequential`4.train(System.Boolean)">
            <summary>
            Sets the module in training mode.
            </summary>
            <remarks>
            This has any effect only on certain modules.See documentations of particular modules for details of their behaviors in training/evaluation mode, if they are affected, e.g.Dropout, BatchNorm, etc.
            </remarks>
        </member>
        <member name="M:TorchSharp.Modules.Sequential`4.eval">
            <summary>
            Sets the module in evaluation mode.
            </summary>
            <remarks>
            This has any effect only on certain modules.See documentations of particular modules for details of their behaviors in training/evaluation mode, if they are affected, e.g.Dropout, BatchNorm, etc.
            </remarks>
        </member>
        <member name="T:TorchSharp.Modules.Sequential`5">
            <summary>
            This class is used to represent a Sequential module.
            </summary>
            <remarks>
            This version of Sequential accepts modules of any type.
            The submodules are not statically typed, so any `forward` implementation will have to validate the module
            types dynamically and cast to the right type in order to invoke them.
            The constructor of a derived type should validate that the entered modules are of the expected types, as should
            the `forward` implementation. Without dynamic type validation, there is a significant risk of silent failure.
            </remarks>
        </member>
        <member name="M:TorchSharp.Modules.Sequential`5.#ctor(System.ValueTuple{System.String,TorchSharp.torch.nn.Module}[])">
            <summary>
            Constructor, intended for derived modules.
            </summary>
            <param name="modules">An ordered list of the contained modules.</param>
        </member>
        <member name="M:TorchSharp.Modules.Sequential`5.#ctor(TorchSharp.torch.nn.Module[])">
            <summary>
            Constructor, intended for derived modules.
            </summary>
            <param name="modules">An ordered list of the contained modules.</param>
        </member>
        <member name="P:TorchSharp.Modules.Sequential`5.Count">
            <summary>
            The number of modules in the SequentialAbstractBase collection.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Sequential`5.SequentialItems(System.Int32)">
            <summary>
            Module indexer.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Sequential`5.SequentialItems(System.ValueTuple{System.Nullable{System.Int32},System.Nullable{System.Int32}})">
            <summary>
            Module indexer.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Sequential`5.SequentialItems(System.Range)">
            <summary>
            Module indexer.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Sequential`5.train(System.Boolean)">
            <summary>
            Sets the module in training mode.
            </summary>
            <remarks>
            This has any effect only on certain modules.See documentations of particular modules for details of their behaviors in training/evaluation mode, if they are affected, e.g.Dropout, BatchNorm, etc.
            </remarks>
        </member>
        <member name="M:TorchSharp.Modules.Sequential`5.eval">
            <summary>
            Sets the module in evaluation mode.
            </summary>
            <remarks>
            This has any effect only on certain modules.See documentations of particular modules for details of their behaviors in training/evaluation mode, if they are affected, e.g.Dropout, BatchNorm, etc.
            </remarks>
        </member>
        <member name="T:TorchSharp.Modules.Sequential`6">
            <summary>
            This class is used to represent a Sequential module.
            </summary>
            <remarks>
            This version of Sequential accepts modules of any type.
            The submodules are not statically typed, so any `forward` implementation will have to validate the module
            types dynamically and cast to the right type in order to invoke them.
            The constructor of a derived type should validate that the entered modules are of the expected types, as should
            the `forward` implementation. Without dynamic type validation, there is a significant risk of silent failure.
            </remarks>
        </member>
        <member name="M:TorchSharp.Modules.Sequential`6.#ctor(System.ValueTuple{System.String,TorchSharp.torch.nn.Module}[])">
            <summary>
            Constructor, intended for derived modules.
            </summary>
            <param name="modules">An ordered list of the contained modules.</param>
        </member>
        <member name="M:TorchSharp.Modules.Sequential`6.#ctor(TorchSharp.torch.nn.Module[])">
            <summary>
            Constructor, intended for derived modules.
            </summary>
            <param name="modules">An ordered list of the contained modules.</param>
        </member>
        <member name="P:TorchSharp.Modules.Sequential`6.Count">
            <summary>
            The number of modules in the SequentialAbstractBase collection.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Sequential`6.SequentialItems(System.Int32)">
            <summary>
            Module indexer.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Sequential`6.SequentialItems(System.ValueTuple{System.Nullable{System.Int32},System.Nullable{System.Int32}})">
            <summary>
            Module indexer.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Sequential`6.SequentialItems(System.Range)">
            <summary>
            Module indexer.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Sequential`6.train(System.Boolean)">
            <summary>
            Sets the module in training mode.
            </summary>
            <remarks>
            This has any effect only on certain modules.See documentations of particular modules for details of their behaviors in training/evaluation mode, if they are affected, e.g.Dropout, BatchNorm, etc.
            </remarks>
        </member>
        <member name="M:TorchSharp.Modules.Sequential`6.eval">
            <summary>
            Sets the module in evaluation mode.
            </summary>
            <remarks>
            This has any effect only on certain modules.See documentations of particular modules for details of their behaviors in training/evaluation mode, if they are affected, e.g.Dropout, BatchNorm, etc.
            </remarks>
        </member>
        <member name="T:TorchSharp.Modules.Sequential`7">
            <summary>
            This class is used to represent a Sequential module.
            </summary>
            <remarks>
            This version of Sequential accepts modules of any type.
            The submodules are not statically typed, so any `forward` implementation will have to validate the module
            types dynamically and cast to the right type in order to invoke them.
            The constructor of a derived type should validate that the entered modules are of the expected types, as should
            the `forward` implementation. Without dynamic type validation, there is a significant risk of silent failure.
            </remarks>
        </member>
        <member name="M:TorchSharp.Modules.Sequential`7.#ctor(System.ValueTuple{System.String,TorchSharp.torch.nn.Module}[])">
            <summary>
            Constructor, intended for derived modules.
            </summary>
            <param name="modules">An ordered list of the contained modules.</param>
        </member>
        <member name="M:TorchSharp.Modules.Sequential`7.#ctor(TorchSharp.torch.nn.Module[])">
            <summary>
            Constructor, intended for derived modules.
            </summary>
            <param name="modules">An ordered list of the contained modules.</param>
        </member>
        <member name="P:TorchSharp.Modules.Sequential`7.Count">
            <summary>
            The number of modules in the SequentialAbstractBase collection.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Sequential`7.SequentialItems(System.Int32)">
            <summary>
            Module indexer.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Sequential`7.SequentialItems(System.ValueTuple{System.Nullable{System.Int32},System.Nullable{System.Int32}})">
            <summary>
            Module indexer.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Sequential`7.SequentialItems(System.Range)">
            <summary>
            Module indexer.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Sequential`7.train(System.Boolean)">
            <summary>
            Sets the module in training mode.
            </summary>
            <remarks>
            This has any effect only on certain modules.See documentations of particular modules for details of their behaviors in training/evaluation mode, if they are affected, e.g.Dropout, BatchNorm, etc.
            </remarks>
        </member>
        <member name="M:TorchSharp.Modules.Sequential`7.eval">
            <summary>
            Sets the module in evaluation mode.
            </summary>
            <remarks>
            This has any effect only on certain modules.See documentations of particular modules for details of their behaviors in training/evaluation mode, if they are affected, e.g.Dropout, BatchNorm, etc.
            </remarks>
        </member>
        <member name="T:TorchSharp.Modules.ModuleDict`1">
             <summary>
             Holds parameters in a dictionary.
             
             ModuleDict can be indexed like a regular dictionary, but the modules it
             contains are properly registered, and will be visible by all Module methods.
            
             ModuleDict is an ordered dictionary that respects the order of insertion, and
             in update(), the order of the merged OrderedDict or another ModuleDict (the argument to update()).
             </summary>
        </member>
        <member name="M:TorchSharp.Modules.ModuleDict`1.clear">
            <summary>
            Remove all items from the ParameterDict.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.ModuleDict`1.items">
            <summary>
            Return an enumeration of the ParameterDict key/value pairs.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.ModuleDict`1.keys">
            <summary>
            Return the ParameterDict keys.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.ModuleDict`1.values">
            <summary>
            Return the ParameterDict values.
            </summary>
            <returns></returns>
        </member>
        <member name="T:TorchSharp.Modules.ModuleList`1">
            <summary>
            Holds modules in a list.
            ModuleList can be indexed like a regular list, but modules it contains are properly registered, and will be visible by all Module methods.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.ModuleList`1.append(`0[])">
            <summary>
            Appends zero or more parameters to the end of the list.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.ModuleList`1.extend(System.Collections.Generic.IEnumerable{`0})">
            <summary>
            Appends parameters from an enumeration to the end of the list.
            </summary>
            <param name="modules"></param>
        </member>
        <member name="M:TorchSharp.Modules.MultiheadAttention.forward(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,System.Boolean,TorchSharp.torch.Tensor)">
            <summary>
            Applies the MultiheadAttention function element-wise.
            </summary>
            <param name="query">map a query and a set of key-value pairs to an output. See “Attention Is All You Need” for more details</param>
            <param name="key"></param>
            <param name="value"></param>
            <param name="key_padding_mask">if provided, specified padding elements in the key will be ignored by the attention. When given a binary mask and a value is True, the corresponding value on the attention layer will be ignored. When given a byte mask and a value is non-zero, the corresponding value on the attention layer will be ignored</param>
            <param name="need_weights">output attn_output_weights</param>
            <param name="attn_mask">2D or 3D mask that prevents attention to certain positions. A 2D mask will be broadcasted for all the batches while a 3D mask allows to specify a different mask for the entries of each batch</param>
            <returns>attn_output, attn_ouput_weights</returns>
        </member>
        <member name="T:TorchSharp.Modules.BatchNorm1d">
            <summary>
            This class is used to represent a BatchNorm1D module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.BatchNorm2d">
            <summary>
            This class is used to represent a BatchNorm2D module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.BatchNorm3d">
            <summary>
            This class is used to represent a BatchNorm3D module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.GroupNorm">
            <summary>
            This class is used to represent a GroupNorm module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.InstanceNorm1d">
            <summary>
            This class is used to represent a InstanceNorm1D module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.InstanceNorm2d">
            <summary>
            This class is used to represent a InstanceNorm2D module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.InstanceNorm3d">
            <summary>
            This class is used to represent a InstanceNorm3D module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.LayerNorm">
            <summary>
            This class is used to represent a LayerNorm module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.LocalResponseNorm">
            <summary>
            This class is used to represent a LocalResponseNorm module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.ConstantPad1d">
            <summary>
            This class is used to represent a ConstantPad1d module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.ConstantPad2d">
            <summary>
            This class is used to represent a ConstantPad2d module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.ConstantPad3d">
            <summary>
            This class is used to represent a ConstantPad3d module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.PadBase">
            <summary>
            This class is used to represent the base of all padding-related modules.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.PadBase.forward(TorchSharp.torch.Tensor)">
            <summary>
            Forward pass.
            </summary>
            <param name="input">Input tensor</param>
            <returns></returns>
        </member>
        <member name="T:TorchSharp.Modules.ReflectionPad1d">
            <summary>
            This class is used to represent a ReflectionPad1d module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.ReflectionPad2d">
            <summary>
            This class is used to represent a ReflectionPad2d module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.ReflectionPad3d">
            <summary>
            This class is used to represent a ReflectionPad3d module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.ReplicationPad1d">
            <summary>
            This class is used to represent a ReplicationPad1d module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.ReplicationPad2d">
            <summary>
            This class is used to represent a ReplicationPad2d module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.ReplicationPad3d">
            <summary>
            This class is used to represent a ReplicationPad3d module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.ZeroPad2d">
            <summary>
            This class is used to represent a ZeroPad2d module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.PairwiseDistance">
            <summary>
            Computes the pairwise distance between vectors using the p-norm.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.Parameter">
             <summary>
             A kind of Tensor that is to be considered a module parameter.
            
             Parameters are Tensor subclasses, that have a very special property when used with Modules -
             when they’re assigned as Module attributes they are automatically added to the list of its parameters,
             and will appear e.g. in parameters() iterator.Assigning a Tensor doesn’t have such effect.This is because
             one might want to cache some temporary state, like last hidden state of the RNN, in the model.
             If there was no such class as Parameter, these temporaries would get registered too.
             </summary>
        </member>
        <member name="M:TorchSharp.Modules.Parameter.#ctor(TorchSharp.torch.Tensor,System.Boolean)">
            <summary>
            Constructor
            </summary>
            <param name="data">A tensor, which will become empty.</param>
            <param name="requires_grad"></param>
        </member>
        <member name="M:TorchSharp.Modules.Parameter.#ctor(System.IntPtr)">
            <summary>
            Constructor
            </summary>
            <param name="handle">A tensor handle.</param>
        </member>
        <member name="T:TorchSharp.Modules.ParameterDict">
             <summary>
             Holds parameters in a dictionary.
            
             ParameterDict can be indexed like a regular dictionary, but the parameters it
             contains are properly registered, and will be visible by all Module methods.
            
             ParameterDict is an ordered dictionary that respects the order of insertion, and
             in update(), the order of the merged OrderedDict or another ParameterDict (the argument to update()).
             </summary>
        </member>
        <member name="M:TorchSharp.Modules.ParameterDict.clear">
            <summary>
            Remove all items from the ParameterDict.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.ParameterDict.items">
            <summary>
            Return an enumeration of the ParameterDict key/value pairs.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.ParameterDict.keys">
            <summary>
            Return the ParameterDict keys.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.ParameterDict.values">
            <summary>
            Return the ParameterDict values.
            </summary>
            <returns></returns>
        </member>
        <member name="T:TorchSharp.Modules.ParameterList">
            <summary>
            Holds parameters in a list.
            ParameterList can be indexed like a regular list, but parameters it contains are properly registered, and will be visible by all Module methods.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.ParameterList.extend(System.Collections.Generic.IEnumerable{TorchSharp.Modules.Parameter})">
            <summary>
            Appends parameters from an enumeration to the end of the list.
            </summary>
            <param name="parameters"></param>
        </member>
        <member name="M:TorchSharp.Modules.ParameterList.append(TorchSharp.Modules.Parameter[])">
            <summary>
            Appends zero or more parameters to the end of the list.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.ParameterLessModule`2">
            <summary>
            Base class for all modules that do not have any tensor parameters or buffers, and
            for which the `_to()` implementation can therefore be simplified.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.ParameterLessModule`3">
            <summary>
            Base class for all modules that do not have any tensor parameters or buffers, and
            for which the `_to()` implementation can therefore be simplified.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.ParameterLessModule`4">
            <summary>
            Base class for all modules that do not have any tensor parameters or buffers, and
            for which the `_to()` implementation can therefore be simplified.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.ParameterLessModule`5">
            <summary>
            Base class for all modules that do not have any tensor parameters or buffers, and
            for which the `_to()` implementation can therefore be simplified.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.ParameterLessModule`6">
            <summary>
            Base class for all modules that do not have any tensor parameters or buffers, and
            for which the `_to()` implementation can therefore be simplified.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.ParameterLessModule`7">
            <summary>
            Base class for all modules that do not have any tensor parameters or buffers, and
            for which the `_to()` implementation can therefore be simplified.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.PixelShuffle">
            <summary>
            This class is used to represent a dropout module.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.PixelShuffle.forward(TorchSharp.torch.Tensor)">
            <summary>
            Forward pass.
            </summary>
            <param name="input">Input tensor</param>
            <returns></returns>
        </member>
        <member name="T:TorchSharp.Modules.PixelUnshuffle">
            <summary>
            This class is used to represent a dropout module.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.PixelUnshuffle.forward(TorchSharp.torch.Tensor)">
            <summary>
            Forward pass.
            </summary>
            <param name="input">Input tensor</param>
            <returns></returns>
        </member>
        <member name="T:TorchSharp.Modules.AdaptiveAvgPool1d">
            <summary>
            This class is used to represent a AdaptiveAvgPool1D module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.AdaptiveAvgPool2d">
            <summary>
            This class is used to represent a AdaptiveAvgPool2D module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.AdaptiveAvgPool3d">
            <summary>
            This class is used to represent a AdaptiveAvgPool3D module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.AdaptiveMaxPool1d">
            <summary>
            This class is used to represent a AdaptiveMaxPool1D module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.AdaptiveMaxPool2d">
            <summary>
            This class is used to represent a AdaptiveMaxPool2D module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.AdaptiveMaxPool3d">
            <summary>
            This class is used to represent a AdaptiveMaxPool3D module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.AvgPool1d">
            <summary>
            This class is used to represent a AvgPool1D module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.AvgPool2d">
            <summary>
            This class is used to represent a AvgPool2D module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.AvgPool3d">
            <summary>
            This class is used to represent a AvgPool3D module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.FractionalMaxPool2d">
            <summary>
            This class is used to represent a FractionalMaxPool2D module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.FractionalMaxPool3d">
            <summary>
            This class is used to represent a FractionalMaxPool3d module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.LPPool1d">
            <summary>
            This class is used to represent a LPPool1D module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.LPPool2d">
            <summary>
            This class is used to represent a LPPool2D module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.MaxPool1d">
            <summary>
            This class is used to represent a MaxPool1D module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.MaxPool2d">
            <summary>
            This class is used to represent a MaxPool2D module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.MaxPool3d">
            <summary>
            This class is used to represent a MaxPool3D module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.MaxUnpool1d">
            <summary>
            This class is used to represent a MaxUnpool1D module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.MaxUnpool2d">
            <summary>
            This class is used to represent a MaxUnpool2D module.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.MaxUnpool3d">
            <summary>
            This class is used to represent a MaxUnpool3D module.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.GRU.forward(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence.
            </summary>
            <param name="input">Tensor of shape (seq_len, batch, input_size) containing the features of the input sequence.</param>
            <param name="h0">Tensor of shape (num_layers * num_directions, batch, hidden_size)containing the initial hidden state for each element in the batch.
            Defaults to 0 if not provided. If the GRU is bidirectional, num_directions should be 2, else it should be 1.</param>
            <returns></returns>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.GRU.call(TorchSharp.torch.nn.utils.rnn.PackedSequence,TorchSharp.torch.Tensor)">
            <summary>
            Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence.
            </summary>
            <param name="input">PackedSequence containing the features of the input sequence.</param>
            <param name="h0">Tensor of shape (num_layers * num_directions, batch, hidden_size)containing the initial hidden state for each element in the batch.
            Defaults to 0 if not provided. If the GRU is bidirectional, num_directions should be 2, else it should be 1.</param>
            <returns></returns>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.GRUCell.forward(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Apply the GRU cell to an input tensor.
            </summary>
            <param name="input">Tensor of shape (batch, input_size) containing the features of the input sequence.</param>
            <param name="h0">Tensor of shape (batch, hidden_size) containing the initial hidden state for each element in the batch.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.LSTM.forward(TorchSharp.torch.Tensor,System.Nullable{System.ValueTuple{TorchSharp.torch.Tensor,TorchSharp.torch.Tensor}})">
            <summary>
            Applies a multi-layer long short-term memory (LSTM) RNN to an input sequence.
            </summary>
            <param name="input">Tensor of shape (seq_len, batch, input_size) containing the features of the input sequence.</param>
            <param name="h0_c0">Tensors of shape (num_layers * num_directions, batch, hidden_size) containing the initial hidden and cell state for each element in the batch</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.LSTM.call(TorchSharp.torch.nn.utils.rnn.PackedSequence,System.Nullable{System.ValueTuple{TorchSharp.torch.Tensor,TorchSharp.torch.Tensor}})">
            <summary>
            Applies a multi-layer long short-term memory (LSTM) RNN to an input sequence.
            </summary>
            <param name="input">PackedSequence containing the features of the input sequence.</param>
            <param name="h0_c0">Tensors of shape (num_layers * num_directions, batch, hidden_size) containing the initial hidden and cell state for each element in the batch</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.LSTMCell.forward(TorchSharp.torch.Tensor,System.Nullable{System.ValueTuple{TorchSharp.torch.Tensor,TorchSharp.torch.Tensor}})">
            <summary>
            Apply the RNN cell to an input tensor.
            </summary>
            <param name="input">Tensor of shape (batch, input_size) containing the features of the input sequence.</param>
            <param name="h0_c0">Tensors of shape (batch, hidden_size) containing the initial hidden and cell state for each element in the batch.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.RNN.forward(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Applies a multi-layer Elman RNN with \tanhtanh or \text{ReLU}ReLU non-linearity to an input sequence.
            </summary>
            <param name="input">Tensor of shape (seq_len, batch, input_size) containing the features of the input sequence.</param>
            <param name="h0">Tensor of shape (num_layers * num_directions, batch, hidden_size)containing the initial hidden state for each element in the batch.
            Defaults to 0 if not provided. If the RNN is bidirectional, num_directions should be 2, else it should be 1.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.RNN.call(TorchSharp.torch.nn.utils.rnn.PackedSequence,TorchSharp.torch.Tensor)">
            <summary>
            Applies a multi-layer Elman RNN with \tanhtanh or \text{ReLU}ReLU non-linearity to an input sequence.
            </summary>
            <param name="input">PackedSequence containing the features of the input sequence.</param>
            <param name="h0">Tensor of shape (num_layers * num_directions, batch, hidden_size)containing the initial hidden state for each element in the batch.
            Defaults to 0 if not provided. If the RNN is bidirectional, num_directions should be 2, else it should be 1.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.RNNCell.forward(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Apply the RNN cell to an input tensor.
            </summary>
            <param name="input">Tensor of shape (batch, input_size) containing the features of the input sequence.</param>
            <param name="h0">Tensor of shape (batch, hidden_size) containing the initial hidden state for each element in the batch.</param>
            <returns></returns>
        </member>
        <member name="T:TorchSharp.Modules.Sequential">
            <summary>
            This class is used to represent a Sequential module.
            </summary>
            <remarks>
            This version of Sequential accepts only modules with a `forward()` that takes a tensor and returns a tensor.
            This allows `Sequential.forward` to be implemented directly in this class, and to do so efficiently.
            For scenarios where customization via derivation is useful, use one of the type-parameterized versions of
            Sequential and implement the `forward` method in the derived class, which do not assume that the submodules
            have a uniform Module base class.
            </remarks>
        </member>
        <member name="M:TorchSharp.Modules.Sequential.#ctor(System.ValueTuple{System.String,TorchSharp.torch.nn.Module{TorchSharp.torch.Tensor,TorchSharp.torch.Tensor}}[])">
            <summary>
            Constructor, intended for derived modules.
            </summary>
            <param name="modules">An ordered list of the contained modules.</param>
        </member>
        <member name="M:TorchSharp.Modules.Sequential.#ctor(TorchSharp.torch.nn.Module{TorchSharp.torch.Tensor,TorchSharp.torch.Tensor}[])">
            <summary>
            Constructor, intended for derived modules.
            </summary>
            <param name="modules">An ordered list of the contained modules.</param>
        </member>
        <member name="P:TorchSharp.Modules.Sequential.Count">
            <summary>
            The number of modules in the Sequential collection.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Sequential.SequentialItems(System.Int32)">
            <summary>
            Module indexer.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Sequential.SequentialItems(System.ValueTuple{System.Nullable{System.Int32},System.Nullable{System.Int32}})">
            <summary>
            Module indexer.
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.Sequential.SequentialItems(System.Range)">
            <summary>
            Module indexer.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Sequential.train(System.Boolean)">
            <summary>
            Sets the module in training mode.
            </summary>
            <remarks>
            This has any effect only on certain modules.See documentations of particular modules for details of their behaviors in training/evaluation mode, if they are affected, e.g.Dropout, BatchNorm, etc.
            </remarks>
        </member>
        <member name="M:TorchSharp.Modules.Sequential.eval">
            <summary>
            Sets the module in evaluation mode.
            </summary>
            <remarks>
            This has any effect only on certain modules.See documentations of particular modules for details of their behaviors in training/evaluation mode, if they are affected, e.g.Dropout, BatchNorm, etc.
            </remarks>
        </member>
        <member name="T:TorchSharp.Modules.ChannelShuffle">
            <summary>
            This class is used to represent a ChannelShuffle module.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Transformer.call(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Take in and process masked source/target sequences.
            </summary>
            <param name="src">The sequence to the encoder (required).</param>
            <param name="tgt">The sequence to the decoder (required).</param>
            <param name="src_mask">The additive mask for the src sequence (optional).</param>
            <param name="tgt_mask">The additive mask for the tgt sequence (optional).</param>
            <param name="memory_mask">The additive mask for the encoder output (optional).</param>
            <param name="src_key_padding_mask">The ByteTensor mask for src keys per batch (optional).</param>
            <param name="tgt_key_padding_mask">The ByteTensor mask for tgt keys per batch (optional).</param>
            <param name="memory_key_padding_mask">The ByteTensor mask for memory keys per batch (optional).</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.Transformer.forward(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Take in and process masked source/target sequences.
            </summary>
            <param name="src">The sequence to the encoder (required).</param>
            <param name="tgt">The sequence to the decoder (required).</param>
        </member>
        <member name="M:TorchSharp.Modules.TransformerDecoder.forward(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Pass the inputs (and mask) through the decoder layers in turn.
            </summary>
            <param name="tgt">The sequence to the decoder layer (required).</param>
            <param name="memory">The sequence from the last layer of the encoder (required).</param>
            <param name="tgt_mask">The mask for the tgt sequence (optional).</param>
            <param name="memory_mask">The mask for the memory sequence (optional).</param>
            <param name="tgt_key_padding_mask">The mask for the tgt keys per batch (optional).</param>
            <param name="memory_key_padding_mask">The mask for the memory keys per batch (optional).</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.TransformerDecoder.call(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Pass the inputs (and mask) through the decoder layers in turn.
            </summary>
            <param name="tgt">The sequence to the decoder layer (required).</param>
            <param name="memory">The sequence from the last layer of the encoder (required).</param>
        </member>
        <member name="M:TorchSharp.Modules.TransformerDecoderLayer.forward(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Pass the inputs (and mask) through the decoder layer.
            </summary>
            <param name="tgt">The sequence to the decoder layer (required).</param>
            <param name="memory">The sequence from the last layer of the encoder (required).</param>
            <param name="tgt_mask">The mask for the tgt sequence (optional).</param>
            <param name="memory_mask">The mask for the memory sequence (optional).</param>
            <param name="tgt_key_padding_mask">The mask for the tgt keys per batch (optional).</param>
            <param name="memory_key_padding_mask">The mask for the memory keys per batch (optional).</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.TransformerDecoderLayer.call(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Pass the inputs (and mask) through the decoder layer.
            </summary>
            <param name="tgt">The sequence to the decoder layer (required).</param>
            <param name="memory">The sequence from the last layer of the encoder (required).</param>
        </member>
        <member name="M:TorchSharp.Modules.TransformerEncoder.forward(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Pass the input through the encoder layers in turn.
            </summary>
            <param name="src">The sequence to the encoder (required).</param>
            <param name="src_mask">The additive mask for the src sequence (optional).</param>
            <param name="src_key_padding_mask">The ByteTensor mask for src keys per batch (optional).</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.TransformerEncoder.call(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Pass the input through the encoder layers in turn.
            </summary>
            <param name="src">The sequence to the encoder (required).</param>
            <param name="src_mask">The additive mask for the src sequence (optional).</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.TransformerEncoder.call(TorchSharp.torch.Tensor)">
            <summary>
            Pass the input through the encoder layers in turn.
            </summary>
            <param name="src">The sequence to the encoder (required).</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.TransformerEncoderLayer.call(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Pass the input through the encoder layer.
            </summary>
            <param name="src">The sequence to the encoder (required).</param>
            <param name="src_mask">The additive mask for the src sequence (optional).</param>
            <param name="src_key_padding_mask">The ByteTensor mask for src keys per batch (optional).</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.TransformerEncoderLayer.call(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Pass the input through the encoder layer.
            </summary>
            <param name="src">The sequence to the encoder (required).</param>
            <param name="src_mask">The additive mask for the src sequence (optional).</param>
        </member>
        <member name="M:TorchSharp.Modules.TransformerEncoderLayer.forward(TorchSharp.torch.Tensor)">
            <summary>
            Pass the input through the encoder layer.
            </summary>
            <param name="src">The sequence to the encoder (required).</param>
        </member>
        <member name="T:TorchSharp.Modules.Unflatten">
            <summary>
            This class is used to represent an unflattening operation.
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.Upsample">
            <summary>
            This class is used to represent an Upsample module.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.Upsample.forward(TorchSharp.torch.Tensor)">
            <summary>
            Forward pass.
            </summary>
            <param name="input">Input tensor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.Adadelta.#ctor(System.Collections.Generic.IEnumerable{TorchSharp.Modules.Parameter},System.Double,System.Double,System.Double,System.Double,System.Boolean)">
            <summary>
            Constructor
            </summary>
            <param name="parameters">Parameters to optimize.</param>
            <param name="lr ">Learning rate</param>
            <param name="rho">Coefficient used for computing a running average of squared gradients (default: 0.9)</param>
            <param name="eps">Term added to the denominator to improve numerical stability, i.e. avoid division-by-zero (default: 1e-6)</param>
            <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
            <param name="maximize">Maximize the params based on the objective, instead of minimizing</param>
        </member>
        <member name="M:TorchSharp.Modules.Adadelta.#ctor(System.Collections.Generic.IEnumerable{TorchSharp.Modules.Adadelta.ParamGroup},System.Double,System.Double,System.Double,System.Double,System.Boolean)">
            <summary>
            Constructor
            </summary>
            <param name="parameters">Parameters to optimize.</param>
            <param name="lr ">Learning rate</param>
            <param name="rho">Coefficient used for computing a running average of squared gradients (default: 0.9)</param>
            <param name="eps">Term added to the denominator to improve numerical stability, i.e. avoid division-by-zero (default: 1e-6)</param>
            <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
            <param name="maximize">Maximize the params based on the objective, instead of minimizing</param>
        </member>
        <member name="M:TorchSharp.Modules.Adadelta.step(System.Func{TorchSharp.torch.Tensor})">
            <summary>
            Performs a single optimization step (parameter update).
            </summary>
            <param name="closure">A closure that reevaluates the model and returns the loss. Optional for most optimizers.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.Adadelta.State.to(TorchSharp.torch.Device)">
            <summary>
            Move all the state to the indicated device.
            </summary>
            <param name="device">The device to move all state to.</param>
        </member>
        <member name="M:TorchSharp.Modules.Adadelta.State.LoadStateDict(System.IO.BinaryReader)">
            <summary>
            Load the optimizer parameter state from a stream.
            </summary>
            <param name="reader">A binary reader connected to a stream open for reading.</param>
        </member>
        <member name="M:TorchSharp.Modules.Adadelta.State.SaveStateDict(System.IO.BinaryWriter)">
            <summary>
            Save the optimizer parameter state to a stream.
            </summary>
            <param name="writer">A binary writer connected to a stream open for writing.</param>
        </member>
        <member name="M:TorchSharp.Modules.Adadelta.State.LoadStateDict(TorchSharp.Modules.OptimizerState)">
            <summary>
            Load optimizer parameter state from another optimizer.
            </summary>
            <param name="source">An optimizer state record.</param>
        </member>
        <member name="M:TorchSharp.Modules.Adadelta.State.Initialize(TorchSharp.Modules.OptimizerOptions)">
            <summary>
            Initialize the values of the state to the initial values.
            </summary>
            <param name="options">The optimizer options</param>
        </member>
        <member name="M:TorchSharp.Modules.Adadelta.add_param_group(TorchSharp.Modules.ParamGroup)">
            <summary>
            Add a param group to the Optimizer s param_groups.
            </summary>
            <param name="param_group"></param>
            <remarks>This can be useful when fine tuning a pre-trained network as frozen layers can be made trainable and added to the Optimizer as training progresses.</remarks>
        </member>
        <member name="M:TorchSharp.Modules.Adadelta.Options.LoadStateDict(TorchSharp.Modules.OptimizerOptions)">
            <summary>
            Load optimizer options (param-group hyperparameters) from another optimizer.
            </summary>
            <param name="source">An optimizer options record.</param>
        </member>
        <member name="M:TorchSharp.Modules.Adadelta.Options.LoadStateDict(System.IO.BinaryReader)">
            <summary>
            Load the optimizer options (param-group hyperparameters) from a stream.
            </summary>
            <param name="reader">A binary reader connected to a stream open for reading.</param>
        </member>
        <member name="M:TorchSharp.Modules.Adadelta.Options.SaveStateDict(System.IO.BinaryWriter)">
            <summary>
            Save the optimizer options (param-group hyperparameters) to a stream.
            </summary>
            <param name="writer">A binary writer connected to a stream open for writing.</param>
        </member>
        <member name="M:TorchSharp.Modules.Adagrad.#ctor(System.Collections.Generic.IEnumerable{TorchSharp.Modules.Parameter},System.Double,System.Double,System.Double,System.Double,System.Double)">
             <summary>
             Implements Adagrad algorithm.
            
             It has been proposed in Adaptive Subgradient Methods for Online Learning and Stochastic Optimization.
             </summary>
             <param name="parameters">Parameters to optimize</param>
             <param name="lr">learning rate (default: 1e-2)</param>
             <param name="lr_decay">learning rate decay (default: 0)</param>
             <param name="weight_decay">weight decay (L2 penalty) (default: 0)</param>
             <param name="initial_accumulator_value"></param>
             <param name="eps">Term added to the denominator to improve numerical stability (default: 1e-10)</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.Adagrad.#ctor(System.Collections.Generic.IEnumerable{TorchSharp.Modules.Adagrad.ParamGroup},System.Double,System.Double,System.Double,System.Double,System.Double)">
             <summary>
             Implements Adagrad algorithm.
            
             It has been proposed in Adaptive Subgradient Methods for Online Learning and Stochastic Optimization.
             </summary>
             <param name="parameters">Parameters to optimize</param>
             <param name="lr">learning rate (default: 1e-2)</param>
             <param name="lr_decay">learning rate decay (default: 0)</param>
             <param name="weight_decay">weight decay (L2 penalty) (default: 0)</param>
             <param name="initial_accumulator_value"></param>
             <param name="eps">Term added to the denominator to improve numerical stability (default: 1e-10)</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.Adagrad.step(System.Func{TorchSharp.torch.Tensor})">
            <summary>
            Performs a single optimization step (parameter update).
            </summary>
            <param name="closure">A closure that reevaluates the model and returns the loss. Optional for most optimizers.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.Adagrad.State.to(TorchSharp.torch.Device)">
            <summary>
            Move all the state to the indicated device.
            </summary>
            <param name="device">The device to move all state to.</param>
        </member>
        <member name="M:TorchSharp.Modules.Adagrad.State.LoadStateDict(System.IO.BinaryReader)">
            <summary>
            Load the optimizer parameter state from a stream.
            </summary>
            <param name="reader">A binary reader connected to a stream open for reading.</param>
        </member>
        <member name="M:TorchSharp.Modules.Adagrad.State.LoadStateDict(TorchSharp.Modules.OptimizerState)">
            <summary>
            Load optimizer parameter state from another optimizer.
            </summary>
            <param name="source">An optimizer state record.</param>
        </member>
        <member name="M:TorchSharp.Modules.Adagrad.State.SaveStateDict(System.IO.BinaryWriter)">
            <summary>
            Save the optimizer parameter state to a stream.
            </summary>
            <param name="writer">A binary writer connected to a stream open for writing.</param>
        </member>
        <member name="M:TorchSharp.Modules.Adagrad.State.ApproximatelyEquals(TorchSharp.Modules.OptimizerState)">
            <summary>
            Useful for tests, allows comparison of one state with another.
            </summary>
            <param name="other">The other optimizer state</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.Adagrad.State.Initialize(TorchSharp.Modules.OptimizerOptions)">
            <summary>
            Initialize the values of the state to the initial values.
            </summary>
            <param name="options">The optimizer options</param>
        </member>
        <member name="M:TorchSharp.Modules.Adagrad.add_param_group(TorchSharp.Modules.ParamGroup)">
            <summary>
            Add a param group to the Optimizer s param_groups.
            </summary>
            <param name="param_group"></param>
            <remarks>This can be useful when fine tuning a pre-trained network as frozen layers can be made trainable and added to the Optimizer as training progresses.</remarks>
        </member>
        <member name="M:TorchSharp.Modules.Adagrad.Options.LoadStateDict(TorchSharp.Modules.OptimizerOptions)">
            <summary>
            Load optimizer options (param-group hyperparameters) from another optimizer.
            </summary>
            <param name="source">An optimizer options record.</param>
        </member>
        <member name="M:TorchSharp.Modules.Adagrad.Options.LoadStateDict(System.IO.BinaryReader)">
            <summary>
            Load the optimizer options (param-group hyperparameters) from a stream.
            </summary>
            <param name="reader">A binary reader connected to a stream open for reading.</param>
        </member>
        <member name="M:TorchSharp.Modules.Adagrad.Options.SaveStateDict(System.IO.BinaryWriter)">
            <summary>
            Save the optimizer options (param-group hyperparameters) to a stream.
            </summary>
            <param name="writer">A binary writer connected to a stream open for writing.</param>
        </member>
        <member name="M:TorchSharp.Modules.Adam.#ctor(System.Collections.Generic.IEnumerable{TorchSharp.Modules.Parameter},System.Double,System.Double,System.Double,System.Double,System.Double,System.Boolean,System.Boolean)">
             <summary>
             Implements Adam algorithm.
            
             It has been proposed in Adam: A Method for Stochastic Optimization.The implementation of the L2 penalty follows changes proposed in Decoupled Weight Decay Regularization.
             </summary>
             <param name="parameters">Parameters to optimize. This optimizer requires the <b>named</b> parameters collection.</param>
             <param name="lr">Learning rate</param>
             <param name="beta1">First coefficient used for computing running averages of gradient and its square</param>
             <param name="beta2">Second coefficient used for computing running averages of gradient and its square</param>
             <param name="eps">Term added to the denominator to improve numerical stability</param>
             <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
             <param name="amsgrad">Whether to use the AMSGrad variant of this algorithm</param>
             <param name="maximize">Maximize the params based on the objective, instead of minimizing</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.Adam.#ctor(System.Collections.Generic.IEnumerable{TorchSharp.Modules.Adam.ParamGroup},System.Double,System.Double,System.Double,System.Double,System.Double,System.Boolean,System.Boolean)">
             <summary>
             Implements Adam algorithm.
            
             It has been proposed in Adam: A Method for Stochastic Optimization.The implementation of the L2 penalty follows changes proposed in Decoupled Weight Decay Regularization.
             </summary>
             <param name="parameters">Parameters to optimize. This optimizer requires the <b>named</b> parameters collection.</param>
             <param name="lr">Learning rate</param>
             <param name="beta1">First coefficient used for computing running averages of gradient and its square</param>
             <param name="beta2">Second coefficient used for computing running averages of gradient and its square</param>
             <param name="eps">Term added to the denominator to improve numerical stability</param>
             <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
             <param name="amsgrad">Whether to use the AMSGrad variant of this algorithm</param>
             <param name="maximize">Maximize the params based on the objective, instead of minimizing</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.Adam.step(System.Func{TorchSharp.torch.Tensor})">
            <summary>
            Performs a single optimization step (parameter update).
            </summary>
            <param name="closure">A closure that reevaluates the model and returns the loss. Optional for most optimizers.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.Adam.State.to(TorchSharp.torch.Device)">
            <summary>
            Move all the state to the indicated device.
            </summary>
            <param name="device">The device to move all state to.</param>
        </member>
        <member name="M:TorchSharp.Modules.Adam.State.LoadStateDict(System.IO.BinaryReader)">
            <summary>
            Load the optimizer parameter state from a stream.
            </summary>
            <param name="reader">A binary reader connected to a stream open for reading.</param>
        </member>
        <member name="M:TorchSharp.Modules.Adam.State.SaveStateDict(System.IO.BinaryWriter)">
            <summary>
            Save the optimizer parameter state to a stream.
            </summary>
            <param name="writer">A binary writer connected to a stream open for writing.</param>
        </member>
        <member name="M:TorchSharp.Modules.Adam.State.LoadStateDict(TorchSharp.Modules.OptimizerState)">
            <summary>
            Load optimizer parameter state from another optimizer.
            </summary>
            <param name="source">An optimizer state record.</param>
        </member>
        <member name="M:TorchSharp.Modules.Adam.State.Initialize(TorchSharp.Modules.OptimizerOptions)">
            <summary>
            Initialize the values of the state to the initial values. 
            </summary>
            <param name="options">The optimizer options</param>
        </member>
        <member name="M:TorchSharp.Modules.Adam.add_param_group(TorchSharp.Modules.ParamGroup)">
            <summary>
            Add a param group to the Optimizer s param_groups.
            </summary>
            <param name="param_group"></param>
            <remarks>This can be useful when fine tuning a pre-trained network as frozen layers can be made trainable and added to the Optimizer as training progresses.</remarks>
        </member>
        <member name="M:TorchSharp.Modules.Adam.Options.LoadStateDict(TorchSharp.Modules.OptimizerOptions)">
            <summary>
            Load optimizer options (param-group hyperparameters) from another optimizer.
            </summary>
            <param name="source">An optimizer options record.</param>
        </member>
        <member name="M:TorchSharp.Modules.Adam.Options.LoadStateDict(System.IO.BinaryReader)">
            <summary>
            Load the optimizer options (param-group hyperparameters) from a stream.
            </summary>
            <param name="reader">A binary reader connected to a stream open for reading.</param>
        </member>
        <member name="M:TorchSharp.Modules.Adam.Options.SaveStateDict(System.IO.BinaryWriter)">
            <summary>
            Save the optimizer options (param-group hyperparameters) to a stream.
            </summary>
            <param name="writer">A binary writer connected to a stream open for writing.</param>
        </member>
        <member name="M:TorchSharp.Modules.Adamax.#ctor(System.Collections.Generic.IEnumerable{TorchSharp.Modules.Parameter},System.Double,System.Double,System.Double,System.Double,System.Double)">
             <summary>
             Implements Adamax algorithm (a variant of Adam based on infinity norm).
            
             It has been proposed in Adam: A Method for Stochastic Optimization.
             </summary>
             <param name="parameters">Parameters to optimize. This optimizer requires the <b>named</b> parameters collection.</param>
             <param name="lr ">Learning rate</param>
             <param name="beta1">Coefficient used for computing running averages of gradient and its square (default: 0.9)</param>
             <param name="beta2">Coefficient used for computing running averages of gradient and its square (default: 0.999)</param>
             <param name="eps">Term added to the denominator to improve numerical stability, i.e. avoid division-by-zero (default: 1e-8)</param>
             <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.Adamax.#ctor(System.Collections.Generic.IEnumerable{TorchSharp.Modules.Adamax.ParamGroup},System.Double,System.Double,System.Double,System.Double,System.Double)">
             <summary>
             Implements Adamax algorithm (a variant of Adam based on infinity norm).
            
             It has been proposed in Adam: A Method for Stochastic Optimization.
             </summary>
             <param name="parameters">Parameters to optimize. This optimizer requires the <b>named</b> parameters collection.</param>
             <param name="lr ">Learning rate</param>
             <param name="beta1">Coefficient used for computing running averages of gradient and its square (default: 0.9)</param>
             <param name="beta2">Coefficient used for computing running averages of gradient and its square (default: 0.999)</param>
             <param name="eps">Term added to the denominator to improve numerical stability, i.e. avoid division-by-zero (default: 1e-8)</param>
             <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.Adamax.step(System.Func{TorchSharp.torch.Tensor})">
            <summary>
            Performs a single optimization step (parameter update).
            </summary>
            <param name="closure">A closure that reevaluates the model and returns the loss. Optional for most optimizers.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.Adamax.State.to(TorchSharp.torch.Device)">
            <summary>
            Move all the state to the indicated device.
            </summary>
            <param name="device">The device to move all state to.</param>
        </member>
        <member name="M:TorchSharp.Modules.Adamax.State.LoadStateDict(System.IO.BinaryReader)">
            <summary>
            Load the optimizer parameter state from a stream.
            </summary>
            <param name="reader">A binary reader connected to a stream open for reading.</param>
        </member>
        <member name="M:TorchSharp.Modules.Adamax.State.SaveStateDict(System.IO.BinaryWriter)">
            <summary>
            Save the optimizer parameter state to a stream.
            </summary>
            <param name="writer">A binary writer connected to a stream open for writing.</param>
        </member>
        <member name="M:TorchSharp.Modules.Adamax.State.LoadStateDict(TorchSharp.Modules.OptimizerState)">
            <summary>
            Useful for tests, allows comparison of one state with another.
            </summary>
            <param name="source">The other optimizer state</param>
        </member>
        <member name="M:TorchSharp.Modules.Adamax.State.Initialize(TorchSharp.Modules.OptimizerOptions)">
            <summary>
            Initialize the values of the state to the initial values.
            </summary>
            <param name="options">The optimizer options</param>
        </member>
        <member name="M:TorchSharp.Modules.Adamax.add_param_group(TorchSharp.Modules.ParamGroup)">
            <summary>
            Add a param group to the Optimizer s param_groups.
            </summary>
            <param name="param_group"></param>
            <remarks>This can be useful when fine tuning a pre-trained network as frozen layers can be made trainable and added to the Optimizer as training progresses.</remarks>
        </member>
        <member name="M:TorchSharp.Modules.Adamax.Options.LoadStateDict(TorchSharp.Modules.OptimizerOptions)">
            <summary>
            Load optimizer options (param-group hyperparameters) from another optimizer.
            </summary>
            <param name="source">An optimizer options record.</param>
        </member>
        <member name="M:TorchSharp.Modules.Adamax.Options.LoadStateDict(System.IO.BinaryReader)">
            <summary>
            Load the optimizer options (param-group hyperparameters) from a stream.
            </summary>
            <param name="reader">A binary reader connected to a stream open for reading.</param>
        </member>
        <member name="M:TorchSharp.Modules.Adamax.Options.SaveStateDict(System.IO.BinaryWriter)">
            <summary>
            Save the optimizer options (param-group hyperparameters) to a stream.
            </summary>
            <param name="writer">A binary writer connected to a stream open for writing.</param>
        </member>
        <member name="M:TorchSharp.Modules.AdamW.#ctor(System.Collections.Generic.IEnumerable{TorchSharp.Modules.Parameter},System.Double,System.Double,System.Double,System.Double,System.Double,System.Boolean,System.Boolean)">
             <summary>
             Implements AdamW algorithm.
            
             It has been proposed in Adam: A Method for Stochastic Optimization. The AdamW variant was proposed in Decoupled Weight Decay Regularization.
             </summary>
             <param name="parameters">Parameters to optimize. This optimizer requires the <b>named</b> parameters collection.</param>
             <param name="lr">Learning rate</param>
             <param name="beta1">First coefficient used for computing running averages of gradient and its square</param>
             <param name="beta2">Second coefficient used for computing running averages of gradient and its square</param>
             <param name="eps">Term added to the denominator to improve numerical stability</param>
             <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
             <param name="amsgrad">Whether to use the AMSGrad variant of this algorithm</param>
             <param name="maximize">Maximize the params based on the objective, instead of minimizing</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.AdamW.#ctor(System.Collections.Generic.IEnumerable{TorchSharp.Modules.AdamW.ParamGroup},System.Double,System.Double,System.Double,System.Double,System.Double,System.Boolean,System.Boolean)">
             <summary>
             Implements AdamW algorithm.
            
             It has been proposed in Adam: A Method for Stochastic Optimization. The AdamW variant was proposed in Decoupled Weight Decay Regularization.
             </summary>
             <param name="parameters">Parameters to optimize. This optimizer requires the <b>named</b> parameters collection.</param>
             <param name="lr">Learning rate</param>
             <param name="beta1">First coefficient used for computing running averages of gradient and its square</param>
             <param name="beta2">Second coefficient used for computing running averages of gradient and its square</param>
             <param name="eps">Term added to the denominator to improve numerical stability</param>
             <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
             <param name="amsgrad">Whether to use the AMSGrad variant of this algorithm</param>
             <param name="maximize">Maximize the params based on the objective, instead of minimizing</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.AdamW.step(System.Func{TorchSharp.torch.Tensor})">
            <summary>
            Performs a single optimization step (parameter update).
            </summary>
            <param name="closure">A closure that reevaluates the model and returns the loss. Optional for most optimizers.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.AdamW.State.to(TorchSharp.torch.Device)">
            <summary>
            Move all the state to the indicated device.
            </summary>
            <param name="device">The device to move all state to.</param>
        </member>
        <member name="M:TorchSharp.Modules.AdamW.State.LoadStateDict(System.IO.BinaryReader)">
            <summary>
            Load the optimizer parameter state from a stream.
            </summary>
            <param name="reader">A binary reader connected to a stream open for reading.</param>
        </member>
        <member name="M:TorchSharp.Modules.AdamW.State.SaveStateDict(System.IO.BinaryWriter)">
            <summary>
            Save the optimizer parameter state to a stream.
            </summary>
            <param name="writer">A binary writer connected to a stream open for writing.</param>
        </member>
        <member name="M:TorchSharp.Modules.AdamW.State.LoadStateDict(TorchSharp.Modules.OptimizerState)">
            <summary>
            Load optimizer parameter state from another optimizer.
            </summary>
            <param name="source">An optimizer state record.</param>
        </member>
        <member name="M:TorchSharp.Modules.AdamW.State.Initialize(TorchSharp.Modules.OptimizerOptions)">
            <summary>
            Initialize the values of the state to the initial values.
            </summary>
            <param name="options">The optimizer options</param>
        </member>
        <member name="M:TorchSharp.Modules.AdamW.add_param_group(TorchSharp.Modules.ParamGroup)">
            <summary>
            Add a param group to the Optimizer s param_groups.
            </summary>
            <param name="param_group"></param>
            <remarks>This can be useful when fine tuning a pre-trained network as frozen layers can be made trainable and added to the Optimizer as training progresses.</remarks>
        </member>
        <member name="M:TorchSharp.Modules.AdamW.Options.LoadStateDict(TorchSharp.Modules.OptimizerOptions)">
            <summary>
            Load optimizer options (param-group hyperparameters) from another optimizer.
            </summary>
            <param name="source">An optimizer options record.</param>
        </member>
        <member name="M:TorchSharp.Modules.AdamW.Options.LoadStateDict(System.IO.BinaryReader)">
            <summary>
            Load the optimizer options (param-group hyperparameters) from a stream.
            </summary>
            <param name="reader">A binary reader connected to a stream open for reading.</param>
        </member>
        <member name="M:TorchSharp.Modules.AdamW.Options.SaveStateDict(System.IO.BinaryWriter)">
            <summary>
            Save the optimizer options (param-group hyperparameters) to a stream.
            </summary>
            <param name="writer">A binary writer connected to a stream open for writing.</param>
        </member>
        <member name="M:TorchSharp.Modules.ASGD.#ctor(System.Collections.Generic.IEnumerable{TorchSharp.Modules.Parameter},System.Double,System.Double,System.Double,System.Double,System.Double,System.Boolean)">
             <summary>
             Implements ASGD algorithm (a variant of Adam based on infinity norm).
            
             It has been proposed in Adam: A Method for Stochastic Optimization.
             </summary>
             <param name="parameters">Parameters to optimize. This optimizer requires the <b>named</b> parameters collection.</param>
             <param name="lr ">Learning rate</param>
             <param name="lambd">Decay term (default: 1e-4)</param>
             <param name="alpha">Power for eta update (default: 0.75)</param>
             <param name="t0">Point at which to start averaging (default: 1e6)</param>
             <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
             <param name="maximize">Maximize the params based on the objective, instead of minimizing.</param>
        </member>
        <member name="M:TorchSharp.Modules.ASGD.#ctor(System.Collections.Generic.IEnumerable{TorchSharp.Modules.ParamGroup{TorchSharp.Modules.ASGD.Options}},System.Double,System.Double,System.Double,System.Double,System.Double,System.Boolean)">
             <summary>
             Implements ASGD algorithm (a variant of Adam based on infinity norm).
            
             It has been proposed in Adam: A Method for Stochastic Optimization.
             </summary>
             <param name="parameters">Parameters to optimize. This optimizer requires the <b>named</b> parameters collection.</param>
             <param name="lr ">Learning rate</param>
             <param name="lambd">Decay term (default: 1e-4)</param>
             <param name="alpha">Power for eta update (default: 0.75)</param>
             <param name="t0">Point at which to start averaging (default: 1e6)</param>
             <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
             <param name="maximize">Maximize the params based on the objective, instead of minimizing.</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.ASGD.step(System.Func{TorchSharp.torch.Tensor})">
            <summary>
            Performs a single optimization step (parameter update).
            </summary>
            <param name="closure">A closure that reevaluates the model and returns the loss. Optional for most optimizers.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.ASGD.State.to(TorchSharp.torch.Device)">
            <summary>
            Move all the state to the indicated device.
            </summary>
            <param name="device">The device to move all state to.</param>
        </member>
        <member name="M:TorchSharp.Modules.ASGD.State.LoadStateDict(System.IO.BinaryReader)">
            <summary>
            Load the optimizer parameter state from a stream.
            </summary>
            <param name="reader">A binary reader connected to a stream open for reading.</param>
        </member>
        <member name="M:TorchSharp.Modules.ASGD.State.LoadStateDict(TorchSharp.Modules.OptimizerState)">
            <summary>
            Load optimizer parameter state from another optimizer.
            </summary>
            <param name="source">An optimizer state record.</param>
        </member>
        <member name="M:TorchSharp.Modules.ASGD.State.SaveStateDict(System.IO.BinaryWriter)">
            <summary>
            Save the optimizer parameter state to a stream.
            </summary>
            <param name="writer">A binary writer connected to a stream open for writing.</param>
        </member>
        <member name="M:TorchSharp.Modules.ASGD.State.ApproximatelyEquals(TorchSharp.Modules.OptimizerState)">
            <summary>
            Useful for tests, allows comparison of one state with another.
            </summary>
            <param name="other">The other optimizer state</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.ASGD.State.Initialize(TorchSharp.Modules.OptimizerOptions)">
            <summary>
            Initialize the values of the state to the initial values.
            </summary>
            <param name="options">The optimizer options</param>
        </member>
        <member name="M:TorchSharp.Modules.ASGD.add_param_group(TorchSharp.Modules.ParamGroup)">
            <summary>
            Add a param group to the Optimizer s param_groups.
            </summary>
            <param name="param_group"></param>
            <remarks>This can be useful when fine tuning a pre-trained network as frozen layers can be made trainable and added to the Optimizer as training progresses.</remarks>
        </member>
        <member name="M:TorchSharp.Modules.ASGD.Options.LoadStateDict(TorchSharp.Modules.OptimizerOptions)">
            <summary>
            Load optimizer options (param-group hyperparameters) from another optimizer.
            </summary>
            <param name="source">An optimizer options record.</param>
        </member>
        <member name="M:TorchSharp.Modules.ASGD.Options.LoadStateDict(System.IO.BinaryReader)">
            <summary>
            Load the optimizer options (param-group hyperparameters) from a stream.
            </summary>
            <param name="reader">A binary reader connected to a stream open for reading.</param>
        </member>
        <member name="M:TorchSharp.Modules.ASGD.Options.SaveStateDict(System.IO.BinaryWriter)">
            <summary>
            Save the optimizer options (param-group hyperparameters) to a stream.
            </summary>
            <param name="writer">A binary writer connected to a stream open for writing.</param>
        </member>
        <member name="M:TorchSharp.Modules.LBFGS.#ctor(System.IntPtr,System.Double)">
             <summary>
             Implements L-BFGS algorithm, heavily inspired by `minFunc`
            
             </summary>
             <param name="handle"></param>
             <param name="lr"></param>
        </member>
        <member name="M:TorchSharp.Modules.LBFGS.step(System.Func{TorchSharp.torch.Tensor})">
            <summary>
            Performs a single optimization step (parameter update).
            </summary>
            <param name="closure">A closure that reevaluates the model and returns the loss. Optional for most optimizers.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.NAdam.#ctor(System.Collections.Generic.IEnumerable{TorchSharp.Modules.Parameter},System.Double,System.Double,System.Double,System.Double,System.Double,System.Double)">
             <summary>
             Implements NAdam algorithm.
            
             For further details regarding the algorithm we refer to Incorporating Nesterov Momentum into Adam.
             https://openreview.net/forum?id=OM0jvwB8jIp57ZJjtNEZ
             </summary>
             <param name="parameters">Parameters to optimize. This optimizer requires the <b>named</b> parameters collection.</param>
             <param name="lr ">Learning rate</param>
             <param name="beta1">Coefficient used for computing running averages of gradient and its square (default: 0.9)</param>
             <param name="beta2">Coefficient used for computing running averages of gradient and its square (default: 0.999)</param>
             <param name="eps">Term added to the denominator to improve numerical stability, i.e. avoid division-by-zero (default: 1e-8)</param>
             <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
             <param name="momentum_decay">Momentum decay</param>
        </member>
        <member name="M:TorchSharp.Modules.NAdam.#ctor(System.Collections.Generic.IEnumerable{TorchSharp.Modules.NAdam.ParamGroup},System.Double,System.Double,System.Double,System.Double,System.Double,System.Double)">
             <summary>
             Implements NAdam algorithm.
            
             For further details regarding the algorithm we refer to Incorporating Nesterov Momentum into Adam.
             https://openreview.net/forum?id=OM0jvwB8jIp57ZJjtNEZ
             </summary>
             <param name="parameters">Parameters to optimize. This optimizer requires the <b>named</b> parameters collection.</param>
             <param name="lr ">Learning rate</param>
             <param name="beta1">Coefficient used for computing running averages of gradient and its square (default: 0.9)</param>
             <param name="beta2">Coefficient used for computing running averages of gradient and its square (default: 0.999)</param>
             <param name="eps">Term added to the denominator to improve numerical stability, i.e. avoid division-by-zero (default: 1e-8)</param>
             <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
             <param name="momentum_decay">Momentum decay</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.NAdam.step(System.Func{TorchSharp.torch.Tensor})">
            <summary>
            Performs a single optimization step (parameter update).
            </summary>
            <param name="closure">A closure that reevaluates the model and returns the loss. Optional for most optimizers.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.NAdam.State.to(TorchSharp.torch.Device)">
            <summary>
            Move all the state to the indicated device.
            </summary>
            <param name="device">The device to move all state to.</param>
        </member>
        <member name="M:TorchSharp.Modules.NAdam.State.LoadStateDict(System.IO.BinaryReader)">
            <summary>
            Load the optimizer parameter state from a stream.
            </summary>
            <param name="reader">A binary reader connected to a stream open for reading.</param>
        </member>
        <member name="M:TorchSharp.Modules.NAdam.State.SaveStateDict(System.IO.BinaryWriter)">
            <summary>
            Save the optimizer parameter state to a stream.
            </summary>
            <param name="writer">A binary writer connected to a stream open for writing.</param>
        </member>
        <member name="M:TorchSharp.Modules.NAdam.State.LoadStateDict(TorchSharp.Modules.OptimizerState)">
            <summary>
            Load optimizer parameter state from another optimizer.
            </summary>
            <param name="source">An optimizer state record.</param>
        </member>
        <member name="M:TorchSharp.Modules.NAdam.State.ApproximatelyEquals(TorchSharp.Modules.OptimizerState)">
            <summary>
            Useful for tests, allows comparison of one state with another.
            </summary>
            <param name="other">The other optimizer state</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.NAdam.State.Initialize(TorchSharp.Modules.OptimizerOptions)">
            <summary>
            Initialize the values of the state to the initial values.
            </summary>
            <param name="options">The optimizer options</param>
        </member>
        <member name="M:TorchSharp.Modules.NAdam.add_param_group(TorchSharp.Modules.ParamGroup)">
            <summary>
            Add a param group to the Optimizer s param_groups.
            </summary>
            <param name="param_group"></param>
            <remarks>This can be useful when fine tuning a pre-trained network as frozen layers can be made trainable and added to the Optimizer as training progresses.</remarks>
        </member>
        <member name="M:TorchSharp.Modules.NAdam.Options.LoadStateDict(TorchSharp.Modules.OptimizerOptions)">
            <summary>
            Load optimizer options (param-group hyperparameters) from another optimizer.
            </summary>
            <param name="source">An optimizer options record.</param>
        </member>
        <member name="M:TorchSharp.Modules.NAdam.Options.LoadStateDict(System.IO.BinaryReader)">
            <summary>
            Load the optimizer options (param-group hyperparameters) from a stream.
            </summary>
            <param name="reader">A binary reader connected to a stream open for reading.</param>
        </member>
        <member name="M:TorchSharp.Modules.NAdam.Options.SaveStateDict(System.IO.BinaryWriter)">
            <summary>
            Save the optimizer options (param-group hyperparameters) to a stream.
            </summary>
            <param name="writer">A binary writer connected to a stream open for writing.</param>
        </member>
        <member name="T:TorchSharp.Modules.OptimizerHelper">
            <summary>
            Base class to help with a couple of the things that managed-code implementations need.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.OptimizerHelper.save_state_dict(System.String)">
            <summary>
            Saves the optimizer state.
            </summary>
            <param name="location">The name of a file where optimizer state data will be stored.</param>
        </member>
        <member name="M:TorchSharp.Modules.OptimizerHelper.load_state_dict(System.String)">
            <summary>
            Loads the optimizer state.
            </summary>
            <param name="location">The name of a file where optimizer state data is stored.</param>
            <remarks>
            Optimizer state saved from PyTorch cannot be restored -- the file format is unique to TorchSharp.
            </remarks>
        </member>
        <member name="M:TorchSharp.Modules.OptimizerHelper.save_state_dict(System.IO.BinaryWriter)">
            <summary>
            Saves the optimizer state.
            </summary>
            <param name="writer">A binary writer connected to a stream where .</param>
        </member>
        <member name="M:TorchSharp.Modules.OptimizerHelper.load_state_dict(System.IO.BinaryReader)">
            <summary>
            Loads the optimizer state.
            </summary>
            <param name="reader">A binary reader connected to a stream containing saved optimizer state.</param>
            <remarks>
            Optimizer state saved from PyTorch cannot be restored -- the file format is unique to TorchSharp.
            </remarks>
        </member>
        <member name="M:TorchSharp.Modules.OptimizerHelper.load_state_dict(TorchSharp.torch.optim.Optimizer.StateDictionary)">
            <summary>
            Loads the optimizer state.
            </summary>
            <param name="state_dict">Optimizer state. Should be an object returned from a call to state_dict().</param>
            <remarks>
            The format of the optimizer state dict is different from PyTorch's. Instead of a dictionary with two entries,
            the state is represented as record with two entries, both containing lists with state.
            </remarks>
        </member>
        <member name="M:TorchSharp.Modules.OptimizerHelper.state_dict">
            <summary>
            Returns the state of the optimizer as a dict.
            </summary>
            <returns></returns>
            <remarks>
            The format of the optimizer state dict is different from PyTorch's. Instead of a dictionary with two entries,
            the state is represented as record with two entries, both containing lists with state.
            </remarks>
        </member>
        <member name="M:TorchSharp.Modules.OptimizerHelper.to(TorchSharp.torch.Device)">
            <summary>
            Move all the state to the indicated device.
            </summary>
            <param name="device">The device to move all state to.</param>
        </member>
        <member name="M:TorchSharp.Modules.OptimizerHelper.zero_grad">
            <summary>
            Sets the gradients of all parameters to zero.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.OptimizerHelper._step``1(System.Action{``0},System.Func{TorchSharp.torch.Tensor})">
            <summary>
            Support routine for implementation of step() in all optimizers that support parameter groups.
            </summary>
            <typeparam name="T">The ParamGroup type in use</typeparam>
            <param name="body">The body of the step update.</param>
            <param name="loss_closure">The closure, if any, for computing the loss.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.OptimizerHelper.parameters">
            <summary>
            Get the parameters that the optimizer is handling.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.OptimizerHelper.add_param_group(TorchSharp.Modules.ParamGroup)">
            <summary>
            Add a param group to the Optimizer s param_groups.
            </summary>
            <param name="param_group"></param>
            <remarks>This can be useful when fine tuning a pre-trained network as frozen layers can be made trainable and added to the Optimizer as training progresses.</remarks>
        </member>
        <member name="T:TorchSharp.Modules.OptimizerOptions">
            <summary>
            Base class for optimizer options.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.OptimizerOptions.SaveStateDict(System.IO.BinaryWriter)">
            <summary>
            Save the optimizer options (param-group hyperparameters) to a stream.
            </summary>
            <param name="writer">A binary writer connected to a stream open for writing.</param>
        </member>
        <member name="M:TorchSharp.Modules.OptimizerOptions.LoadStateDict(System.IO.BinaryReader)">
            <summary>
            Load the optimizer options (param-group hyperparameters) from a stream.
            </summary>
            <param name="reader">A binary reader connected to a stream open for reading.</param>
        </member>
        <member name="M:TorchSharp.Modules.OptimizerOptions.LoadStateDict(TorchSharp.Modules.OptimizerOptions)">
            <summary>
            Load optimizer options (param-group hyperparameters) from another optimizer.
            </summary>
            <param name="source">An optimizer options record.</param>
        </member>
        <member name="T:TorchSharp.Modules.OptimizerState">
            <summary>
            Base class for optimizer options.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.OptimizerState.#ctor(TorchSharp.Modules.Parameter)">
            <summary>
            Create a new OptimizerState instance linked to a specific parameter
            </summary>
            <param name="parameter">The parameter linked to this state</param>
        </member>
        <member name="M:TorchSharp.Modules.OptimizerState.SaveStateDict(System.IO.BinaryWriter)">
            <summary>
            Save the optimizer parameter state to a stream.
            </summary>
            <param name="writer">A binary writer connected to a stream open for writing.</param>
        </member>
        <member name="M:TorchSharp.Modules.OptimizerState.LoadStateDict(System.IO.BinaryReader)">
            <summary>
            Load the optimizer parameter state from a stream.
            </summary>
            <param name="reader">A binary reader connected to a stream open for reading.</param>
        </member>
        <member name="M:TorchSharp.Modules.OptimizerState.LoadStateDict(TorchSharp.Modules.OptimizerState)">
            <summary>
            Load optimizer parameter state from another optimizer.
            </summary>
            <param name="source">An optimizer state record.</param>
        </member>
        <member name="M:TorchSharp.Modules.OptimizerState.ApproximatelyEquals(TorchSharp.Modules.OptimizerState)">
            <summary>
            Useful for tests, allows comparison of one state with another.
            </summary>
            <param name="other">The other optimizer state</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.OptimizerState.Initialize(TorchSharp.Modules.OptimizerOptions)">
            <summary>
            Initialize the values of the state to the initial values.
            </summary>
            <param name="options">The optimizer options</param>
        </member>
        <member name="M:TorchSharp.Modules.OptimizerState.to(TorchSharp.torch.Device)">
            <summary>
            Move all the state to the indicated device.
            </summary>
            <param name="device">The device to move all state to.</param>
        </member>
        <member name="T:TorchSharp.Modules.ParamGroup">
            <summary>
            Base class for parameter groups
            </summary>
        </member>
        <member name="T:TorchSharp.Modules.ParamGroup`1">
            <summary>
            Generic-typed version of ParamGroup
            </summary>
            <typeparam name="TOptions">The type of options used for the parameter group.</typeparam>
        </member>
        <member name="M:TorchSharp.Modules.ParamGroup`1.#ctor">
            <summary>
            Constructor
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.ParamGroup`1.#ctor(System.Collections.Generic.IEnumerable{TorchSharp.Modules.Parameter},`0)">
            <summary>
            Constructor
            </summary>
            <param name="parameters">The parameters of the parameter group</param>
            <param name="options">The options of the parameter group</param>
        </member>
        <member name="P:TorchSharp.Modules.ParamGroup`1.Options">
            <summary>
            Parameter group options / hyperparameters, used to control the optimizer algorithm.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.RAdam.#ctor(System.Collections.Generic.IEnumerable{TorchSharp.Modules.Parameter},System.Double,System.Double,System.Double,System.Double,System.Double)">
             <summary>
             Implements RAdam algorithm.
            
             For further details regarding the algorithm we refer to 'On the variance of the adaptive learning rate and beyond.'
             https://arxiv.org/abs/1908.03265
             </summary>
             <param name="parameters">Parameters to optimize. This optimizer requires the <b>named</b> parameters collection.</param>
             <param name="lr ">Learning rate</param>
             <param name="beta1">Coefficient used for computing running averages of gradient and its square (default: 0.9)</param>
             <param name="beta2">Coefficient used for computing running averages of gradient and its square (default: 0.999)</param>
             <param name="eps">Term added to the denominator to improve numerical stability, i.e. avoid division-by-zero (default: 1e-8)</param>
             <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.RAdam.#ctor(System.Collections.Generic.IEnumerable{TorchSharp.Modules.RAdam.ParamGroup},System.Double,System.Double,System.Double,System.Double,System.Double)">
             <summary>
             Implements RAdam algorithm.
            
             For further details regarding the algorithm we refer to 'On the variance of the adaptive learning rate and beyond.'
             https://arxiv.org/abs/1908.03265
             </summary>
             <param name="parameters">Parameters to optimize. This optimizer requires the <b>named</b> parameters collection.</param>
             <param name="lr ">Learning rate</param>
             <param name="beta1">Coefficient used for computing running averages of gradient and its square (default: 0.9)</param>
             <param name="beta2">Coefficient used for computing running averages of gradient and its square (default: 0.999)</param>
             <param name="eps">Term added to the denominator to improve numerical stability, i.e. avoid division-by-zero (default: 1e-8)</param>
             <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.RAdam.step(System.Func{TorchSharp.torch.Tensor})">
            <summary>
            Performs a single optimization step (parameter update).
            </summary>
            <param name="closure">A closure that reevaluates the model and returns the loss. Optional for most optimizers.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.RAdam.State.to(TorchSharp.torch.Device)">
            <summary>
            Move all the state to the indicated device.
            </summary>
            <param name="device">The device to move all state to.</param>
        </member>
        <member name="M:TorchSharp.Modules.RAdam.State.LoadStateDict(System.IO.BinaryReader)">
            <summary>
            Load the optimizer parameter state from a stream.
            </summary>
            <param name="reader">A binary reader connected to a stream open for reading.</param>
        </member>
        <member name="M:TorchSharp.Modules.RAdam.State.SaveStateDict(System.IO.BinaryWriter)">
            <summary>
            Save the optimizer parameter state to a stream.
            </summary>
            <param name="writer">A binary writer connected to a stream open for writing.</param>
        </member>
        <member name="M:TorchSharp.Modules.RAdam.State.LoadStateDict(TorchSharp.Modules.OptimizerState)">
            <summary>
            Load optimizer parameter state from another optimizer.
            </summary>
            <param name="source">An optimizer state record.</param>
        </member>
        <member name="M:TorchSharp.Modules.RAdam.State.ApproximatelyEquals(TorchSharp.Modules.OptimizerState)">
            <summary>
            Useful for tests, allows comparison of one state with another.
            </summary>
            <param name="other">The other optimizer state</param>
        </member>
        <member name="M:TorchSharp.Modules.RAdam.State.Initialize(TorchSharp.Modules.OptimizerOptions)">
            <summary>
            Initialize the values of the state to the initial values.
            </summary>
            <param name="options">The optimizer options</param>
        </member>
        <member name="M:TorchSharp.Modules.RAdam.add_param_group(TorchSharp.Modules.ParamGroup)">
            <summary>
            Add a param group to the Optimizer s param_groups.
            </summary>
            <param name="param_group"></param>
            <remarks>This can be useful when fine tuning a pre-trained network as frozen layers can be made trainable and added to the Optimizer as training progresses.</remarks>
        </member>
        <member name="M:TorchSharp.Modules.RAdam.Options.LoadStateDict(TorchSharp.Modules.OptimizerOptions)">
            <summary>
            Load optimizer options (param-group hyperparameters) from another optimizer.
            </summary>
            <param name="source">An optimizer options record.</param>
        </member>
        <member name="M:TorchSharp.Modules.RAdam.Options.LoadStateDict(System.IO.BinaryReader)">
            <summary>
            Load the optimizer options (param-group hyperparameters) from a stream.
            </summary>
            <param name="reader">A binary reader connected to a stream open for reading.</param>
        </member>
        <member name="M:TorchSharp.Modules.RAdam.Options.SaveStateDict(System.IO.BinaryWriter)">
            <summary>
            Save the optimizer options (param-group hyperparameters) to a stream.
            </summary>
            <param name="writer">A binary writer connected to a stream open for writing.</param>
        </member>
        <member name="M:TorchSharp.Modules.RMSProp.#ctor(System.Collections.Generic.IEnumerable{TorchSharp.Modules.Parameter},System.Double,System.Double,System.Double,System.Double,System.Double,System.Boolean,System.Boolean)">
             <summary>
             Implements RMSprop algorithm.
            
             Proposed by G.Hinton in his course.
             </summary>
             <param name="parameters">Parameters to optimize. This optimizer requires the parameters collection.</param>
             <param name="lr">Learning rate</param>
             <param name="alpha">Smoothing constant.</param>
             <param name="momentum">Momentum factor (default: 0)</param>
             <param name="eps">Term added to the denominator to improve numerical stability</param>
             <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
             <param name="centered">if ``True``, compute the centered RMSProp, the gradient is normalized by an estimation of its variance</param>
             <param name="maximize">Maximize the params based on the objective, instead of minimizing.</param>
        </member>
        <member name="M:TorchSharp.Modules.RMSProp.#ctor(System.Collections.Generic.IEnumerable{TorchSharp.Modules.RMSProp.ParamGroup},System.Double,System.Double,System.Double,System.Double,System.Double,System.Boolean,System.Boolean)">
             <summary>
             Implements RMSprop algorithm.
            
             Proposed by G.Hinton in his course.
             </summary>
             <param name="parameters">Parameters to optimize. This optimizer requires the parameters collection.</param>
             <param name="lr">Learning rate</param>
             <param name="alpha">Smoothing constant.</param>
             <param name="momentum">Momentum factor (default: 0)</param>
             <param name="eps">Term added to the denominator to improve numerical stability</param>
             <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
             <param name="centered">if ``True``, compute the centered RMSProp, the gradient is normalized by an estimation of its variance</param>
             <param name="maximize">Maximize the params based on the objective, instead of minimizing.</param>
        </member>
        <member name="M:TorchSharp.Modules.RMSProp.step(System.Func{TorchSharp.torch.Tensor})">
            <summary>
            Performs a single optimization step (parameter update).
            </summary>
            <param name="closure">A closure that reevaluates the model and returns the loss. Optional for most optimizers.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.RMSProp.State.to(TorchSharp.torch.Device)">
            <summary>
            Move all the state to the indicated device.
            </summary>
            <param name="device">The device to move all state to.</param>
        </member>
        <member name="M:TorchSharp.Modules.RMSProp.State.LoadStateDict(System.IO.BinaryReader)">
            <summary>
            Load the optimizer parameter state from a stream.
            </summary>
            <param name="reader">A binary reader connected to a stream open for reading.</param>
        </member>
        <member name="M:TorchSharp.Modules.RMSProp.State.SaveStateDict(System.IO.BinaryWriter)">
            <summary>
            Save the optimizer parameter state to a stream.
            </summary>
            <param name="writer">A binary writer connected to a stream open for writing.</param>
        </member>
        <member name="M:TorchSharp.Modules.RMSProp.State.LoadStateDict(TorchSharp.Modules.OptimizerState)">
            <summary>
            Load optimizer parameter state from another optimizer.
            </summary>
            <param name="source">An optimizer state record.</param>
        </member>
        <member name="M:TorchSharp.Modules.RMSProp.State.ApproximatelyEquals(TorchSharp.Modules.OptimizerState)">
            <summary>
            Useful for tests, allows comparison of one state with another.
            </summary>
            <param name="other">The other optimizer state</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.RMSProp.State.Initialize(TorchSharp.Modules.OptimizerOptions)">
            <summary>
            Initialize the values of the state to the initial values.
            </summary>
            <param name="options">The optimizer options</param>
        </member>
        <member name="M:TorchSharp.Modules.RMSProp.add_param_group(TorchSharp.Modules.ParamGroup)">
            <summary>
            Add a param group to the Optimizer s param_groups.
            </summary>
            <param name="param_group"></param>
            <remarks>This can be useful when fine tuning a pre-trained network as frozen layers can be made trainable and added to the Optimizer as training progresses.</remarks>
        </member>
        <member name="M:TorchSharp.Modules.RMSProp.Options.LoadStateDict(TorchSharp.Modules.OptimizerOptions)">
            <summary>
            Load optimizer options (param-group hyperparameters) from another optimizer.
            </summary>
            <param name="source">An optimizer options record.</param>
        </member>
        <member name="M:TorchSharp.Modules.RMSProp.Options.LoadStateDict(System.IO.BinaryReader)">
            <summary>
            Load the optimizer options (param-group hyperparameters) from a stream.
            </summary>
            <param name="reader">A binary reader connected to a stream open for reading.</param>
        </member>
        <member name="M:TorchSharp.Modules.RMSProp.Options.SaveStateDict(System.IO.BinaryWriter)">
            <summary>
            Save the optimizer options (param-group hyperparameters) to a stream.
            </summary>
            <param name="writer">A binary writer connected to a stream open for writing.</param>
        </member>
        <member name="M:TorchSharp.Modules.Rprop.#ctor(System.Collections.Generic.IEnumerable{TorchSharp.Modules.Parameter},System.Double,System.Double,System.Double,System.Double,System.Double,System.Boolean)">
             <summary>
             Implements Rprop algorithm (a variant of Adam based on infinity norm).
            
             It has been proposed in Adam: A Method for Stochastic Optimization.
             </summary>
             <param name="parameters">Parameters to optimize.</param>
             <param name="lr ">Learning rate</param>
             <param name="etaminus">Multiplicative increase factor.</param>
             <param name="etaplus">Multiplicative decrease factor.</param>
             <param name="min_step">Minimum allowed step size.</param>
             <param name="max_step">Maximum allowed step size.</param>
             <param name="maximize">Maximize the params based on the objective, instead of minimizing.</param>
        </member>
        <member name="M:TorchSharp.Modules.Rprop.#ctor(System.Collections.Generic.IEnumerable{TorchSharp.Modules.Rprop.ParamGroup},System.Double,System.Double,System.Double,System.Double,System.Double,System.Boolean)">
             <summary>
             Implements Rprop algorithm (a variant of Adam based on infinity norm).
            
             It has been proposed in Adam: A Method for Stochastic Optimization.
             </summary>
             <param name="parameters">Parameters to optimize.</param>
             <param name="lr ">Learning rate</param>
             <param name="etaminus">Multiplicative increase factor.</param>
             <param name="etaplus">Multiplicative decrease factor.</param>
             <param name="min_step">Minimum allowed step size.</param>
             <param name="max_step">Maximum allowed step size.</param>
             <param name="maximize">Maximize the params based on the objective, instead of minimizing.</param>
        </member>
        <member name="M:TorchSharp.Modules.Rprop.step(System.Func{TorchSharp.torch.Tensor})">
            <summary>
            Performs a single optimization step (parameter update).
            </summary>
            <param name="closure">A closure that reevaluates the model and returns the loss. Optional for most optimizers.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.Rprop.add_param_group(TorchSharp.Modules.ParamGroup)">
            <summary>
            Add a param group to the Optimizer s param_groups.
            </summary>
            <param name="param_group"></param>
            <remarks>This can be useful when fine tuning a pre-trained network as frozen layers can be made trainable and added to the Optimizer as training progresses.</remarks>
        </member>
        <member name="M:TorchSharp.Modules.Rprop.State.to(TorchSharp.torch.Device)">
            <summary>
            Move all the state to the indicated device.
            </summary>
            <param name="device">The device to move all state to.</param>
        </member>
        <member name="M:TorchSharp.Modules.Rprop.State.LoadStateDict(System.IO.BinaryReader)">
            <summary>
            Load the optimizer parameter state from a stream.
            </summary>
            <param name="reader">A binary reader connected to a stream open for reading.</param>
        </member>
        <member name="M:TorchSharp.Modules.Rprop.State.SaveStateDict(System.IO.BinaryWriter)">
            <summary>
            Save the optimizer parameter state to a stream.
            </summary>
            <param name="writer">A binary writer connected to a stream open for writing.</param>
        </member>
        <member name="M:TorchSharp.Modules.Rprop.State.LoadStateDict(TorchSharp.Modules.OptimizerState)">
            <summary>
            Load optimizer parameter state from another optimizer.
            </summary>
            <param name="source">An optimizer state record.</param>
        </member>
        <member name="M:TorchSharp.Modules.Rprop.State.ApproximatelyEquals(TorchSharp.Modules.OptimizerState)">
            <summary>
            Useful for tests, allows comparison of one state with another.
            </summary>
            <param name="other">The other optimizer state</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.Rprop.State.Initialize(TorchSharp.Modules.OptimizerOptions)">
            <summary>
            Initialize the values of the state to the initial values.
            </summary>
            <param name="options">The optimizer options</param>
        </member>
        <member name="M:TorchSharp.Modules.Rprop.Options.SaveStateDict(System.IO.BinaryWriter)">
            <summary>
            Save the optimizer options (param-group hyperparameters) to a stream.
            </summary>
            <param name="writer">A binary writer connected to a stream open for writing.</param>
        </member>
        <member name="M:TorchSharp.Modules.Rprop.Options.LoadStateDict(System.IO.BinaryReader)">
            <summary>
            Load the optimizer options (param-group hyperparameters) from a stream.
            </summary>
            <param name="reader">A binary reader connected to a stream open for reading.</param>
        </member>
        <member name="M:TorchSharp.Modules.Rprop.Options.LoadStateDict(TorchSharp.Modules.OptimizerOptions)">
            <summary>
            Load optimizer options (param-group hyperparameters) from another optimizer.
            </summary>
            <param name="source">An optimizer options record.</param>
        </member>
        <member name="M:TorchSharp.Modules.SGD.#ctor(System.Collections.Generic.IEnumerable{TorchSharp.Modules.Parameter},System.Double,System.Double,System.Double,System.Double,System.Boolean,System.Boolean)">
            <summary>
            Implements stochastic gradient descent (optionally with momentum).
            </summary>
            <param name="parameters">Parameters to optimize. This optimizer requires the <b>named</b> parameters collection.</param>
            <param name="lr">Learning rate</param>
            <param name="momentum">Momentum factor (default: 0)</param>
            <param name="dampening">Dampening for momentum (default: 0)</param>
            <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
            <param name="nesterov">Enables Nesterov momentum (default: False)</param>
            <param name="maximize"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.SGD.#ctor(System.Collections.Generic.IEnumerable{TorchSharp.Modules.SGD.ParamGroup},System.Double,System.Double,System.Double,System.Double,System.Boolean,System.Boolean)">
            <summary>
            Implements stochastic gradient descent (optionally with momentum).
            </summary>
            <param name="parameters">Parameters to optimize. This optimizer requires the <b>named</b> parameters collection.</param>
            <param name="lr">Learning rate</param>
            <param name="momentum">Momentum factor (default: 0)</param>
            <param name="dampening">Dampening for momentum (default: 0)</param>
            <param name="weight_decay">Weight decay (L2 penalty) (default: 0)</param>
            <param name="nesterov">Enables Nesterov momentum (default: False)</param>
            <param name="maximize"></param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.SGD.step(System.Func{TorchSharp.torch.Tensor})">
            <summary>
            Performs a single optimization step (parameter update).
            </summary>
            <param name="closure">A closure that reevaluates the model and returns the loss. Optional for most optimizers.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.SGD.State.to(TorchSharp.torch.Device)">
            <summary>
            Move all the state to the indicated device.
            </summary>
            <param name="device">The device to move all state to.</param>
        </member>
        <member name="M:TorchSharp.Modules.SGD.State.LoadStateDict(System.IO.BinaryReader)">
            <summary>
            Load the optimizer parameter state from a stream.
            </summary>
            <param name="reader">A binary reader connected to a stream open for reading.</param>
        </member>
        <member name="M:TorchSharp.Modules.SGD.State.SaveStateDict(System.IO.BinaryWriter)">
            <summary>
            Save the optimizer parameter state to a stream.
            </summary>
            <param name="writer">A binary writer connected to a stream open for writing.</param>
        </member>
        <member name="M:TorchSharp.Modules.SGD.State.LoadStateDict(TorchSharp.Modules.OptimizerState)">
            <summary>
            Load optimizer parameter state from another optimizer.
            </summary>
            <param name="source">An optimizer state record.</param>
        </member>
        <member name="M:TorchSharp.Modules.SGD.State.ApproximatelyEquals(TorchSharp.Modules.OptimizerState)">
            <summary>
            Useful for tests, allows comparison of one state with another.
            </summary>
            <param name="other">The other optimizer state</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Modules.SGD.State.Initialize(TorchSharp.Modules.OptimizerOptions)">
            <summary>
            Initialize the values of the state to the initial values.
            </summary>
            <param name="options">The optimizer options</param>
        </member>
        <member name="M:TorchSharp.Modules.SGD.add_param_group(TorchSharp.Modules.ParamGroup)">
            <summary>
            Add a param group to the Optimizer s param_groups.
            </summary>
            <param name="param_group"></param>
            <remarks>This can be useful when fine tuning a pre-trained network as frozen layers can be made trainable and added to the Optimizer as training progresses.</remarks>
        </member>
        <member name="M:TorchSharp.Modules.SGD.Options.LoadStateDict(System.IO.BinaryReader)">
            <summary>
            Load the optimizer options (param-group hyperparameters) from a stream.
            </summary>
            <param name="reader">A binary reader connected to a stream open for reading.</param>
        </member>
        <member name="M:TorchSharp.Modules.SGD.Options.LoadStateDict(TorchSharp.Modules.OptimizerOptions)">
            <summary>
            Load optimizer options (param-group hyperparameters) from another optimizer.
            </summary>
            <param name="source">An optimizer options record.</param>
        </member>
        <member name="M:TorchSharp.Modules.SGD.Options.SaveStateDict(System.IO.BinaryWriter)">
            <summary>
            Save the optimizer options (param-group hyperparameters) to a stream.
            </summary>
            <param name="writer">A binary writer connected to a stream open for writing.</param>
        </member>
        <member name="T:TorchSharp.Modules.SummaryWriter">
             <summary>
             Writes entries directly to event files in the log_dir to be consumed by TensorBoard.
             
             The SummaryWriter class provides a high-level API to create an event file in a given directory and add summaries and events to it.The class updates the file contents asynchronously.
            
             This allows a training program to call methods to add data to the file directly from the training loop, without slowing down training.
             </summary>
        </member>
        <member name="P:TorchSharp.Modules.SummaryWriter.LogDir">
            <summary>
            The directory/folder where logging is made.
            </summary>
        </member>
        <member name="M:TorchSharp.Modules.SummaryWriter.add_scalar(System.String,System.Single,System.Int32,System.Nullable{System.Int64})">
            <summary>
            Add scalar data to summary.
            </summary>
            <param name="tag">Data identifier</param>
            <param name="scalar_value">Value to save</param>
            <param name="global_step">Global step value to record</param>
            <param name="walltime">Optional override default walltime (DateTimeOffset.Now.ToUnixTimeSeconds())</param>
        </member>
        <member name="M:TorchSharp.Modules.SummaryWriter.add_scalars(System.String,System.Collections.Generic.IDictionary{System.String,System.Single},System.Int32,System.Nullable{System.Int64})">
            <summary>
            Adds many scalar data points to summary.
            </summary>
            <param name="main_tag">Data identifier</param>
            <param name="tag_scalar_dict">Dictionary storing the tag and corresponding values</param>
            <param name="global_step">Global step value to record</param>
            <param name="walltime">Optional override default walltime (DateTimeOffset.Now.ToUnixTimeSeconds())</param>
        </member>
        <member name="M:TorchSharp.Modules.SummaryWriter.add_scalars(System.String,System.Collections.Generic.IList{System.ValueTuple{System.String,System.Single}},System.Int32,System.Nullable{System.Int64})">
            <summary>
            Adds many scalar data points to summary.
            </summary>
            <param name="main_tag">Data identifier</param>
            <param name="tag_scalar_dict">List of tuples storing the tag and corresponding values</param>
            <param name="global_step">Global step value to record</param>
            <param name="walltime">Optional override default walltime (DateTimeOffset.Now.ToUnixTimeSeconds())</param>
        </member>
        <member name="M:TorchSharp.Modules.SummaryWriter.add_histogram(System.String,TorchSharp.torch.Tensor,System.Int32,TorchSharp.Utils.tensorboard.Enums.HistogramBinSelector,System.Nullable{System.Int64},System.Nullable{System.Int64})">
             <summary>
             Add histogram to summary.
            
             https://pytorch.org/docs/stable/_modules/torch/utils/tensorboard/writer.html#SummaryWriter.add_histogram
             </summary>
             <param name="tag"> Data identifier </param>
             <param name="values"> Values to build histogram </param>
             <param name="global_step"> Global step value to record </param>
             <param name="bins"> This determines how the bins are made </param>
             <param name="walltime"> Optional override default walltime (DateTimeOffset.Now.ToUnixTimeSeconds()) </param>
             <param name="max_bins"></param>
        </member>
        <member name="M:TorchSharp.Modules.SummaryWriter.add_img(System.String,TorchSharp.torch.Tensor,System.Int32,System.Nullable{System.Int64},System.String)">
             <summary>
             Add batched image data to summary.
            
             https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_image
             </summary>
             <param name="tag"> Data identifier </param>
             <param name="img_tensor"> Image data </param>
             <param name="global_step"> Global step value to record </param>
             <param name="walltime"> Optional override default walltime (DateTimeOffset.Now.ToUnixTimeSeconds()) </param>
             <param name="dataformats"> Image data format specification of the form CHW, HWC, HW, WH, etc. </param>
        </member>
        <member name="M:TorchSharp.Modules.SummaryWriter.add_img(System.String,System.String,System.Int32,System.Nullable{System.Int64})">
             <summary>
             Add batched image data to summary.
            
             https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_image
             </summary>
             <param name="tag"> Data identifier </param>
             <param name="file_name"> Image file </param>
             <param name="global_step"> Global step value to record </param>
             <param name="walltime"> Optional override default walltime (DateTimeOffset.Now.ToUnixTimeSeconds()) </param>
        </member>
        <member name="M:TorchSharp.Modules.SummaryWriter.add_video(System.String,TorchSharp.torch.Tensor,System.Int32,System.Int32,System.Nullable{System.Int64})">
             <summary>
             Add video data to summary.
            
             https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter.add_video
             </summary>
             <param name="tag"> Data identifier </param>
             <param name="vid_tensor">
             Video data
            
             Shape: (N,T,C,H,W). The values should lie in [0, 255] for type uint8 or [0, 1] for type float.
             </param>
             <param name="global_step"> Global step value to record </param>
             <param name="fps"> Frames per second </param>
             <param name="walltime"> Optional override default walltime (DateTimeOffset.Now.ToUnixTimeSeconds()) </param>
        </member>
        <member name="M:TorchSharp.Modules.SummaryWriter.add_text(System.String,System.String,System.Int32,System.Nullable{System.Int64})">
            <summary>
            Add text data to summary.
            
            https://pytorch.org/docs/stable/_modules/torch/utils/tensorboard/writer.html#SummaryWriter.add_text
            </summary>
            <param name="tag"> Data identifier </param>
            <param name="text_string"> String to save </param>
            <param name="global_step"> Global step value to record </param>
            <param name="walltime"> Optional override default walltime (DateTimeOffset.Now.ToUnixTimeSeconds()) </param>
        </member>
        <member name="P:TorchSharp.Modules.TensorDataset.Item(System.Int64)">
            <summary>
            Indexer
            </summary>
        </member>
        <member name="P:TorchSharp.Modules.TensorDataset.Count">
            <summary>
            Length of the dataset, i.e. the size of the first dimension.
            </summary>
        </member>
        <member name="T:TorchSharp.DisposeScope">
            <summary>
            Keeps track of all disposables that are in the current scope - the dispose scopes can be nested and the
            nesting functionality is mainly managed by DisposeScopeManager.
            </summary>
        </member>
        <member name="P:TorchSharp.DisposeScope.OuterScope">
            <summary>
            The outer scope with relation to this scope.
            </summary>
        </member>
        <member name="P:TorchSharp.DisposeScope.Disposables">
            <summary>
            The disposables that are scheduled for disposing.
            </summary>
        </member>
        <member name="P:TorchSharp.DisposeScope.DisposablesView">
            <summary>
            A view of the disposables in the scope - this list will not be kept in synch with the disposables
            in the scope.
            </summary>
        </member>
        <member name="P:TorchSharp.DisposeScope.DisposablesCount">
            <summary>
            The number of disposables currently held in the scope
            </summary>
        </member>
        <member name="M:TorchSharp.DisposeScope.MoveToOuter``1(``0)">
            <summary>
            Excludes a set of tensors/disposables from the current dispose scope, and moves it up to the outer
            dispose scope, if one exists. See overloaded methods. If you wish to exclude a tensor from all sccopes,
            use Detach.
            </summary>
        </member>
        <member name="M:TorchSharp.DisposeScope.MoveToOuter``2(``0,``1)">
            <summary>
            Excludes a set of tensors/disposables from the current dispose scope, and moves it up to the outer
            dispose scope, if one exists. See overloaded methods. If you wish to exclude a tensor from all sccopes,
            use Detach.
            </summary>
        </member>
        <member name="M:TorchSharp.DisposeScope.MoveToOuter``3(``0,``1,``2)">
            <summary>
            Excludes a set of tensors/disposables from the current dispose scope, and moves it up to the outer
            dispose scope, if one exists. See overloaded methods. If you wish to exclude a tensor from all sccopes,
            use Detach.
            </summary>
        </member>
        <member name="M:TorchSharp.DisposeScope.MoveToOuter(System.IDisposable[])">
            <summary>
            Excludes a set of tensors/disposables from the current dispose scope, and moves it up to the outer
            dispose scope, if one exists. See overloaded methods. If you wish to exclude a tensor from all sccopes,
            use Detach.
            </summary>
        </member>
        <member name="M:TorchSharp.DisposeScope.MoveToOuter(System.Collections.Generic.IEnumerable{System.IDisposable})">
            <summary>
            Excludes a set of tensors/disposables from the current dispose scope, and moves it up to the outer
            dispose scope, if one exists. See overloaded methods. If you wish to exclude a tensor from all sccopes,
            use Detach.
            </summary>
        </member>
        <member name="M:TorchSharp.DisposeScope.MoveToOther``1(TorchSharp.DisposeScope,``0)">
            <summary>
            Excludes a set of tensors/disposables from the current dispose scope, and moves it to another
            dispose scope. See overloaded methods. If you wish to exclude a tensor from all sccopes, use Detach.
            </summary>
        </member>
        <member name="M:TorchSharp.DisposeScope.MoveToOther``2(TorchSharp.DisposeScope,``0,``1)">
            <summary>
            Excludes a set of tensors/disposables from the current dispose scope, and moves it to another
            dispose scope. See overloaded methods. If you wish to exclude a tensor from all sccopes, use Detach.
            </summary>
        </member>
        <member name="M:TorchSharp.DisposeScope.MoveToOther``3(TorchSharp.DisposeScope,``0,``1,``2)">
            <summary>
            Excludes a set of tensors/disposables from the current dispose scope, and moves it to another
            dispose scope. See overloaded methods. If you wish to exclude a tensor from all sccopes, use Detach.
            </summary>
        </member>
        <member name="M:TorchSharp.DisposeScope.MoveToOther(TorchSharp.DisposeScope,System.IDisposable[])">
            <summary>
            Excludes a set of tensors/disposables from the current dispose scope, and moves it to another
            dispose scope. See overloaded methods. If you wish to exclude a tensor from all sccopes, use Detach.
            </summary>
        </member>
        <member name="M:TorchSharp.DisposeScope.MoveToOther(TorchSharp.DisposeScope,System.Collections.Generic.IEnumerable{System.IDisposable})">
            <summary>
            Excludes a set of tensors/disposables from the current dispose scope, and moves it to another
            dispose scope. See overloaded methods. If you wish to exclude a tensor from all sccopes, use Detach.
            </summary>
        </member>
        <member name="M:TorchSharp.DisposeScope.Detach``1(``0)">
            <summary>
            Detaches/excludes a set of tensors/disposables from the all dispose scopes, see overloaded methods. See MoveToOuter
            if you wish to move it to the outer dispose scope.
            </summary>
        </member>
        <member name="M:TorchSharp.DisposeScope.Detach``2(``0,``1)">
            <summary>
            Detaches/excludes a set of tensors/disposables from the all dispose scopes, see overloaded methods. See MoveToOuter
            if you wish to move it to the outer dispose scope.
            </summary>
        </member>
        <member name="M:TorchSharp.DisposeScope.Detach``3(``0,``1,``2)">
            <summary>
            Detaches/excludes a set of tensors/disposables from the all dispose scopes, see overloaded methods. See MoveToOuter
            if you wish to move it to the outer dispose scope.
            </summary>
        </member>
        <member name="M:TorchSharp.DisposeScope.Detach(System.IDisposable[])">
            <summary>
            Detaches/excludes a set of tensors/disposables from the all dispose scopes, see overloaded methods. See MoveToOuter
            if you wish to move it to the outer dispose scope.
            </summary>
        </member>
        <member name="M:TorchSharp.DisposeScope.Detach(System.Collections.Generic.IEnumerable{System.IDisposable})">
            <summary>
            Detaches/excludes a set of tensors/disposables from the all dispose scopes, see overloaded methods. See MoveToOuter
            if you wish to move it to the outer dispose scope.
            </summary>
        </member>
        <member name="M:TorchSharp.DisposeScope.ReplaceWith(TorchSharp.torch.Tensor,TorchSharp.torch.Tensor)">
            <summary>
            Replaces registration of one tensor with another.
            </summary>
            <param name="original">The original tensor, possibly registered under a dispose scope.</param>
            <param name="replacement">The replacement tensor.</param>
        </member>
        <member name="M:TorchSharp.DisposeScope.DisposeEverything">
            <summary>
            Disposes everything currently in the dispose scope.
            </summary>
        </member>
        <member name="M:TorchSharp.DisposeScope.DisposeEverythingBut(System.Collections.Generic.IEnumerable{System.IDisposable})">
            <summary>
            As an intermediate step, you can dispose all the tensors/disposables currently scheduled for dispose, to
            clear up some memory without creating a new scope. Note that this doesn't permanently exclude the
            tensors from disposing, use Exclude for that. Also, excluded tensors don't need to be included
            here.
            </summary>
        </member>
        <member name="M:TorchSharp.DisposeScope.DisposeEverythingBut(System.IDisposable[])">
            <summary>
            As an intermediate step, you can dispose all the tensors/disposables currently scheduled for dispose, to
            clear up some memory without creating a new scope. Note that this doesn't permanently exclude the
            tensors from disposing, use Exclude for that. Also, excluded tensors don't need to be included
            here.
            </summary>
        </member>
        <member name="M:TorchSharp.DisposeScope.DisposeEverythingBut``1(``0)">
            <summary>
            As an intermediate step, you can dispose all the tensors/disposables currently scheduled for dispose, to
            clear up some memory without creating a new scope. Note that this doesn't permanently exclude the
            tensors from disposing, use Exclude for that. Also, excluded tensors don't need to be included
            here.
            </summary>
        </member>
        <member name="M:TorchSharp.DisposeScope.DisposeEverythingBut``2(``0,``1)">
            <summary>
            As an intermediate step, you can dispose all the tensors/disposables currently scheduled for dispose, to
            clear up some memory without creating a new scope. Note that this doesn't permanently exclude the
            tensors from disposing, use Exclude for that. Also, excluded tensors don't need to be included
            here.
            </summary>
        </member>
        <member name="M:TorchSharp.DisposeScope.DisposeEverythingBut``3(``0,``1,``2)">
            <summary>
            As an intermediate step, you can dispose all the tensors/disposables currently scheduled for dispose, to
            clear up some memory without creating a new scope. Note that this doesn't permanently exclude the
            tensors from disposing, use Exclude for that. Also, excluded tensors don't need to be included
            here.
            </summary>
        </member>
        <member name="M:TorchSharp.DisposeScope.Dispose">
            <summary>
            Disposes of the DisposeScope and all the disposables in its list. You would typically not call this method,
            instead you should use a usings clause around the scope.
            </summary>
        </member>
        <member name="M:TorchSharp.DisposeScope.MarkAsDisposed(System.IDisposable)">
            <summary>
            A method that notifies the DisposeScope that a disposable was disposed, so that it can be removed from the
            tracked list. This will be called if a tensor is manually disposed, but you can also add your own
            disposables to the dispose scope. If you do, and dispose them manually, you should make sure to call this
            method.
            </summary>
            <param name="disposable">The disposable that was disposed</param>
        </member>
        <member name="M:TorchSharp.DisposeScope.Contains(System.IDisposable)">
            <summary>
            Checks if the DisposeScope contains the disposable
            </summary>
            <param name="disposable">The disposable that's searched for</param>
            <returns></returns>
        </member>
        <member name="T:TorchSharp.DisposeScopeManager">
            <summary>
            Manages dispose scopes, that can make automatic tensor disposal easier. Note that the
            DisposeManager is thread local. The DisposeScopeManager can also manage other disposables, such as training
            batches and the like.
            </summary>
        </member>
        <member name="T:TorchSharp.IProgressBar">
            <summary>
            Interface to implement progress bar.
            </summary>
        </member>
        <member name="P:TorchSharp.IProgressBar.Value">
            <summary>
            The current position of the progress bar
            </summary>
        </member>
        <member name="P:TorchSharp.IProgressBar.Maximum">
            <summary>
            The maximum position of the progress bar
            </summary>
        </member>
        <member name="M:TorchSharp.ModuleExtensionMethods.to``1(``0,TorchSharp.torch.ScalarType,System.Boolean)">
            <summary>
            Converts the parameters and buffers.
            </summary>
            <param name="module">The module to move</param>
            <param name="type">The target element type.</param>
            <param name="non_blocking">
            When non_blocking is set, it tries to convert/move asynchronously with respect to the host if possible,
            e.g., moving CPU Tensors with pinned memory to CUDA devices.
            </param>
        </member>
        <member name="M:TorchSharp.ModuleExtensionMethods.to``1(``0,TorchSharp.torch.Device,TorchSharp.torch.ScalarType,System.Boolean)">
            <summary>
            Moves and converts the parameters and buffers.
            </summary>
            <param name="module">The module to move</param>
            <param name="device">The target device.</param>
            <param name="type">The target element type.</param>
            <param name="non_blocking">
            When non_blocking is set, it tries to convert/move asynchronously with respect to the host if possible,
            e.g., moving CPU Tensors with pinned memory to CUDA devices.
            </param>
        </member>
        <member name="M:TorchSharp.ModuleExtensionMethods.to``1(``0,TorchSharp.DeviceType,System.Int32,System.Boolean)">
            <summary>
            Moves the parameters and buffers.
            </summary>
            <param name="module">The module to move</param>
            <param name="deviceType">The device type, e.g. 'CPU' or 'CUDA'.</param>
            <param name="deviceIndex">The optional device index.</param>
            <param name="non_blocking">
            When non_blocking is set, it tries to convert/move asynchronously with respect to the host if possible,
            e.g., moving CPU Tensors with pinned memory to CUDA devices.
            </param>
        </member>
        <member name="M:TorchSharp.ModuleExtensionMethods.to``1(``0,TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Moves the parameters and buffers.
            </summary>
            <param name="module">The module to move</param>"
            <param name="device">The target device</param>
            <param name="non_blocking">
            When non_blocking is set, it tries to convert/move asynchronously with respect to the host if possible,
            e.g., moving CPU Tensors with pinned memory to CUDA devices.
            </param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.ModuleExtensionMethods.to``1(``0,System.String,System.Boolean)">
            <summary>
            Moves the parameters and buffers.
            </summary>
            <param name="module">The module to move</param>
            <param name="device">A string denoting the target device.</param>
            <param name="non_blocking">
            When non_blocking is set, it tries to convert/move asynchronously with respect to the host if possible,
            e.g., moving CPU Tensors with pinned memory to CUDA devices.
            </param>
            <returns></returns>
            <remarks>Relies on the Device constructor to parse the string.</remarks>
        </member>
        <member name="M:TorchSharp.ModuleExtensionMethods.to``1(``0,TorchSharp.torch.Tensor,System.Boolean)">
            <summary>
            Moves and converts the parameters and buffers.
            </summary>
            <param name="module">The module to move</param>
            <param name="other">The tensor serving as a template.</param>
            <param name="non_blocking">
            When non_blocking is set, it tries to convert/move asynchronously with respect to the host if possible,
            e.g., moving CPU Tensors with pinned memory to CUDA devices.
            </param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.ModuleExtensionMethods.cpu``1(``0,System.Boolean)">
            <summary>
            Moves all model parameters and buffers to the CPU.
            </summary>
        </member>
        <member name="M:TorchSharp.ModuleExtensionMethods.cuda``1(``0,System.Int32,System.Boolean)">
             <summary>
             Moves all model parameters and buffers to a GPU.
            
             This also makes associated parameters and buffers different objects.So it should be called before constructing optimizer if the module will live on GPU while being optimized.
             </summary>
             <param name="module">The module to move</param>
             <param name="deviceIndex">If specified, all parameters will be copied to that device</param>
             <param name="non_blocking">
             When non_blocking is set, it tries to convert/move asynchronously with respect to the host if possible,
             e.g., moving CPU Tensors with pinned memory to CUDA devices.
             </param>
        </member>
        <member name="M:TorchSharp.ModuleExtensionMethods.bool``1(``0,System.Boolean)">
            <summary>
            Converts all model parameters and buffers to `ScalarType.Bool`.
            </summary>
            <param name="module">The module to convert</param>
            <param name="non_blocking">
            When non_blocking is set, it tries to convert/move asynchronously with respect to the host if possible,
            e.g., moving CPU Tensors with pinned memory to CUDA devices.
            </param>
        </member>
        <member name="M:TorchSharp.ModuleExtensionMethods.byte``1(``0,System.Boolean)">
            <summary>
            Converts all model parameters and buffers to `ScalarType.Byte`.
            </summary>
            <param name="module">The module to convert</param>
            <param name="non_blocking">
            When non_blocking is set, it tries to convert/move asynchronously with respect to the host if possible,
            e.g., moving CPU Tensors with pinned memory to CUDA devices.
            </param>
        </member>
        <member name="M:TorchSharp.ModuleExtensionMethods.char``1(``0,System.Boolean)">
            <summary>
            Converts all model parameters and buffers to `ScalarType.Int8`.
            </summary>
            <param name="module">The module to convert</param>
            <param name="non_blocking">
            When non_blocking is set, it tries to convert/move asynchronously with respect to the host if possible,
            e.g., moving CPU Tensors with pinned memory to CUDA devices.
            </param>
        </member>
        <member name="M:TorchSharp.ModuleExtensionMethods.short``1(``0,System.Boolean)">
            <summary>
            Converts all model parameters and buffers to `ScalarType.Int16`.
            </summary>
            <param name="module">The module to convert</param>
            <param name="non_blocking">
            When non_blocking is set, it tries to convert/move asynchronously with respect to the host if possible,
            e.g., moving CPU Tensors with pinned memory to CUDA devices.
            </param>
        </member>
        <member name="M:TorchSharp.ModuleExtensionMethods.int``1(``0,System.Boolean)">
            <summary>
            Converts all model parameters and buffers to `ScalarType.Int32`.
            </summary>
            <param name="module">The module to convert</param>
            <param name="non_blocking">
            When non_blocking is set, it tries to convert/move asynchronously with respect to the host if possible,
            e.g., moving CPU Tensors with pinned memory to CUDA devices.
            </param>
        </member>
        <member name="M:TorchSharp.ModuleExtensionMethods.long``1(``0,System.Boolean)">
            <summary>
            Converts all model parameters and buffers to `ScalarType.Int64`.
            </summary>
            <param name="module">The module to convert</param>
            <param name="non_blocking">
            When non_blocking is set, it tries to convert/move asynchronously with respect to the host if possible,
            e.g., moving CPU Tensors with pinned memory to CUDA devices.
            </param>
        </member>
        <member name="M:TorchSharp.ModuleExtensionMethods.half``1(``0,System.Boolean)">
            <summary>
            Converts all model parameters and buffers to `ScalarType.Float16`.
            </summary>
            <param name="module">The module to convert</param>
            <param name="non_blocking">
            When non_blocking is set, it tries to convert/move asynchronously with respect to the host if possible,
            e.g., moving CPU Tensors with pinned memory to CUDA devices.
            </param>
        </member>
        <member name="M:TorchSharp.ModuleExtensionMethods.bfloat16``1(``0,System.Boolean)">
            <summary>
            Converts all model parameters and buffers to `ScalarType.BFloat16`.
            </summary>
            <param name="module">The module to convert</param>
            <param name="non_blocking">
            When non_blocking is set, it tries to convert/move asynchronously with respect to the host if possible,
            e.g., moving CPU Tensors with pinned memory to CUDA devices.
            </param>
        </member>
        <member name="M:TorchSharp.ModuleExtensionMethods.float``1(``0,System.Boolean)">
            <summary>
            Converts all model parameters and buffers to `ScalarType.Float32`.
            </summary>
            <param name="module">The module to convert</param>
            <param name="non_blocking">
            When non_blocking is set, it tries to convert/move asynchronously with respect to the host if possible,
            e.g., moving CPU Tensors with pinned memory to CUDA devices.
            </param>
        </member>
        <member name="M:TorchSharp.ModuleExtensionMethods.double``1(``0,System.Boolean)">
            <summary>
            Converts all model parameters and buffers to `ScalarType.Float64`.
            </summary>
            <param name="module">The module to convert</param>
            <param name="non_blocking">
            When non_blocking is set, it tries to convert/move asynchronously with respect to the host if possible,
            e.g., moving CPU Tensors with pinned memory to CUDA devices.
            </param>
        </member>
        <member name="M:TorchSharp.ModuleExtensionMethods.cfloat``1(``0,System.Boolean)">
            <summary>
            Converts all model parameters and buffers to `ScalarType.ComplexFloat32`.
            </summary>
            <param name="module">The module to convert</param>
            <param name="non_blocking">
            When non_blocking is set, it tries to convert/move asynchronously with respect to the host if possible,
            e.g., moving CPU Tensors with pinned memory to CUDA devices.
            </param>
        </member>
        <member name="M:TorchSharp.ModuleExtensionMethods.cdouble``1(``0,System.Boolean)">
            <summary>
            Converts all model parameters and buffers to `ScalarType.ComplexFloat64`.
            </summary>
            <param name="module">The module to convert</param>
            <param name="non_blocking">
            When non_blocking is set, it tries to convert/move asynchronously with respect to the host if possible,
            e.g., moving CPU Tensors with pinned memory to CUDA devices.
            </param>
        </member>
        <member name="M:TorchSharp.FieldInfoExtensionMethods.ComponentName(System.Reflection.FieldInfo)">
            <summary>
            Retrieves the custom component name defined by the ComponentNameAttribute for a given field,
            or defaults to the field's own name if the attribute is not present.
            </summary>
            <param name="field">The field for which to retrieve the component name.</param>
            <returns>The custom component name if specified, otherwise the field's name.</returns>
        </member>
        <member name="T:TorchSharp.Scalar">
            <summary>
            Represents a dynamically typed scalar value to the LibTorch runtime.
            </summary>
        </member>
        <member name="M:TorchSharp.Scalar.op_Implicit(System.Byte)~TorchSharp.Scalar">
            <summary>
            Implicitly convert a .NET scalar value to Scalar
            </summary>
            <param name="value">The scalar value.</param>
        </member>
        <member name="M:TorchSharp.Scalar.op_Implicit(System.SByte)~TorchSharp.Scalar">
            <summary>
            Implicitly convert a .NET scalar value to Scalar
            </summary>
            <param name="value">The scalar value.</param>
        </member>
        <member name="M:TorchSharp.Scalar.op_Implicit(System.Int16)~TorchSharp.Scalar">
            <summary>
            Implicitly convert a .NET scalar value to Scalar
            </summary>
            <param name="value">The scalar value.</param>
        </member>
        <member name="M:TorchSharp.Scalar.op_Implicit(System.Int32)~TorchSharp.Scalar">
            <summary>
            Implicitly convert a .NET scalar value to Scalar
            </summary>
            <param name="value">The scalar value.</param>
        </member>
        <member name="M:TorchSharp.Scalar.op_Implicit(System.Int64)~TorchSharp.Scalar">
            <summary>
            Implicitly convert a .NET scalar value to Scalar
            </summary>
            <param name="value">The scalar value.</param>
        </member>
        <member name="M:TorchSharp.Scalar.op_Implicit(System.Half)~TorchSharp.Scalar">
            <summary>
            Implicitly convert a .NET scalar value to Scalar
            </summary>
            <param name="value">The scalar value.</param>
        </member>
        <member name="M:TorchSharp.Scalar.op_Implicit(System.Single)~TorchSharp.Scalar">
            <summary>
            Implicitly convert a .NET scalar value to Scalar
            </summary>
            <param name="value">The scalar value.</param>
        </member>
        <member name="M:TorchSharp.Scalar.op_Implicit(System.Double)~TorchSharp.Scalar">
            <summary>
            Implicitly convert a .NET scalar value to Scalar
            </summary>
            <param name="value">The scalar value.</param>
        </member>
        <member name="M:TorchSharp.Scalar.op_Implicit(System.Boolean)~TorchSharp.Scalar">
            <summary>
            Implicitly convert a .NET scalar value to Scalar
            </summary>
            <param name="value">The scalar value.</param>
        </member>
        <member name="M:TorchSharp.Scalar.op_Implicit(System.ValueTuple{System.Single,System.Single})~TorchSharp.Scalar">
            <summary>
            Implicitly convert a .NET scalar value to Scalar
            </summary>
            <param name="value">The scalar value.</param>
        </member>
        <member name="M:TorchSharp.Scalar.op_Implicit(System.Numerics.Complex)~TorchSharp.Scalar">
            <summary>
            Implicitly convert a .NET scalar value to Scalar
            </summary>
            <param name="value">The scalar value.</param>
        </member>
        <member name="P:TorchSharp.Scalar.Type">
            <summary>
            Gets the actual type of the Scalar value
            </summary>
        </member>
        <member name="M:TorchSharp.Scalar.Finalize">
            <summary>
              Finalize the tensor. Releases the tensor and its associated data.
            </summary>
        </member>
        <member name="M:TorchSharp.Scalar.Dispose(System.Boolean)">
            <summary>
              Implements the .NET Dispose pattern.
            </summary>
        </member>
        <member name="M:TorchSharp.ScalarExtensionMethods.ToScalar(System.Byte)">
            <summary>
            Explcitly construct a Scalar from a .NET scalar.
            </summary>
            <param name="value">The input scalar value</param>
        </member>
        <member name="M:TorchSharp.ScalarExtensionMethods.ToScalar(System.SByte)">
            <summary>
            Explcitly construct a Scalar from a .NET scalar.
            </summary>
            <param name="value">The input scalar value</param>
        </member>
        <member name="M:TorchSharp.ScalarExtensionMethods.ToScalar(System.Int16)">
            <summary>
            Explcitly construct a Scalar from a .NET scalar.
            </summary>
            <param name="value">The input scalar value</param>
        </member>
        <member name="M:TorchSharp.ScalarExtensionMethods.ToScalar(System.Int32)">
            <summary>
            Explcitly construct a Scalar from a .NET scalar.
            </summary>
            <param name="value">The input scalar value</param>
        </member>
        <member name="M:TorchSharp.ScalarExtensionMethods.ToScalar(System.Int64)">
            <summary>
            Explcitly construct a Scalar from a .NET scalar.
            </summary>
            <param name="value">The input scalar value</param>
        </member>
        <member name="M:TorchSharp.ScalarExtensionMethods.ToScalar(System.Single)">
            <summary>
            Explcitly construct a Scalar from a .NET scalar.
            </summary>
            <param name="value">The input scalar value</param>
        </member>
        <member name="M:TorchSharp.ScalarExtensionMethods.ToScalar(System.Double)">
            <summary>
            Explcitly construct a Scalar from a .NET scalar.
            </summary>
            <param name="value">The input scalar value</param>
        </member>
        <member name="M:TorchSharp.ScalarExtensionMethods.ToScalar(System.ValueTuple{System.Single,System.Single})">
            <summary>
            Explcitly construct a Scalar from a .NET scalar.
            </summary>
            <param name="value">The input scalar value</param>
        </member>
        <member name="M:TorchSharp.ScalarExtensionMethods.ToScalar(System.Numerics.Complex)">
            <summary>
            Explcitly construct a Scalar from a .NET scalar.
            </summary>
            <param name="value">The input scalar value</param>
        </member>
        <member name="M:TorchSharp.ScalarExtensionMethods.ToScalar(System.Boolean)">
            <summary>
            Explcitly construct a Scalar from a .NET scalar.
            </summary>
            <param name="value">The input scalar value</param>
        </member>
        <member name="M:TorchSharp.ScalarExtensionMethods.ToScalar(System.Half)">
            <summary>
            Explcitly construct a Scalar from a .NET scalar.
            </summary>
            <param name="value">The input scalar value</param>
        </member>
        <member name="M:TorchSharp.ScalarExtensionMethods.ToBFloat16Scalar(System.Single)">
            <summary>
            Explcitly construct a Scalar from a .NET scalar.
            </summary>
            <param name="value">The input scalar value</param>
        </member>
        <member name="M:TorchSharp.ScalarExtensionMethods.ToHalf(TorchSharp.Scalar)">
            <summary>
            Explicitly convert a Scalar value to a .NET scalar
            </summary>
            <param name="value">The input value.</param>
        </member>
        <member name="M:TorchSharp.ScalarExtensionMethods.ToSingle(TorchSharp.Scalar)">
            <summary>
            Explicitly convert a Scalar value to a .NET scalar
            </summary>
            <param name="value">The input value.</param>
        </member>
        <member name="M:TorchSharp.ScalarExtensionMethods.ToDouble(TorchSharp.Scalar)">
            <summary>
            Explicitly convert a Scalar value to a .NET scalar
            </summary>
            <param name="value">The input value.</param>
        </member>
        <member name="M:TorchSharp.ScalarExtensionMethods.ToSByte(TorchSharp.Scalar)">
            <summary>
            Explicitly convert a Scalar value to a .NET scalar
            </summary>
            <param name="value">The input value.</param>
        </member>
        <member name="M:TorchSharp.ScalarExtensionMethods.ToByte(TorchSharp.Scalar)">
            <summary>
            Explicitly convert a Scalar value to a .NET scalar
            </summary>
            <param name="value">The input value.</param>
        </member>
        <member name="M:TorchSharp.ScalarExtensionMethods.ToInt16(TorchSharp.Scalar)">
            <summary>
            Explicitly convert a Scalar value to a .NET scalar
            </summary>
            <param name="value">The input value.</param>
        </member>
        <member name="M:TorchSharp.ScalarExtensionMethods.ToInt32(TorchSharp.Scalar)">
            <summary>
            Explicitly convert a Scalar value to a .NET scalar
            </summary>
            <param name="value">The input value.</param>
        </member>
        <member name="M:TorchSharp.ScalarExtensionMethods.ToInt64(TorchSharp.Scalar)">
            <summary>
            Explicitly convert a Scalar value to a .NET scalar
            </summary>
            <param name="value">The input value.</param>
        </member>
        <member name="M:TorchSharp.ScalarExtensionMethods.ToBoolean(TorchSharp.Scalar)">
            <summary>
            Explicitly convert a Scalar value to a .NET scalar
            </summary>
            <param name="value">The input value.</param>
        </member>
        <member name="M:TorchSharp.ScalarExtensionMethods.ToComplexFloat32(TorchSharp.Scalar)">
            <summary>
            Explicitly convert a Scalar value to a .NET scalar
            </summary>
            <param name="value">The input value.</param>
        </member>
        <member name="M:TorchSharp.ScalarExtensionMethods.ToComplexFloat64(TorchSharp.Scalar)">
            <summary>
            Explicitly convert a Scalar value to a .NET scalar
            </summary>
            <param name="value">The input value.</param>
        </member>
        <member name="F:TorchSharp.layout.strided">
            <summary>
            dense Tensors
            </summary>
        </member>
        <member name="F:TorchSharp.layout.sparse_coo">
            <summary>
            sparse COO Tensors
            </summary>
        </member>
        <member name="T:TorchSharp.TensorExtensionMethods">
            <summary>
            A few extensions to the Tensor type.
            </summary>
        </member>
        <member name="M:TorchSharp.TensorExtensionMethods.AsParameter(TorchSharp.torch.Tensor)">
            <summary>
            Convert to a parameter.
            </summary>
            <param name="tensor">A tensor.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.TensorExtensionMethods.str(TorchSharp.torch.Tensor,System.String,System.Nullable{System.Int32},System.String,System.Globalization.CultureInfo,TorchSharp.TensorStringStyle)">
             <summary>
             Get a string representation of the tensor.
             </summary>
             <param name="tensor">The input tensor.</param>
             <param name="fltFormat">
             The format string to use for floating point values.
             See: https://learn.microsoft.com/en-us/dotnet/standard/base-types/standard-numeric-format-strings
             </param>
             <param name="width">The width of each line of the output string.</param>
             <param name="newLine">The newline string to use, defaults to system default.</param>
             <param name="cultureInfo">The culture info to be used when formatting the numbers.</param>
             <param name="style">
             The style to use -- either 'default,' 'metadata,' 'julia,' or 'numpy'
             </param>
             <remarks>
             This method does exactly the same as ToString(bool, string, int), but is shorter,
             looks more like Python 'str' and doesn't require a style argument in order
             to discriminate.
            
             Primarily intended for use in interactive notebooks.
             </remarks>
        </member>
        <member name="M:TorchSharp.TensorExtensionMethods.jlstr(TorchSharp.torch.Tensor,System.String,System.Nullable{System.Int32},System.String,System.Globalization.CultureInfo)">
             <summary>
             Get a Julia-style string representation of the tensor.
             </summary>
             <param name="tensor">The input tensor.</param>
             <param name="fltFormat">
             The format string to use for floating point values.
             See: https://learn.microsoft.com/en-us/dotnet/standard/base-types/standard-numeric-format-strings
             </param>
             <param name="width">The width of each line of the output string.</param>
             <param name="newLine">The newline string to use, defaults to system default.</param>
             <param name="cultureInfo">The culture info to be used when formatting the numbers.</param>
             <returns></returns>
             <remarks>
             This method does exactly the same as str(TensorStringStyle.Julia, ...) but is shorter,
             looks more like Python 'str' and doesn't require a style argument in order
             to discriminate.
            
             Primarily intended for use in interactive notebooks.
             </remarks>
        </member>
        <member name="M:TorchSharp.TensorExtensionMethods.metastr(TorchSharp.torch.Tensor)">
             <summary>
             Get a metadata string representation of the tensor.
             Creating metadata string will ignore fltFormat, etc. so this method will not accept them as parameter.
             </summary>
             <param name="tensor">The input tensor.</param>
             <returns></returns>
             <remarks>
             This method does exactly the same as str(TensorStringStyle.Metadata, ...) but is shorter,
             looks more like Python 'str' and doesn't require a style argument in order
             to discriminate.
            
             Primarily intended for use in interactive notebooks.
             </remarks>
        </member>
        <member name="M:TorchSharp.TensorExtensionMethods.npstr(TorchSharp.torch.Tensor,System.String,System.Nullable{System.Int32},System.String,System.Globalization.CultureInfo)">
             <summary>
             Get a numpy-style string representation of the tensor.
             </summary>
             <param name="tensor">The input tensor.</param>
             <param name="fltFormat">
             The format string to use for floating point values.
             See: https://learn.microsoft.com/en-us/dotnet/standard/base-types/standard-numeric-format-strings
             </param>
             <param name="width">The width of each line of the output string.</param>
             <param name="newLine">The newline string to use, defaults to system default.</param>
             <param name="cultureInfo">The culture info to be used when formatting the numbers.</param>
             <returns></returns>
             <remarks>
             This method does exactly the same as str(TensorStringStyle.Numpy, ...) but is shorter,
             looks more like Python 'str()' and doesn't require a style argument in order
             to discriminate.
            
             Primarily intended for use in interactive notebooks.
             </remarks>
        </member>
        <member name="M:TorchSharp.TensorExtensionMethods.cstr(TorchSharp.torch.Tensor,System.String,System.Nullable{System.Int32},System.String,System.Globalization.CultureInfo)">
             <summary>
             Get a C#-style string representation of the tensor.
             </summary>
             <param name="tensor">The input tensor.</param>
             <param name="fltFormat">
             The format string to use for floating point values.
             See: https://learn.microsoft.com/en-us/dotnet/standard/base-types/standard-numeric-format-strings
             </param>
             <param name="width">The width of each line of the output string.</param>
             <param name="newLine">The newline string to use, defaults to system default.</param>
             <param name="cultureInfo">The culture info to be used when formatting the numbers.</param>
             <returns></returns>
             <remarks>
             This method does exactly the same as str(TensorStringStyle.CSharp, ...) but is shorter,
             looks more like Python 'str()' and doesn't require a style argument in order
             to discriminate.
            
             Primarily intended for use in interactive notebooks.
             </remarks>
        </member>
        <member name="M:TorchSharp.TensorExtensionMethods.print(TorchSharp.torch.Tensor,System.String,System.Nullable{System.Int32},System.String,System.Globalization.CultureInfo,TorchSharp.TensorStringStyle)">
            <summary>
            Uses Console.WriteLine to print a tensor expression on stdout. This is intended for
            interactive notebook use, primarily.
            </summary>
            <param name="t">The input tensor.</param>
            <param name="fltFormat">
            The format string to use for floating point values.
            See: https://learn.microsoft.com/en-us/dotnet/standard/base-types/standard-numeric-format-strings
            </param>
            <param name="width">The width of each line of the output string.</param>
            <param name="newLine">The newline string to use, defaults to system default.</param>
            <param name="cultureInfo">The culture info to be used when formatting the numbers.</param>
            <param name="style">
            The style to use -- either 'default,' 'metadata,' 'julia,' or 'numpy'
            </param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.TensorExtensionMethods.IsIntegral(TorchSharp.torch.Tensor)">
            <summary>
            Indicates whether the element type of a given tensor is integral.
            </summary>
            <param name="tensor">The input tensor.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.TensorExtensionMethods.ElementSize(TorchSharp.torch.ScalarType)">
            <summary>
            Get the size of each element of this ScalarType.
            </summary>
            <param name="type">The input type.</param>
            <returns>The element size</returns>
            <exception cref="T:System.NotImplementedException">Invalid ScalarType</exception>
        </member>
        <member name="M:TorchSharp.TensorExtensionMethods.IsIntegral(TorchSharp.torch.ScalarType)">
            <summary>
            Indicates whether a given element type is integral.
            </summary>
            <param name="type">The input type.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.TensorExtensionMethods.IsFloatingPoint(TorchSharp.torch.ScalarType)">
            <summary>
            Indicates whether a given element type is real.
            </summary>
            <param name="type">The input type.</param>
            <returns></returns>
            <remarks>
            Complex numbers are not real, and thus will return 'false'
            </remarks>
        </member>
        <member name="M:TorchSharp.TensorExtensionMethods.IsComplex(TorchSharp.torch.ScalarType)">
            <summary>
            Indicates whether a given element type is complex.
            </summary>
            <param name="type">The input type.</param>
            <returns></returns>
            <remarks>
            Complex numbers are not real, and thus will return 'false'
            </remarks>
        </member>
        <member name="M:TorchSharp.TensorExtensionMethods.Save(TorchSharp.torch.Tensor,System.IO.BinaryWriter)">
            <summary>
            Save the tensor in a .NET-specific format.
            </summary>
            <param name="tensor">The tensor to save</param>
            <param name="writer">A BinaryWriter instance.</param>
        </member>
        <member name="M:TorchSharp.TensorExtensionMethods.Save(TorchSharp.torch.Tensor,System.IO.Stream)">
            <summary>
            Save the tensor in a .NET-specific format.
            </summary>
            <param name="tensor">The tensor to save</param>
            <param name="stream">A stream opened for writing binary data.</param>
        </member>
        <member name="M:TorchSharp.TensorExtensionMethods.Save(TorchSharp.torch.Tensor,System.String)">
            <summary>
            Save the tensor in a .NET-specific format.
            </summary>
            <param name="tensor">The tensor to save</param>
            <param name="location">A file path.</param>
        </member>
        <member name="M:TorchSharp.TensorExtensionMethods.Load(TorchSharp.torch.Tensor,System.IO.BinaryReader,System.Boolean)">
            <summary>
            Load the tensor using a .NET-specific format.
            </summary>
            <param name="tensor">The tensor into which to load serialized data.</param>
            <param name="reader">A BinaryReader instance</param>
            <param name="skip">If true, the data will be read from the stream, but not copied to the target tensor.</param>
            <remarks>
            Using a skip list only prevents tensors in the target module from being modified, it
            does not alter the logic related to checking for matching tensor element types.
            </remarks>
        </member>
        <member name="M:TorchSharp.TensorExtensionMethods.Load(System.IO.BinaryReader,System.Boolean)">
            <summary>
            Load the tensor using a .NET-specific format.
            </summary>
            <param name="reader">A BinaryReader instance</param>
            <param name="skip">If true, the data will be read from the stream, but not stored in the return tensor.</param>
            <remarks>
            Using skip returns an empty tensor with the dimensions of the tensor that was loaded.
            </remarks>
        </member>
        <member name="M:TorchSharp.TensorExtensionMethods.Load(TorchSharp.torch.Tensor@,System.IO.BinaryReader,System.Boolean)">
            <summary>
            Load the tensor using a .NET-specific format.
            </summary>
            <param name="tensor">The tensor into which to load serialized data. If null, will create a new tensor.</param>
            <param name="reader">A BinaryReader instance</param>
            <param name="skip">If true, the data will be read from the stream, but not stored in the return tensor.</param>
            <remarks>
            Using skip returns an empty tensor with the dimensions of the tensor that was loaded.
            </remarks>
            <exception cref="T:System.NotImplementedException"></exception>
            <exception cref="T:System.ArgumentException"></exception>
        </member>
        <member name="M:TorchSharp.TensorExtensionMethods.ToTensor``1(``0[],System.Int64[],System.Boolean,System.Boolean)">
            <summary>
            Creating a tensor form an array of data.
            </summary>
            <typeparam name="T">The .NET element type.</typeparam>
            <param name="rawArray">Input data.</param>
            <param name="dimensions">The shape of the tensor that is created.</param>
            <param name="doCopy">Perform a copy rather than using the array as backing storage for the tensor.</param>
            <param name="requires_grad">If true, the tensor must track its gradients.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.TensorExtensionMethods.ToTensor``1(``0,TorchSharp.torch.Device,System.Boolean)">
            <summary>
            Creating a tensor from a scalar value.
            </summary>
            <typeparam name="T">The .NET element type.</typeparam>
            <param name="scalar">Scalar input value</param>
            <param name="device">The device to place the tensor on.</param>
            <param name="requires_grad">If true, the tensor must track its gradients.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.TensorExtensionMethods.ToComplexFloat32(TorchSharp.torch.Tensor)">
            <summary>
            Explicitly convert a singleton tensor to a .NET scalar value.
            </summary>
            <param name="value">The input tensor</param>
        </member>
        <member name="M:TorchSharp.TensorExtensionMethods.ToComplexFloat64(TorchSharp.torch.Tensor)">
            <summary>
            Explicitly convert a singleton tensor to a .NET scalar value.
            </summary>
            <param name="value">The input tensor</param>
        </member>
        <member name="M:TorchSharp.TensorExtensionMethods.ToHalf(TorchSharp.torch.Tensor)">
            <summary>
            Explicitly convert a singleton tensor to a .NET scalar value.
            </summary>
            <param name="value">The input tensor</param>
        </member>
        <member name="M:TorchSharp.TensorExtensionMethods.ToSingle(TorchSharp.torch.Tensor)">
            <summary>
            Explicitly convert a singleton tensor to a .NET scalar value.
            </summary>
            <param name="value">The input tensor</param>
        </member>
        <member name="M:TorchSharp.TensorExtensionMethods.ToDouble(TorchSharp.torch.Tensor)">
            <summary>
            Explicitly convert a singleton tensor to a .NET scalar value.
            </summary>
            <param name="value">The input tensor</param>
        </member>
        <member name="M:TorchSharp.TensorExtensionMethods.ToSByte(TorchSharp.torch.Tensor)">
            <summary>
            Explicitly convert a singleton tensor to a .NET scalar value.
            </summary>
            <param name="value">The input tensor</param>
        </member>
        <member name="M:TorchSharp.TensorExtensionMethods.ToByte(TorchSharp.torch.Tensor)">
            <summary>
            Explicitly convert a singleton tensor to a .NET scalar value.
            </summary>
            <param name="value">The input tensor</param>
        </member>
        <member name="M:TorchSharp.TensorExtensionMethods.ToInt16(TorchSharp.torch.Tensor)">
            <summary>
            Explicitly convert a singleton tensor to a .NET scalar value.
            </summary>
            <param name="value">The input tensor</param>
        </member>
        <member name="M:TorchSharp.TensorExtensionMethods.ToInt32(TorchSharp.torch.Tensor)">
            <summary>
            Explicitly convert a singleton tensor to a .NET scalar value.
            </summary>
            <param name="value">The input tensor</param>
        </member>
        <member name="M:TorchSharp.TensorExtensionMethods.ToInt64(TorchSharp.torch.Tensor)">
            <summary>
            Explicitly convert a singleton tensor to a .NET scalar value.
            </summary>
            <param name="value">The input tensor</param>
        </member>
        <member name="M:TorchSharp.TensorExtensionMethods.ToBoolean(TorchSharp.torch.Tensor)">
            <summary>
            Explicitly convert a singleton tensor to a .NET scalar value.
            </summary>
            <param name="value">The input tensor</param>
        </member>
        <member name="M:TorchSharp.TensorExtensionMethods.ToComplex32(TorchSharp.torch.Tensor)">
            <summary>
            Explicitly convert a singleton tensor to a .NET scalar value.
            </summary>
            <param name="value">The input tensor</param>
        </member>
        <member name="M:TorchSharp.TensorExtensionMethods.ToComplex64(TorchSharp.torch.Tensor)">
            <summary>
            Explicitly convert a singleton tensor to a .NET scalar value.
            </summary>
            <param name="value">The input tensor</param>
        </member>
        <member name="M:TorchSharp.TensorExtensionMethods.TotalSize(System.Collections.Generic.IEnumerable{System.Int64})">
            <summary>
            Multiply the dimensions of a tensor shape to provide a complete size.
            </summary>
            <param name="shape">The shape.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.TensorExtensionMethods.toWillCopy(TorchSharp.torch.Tensor,TorchSharp.torch.Device)">
            <summary>
            Checks if calling `Tensor.to()` with the parameters will result in actually copying the tensor.
            </summary>
            <param name="tensor">The tensor</param>
            <param name="device">The device to move to</param>
            <returns>True if the tensor will be copied</returns>
        </member>
        <member name="M:TorchSharp.TensorExtensionMethods.toWillCopy(TorchSharp.torch.Tensor,TorchSharp.DeviceType,System.Int32)">
            <summary>
            Checks if calling `Tensor.to()` with the parameters will result in actually copying the tensor.
            </summary>
            <param name="tensor">The tensor</param>
            <param name="deviceType">The device type to move to</param>
            <param name="deviceIndex">The device index to move to</param>
            <returns>True if the tensor will be copied</returns>
        </member>
        <member name="M:TorchSharp.TensorExtensionMethods.toWillCopy(TorchSharp.torch.Tensor,TorchSharp.torch.ScalarType)">
            <summary>
            Checks if calling `Tensor.to()` with the parameters will result in actually copying the tensor.
            </summary>
            <param name="tensor">The tensor</param>
            <param name="dtype">The dtype to move to</param>
            <returns>True if the tensor will be copied</returns>
        </member>
        <member name="M:TorchSharp.TensorExtensionMethods.toWillCopy(TorchSharp.torch.Tensor,TorchSharp.torch.ScalarType,TorchSharp.torch.Device)">
            <summary>
            Checks if calling `Tensor.to()` with the parameters will result in actually copying the tensor.
            </summary>
            <param name="tensor">The tensor</param>
            <param name="dtype">The dtype to move to</param>
            <param name="device">The device to move to</param>
            <returns>True if the tensor will be copied</returns>
        </member>
        <member name="M:TorchSharp.TensorExtensionMethods.toWillCopy(TorchSharp.torch.Tensor,TorchSharp.torch.ScalarType,TorchSharp.DeviceType,System.Int32)">
            <summary>
            Checks if calling `Tensor.to()` with the parameters will result in actually copying the tensor.
            </summary>
            <param name="tensor">The tensor</param>
            <param name="dtype">The dtype to move to</param>
            <param name="deviceType">The device type to move to</param>
            <param name="deviceIndex">The device index to move to</param>
            <returns>True if the tensor will be copied</returns>
        </member>
        <member name="T:TorchSharp.ThreadDisposeScopeStatistics">
            <summary>
            Keeps track of the combined Tensor and PackedSequence statistics for the current thread. Can be queried to figure out performance/memory issues.
            </summary>
        </member>
        <member name="P:TorchSharp.ThreadDisposeScopeStatistics.CreatedOutsideScopeCount">
            <summary>
            The total number of Tensors and PackedSequence instances that were created on this thread, but weren't
            captured by a DisposeScope.
            </summary>
        </member>
        <member name="P:TorchSharp.ThreadDisposeScopeStatistics.DisposedOutsideScopeCount">
            <summary>
            The number of Tensors and PackedSequence instances that were Disposed on this thread, but weren't
            captured by a DisposeScope.
            </summary>
        </member>
        <member name="P:TorchSharp.ThreadDisposeScopeStatistics.CreatedInScopeCount">
            <summary>
            The number of Tensors and PackedSequence instances that were created on this thread and were captured
            by a DisposeScope.
            </summary>
        </member>
        <member name="P:TorchSharp.ThreadDisposeScopeStatistics.DisposedInScopeCount">
            <summary>
            The number of Tensors and PackedSequence instances that were disposed on this thread and were disposed
            while in a DisposeScope.
            </summary>
        </member>
        <member name="P:TorchSharp.ThreadDisposeScopeStatistics.AttachedToScopeCount">
            <summary>
            The number of Tensors and PackedSequence instances that were created on this thread outside a DisposeScope,
            and then eventually were attached to one.
            </summary>
        </member>
        <member name="P:TorchSharp.ThreadDisposeScopeStatistics.DetachedFromScopeCount">
            <summary>
            Number of Tensors and PackedSequence instances that were once included in a DisposeScope, but were
            subsequently detached.
            </summary>
        </member>
        <member name="P:TorchSharp.ThreadDisposeScopeStatistics.ThreadTotalLiveCount">
            <summary>
            Exact number of Tensors and PackedSequence instances that are still live. Is the difference of all
            created objects minus all disposed objects.
            </summary>
        </member>
        <member name="M:TorchSharp.ThreadDisposeScopeStatistics.Reset">
            <summary>
            Resets the counts for the current thread. See ThreadTotalLiveCount etc. Mainly used in tests and memory
            leak debugging to make sure we get a clean slate on the thread.
            </summary>
        </member>
        <member name="M:TorchSharp.ThreadDisposeScopeStatistics.ToString">
            <summary>
            A debug printout of all the properties and their values, suitable for a log or console output
            </summary>
            <returns></returns>
        </member>
        <member name="P:TorchSharp.ThreadDisposeScopeStatistics.TensorStatistics">
            <summary>
            Keeps track of the Tensor statistics for the current thread. Can be queried to figure out performance/memory issues.
            </summary>
        </member>
        <member name="P:TorchSharp.ThreadDisposeScopeStatistics.PackedSequenceStatistics">
            <summary>
            Keeps track of the PackedSequence statistics for the current thread. Can be queried to figure out performance/memory issues.
            </summary>
        </member>
        <member name="P:TorchSharp.LifetimeStatistics.CreatedOutsideScopeCount">
            <summary>
            The number of disposables that were created on this thread, but weren't captured by a DisposeScope.
            </summary>
        </member>
        <member name="P:TorchSharp.LifetimeStatistics.DisposedOutsideScopeCount">
            <summary>
            The number of disposables that were Disposed on this thread, but weren't captured by a DisposeScope.
            </summary>
        </member>
        <member name="P:TorchSharp.LifetimeStatistics.CreatedInScopeCount">
            <summary>
            The number of disposables that were created on this thread and were captured by a DisposeScope.
            </summary>
        </member>
        <member name="P:TorchSharp.LifetimeStatistics.DisposedInScopeCount">
            <summary>
            The number of disposables that were disposed on this thread and were disposed while in a DisposeScope.
            </summary>
        </member>
        <member name="P:TorchSharp.LifetimeStatistics.AttachedToScopeCount">
            <summary>
            The number of disposables that were created on this thread outside a DisposeScope, and then
            eventually were attached to one.
            </summary>
        </member>
        <member name="P:TorchSharp.LifetimeStatistics.DetachedFromScopeCount">
            <summary>
            Number of disposables that were once included in a DisposeScope, but were subsequently detached.
            </summary>
        </member>
        <member name="P:TorchSharp.LifetimeStatistics.ThreadTotalLiveCount">
            <summary>
            Exact number of objects that are still live. Is the difference of all created objects
            minus all disposed objects.
            </summary>
        </member>
        <member name="M:TorchSharp.LifetimeStatistics.Reset">
            <summary>
            Resets the counts for the current thread. See ThreadTotalLiveCount etc. Mainly used in tests to make sure
            we get a clean slate on the thread.
            </summary>
        </member>
        <member name="M:TorchSharp.LifetimeStatistics.ToString">
            <summary>
            A debug printout of all the properties and their values, suitable for a log or console output
            </summary>
            <returns></returns>
        </member>
        <member name="T:TorchSharp.DeviceType">
            <summary>
            The LibTorch device types.
            </summary>
            <remarks>TorchSharp currently only supports CPU and CUDA.</remarks>
        </member>
        <member name="T:TorchSharp.Utils.ComponentNameAttribute">
            <summary>
            Specifies the custom name for a component to be used in the module's state_dict instead of the default field name.
            </summary>
        </member>
        <member name="M:TorchSharp.Utils.CRC32C.process(System.Byte[])">
            <summary>
            Compule the CRC32C value for a byte array.
            </summary>
            <param name="data">A byte array.</param>
        </member>
        <member name="M:TorchSharp.Utils.CRC32C.process(System.Int32)">
            <summary>
            Compule the CRC32C value for a 32-bit integer.
            </summary>
            <param name="data">A byte array.</param>
        </member>
        <member name="M:TorchSharp.Utils.CRC32C.process(System.Int64)">
            <summary>
            Compule the CRC32C value for a 64-bit integer.
            </summary>
            <param name="data">A byte array.</param>
        </member>
        <member name="M:TorchSharp.Utils.Histogram.GetBinEdges(TorchSharp.torch.Tensor,TorchSharp.HistogramBinSelector,System.Nullable{System.ValueTuple{System.Double,System.Double}})">
            <summary>
            Computes the bins used internally by `histogram`.
            </summary>
            <param name="a"> Ravelled data array </param>
            <param name="bins"> Forwarded arguments from `histogram`. </param>
            <param name="range"> Ravelled weights array, or None </param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Utils.Histogram.GetOuterEdges(TorchSharp.torch.Tensor,System.Nullable{System.ValueTuple{System.Double,System.Double}})">
            <summary>
            Determine the outer bin edges to use, from either the data or the range argument
            </summary>
            <param name="a"></param>
            <param name="range"></param>
            <returns></returns>
            <exception cref="T:System.ArgumentException"></exception>
        </member>
        <member name="M:TorchSharp.Utils.Histogram.RavelAndCheckWeights(TorchSharp.torch.Tensor)">
             <summary>
             Check a and weights have matching shapes, and ravel both
            
             https://github.com/numpy/numpy/blob/v1.24.0/numpy/lib/histograms.py#L283
             </summary>
             <param name="input"></param>
             <returns></returns>
        </member>
        <member name="M:TorchSharp.Utils.Histogram.HistBinSqrt(TorchSharp.torch.Tensor,System.Nullable{System.ValueTuple{System.Double,System.Double}})">
             <summary>
             Square root histogram bin estimator.
            
             Bin width is inversely proportional to the data size. Used by many
             programs for its simplicity.
            
             https://github.com/numpy/numpy/blob/v1.24.0/numpy/lib/histograms.py#L32
             </summary>
             <param name="x"> Input data that is to be histogrammed, trimmed to range. May not be empty. </param>
             <param name="_"></param>
             <returns> An estimate of the optimal bin width for the given data. </returns>
        </member>
        <member name="M:TorchSharp.Utils.Histogram.HistBinSturges(TorchSharp.torch.Tensor,System.Nullable{System.ValueTuple{System.Double,System.Double}})">
             <summary>
             Sturges histogram bin estimator.
            
             A very simplistic estimator based on the assumption of normality of
             the data.This estimator has poor performance for non-normal data,
             which becomes especially obvious for large data sets.The estimate
             depends only on size of the data.
            
             https://github.com/numpy/numpy/blob/v1.24.0/numpy/lib/histograms.py#L53
             </summary>
             <param name="x"> Input data that is to be histogrammed, trimmed to range. May not be empty. </param>
             <param name="_"></param>
             <returns> An estimate of the optimal bin width for the given data. </returns>
        </member>
        <member name="M:TorchSharp.Utils.Histogram.HistBinRice(TorchSharp.torch.Tensor,System.Nullable{System.ValueTuple{System.Double,System.Double}})">
             <summary>
             Rice histogram bin estimator.
            
             Another simple estimator with no normality assumption. It has better
             performance for large data than Sturges, but tends to overestimate
             the number of bins. The number of bins is proportional to the cube
             root of data size (asymptotically optimal). The estimate depends
             only on size of the data.
            
             https://github.com/numpy/numpy/blob/v1.24.0/numpy/lib/histograms.py#L76
             </summary>
             <param name="x"> Input data that is to be histogrammed, trimmed to range. May not be empty. </param>
             <param name="_"></param>
             <returns> An estimate of the optimal bin width for the given data. </returns>
        </member>
        <member name="M:TorchSharp.Utils.Histogram.HistBinScott(TorchSharp.torch.Tensor,System.Nullable{System.ValueTuple{System.Double,System.Double}})">
             <summary>
             Scott histogram bin estimator.
            
             The binwidth is proportional to the standard deviation of the data
             and inversely proportional to the cube root of data size
             (asymptotically optimal).
            
             https://github.com/numpy/numpy/blob/v1.24.0/numpy/lib/histograms.py#L100
             </summary>
             <param name="x"> Input data that is to be histogrammed, trimmed to range. May not be empty. </param>
             <param name="_"></param>
             <returns> An estimate of the optimal bin width for the given data. </returns>
        </member>
        <member name="M:TorchSharp.Utils.Histogram.HistBinStone(TorchSharp.torch.Tensor,System.Nullable{System.ValueTuple{System.Double,System.Double}})">
             <summary>
             Histogram bin estimator based on minimizing the estimated integrated squared error (ISE).
            
             The number of bins is chosen by minimizing the estimated ISE against the unknown true distribution.
             The ISE is estimated using cross-validation and can be regarded as a generalization of Scott's rule.
             https://en.wikipedia.org/wiki/Histogram#Scott.27s_normal_reference_rule
             
             This paper by Stone appears to be the origination of this rule.
             http://digitalassets.lib.berkeley.edu/sdtr/ucb/text/34.pdf
            
             https://github.com/numpy/numpy/blob/v1.24.0/numpy/lib/histograms.py#L122
             </summary>
             <param name="x"> Input data that is to be histogrammed, trimmed to range. May not be empty. </param>
             <param name="range"> The lower and upper range of the bins. </param>
             <returns> An estimate of the optimal bin width for the given data. </returns>
        </member>
        <member name="M:TorchSharp.Utils.Histogram.HistBinDoane(TorchSharp.torch.Tensor,System.Nullable{System.ValueTuple{System.Double,System.Double}})">
             <summary>
             Doane's histogram bin estimator.
            
             Improved version of Sturges' formula which works better for
             non-normal data. See
             stats.stackexchange.com/questions/55134/doanes-formula-for-histogram-binning
            
             https://github.com/numpy/numpy/blob/v1.24.0/numpy/lib/histograms.py#L164
             </summary>
             <param name="x"> Input data that is to be histogrammed, trimmed to range. May not be empty. </param>
             <param name="_"></param>
             <returns> An estimate of the optimal bin width for the given data. </returns>
        </member>
        <member name="M:TorchSharp.Utils.Histogram.Ptp(TorchSharp.torch.Tensor)">
             <summary>
             This implementation avoids the problem of signed integer arrays having a
             peak-to-peak value that cannot be represented with the array's data type.
             This function returns an value for signed integer arrays.
            
             https://github.com/numpy/numpy/blob/v1.24.0/numpy/lib/histograms.py#L22
             </summary>
             <param name="input"></param>
             <returns></returns>
        </member>
        <member name="T:TorchSharp.Utils.LEB128Codec">
             <summary>
             LEB128 encoder / decoder
            
             LEB128 is the compression format used by BinaryWriter/Reader to encode string lengths,
             and it is convenient to use it for other lengths in the encoding of tensors and module
             state dictionaries.
             
             https://en.wikipedia.org/wiki/LEB128
             </summary>
        </member>
        <member name="M:TorchSharp.Utils.LEB128Codec.Encode(System.Int64)">
            <summary>
            Encode a long value.
            </summary>
            <param name="value">The input value.</param>
            <returns>The encoded value as a sequence of bytes.</returns>
        </member>
        <member name="M:TorchSharp.Utils.LEB128Codec.Encode(System.IO.BinaryWriter,System.Int64)">
            <summary>
            Encode a long value into a binary writer.
            </summary>
            <param name="writer">A BinaryWriter instance</param>
            <param name="value">The input value.</param>
        </member>
        <member name="M:TorchSharp.Utils.LEB128Codec.Decode(System.IO.BinaryReader)">
            <summary>
            Decode a long value from a binary reader
            </summary>
            <param name="reader">A BinaryReader instance used for input.</param>
            <returns>The decoded value</returns>
        </member>
        <member name="M:TorchSharp.Utils.LEB128Codec.Decode(System.Collections.Generic.IList{System.Byte})">
            <summary>
            Decode a long value from a sequence of bytes
            </summary>
            <param name="input">A sequence of bytes used for input.</param>
            <returns>The decoded value</returns>
        </member>
        <member name="T:TorchSharp.Utils.TypeFormatterSourceAttribute">
            <summary>
            Class used to identify the formatting logic for Tensors when using .NET Interactive.
            </summary>
        </member>
        <member name="T:TorchSharp.Utils.ReferenceEqualityComparer`1">
            <summary>
            A generic object comparerer that would only use object's reference,
            ignoring any <see cref="T:System.IEquatable`1"/> or <see cref="M:System.Object.Equals(System.Object)"/>  overrides.
            This should be replaced with the official ReferenceEqualityComparer as soon as the TorchSharp uses .NET 6.
            </summary>
        </member>
        <member name="M:TorchSharp.Utils.OrderedDict`2.clear">
            <summary>
            Remove all items from the ParameterDict.
            </summary>
        </member>
        <member name="M:TorchSharp.Utils.OrderedDict`2.items">
            <summary>
            Return an enumeration of the ParameterDict key/value pairs.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Utils.OrderedDict`2.keys">
            <summary>
            Return the ParameterDict keys.
            </summary>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Utils.OrderedDict`2.values">
            <summary>
            Return the ParameterDict values.
            </summary>
            <returns></returns>
        </member>
        <member name="T:TorchSharp.Utils.TensorAccessor`1">
            <summary>
            TensorAccessor is used to present the contents of a tensor or tensor view to the .NET world as an ordered collection
            of values that integrates well with things like LINQ and foreach loops in the .NET world.
            </summary>
            <typeparam name="T">The type of the tensor elements.</typeparam>
        </member>
        <member name="M:TorchSharp.Utils.TensorAccessor`1.ToNDArray">
            <summary>
            Extract tensor data as a multi-dimensional .NET array, with the same number of dimensions as the tensor.
            </summary>
            <returns>An array object, which should be cast to the concrete array type.</returns>
        </member>
        <member name="P:TorchSharp.Utils.TensorAccessor`1.Item(System.Int64[])">
            <summary>
            Access elements of the underlying tensor / tensor view.
            </summary>
            <param name="indices">A linear index into the data.</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Utils.TensorAccessor`1.TranslateIndex(System.Int64,TorchSharp.torch.Tensor)">
            <summary>
            Translates a linear index within the span represented by the accessor to a linear index
            used by the underlying tensor. The two should only be different if the tensor is a view
            rather than an allocated tensor.
            </summary>
        </member>
        <member name="M:TorchSharp.Utils.TensorAccessor`1.op_Equality(TorchSharp.Utils.TensorAccessor{`0},TorchSharp.Utils.TensorAccessor{`0})">
            <summary>
            Compare two tensors element-wise.
            </summary>
            <param name="left">A tensor</param>
            <param name="right">Another tensor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Utils.TensorAccessor`1.op_Inequality(TorchSharp.Utils.TensorAccessor{`0},TorchSharp.Utils.TensorAccessor{`0})">
            <summary>
            Compare two tensors element-wise.
            </summary>
            <param name="left">A tensor</param>
            <param name="right">Another tensor</param>
            <returns></returns>
        </member>
        <member name="M:TorchSharp.Utils.TensorAccessor`1.Equals(System.Object)">
            <summary>
            Compare two tensors element-wise.
            </summary>
            <param name="obj">Another tensor</param>
            <returns></returns>
        </member>
        <member name="T:TorchSharp.NativeTensorOrScalarIndexedArray">
            <summary>
            Allocator of TensorOrScalar[] that is used by the native runtime to allocate and register
            native memory for processing TorchScript arguments and return values.
            </summary>
        </member>
        <member name="T:TorchSharp.PinnedArray`1">
            <summary>
            Allocator of T[] that pins the memory and handles unpinning.
            (taken from StackOverflow)
            </summary>
            <typeparam name="T"></typeparam>
        </member>
        <member name="T:Tensorboard.AllocationDescriptionReflection">
            <summary>Holder for reflection information generated from tensorboard/compat/proto/allocation_description.proto</summary>
        </member>
        <member name="P:Tensorboard.AllocationDescriptionReflection.Descriptor">
            <summary>File descriptor for tensorboard/compat/proto/allocation_description.proto</summary>
        </member>
        <member name="F:Tensorboard.AllocationDescription.RequestedBytesFieldNumber">
            <summary>Field number for the "requested_bytes" field.</summary>
        </member>
        <member name="P:Tensorboard.AllocationDescription.RequestedBytes">
            <summary>
            Total number of bytes requested
            </summary>
        </member>
        <member name="F:Tensorboard.AllocationDescription.AllocatedBytesFieldNumber">
            <summary>Field number for the "allocated_bytes" field.</summary>
        </member>
        <member name="P:Tensorboard.AllocationDescription.AllocatedBytes">
            <summary>
            Total number of bytes allocated if known
            </summary>
        </member>
        <member name="F:Tensorboard.AllocationDescription.AllocatorNameFieldNumber">
            <summary>Field number for the "allocator_name" field.</summary>
        </member>
        <member name="P:Tensorboard.AllocationDescription.AllocatorName">
            <summary>
            Name of the allocator used
            </summary>
        </member>
        <member name="F:Tensorboard.AllocationDescription.AllocationIdFieldNumber">
            <summary>Field number for the "allocation_id" field.</summary>
        </member>
        <member name="P:Tensorboard.AllocationDescription.AllocationId">
            <summary>
            Identifier of the allocated buffer if known
            </summary>
        </member>
        <member name="F:Tensorboard.AllocationDescription.HasSingleReferenceFieldNumber">
            <summary>Field number for the "has_single_reference" field.</summary>
        </member>
        <member name="P:Tensorboard.AllocationDescription.HasSingleReference">
            <summary>
            Set if this tensor only has one remaining reference
            </summary>
        </member>
        <member name="F:Tensorboard.AllocationDescription.PtrFieldNumber">
            <summary>Field number for the "ptr" field.</summary>
        </member>
        <member name="P:Tensorboard.AllocationDescription.Ptr">
            <summary>
            Address of the allocation.
            </summary>
        </member>
        <member name="T:Tensorboard.ApiDefReflection">
            <summary>Holder for reflection information generated from tensorboard/compat/proto/api_def.proto</summary>
        </member>
        <member name="P:Tensorboard.ApiDefReflection.Descriptor">
            <summary>File descriptor for tensorboard/compat/proto/api_def.proto</summary>
        </member>
        <member name="T:Tensorboard.ApiDef">
             <summary>
             Used to specify and override the default API &amp; behavior in the
             generated code for client languages, from what you would get from
             the OpDef alone. There will be a set of ApiDefs that are common
             to all client languages, and another set per client language.
             The per-client-language ApiDefs will inherit values from the
             common ApiDefs which it can either replace or modify.
            
             We separate the API definition from the OpDef so we can evolve the
             API while remaining backwards compatible when interpreting old
             graphs.  Overrides go in an "api_def.pbtxt" file with a text-format
             ApiDefs message.
            
             WARNING: Be *very* careful changing the API for any existing op --
             you can change the semantics of existing code.  These changes may
             need to wait until a major release of TensorFlow to avoid breaking
             our compatibility promises.
             </summary>
        </member>
        <member name="F:Tensorboard.ApiDef.GraphOpNameFieldNumber">
            <summary>Field number for the "graph_op_name" field.</summary>
        </member>
        <member name="P:Tensorboard.ApiDef.GraphOpName">
            <summary>
            Name of the op (in the OpDef) to specify the API for.
            </summary>
        </member>
        <member name="F:Tensorboard.ApiDef.DeprecationMessageFieldNumber">
            <summary>Field number for the "deprecation_message" field.</summary>
        </member>
        <member name="P:Tensorboard.ApiDef.DeprecationMessage">
            <summary>
            If this op is deprecated, set deprecation message to the message
            that should be logged when this op is used.
            The message should indicate alternative op to use, if any.
            </summary>
        </member>
        <member name="F:Tensorboard.ApiDef.DeprecationVersionFieldNumber">
            <summary>Field number for the "deprecation_version" field.</summary>
        </member>
        <member name="P:Tensorboard.ApiDef.DeprecationVersion">
            <summary>
            Major version when the op will be deleted. For e.g. set this
            value to 2 if op API should be removed in TensorFlow 2.0 and
            deprecated in versions before that.
            </summary>
        </member>
        <member name="F:Tensorboard.ApiDef.VisibilityFieldNumber">
            <summary>Field number for the "visibility" field.</summary>
        </member>
        <member name="F:Tensorboard.ApiDef.EndpointFieldNumber">
            <summary>Field number for the "endpoint" field.</summary>
        </member>
        <member name="F:Tensorboard.ApiDef.InArgFieldNumber">
            <summary>Field number for the "in_arg" field.</summary>
        </member>
        <member name="F:Tensorboard.ApiDef.OutArgFieldNumber">
            <summary>Field number for the "out_arg" field.</summary>
        </member>
        <member name="F:Tensorboard.ApiDef.ArgOrderFieldNumber">
            <summary>Field number for the "arg_order" field.</summary>
        </member>
        <member name="P:Tensorboard.ApiDef.ArgOrder">
            <summary>
            List of original in_arg names to specify new argument order.
            Length of arg_order should be either empty to keep current order
            or match size of in_arg.
            </summary>
        </member>
        <member name="F:Tensorboard.ApiDef.AttrFieldNumber">
            <summary>Field number for the "attr" field.</summary>
        </member>
        <member name="F:Tensorboard.ApiDef.SummaryFieldNumber">
            <summary>Field number for the "summary" field.</summary>
        </member>
        <member name="P:Tensorboard.ApiDef.Summary">
            <summary>
            One-line human-readable description of what the Op does.
            </summary>
        </member>
        <member name="F:Tensorboard.ApiDef.DescriptionFieldNumber">
            <summary>Field number for the "description" field.</summary>
        </member>
        <member name="P:Tensorboard.ApiDef.Description">
            <summary>
            Additional, longer human-readable description of what the Op does.
            </summary>
        </member>
        <member name="F:Tensorboard.ApiDef.DescriptionPrefixFieldNumber">
            <summary>Field number for the "description_prefix" field.</summary>
        </member>
        <member name="P:Tensorboard.ApiDef.DescriptionPrefix">
            <summary>
            Modify an existing/inherited description by adding text to the beginning
            or end.
            </summary>
        </member>
        <member name="F:Tensorboard.ApiDef.DescriptionSuffixFieldNumber">
            <summary>Field number for the "description_suffix" field.</summary>
        </member>
        <member name="T:Tensorboard.ApiDef.Types">
            <summary>Container for nested types declared in the ApiDef message type.</summary>
        </member>
        <member name="F:Tensorboard.ApiDef.Types.Visibility.DefaultVisibility">
            <summary>
            Normally this is "VISIBLE" unless you are inheriting a
            different value from another ApiDef.
            </summary>
        </member>
        <member name="F:Tensorboard.ApiDef.Types.Visibility.Visible">
            <summary>
            Publicly visible in the API.
            </summary>
        </member>
        <member name="F:Tensorboard.ApiDef.Types.Visibility.Skip">
            <summary>
            Do not include this op in the generated API. If visibility is
            set to 'SKIP', other fields are ignored for this op.
            </summary>
        </member>
        <member name="F:Tensorboard.ApiDef.Types.Visibility.Hidden">
            <summary>
            Hide this op by putting it into an internal namespace (or whatever
            is appropriate in the target language).
            </summary>
        </member>
        <member name="T:Tensorboard.ApiDef.Types.Endpoint">
            <summary>
            If you specify any endpoint, this will replace all of the
            inherited endpoints.  The first endpoint should be the
            "canonical" endpoint, and should not be deprecated (unless all
            endpoints are deprecated).
            </summary>
        </member>
        <member name="F:Tensorboard.ApiDef.Types.Endpoint.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="P:Tensorboard.ApiDef.Types.Endpoint.Name">
            <summary>
            Name should be either like "CamelCaseName" or
            "Package.CamelCaseName". Client-language-specific ApiDefs may
            use a snake_case convention instead of CamelCase.
            </summary>
        </member>
        <member name="F:Tensorboard.ApiDef.Types.Endpoint.DeprecatedFieldNumber">
            <summary>Field number for the "deprecated" field.</summary>
        </member>
        <member name="P:Tensorboard.ApiDef.Types.Endpoint.Deprecated">
            <summary>
            Set if this endpoint is deprecated. If set to true, a message suggesting
            to use a non-deprecated endpoint instead will be printed. If all
            endpoints are deprecated, set deprecation_message in ApiDef instead.
            </summary>
        </member>
        <member name="F:Tensorboard.ApiDef.Types.Endpoint.DeprecationVersionFieldNumber">
            <summary>Field number for the "deprecation_version" field.</summary>
        </member>
        <member name="P:Tensorboard.ApiDef.Types.Endpoint.DeprecationVersion">
            <summary>
            Major version when an endpoint will be deleted. For e.g. set this
            value to 2 if endpoint should be removed in TensorFlow 2.0 and
            deprecated in versions before that.
            </summary>
        </member>
        <member name="F:Tensorboard.ApiDef.Types.Arg.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="F:Tensorboard.ApiDef.Types.Arg.RenameToFieldNumber">
            <summary>Field number for the "rename_to" field.</summary>
        </member>
        <member name="P:Tensorboard.ApiDef.Types.Arg.RenameTo">
            <summary>
            Change the name used to access this arg in the API from what
            is used in the GraphDef.  Note that these names in `backticks`
            will also be replaced in the summary &amp; description fields.
            </summary>
        </member>
        <member name="F:Tensorboard.ApiDef.Types.Arg.DescriptionFieldNumber">
            <summary>Field number for the "description" field.</summary>
        </member>
        <member name="P:Tensorboard.ApiDef.Types.Arg.Description">
            <summary>
            Note: this will replace any inherited arg doc. There is no
            current way of modifying arg descriptions (other than replacing
            them entirely) as can be done with op descriptions.
            </summary>
        </member>
        <member name="T:Tensorboard.ApiDef.Types.Attr">
            <summary>
            Description of the graph-construction-time configuration of this
            Op.  That is to say, this describes the attr fields that will
            be specified in the NodeDef.
            </summary>
        </member>
        <member name="F:Tensorboard.ApiDef.Types.Attr.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="F:Tensorboard.ApiDef.Types.Attr.RenameToFieldNumber">
            <summary>Field number for the "rename_to" field.</summary>
        </member>
        <member name="P:Tensorboard.ApiDef.Types.Attr.RenameTo">
            <summary>
            Change the name used to access this attr in the API from what
            is used in the GraphDef.  Note that these names in `backticks`
            will also be replaced in the summary &amp; description fields.
            </summary>
        </member>
        <member name="F:Tensorboard.ApiDef.Types.Attr.DefaultValueFieldNumber">
            <summary>Field number for the "default_value" field.</summary>
        </member>
        <member name="P:Tensorboard.ApiDef.Types.Attr.DefaultValue">
            <summary>
            Specify a new default value to use for this attr.  This default
            will be used when creating new graphs, as opposed to the
            default in the OpDef, which will be used when interpreting old
            GraphDefs.
            </summary>
        </member>
        <member name="F:Tensorboard.ApiDef.Types.Attr.DescriptionFieldNumber">
            <summary>Field number for the "description" field.</summary>
        </member>
        <member name="P:Tensorboard.ApiDef.Types.Attr.Description">
            <summary>
            Note: this will replace any inherited attr doc, there is no current
            way of modifying attr descriptions as can be done with op descriptions.
            </summary>
        </member>
        <member name="F:Tensorboard.ApiDefs.OpFieldNumber">
            <summary>Field number for the "op" field.</summary>
        </member>
        <member name="T:Tensorboard.AttrValueReflection">
            <summary>Holder for reflection information generated from tensorboard/compat/proto/attr_value.proto</summary>
        </member>
        <member name="P:Tensorboard.AttrValueReflection.Descriptor">
            <summary>File descriptor for tensorboard/compat/proto/attr_value.proto</summary>
        </member>
        <member name="T:Tensorboard.AttrValue">
            <summary>
            Protocol buffer representing the value for an attr used to configure an Op.
            Comment indicates the corresponding attr type.  Only the field matching the
            attr type may be filled.
            </summary>
        </member>
        <member name="F:Tensorboard.AttrValue.SFieldNumber">
            <summary>Field number for the "s" field.</summary>
        </member>
        <member name="P:Tensorboard.AttrValue.S">
            <summary>
            "string"
            </summary>
        </member>
        <member name="F:Tensorboard.AttrValue.IFieldNumber">
            <summary>Field number for the "i" field.</summary>
        </member>
        <member name="P:Tensorboard.AttrValue.I">
            <summary>
            "int"
            </summary>
        </member>
        <member name="F:Tensorboard.AttrValue.FFieldNumber">
            <summary>Field number for the "f" field.</summary>
        </member>
        <member name="P:Tensorboard.AttrValue.F">
            <summary>
            "float"
            </summary>
        </member>
        <member name="F:Tensorboard.AttrValue.BFieldNumber">
            <summary>Field number for the "b" field.</summary>
        </member>
        <member name="P:Tensorboard.AttrValue.B">
            <summary>
            "bool"
            </summary>
        </member>
        <member name="F:Tensorboard.AttrValue.TypeFieldNumber">
            <summary>Field number for the "type" field.</summary>
        </member>
        <member name="P:Tensorboard.AttrValue.Type">
            <summary>
            "type"
            </summary>
        </member>
        <member name="F:Tensorboard.AttrValue.ShapeFieldNumber">
            <summary>Field number for the "shape" field.</summary>
        </member>
        <member name="P:Tensorboard.AttrValue.Shape">
            <summary>
            "shape"
            </summary>
        </member>
        <member name="F:Tensorboard.AttrValue.TensorFieldNumber">
            <summary>Field number for the "tensor" field.</summary>
        </member>
        <member name="P:Tensorboard.AttrValue.Tensor">
            <summary>
            "tensor"
            </summary>
        </member>
        <member name="F:Tensorboard.AttrValue.ListFieldNumber">
            <summary>Field number for the "list" field.</summary>
        </member>
        <member name="P:Tensorboard.AttrValue.List">
            <summary>
            any "list(...)"
            </summary>
        </member>
        <member name="F:Tensorboard.AttrValue.FuncFieldNumber">
            <summary>Field number for the "func" field.</summary>
        </member>
        <member name="P:Tensorboard.AttrValue.Func">
            <summary>
            "func" represents a function. func.name is a function's name or
            a primitive op's name. func.attr.first is the name of an attr
            defined for that function. func.attr.second is the value for
            that attr in the instantiation.
            </summary>
        </member>
        <member name="F:Tensorboard.AttrValue.PlaceholderFieldNumber">
            <summary>Field number for the "placeholder" field.</summary>
        </member>
        <member name="P:Tensorboard.AttrValue.Placeholder">
            <summary>
            This is a placeholder only used in nodes defined inside a
            function.  It indicates the attr value will be supplied when
            the function is instantiated.  For example, let us suppose a
            node "N" in function "FN". "N" has an attr "A" with value
            placeholder = "foo". When FN is instantiated with attr "foo"
            set to "bar", the instantiated node N's attr A will have been
            given the value "bar".
            </summary>
        </member>
        <member name="T:Tensorboard.AttrValue.ValueOneofCase">
            <summary>Enum of possible cases for the "value" oneof.</summary>
        </member>
        <member name="T:Tensorboard.AttrValue.Types">
            <summary>Container for nested types declared in the AttrValue message type.</summary>
        </member>
        <member name="T:Tensorboard.AttrValue.Types.ListValue">
            <summary>
            DISABLED.IfChange
            </summary>
        </member>
        <member name="F:Tensorboard.AttrValue.Types.ListValue.SFieldNumber">
            <summary>Field number for the "s" field.</summary>
        </member>
        <member name="P:Tensorboard.AttrValue.Types.ListValue.S">
            <summary>
            "list(string)"
            </summary>
        </member>
        <member name="F:Tensorboard.AttrValue.Types.ListValue.IFieldNumber">
            <summary>Field number for the "i" field.</summary>
        </member>
        <member name="P:Tensorboard.AttrValue.Types.ListValue.I">
            <summary>
            "list(int)"
            </summary>
        </member>
        <member name="F:Tensorboard.AttrValue.Types.ListValue.FFieldNumber">
            <summary>Field number for the "f" field.</summary>
        </member>
        <member name="P:Tensorboard.AttrValue.Types.ListValue.F">
            <summary>
            "list(float)"
            </summary>
        </member>
        <member name="F:Tensorboard.AttrValue.Types.ListValue.BFieldNumber">
            <summary>Field number for the "b" field.</summary>
        </member>
        <member name="P:Tensorboard.AttrValue.Types.ListValue.B">
            <summary>
            "list(bool)"
            </summary>
        </member>
        <member name="F:Tensorboard.AttrValue.Types.ListValue.TypeFieldNumber">
            <summary>Field number for the "type" field.</summary>
        </member>
        <member name="P:Tensorboard.AttrValue.Types.ListValue.Type">
            <summary>
            "list(type)"
            </summary>
        </member>
        <member name="F:Tensorboard.AttrValue.Types.ListValue.ShapeFieldNumber">
            <summary>Field number for the "shape" field.</summary>
        </member>
        <member name="P:Tensorboard.AttrValue.Types.ListValue.Shape">
            <summary>
            "list(shape)"
            </summary>
        </member>
        <member name="F:Tensorboard.AttrValue.Types.ListValue.TensorFieldNumber">
            <summary>Field number for the "tensor" field.</summary>
        </member>
        <member name="P:Tensorboard.AttrValue.Types.ListValue.Tensor">
            <summary>
            "list(tensor)"
            </summary>
        </member>
        <member name="F:Tensorboard.AttrValue.Types.ListValue.FuncFieldNumber">
            <summary>Field number for the "func" field.</summary>
        </member>
        <member name="P:Tensorboard.AttrValue.Types.ListValue.Func">
            <summary>
            "list(attr)"
            </summary>
        </member>
        <member name="T:Tensorboard.NameAttrList">
            <summary>
            A list of attr names and their values. The whole list is attached
            with a string name.  E.g., MatMul[T=float].
            </summary>
        </member>
        <member name="F:Tensorboard.NameAttrList.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="F:Tensorboard.NameAttrList.AttrFieldNumber">
            <summary>Field number for the "attr" field.</summary>
        </member>
        <member name="T:Tensorboard.ClusterReflection">
            <summary>Holder for reflection information generated from tensorboard/compat/proto/cluster.proto</summary>
        </member>
        <member name="P:Tensorboard.ClusterReflection.Descriptor">
            <summary>File descriptor for tensorboard/compat/proto/cluster.proto</summary>
        </member>
        <member name="T:Tensorboard.JobDef">
            <summary>
            Defines a single job in a TensorFlow cluster.
            </summary>
        </member>
        <member name="F:Tensorboard.JobDef.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="P:Tensorboard.JobDef.Name">
            <summary>
            The name of this job.
            </summary>
        </member>
        <member name="F:Tensorboard.JobDef.TasksFieldNumber">
            <summary>Field number for the "tasks" field.</summary>
        </member>
        <member name="P:Tensorboard.JobDef.Tasks">
             <summary>
             Mapping from task ID to "hostname:port" string.
            
             If the `name` field contains "worker", and the `tasks` map contains a
             mapping from 7 to "example.org:2222", then the device prefix
             "/job:worker/task:7" will be assigned to "example.org:2222".
             </summary>
        </member>
        <member name="T:Tensorboard.ClusterDef">
            <summary>
            Defines a TensorFlow cluster as a set of jobs.
            </summary>
        </member>
        <member name="F:Tensorboard.ClusterDef.JobFieldNumber">
            <summary>Field number for the "job" field.</summary>
        </member>
        <member name="P:Tensorboard.ClusterDef.Job">
            <summary>
            The jobs that comprise the cluster.
            </summary>
        </member>
        <member name="T:Tensorboard.ConfigReflection">
            <summary>Holder for reflection information generated from tensorboard/compat/proto/config.proto</summary>
        </member>
        <member name="P:Tensorboard.ConfigReflection.Descriptor">
            <summary>File descriptor for tensorboard/compat/proto/config.proto</summary>
        </member>
        <member name="F:Tensorboard.GPUOptions.PerProcessGpuMemoryFractionFieldNumber">
            <summary>Field number for the "per_process_gpu_memory_fraction" field.</summary>
        </member>
        <member name="P:Tensorboard.GPUOptions.PerProcessGpuMemoryFraction">
             <summary>
             Fraction of the available GPU memory to allocate for each process.
             1 means to allocate all of the GPU memory, 0.5 means the process
             allocates up to ~50% of the available GPU memory.
            
             GPU memory is pre-allocated unless the allow_growth option is enabled.
            
             If greater than 1.0, uses CUDA unified memory to potentially oversubscribe
             the amount of memory available on the GPU device by using host memory as a
             swap space. Accessing memory not available on the device will be
             significantly slower as that would require memory transfer between the host
             and the device. Options to reduce the memory requirement should be
             considered before enabling this option as this may come with a negative
             performance impact. Oversubscription using the unified memory requires
             Pascal class or newer GPUs and it is currently only supported on the Linux
             operating system. See
             https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#um-requirements
             for the detailed requirements.
             </summary>
        </member>
        <member name="F:Tensorboard.GPUOptions.AllowGrowthFieldNumber">
            <summary>Field number for the "allow_growth" field.</summary>
        </member>
        <member name="P:Tensorboard.GPUOptions.AllowGrowth">
            <summary>
            If true, the allocator does not pre-allocate the entire specified
            GPU memory region, instead starting small and growing as needed.
            </summary>
        </member>
        <member name="F:Tensorboard.GPUOptions.AllocatorTypeFieldNumber">
            <summary>Field number for the "allocator_type" field.</summary>
        </member>
        <member name="P:Tensorboard.GPUOptions.AllocatorType">
             <summary>
             The type of GPU allocation strategy to use.
            
             Allowed values:
             "": The empty string (default) uses a system-chosen default
                 which may change over time.
            
             "BFC": A "Best-fit with coalescing" algorithm, simplified from a
                    version of dlmalloc.
             </summary>
        </member>
        <member name="F:Tensorboard.GPUOptions.DeferredDeletionBytesFieldNumber">
            <summary>Field number for the "deferred_deletion_bytes" field.</summary>
        </member>
        <member name="P:Tensorboard.GPUOptions.DeferredDeletionBytes">
            <summary>
            Delay deletion of up to this many bytes to reduce the number of
            interactions with gpu driver code.  If 0, the system chooses
            a reasonable default (several MBs).
            </summary>
        </member>
        <member name="F:Tensorboard.GPUOptions.VisibleDeviceListFieldNumber">
            <summary>Field number for the "visible_device_list" field.</summary>
        </member>
        <member name="P:Tensorboard.GPUOptions.VisibleDeviceList">
             <summary>
             A comma-separated list of GPU ids that determines the 'visible'
             to 'virtual' mapping of GPU devices.  For example, if TensorFlow
             can see 8 GPU devices in the process, and one wanted to map
             visible GPU devices 5 and 3 as "/device:GPU:0", and "/device:GPU:1",
             then one would specify this field as "5,3".  This field is similar in
             spirit to the CUDA_VISIBLE_DEVICES environment variable, except
             it applies to the visible GPU devices in the process.
            
             NOTE:
             1. The GPU driver provides the process with the visible GPUs
                in an order which is not guaranteed to have any correlation to
                the *physical* GPU id in the machine.  This field is used for
                remapping "visible" to "virtual", which means this operates only
                after the process starts.  Users are required to use vendor
                specific mechanisms (e.g., CUDA_VISIBLE_DEVICES) to control the
                physical to visible device mapping prior to invoking TensorFlow.
             2. In the code, the ids in this list are also called "platform GPU id"s,
                and the 'virtual' ids of GPU devices (i.e. the ids in the device
                name "/device:GPU:&lt;id>") are also called "TF GPU id"s. Please
                refer to third_party/tensorflow/core/common_runtime/gpu/gpu_id.h
                for more information.
             </summary>
        </member>
        <member name="F:Tensorboard.GPUOptions.PollingActiveDelayUsecsFieldNumber">
            <summary>Field number for the "polling_active_delay_usecs" field.</summary>
        </member>
        <member name="P:Tensorboard.GPUOptions.PollingActiveDelayUsecs">
            <summary>
            In the event polling loop sleep this many microseconds between
            PollEvents calls, when the queue is not empty.  If value is not
            set or set to 0, gets set to a non-zero default.
            </summary>
        </member>
        <member name="F:Tensorboard.GPUOptions.PollingInactiveDelayMsecsFieldNumber">
            <summary>Field number for the "polling_inactive_delay_msecs" field.</summary>
        </member>
        <member name="P:Tensorboard.GPUOptions.PollingInactiveDelayMsecs">
            <summary>
            This field is deprecated and ignored.
            </summary>
        </member>
        <member name="F:Tensorboard.GPUOptions.ForceGpuCompatibleFieldNumber">
            <summary>Field number for the "force_gpu_compatible" field.</summary>
        </member>
        <member name="P:Tensorboard.GPUOptions.ForceGpuCompatible">
            <summary>
            Force all tensors to be gpu_compatible. On a GPU-enabled TensorFlow,
            enabling this option forces all CPU tensors to be allocated with Cuda
            pinned memory. Normally, TensorFlow will infer which tensors should be
            allocated as the pinned memory. But in case where the inference is
            incomplete, this option can significantly speed up the cross-device memory
            copy performance as long as it fits the memory.
            Note that this option is not something that should be
            enabled by default for unknown or very large models, since all Cuda pinned
            memory is unpageable, having too much pinned memory might negatively impact
            the overall host system performance.
            </summary>
        </member>
        <member name="F:Tensorboard.GPUOptions.ExperimentalFieldNumber">
            <summary>Field number for the "experimental" field.</summary>
        </member>
        <member name="P:Tensorboard.GPUOptions.Experimental">
            <summary>
            Everything inside experimental is subject to change and is not subject
            to API stability guarantees in
            https://www.tensorflow.org/guide/version_compat.
            </summary>
        </member>
        <member name="T:Tensorboard.GPUOptions.Types">
            <summary>Container for nested types declared in the GPUOptions message type.</summary>
        </member>
        <member name="F:Tensorboard.GPUOptions.Types.Experimental.VirtualDevicesFieldNumber">
            <summary>Field number for the "virtual_devices" field.</summary>
        </member>
        <member name="P:Tensorboard.GPUOptions.Types.Experimental.VirtualDevices">
             <summary>
             The multi virtual device settings. If empty (not set), it will create
             single virtual device on each visible GPU, according to the settings
             in "visible_device_list" above. Otherwise, the number of elements in the
             list must be the same as the number of visible GPUs (after
             "visible_device_list" filtering if it is set), and the string represented
             device names (e.g. /device:GPU:&lt;id>) will refer to the virtual
             devices and have the &lt;id> field assigned sequentially starting from 0,
             according to the order they appear in this list and the "memory_limit"
             list inside each element. For example,
               visible_device_list = "1,0"
               virtual_devices { memory_limit: 1GB memory_limit: 2GB }
               virtual_devices {}
             will create three virtual devices as:
               /device:GPU:0 -> visible GPU 1 with 1GB memory
               /device:GPU:1 -> visible GPU 1 with 2GB memory
               /device:GPU:2 -> visible GPU 0 with all available memory
            
             NOTE:
             1. It's invalid to set both this and "per_process_gpu_memory_fraction"
                at the same time.
             2. Currently this setting is per-process, not per-session. Using
                different settings in different sessions within same process will
                result in undefined behavior.
             </summary>
        </member>
        <member name="F:Tensorboard.GPUOptions.Types.Experimental.UseUnifiedMemoryFieldNumber">
            <summary>Field number for the "use_unified_memory" field.</summary>
        </member>
        <member name="P:Tensorboard.GPUOptions.Types.Experimental.UseUnifiedMemory">
            <summary>
            If true, uses CUDA unified memory for memory allocations. If
            per_process_gpu_memory_fraction option is greater than 1.0, then unified
            memory is used regardless of the value for this field. See comments for
            per_process_gpu_memory_fraction field for more details and requirements
            of the unified memory. This option is useful to oversubscribe memory if
            multiple processes are sharing a single GPU while individually using less
            than 1.0 per process memory fraction.
            </summary>
        </member>
        <member name="F:Tensorboard.GPUOptions.Types.Experimental.NumDevToDevCopyStreamsFieldNumber">
            <summary>Field number for the "num_dev_to_dev_copy_streams" field.</summary>
        </member>
        <member name="P:Tensorboard.GPUOptions.Types.Experimental.NumDevToDevCopyStreams">
            <summary>
            If > 1, the number of device-to-device copy streams to create
            for each GPUDevice.  Default value is 0, which is automatically
            converted to 1.
            </summary>
        </member>
        <member name="F:Tensorboard.GPUOptions.Types.Experimental.CollectiveRingOrderFieldNumber">
            <summary>Field number for the "collective_ring_order" field.</summary>
        </member>
        <member name="P:Tensorboard.GPUOptions.Types.Experimental.CollectiveRingOrder">
            <summary>
            If non-empty, defines a good GPU ring order on a single worker based on
            device interconnect.  This assumes that all workers have the same GPU
            topology.  Specify as a comma-separated string, e.g. "3,2,1,0,7,6,5,4".
            This ring order is used by the RingReducer implementation of
            CollectiveReduce, and serves as an override to automatic ring order
            generation in OrderTaskDeviceMap() during CollectiveParam resolution.
            </summary>
        </member>
        <member name="F:Tensorboard.GPUOptions.Types.Experimental.TimestampedAllocatorFieldNumber">
            <summary>Field number for the "timestamped_allocator" field.</summary>
        </member>
        <member name="P:Tensorboard.GPUOptions.Types.Experimental.TimestampedAllocator">
            <summary>
            If true then extra work is done by GPUDevice and GPUBFCAllocator to
            keep track of when GPU memory is freed and when kernels actually
            complete so that we can know when a nominally free memory chunk
            is really not subject to pending use.
            </summary>
        </member>
        <member name="F:Tensorboard.GPUOptions.Types.Experimental.KernelTrackerMaxIntervalFieldNumber">
            <summary>Field number for the "kernel_tracker_max_interval" field.</summary>
        </member>
        <member name="P:Tensorboard.GPUOptions.Types.Experimental.KernelTrackerMaxInterval">
             <summary>
             Parameters for GPUKernelTracker.  By default no kernel tracking is done.
             Note that timestamped_allocator is only effective if some tracking is
             specified.
            
             If kernel_tracker_max_interval = n > 0, then a tracking event
             is inserted after every n kernels without an event.
             </summary>
        </member>
        <member name="F:Tensorboard.GPUOptions.Types.Experimental.KernelTrackerMaxBytesFieldNumber">
            <summary>Field number for the "kernel_tracker_max_bytes" field.</summary>
        </member>
        <member name="P:Tensorboard.GPUOptions.Types.Experimental.KernelTrackerMaxBytes">
            <summary>
            If kernel_tracker_max_bytes = n > 0, then a tracking event is
            inserted after every series of kernels allocating a sum of
            memory >= n.  If one kernel allocates b * n bytes, then one
            event will be inserted after it, but it will count as b against
            the pending limit.
            </summary>
        </member>
        <member name="F:Tensorboard.GPUOptions.Types.Experimental.KernelTrackerMaxPendingFieldNumber">
            <summary>Field number for the "kernel_tracker_max_pending" field.</summary>
        </member>
        <member name="P:Tensorboard.GPUOptions.Types.Experimental.KernelTrackerMaxPending">
            <summary>
            If kernel_tracker_max_pending > 0 then no more than this many
            tracking events can be outstanding at a time.  An attempt to
            launch an additional kernel will stall until an event
            completes.
            </summary>
        </member>
        <member name="F:Tensorboard.GPUOptions.Types.Experimental.InternalFragmentationFractionFieldNumber">
            <summary>Field number for the "internal_fragmentation_fraction" field.</summary>
        </member>
        <member name="P:Tensorboard.GPUOptions.Types.Experimental.InternalFragmentationFraction">
            <summary>
            BFC Allocator can return an allocated chunk of memory upto 2x the
            requested size. For virtual devices with tight memory constraints, and
            proportionately large allocation requests, this can lead to a significant
            reduction in available memory. The threshold below controls when a chunk
            should be split if the chunk size exceeds requested memory size. It is
            expressed as a fraction of total available memory for the tf device. For
            example setting it to 0.05 would imply a chunk needs to be split if its
            size exceeds the requested memory by 5% of the total virtual device/gpu
            memory size.
            </summary>
        </member>
        <member name="F:Tensorboard.GPUOptions.Types.Experimental.UseCudaMallocAsyncFieldNumber">
            <summary>Field number for the "use_cuda_malloc_async" field.</summary>
        </member>
        <member name="P:Tensorboard.GPUOptions.Types.Experimental.UseCudaMallocAsync">
            <summary>
            When true, use CUDA cudaMallocAsync API instead of TF gpu allocator.
            </summary>
        </member>
        <member name="F:Tensorboard.GPUOptions.Types.Experimental.DisallowRetryOnAllocationFailureFieldNumber">
            <summary>Field number for the "disallow_retry_on_allocation_failure" field.</summary>
        </member>
        <member name="P:Tensorboard.GPUOptions.Types.Experimental.DisallowRetryOnAllocationFailure">
            <summary>
            By default, BFCAllocator may sleep when it runs out of memory, in the
            hopes that another thread will free up memory in the meantime.  Setting
            this to true disables the sleep; instead we'll OOM immediately.
            </summary>
        </member>
        <member name="T:Tensorboard.GPUOptions.Types.Experimental.Types">
            <summary>Container for nested types declared in the Experimental message type.</summary>
        </member>
        <member name="T:Tensorboard.GPUOptions.Types.Experimental.Types.VirtualDevices">
            <summary>
            Configuration for breaking down a visible GPU into multiple "virtual"
            devices.
            </summary>
        </member>
        <member name="F:Tensorboard.GPUOptions.Types.Experimental.Types.VirtualDevices.MemoryLimitMbFieldNumber">
            <summary>Field number for the "memory_limit_mb" field.</summary>
        </member>
        <member name="P:Tensorboard.GPUOptions.Types.Experimental.Types.VirtualDevices.MemoryLimitMb">
             <summary>
             Per "virtual" device memory limit, in MB. The number of elements in
             the list is the number of virtual devices to create on the
             corresponding visible GPU (see "virtual_devices" below).
             If empty, it will create single virtual device taking all available
             memory from the device.
            
             For the concept of "visible" and "virtual" GPU, see the comments for
             "visible_device_list" above for more information.
             </summary>
        </member>
        <member name="F:Tensorboard.GPUOptions.Types.Experimental.Types.VirtualDevices.PriorityFieldNumber">
            <summary>Field number for the "priority" field.</summary>
        </member>
        <member name="P:Tensorboard.GPUOptions.Types.Experimental.Types.VirtualDevices.Priority">
             <summary>
             Priority values to use with the virtual devices. Use the cuda function
             cudaDeviceGetStreamPriorityRange to query for valid range of values for
             priority.
            
             On a P4000 GPU with cuda 10.1, the priority range reported was 0 for
             least priority and -1 for greatest priority.
            
             If this field is not specified, then the virtual devices will be
             created with the default. If this field has values set, then the size
             of this must match with the above memory_limit_mb.
             </summary>
        </member>
        <member name="T:Tensorboard.OptimizerOptions">
            <summary>
            Options passed to the graph optimizer
            </summary>
        </member>
        <member name="F:Tensorboard.OptimizerOptions.DoCommonSubexpressionEliminationFieldNumber">
            <summary>Field number for the "do_common_subexpression_elimination" field.</summary>
        </member>
        <member name="P:Tensorboard.OptimizerOptions.DoCommonSubexpressionElimination">
            <summary>
            If true, optimize the graph using common subexpression elimination.
            Note: the optimization Level L1 will override this setting to true. So in
            order to disable common subexpression elimination the opt_level has to be
            set to L0.
            </summary>
        </member>
        <member name="F:Tensorboard.OptimizerOptions.DoConstantFoldingFieldNumber">
            <summary>Field number for the "do_constant_folding" field.</summary>
        </member>
        <member name="P:Tensorboard.OptimizerOptions.DoConstantFolding">
            <summary>
            If true, perform constant folding optimization on the graph.
            Note: the optimization Level L1 will override this setting to true. So in
            order to disable constant folding the opt_level has to be set to L0.
            </summary>
        </member>
        <member name="F:Tensorboard.OptimizerOptions.MaxFoldedConstantInBytesFieldNumber">
            <summary>Field number for the "max_folded_constant_in_bytes" field.</summary>
        </member>
        <member name="P:Tensorboard.OptimizerOptions.MaxFoldedConstantInBytes">
            <summary>
            Constant folding optimization replaces tensors whose values can be
            predetermined, with constant nodes. To avoid inserting too large constants,
            the size of each constant created can be limited. If this value is zero, a
            default limit of 10 MiB will be applied. If constant folding optimization
            is disabled, this value is ignored.
            </summary>
        </member>
        <member name="F:Tensorboard.OptimizerOptions.DoFunctionInliningFieldNumber">
            <summary>Field number for the "do_function_inlining" field.</summary>
        </member>
        <member name="P:Tensorboard.OptimizerOptions.DoFunctionInlining">
            <summary>
            If true, perform function inlining on the graph.
            </summary>
        </member>
        <member name="F:Tensorboard.OptimizerOptions.OptLevelFieldNumber">
            <summary>Field number for the "opt_level" field.</summary>
        </member>
        <member name="P:Tensorboard.OptimizerOptions.OptLevel">
            <summary>
            Overall optimization level. The actual optimizations applied will be the
            logical OR of the flags that this level implies and any flags already set.
            </summary>
        </member>
        <member name="F:Tensorboard.OptimizerOptions.GlobalJitLevelFieldNumber">
            <summary>Field number for the "global_jit_level" field.</summary>
        </member>
        <member name="F:Tensorboard.OptimizerOptions.CpuGlobalJitFieldNumber">
            <summary>Field number for the "cpu_global_jit" field.</summary>
        </member>
        <member name="P:Tensorboard.OptimizerOptions.CpuGlobalJit">
            <summary>
            CPU code will be autoclustered only if global_jit_level >= ON_1 and either:
             - this flag is true, or
             - TF_XLA_FLAGS contains --tf_xla_cpu_global_jit=true.
            </summary>
        </member>
        <member name="T:Tensorboard.OptimizerOptions.Types">
            <summary>Container for nested types declared in the OptimizerOptions message type.</summary>
        </member>
        <member name="T:Tensorboard.OptimizerOptions.Types.Level">
            <summary>
            Optimization level
            </summary>
        </member>
        <member name="F:Tensorboard.OptimizerOptions.Types.Level.L1">
            <summary>
            L1 is the default level.
            Optimization performed at L1 :
            1. Common subexpression elimination
            2. Constant folding
            </summary>
        </member>
        <member name="F:Tensorboard.OptimizerOptions.Types.Level.L0">
            <summary>
            No optimizations
            </summary>
        </member>
        <member name="T:Tensorboard.OptimizerOptions.Types.GlobalJitLevel">
            <summary>
            Control the use of the compiler/jit.  Experimental.
            </summary>
        </member>
        <member name="F:Tensorboard.OptimizerOptions.Types.GlobalJitLevel.Default">
            <summary>
            Default setting ("off" now, but later expected to be "on")
            </summary>
        </member>
        <member name="F:Tensorboard.OptimizerOptions.Types.GlobalJitLevel.On1">
            <summary>
            The following settings turn on compilation, with higher values being
            more aggressive.  Higher values may reduce opportunities for parallelism
            and may use more memory.  (At present, there is no distinction, but this
            is expected to change.)
            </summary>
        </member>
        <member name="F:Tensorboard.GraphOptions.EnableRecvSchedulingFieldNumber">
            <summary>Field number for the "enable_recv_scheduling" field.</summary>
        </member>
        <member name="P:Tensorboard.GraphOptions.EnableRecvScheduling">
            <summary>
            If true, use control flow to schedule the activation of Recv nodes.
            (Currently ignored.)
            </summary>
        </member>
        <member name="F:Tensorboard.GraphOptions.OptimizerOptionsFieldNumber">
            <summary>Field number for the "optimizer_options" field.</summary>
        </member>
        <member name="P:Tensorboard.GraphOptions.OptimizerOptions">
            <summary>
            Options controlling how graph is optimized.
            </summary>
        </member>
        <member name="F:Tensorboard.GraphOptions.BuildCostModelFieldNumber">
            <summary>Field number for the "build_cost_model" field.</summary>
        </member>
        <member name="P:Tensorboard.GraphOptions.BuildCostModel">
            <summary>
            The number of steps to run before returning a cost model detailing
            the memory usage and performance of each node of the graph. 0 means
            no cost model.
            </summary>
        </member>
        <member name="F:Tensorboard.GraphOptions.BuildCostModelAfterFieldNumber">
            <summary>Field number for the "build_cost_model_after" field.</summary>
        </member>
        <member name="P:Tensorboard.GraphOptions.BuildCostModelAfter">
            <summary>
            The number of steps to skip before collecting statistics for the
            cost model.
            </summary>
        </member>
        <member name="F:Tensorboard.GraphOptions.InferShapesFieldNumber">
            <summary>Field number for the "infer_shapes" field.</summary>
        </member>
        <member name="P:Tensorboard.GraphOptions.InferShapes">
            <summary>
            Annotate each Node with Op output shape data, to the extent it can
            be statically inferred.
            </summary>
        </member>
        <member name="F:Tensorboard.GraphOptions.PlacePrunedGraphFieldNumber">
            <summary>Field number for the "place_pruned_graph" field.</summary>
        </member>
        <member name="P:Tensorboard.GraphOptions.PlacePrunedGraph">
             <summary>
             Only place the subgraphs that are run, rather than the entire graph.
            
             This is useful for interactive graph building, where one might
             produce graphs that cannot be placed during the debugging
             process.  In particular, it allows the client to continue work in
             a session after adding a node to a graph whose placement
             constraints are unsatisfiable.
             </summary>
        </member>
        <member name="F:Tensorboard.GraphOptions.EnableBfloat16SendrecvFieldNumber">
            <summary>Field number for the "enable_bfloat16_sendrecv" field.</summary>
        </member>
        <member name="P:Tensorboard.GraphOptions.EnableBfloat16Sendrecv">
            <summary>
            If true, transfer float values between processes as bfloat16.
            </summary>
        </member>
        <member name="F:Tensorboard.GraphOptions.TimelineStepFieldNumber">
            <summary>Field number for the "timeline_step" field.</summary>
        </member>
        <member name="P:Tensorboard.GraphOptions.TimelineStep">
            <summary>
            If > 0, record a timeline every this many steps.
            EXPERIMENTAL: This currently has no effect in MasterSession.
            </summary>
        </member>
        <member name="F:Tensorboard.GraphOptions.RewriteOptionsFieldNumber">
            <summary>Field number for the "rewrite_options" field.</summary>
        </member>
        <member name="P:Tensorboard.GraphOptions.RewriteOptions">
            <summary>
            Options that control the type and amount of graph rewriting.
            Not currently configurable via the public Python API (i.e. there is no API
            stability guarantee if you import RewriterConfig explicitly).
            </summary>
        </member>
        <member name="F:Tensorboard.ThreadPoolOptionProto.NumThreadsFieldNumber">
            <summary>Field number for the "num_threads" field.</summary>
        </member>
        <member name="P:Tensorboard.ThreadPoolOptionProto.NumThreads">
             <summary>
             The number of threads in the pool.
            
             0 means the system picks a value based on where this option proto is used
             (see the declaration of the specific field for more info).
             </summary>
        </member>
        <member name="F:Tensorboard.ThreadPoolOptionProto.GlobalNameFieldNumber">
            <summary>Field number for the "global_name" field.</summary>
        </member>
        <member name="P:Tensorboard.ThreadPoolOptionProto.GlobalName">
             <summary>
             The global name of the threadpool.
            
             If empty, then the threadpool is made and used according to the scope it's
             in - e.g., for a session threadpool, it is used by that session only.
            
             If non-empty, then:
             - a global threadpool associated with this name is looked
               up or created. This allows, for example, sharing one threadpool across
               many sessions (e.g., like the default behavior, if
               inter_op_parallelism_threads is not configured), but still partitioning
               into a large and small pool.
             - if the threadpool for this global_name already exists, then it is an
               error if the existing pool was created using a different num_threads
               value as is specified on this call.
             - threadpools created this way are never garbage collected.
             </summary>
        </member>
        <member name="F:Tensorboard.RPCOptions.UseRpcForInprocessMasterFieldNumber">
            <summary>Field number for the "use_rpc_for_inprocess_master" field.</summary>
        </member>
        <member name="P:Tensorboard.RPCOptions.UseRpcForInprocessMaster">
             <summary>
             If true, always use RPC to contact the session target.
            
             If false (the default option), TensorFlow may use an optimized
             transport for client-master communication that avoids the RPC
             stack. This option is primarily for used testing the RPC stack.
             </summary>
        </member>
        <member name="F:Tensorboard.RPCOptions.CompressionAlgorithmFieldNumber">
            <summary>Field number for the "compression_algorithm" field.</summary>
        </member>
        <member name="P:Tensorboard.RPCOptions.CompressionAlgorithm">
            <summary>
            The compression algorithm to be used. One of "deflate", "gzip".
            </summary>
        </member>
        <member name="F:Tensorboard.RPCOptions.CompressionLevelFieldNumber">
            <summary>Field number for the "compression_level" field.</summary>
        </member>
        <member name="P:Tensorboard.RPCOptions.CompressionLevel">
            <summary>
            If compression_algorithm is set, the compression level to be used.
            From 0 (no compression), up to 3.
            </summary>
        </member>
        <member name="F:Tensorboard.RPCOptions.CacheRpcResponseFieldNumber">
            <summary>Field number for the "cache_rpc_response" field.</summary>
        </member>
        <member name="P:Tensorboard.RPCOptions.CacheRpcResponse">
            <summary>
            Setting cache_rpc_response to true will enable sender side caching of
            response for RecvTensorAsync and RecvBufAsync to allow receiver to retry
            requests . This is only necessary when the network fabric is experiencing a
            significant error rate.  Without it we'll fail a step on an network error,
            while with it we'll be able to complete long steps (like complex
            initializations) in the face of some network errors during RecvTensor.
            </summary>
        </member>
        <member name="F:Tensorboard.RPCOptions.DisableSessionConnectionSharingFieldNumber">
            <summary>Field number for the "disable_session_connection_sharing" field.</summary>
        </member>
        <member name="P:Tensorboard.RPCOptions.DisableSessionConnectionSharing">
            <summary>
            Disables TCP connection sharing when opening a new RPC channel.
            </summary>
        </member>
        <member name="F:Tensorboard.RPCOptions.NumChannelsPerTargetFieldNumber">
            <summary>Field number for the "num_channels_per_target" field.</summary>
        </member>
        <member name="P:Tensorboard.RPCOptions.NumChannelsPerTarget">
            <summary>
            Setting num_channels_per_target > 0 allows uses of multiple channels to
            communicate to the same target. This can be used to improve the aggregate
            throughput on high speed links (e.g 100G) where single connection is not
            sufficient to maximize link utilization. Note that a single RPC only goes
            on a single channel, this only helps in situations where there are multiple
            transfers to the same target overlapping in time.
            </summary>
        </member>
        <member name="T:Tensorboard.SessionMetadata">
             <summary>
             Metadata about the session.
            
             This can be used by the runtime and the Ops for debugging, monitoring, etc.
            
             The (name, version) tuple is expected to be a unique identifier for
             sessions within the same process.
            
             NOTE: This is currently used and propagated only by the direct session.
             </summary>
        </member>
        <member name="F:Tensorboard.SessionMetadata.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="F:Tensorboard.SessionMetadata.VersionFieldNumber">
            <summary>Field number for the "version" field.</summary>
        </member>
        <member name="P:Tensorboard.SessionMetadata.Version">
            <summary>
            The version is optional. If set, needs to be >= 0.
            </summary>
        </member>
        <member name="T:Tensorboard.ConfigProto">
            <summary>
            Session configuration parameters.
            The system picks appropriate values for fields that are not set.
            </summary>
        </member>
        <member name="F:Tensorboard.ConfigProto.DeviceCountFieldNumber">
            <summary>Field number for the "device_count" field.</summary>
        </member>
        <member name="P:Tensorboard.ConfigProto.DeviceCount">
            <summary>
            Map from device type name (e.g., "CPU" or "GPU" ) to maximum
            number of devices of that type to use.  If a particular device
            type is not found in the map, the system picks an appropriate
            number.
            </summary>
        </member>
        <member name="F:Tensorboard.ConfigProto.IntraOpParallelismThreadsFieldNumber">
            <summary>Field number for the "intra_op_parallelism_threads" field.</summary>
        </member>
        <member name="P:Tensorboard.ConfigProto.IntraOpParallelismThreads">
             <summary>
             The execution of an individual op (for some op types) can be
             parallelized on a pool of intra_op_parallelism_threads.
             0 means the system picks an appropriate number.
            
             If you create an ordinary session, e.g., from Python or C++,
             then there is exactly one intra op thread pool per process.
             The first session created determines the number of threads in this pool.
             All subsequent sessions reuse/share this one global pool.
            
             There are notable exceptions to the default behavior described above:
             1. There is an environment variable  for overriding this thread pool,
                named TF_OVERRIDE_GLOBAL_THREADPOOL.
             2. When connecting to a server, such as a remote `tf.train.Server`
                instance, then this option will be ignored altogether.
             </summary>
        </member>
        <member name="F:Tensorboard.ConfigProto.InterOpParallelismThreadsFieldNumber">
            <summary>Field number for the "inter_op_parallelism_threads" field.</summary>
        </member>
        <member name="P:Tensorboard.ConfigProto.InterOpParallelismThreads">
             <summary>
             Nodes that perform blocking operations are enqueued on a pool of
             inter_op_parallelism_threads available in each process.
            
             0 means the system picks an appropriate number.
             Negative means all operations are performed in caller's thread.
            
             Note that the first Session created in the process sets the
             number of threads for all future sessions unless use_per_session_threads is
             true or session_inter_op_thread_pool is configured.
             </summary>
        </member>
        <member name="F:Tensorboard.ConfigProto.UsePerSessionThreadsFieldNumber">
            <summary>Field number for the "use_per_session_threads" field.</summary>
        </member>
        <member name="P:Tensorboard.ConfigProto.UsePerSessionThreads">
             <summary>
             If true, use a new set of threads for this session rather than the global
             pool of threads. Only supported by direct sessions.
            
             If false, use the global threads created by the first session, or the
             per-session thread pools configured by session_inter_op_thread_pool.
            
             This option is deprecated. The same effect can be achieved by setting
             session_inter_op_thread_pool to have one element, whose num_threads equals
             inter_op_parallelism_threads.
             </summary>
        </member>
        <member name="F:Tensorboard.ConfigProto.SessionInterOpThreadPoolFieldNumber">
            <summary>Field number for the "session_inter_op_thread_pool" field.</summary>
        </member>
        <member name="P:Tensorboard.ConfigProto.SessionInterOpThreadPool">
             <summary>
             This option is experimental - it may be replaced with a different mechanism
             in the future.
            
             Configures session thread pools. If this is configured, then RunOptions for
             a Run call can select the thread pool to use.
            
             The intended use is for when some session invocations need to run in a
             background pool limited to a small number of threads:
             - For example, a session may be configured to have one large pool (for
             regular compute) and one small pool (for periodic, low priority work);
             using the small pool is currently the mechanism for limiting the inter-op
             parallelism of the low priority work.  Note that it does not limit the
             parallelism of work spawned by a single op kernel implementation.
             - Using this setting is normally not needed in training, but may help some
             serving use cases.
             - It is also generally recommended to set the global_name field of this
             proto, to avoid creating multiple large pools. It is typically better to
             run the non-low-priority work, even across sessions, in a single large
             pool.
             </summary>
        </member>
        <member name="F:Tensorboard.ConfigProto.PlacementPeriodFieldNumber">
            <summary>Field number for the "placement_period" field.</summary>
        </member>
        <member name="P:Tensorboard.ConfigProto.PlacementPeriod">
            <summary>
            Assignment of Nodes to Devices is recomputed every placement_period
            steps until the system warms up (at which point the recomputation
            typically slows down automatically).
            </summary>
        </member>
        <member name="F:Tensorboard.ConfigProto.DeviceFiltersFieldNumber">
            <summary>Field number for the "device_filters" field.</summary>
        </member>
        <member name="P:Tensorboard.ConfigProto.DeviceFilters">
            <summary>
            When any filters are present sessions will ignore all devices which do not
            match the filters. Each filter can be partially specified, e.g. "/job:ps"
            "/job:worker/replica:3", etc.
            </summary>
        </member>
        <member name="F:Tensorboard.ConfigProto.GpuOptionsFieldNumber">
            <summary>Field number for the "gpu_options" field.</summary>
        </member>
        <member name="P:Tensorboard.ConfigProto.GpuOptions">
            <summary>
            Options that apply to all GPUs.
            </summary>
        </member>
        <member name="F:Tensorboard.ConfigProto.AllowSoftPlacementFieldNumber">
            <summary>Field number for the "allow_soft_placement" field.</summary>
        </member>
        <member name="P:Tensorboard.ConfigProto.AllowSoftPlacement">
            <summary>
            Whether soft placement is allowed. If allow_soft_placement is true,
            an op will be placed on CPU if
              1. there's no GPU implementation for the OP
            or
              2. no GPU devices are known or registered
            or
              3. need to co-locate with reftype input(s) which are from CPU.
            </summary>
        </member>
        <member name="F:Tensorboard.ConfigProto.LogDevicePlacementFieldNumber">
            <summary>Field number for the "log_device_placement" field.</summary>
        </member>
        <member name="P:Tensorboard.ConfigProto.LogDevicePlacement">
            <summary>
            Whether device placements should be logged.
            </summary>
        </member>
        <member name="F:Tensorboard.ConfigProto.GraphOptionsFieldNumber">
            <summary>Field number for the "graph_options" field.</summary>
        </member>
        <member name="P:Tensorboard.ConfigProto.GraphOptions">
            <summary>
            Options that apply to all graphs.
            </summary>
        </member>
        <member name="F:Tensorboard.ConfigProto.OperationTimeoutInMsFieldNumber">
            <summary>Field number for the "operation_timeout_in_ms" field.</summary>
        </member>
        <member name="P:Tensorboard.ConfigProto.OperationTimeoutInMs">
            <summary>
            Global timeout for all blocking operations in this session.  If non-zero,
            and not overridden on a per-operation basis, this value will be used as the
            deadline for all blocking operations.
            </summary>
        </member>
        <member name="F:Tensorboard.ConfigProto.RpcOptionsFieldNumber">
            <summary>Field number for the "rpc_options" field.</summary>
        </member>
        <member name="P:Tensorboard.ConfigProto.RpcOptions">
            <summary>
            Options that apply when this session uses the distributed runtime.
            </summary>
        </member>
        <member name="F:Tensorboard.ConfigProto.ClusterDefFieldNumber">
            <summary>Field number for the "cluster_def" field.</summary>
        </member>
        <member name="P:Tensorboard.ConfigProto.ClusterDef">
            <summary>
            Optional list of all workers to use in this session.
            </summary>
        </member>
        <member name="F:Tensorboard.ConfigProto.IsolateSessionStateFieldNumber">
            <summary>Field number for the "isolate_session_state" field.</summary>
        </member>
        <member name="P:Tensorboard.ConfigProto.IsolateSessionState">
            <summary>
            If true, any resources such as Variables used in the session will not be
            shared with other sessions. However, when clusterspec propagation is
            enabled, this field is ignored and sessions are always isolated.
            </summary>
        </member>
        <member name="F:Tensorboard.ConfigProto.ShareClusterDevicesInSessionFieldNumber">
            <summary>Field number for the "share_cluster_devices_in_session" field.</summary>
        </member>
        <member name="P:Tensorboard.ConfigProto.ShareClusterDevicesInSession">
            <summary>
            When true, WorkerSessions are created with device attributes from the
            full cluster.
            This is helpful when a worker wants to partition a graph
            (for example during a PartitionedCallOp).
            </summary>
        </member>
        <member name="F:Tensorboard.ConfigProto.ExperimentalFieldNumber">
            <summary>Field number for the "experimental" field.</summary>
        </member>
        <member name="T:Tensorboard.ConfigProto.Types">
            <summary>Container for nested types declared in the ConfigProto message type.</summary>
        </member>
        <member name="T:Tensorboard.ConfigProto.Types.Experimental">
            <summary>
            Everything inside Experimental is subject to change and is not subject
            to API stability guarantees in
            https://www.tensorflow.org/guide/version_compat.
            </summary>
        </member>
        <member name="F:Tensorboard.ConfigProto.Types.Experimental.CollectiveGroupLeaderFieldNumber">
            <summary>Field number for the "collective_group_leader" field.</summary>
        </member>
        <member name="P:Tensorboard.ConfigProto.Types.Experimental.CollectiveGroupLeader">
            <summary>
            Task name for group resolution.
            </summary>
        </member>
        <member name="F:Tensorboard.ConfigProto.Types.Experimental.ExecutorTypeFieldNumber">
            <summary>Field number for the "executor_type" field.</summary>
        </member>
        <member name="P:Tensorboard.ConfigProto.Types.Experimental.ExecutorType">
            <summary>
            Which executor to use, the default executor will be used
            if it is an empty string or "DEFAULT"
            </summary>
        </member>
        <member name="F:Tensorboard.ConfigProto.Types.Experimental.RecvBufMaxChunkFieldNumber">
            <summary>Field number for the "recv_buf_max_chunk" field.</summary>
        </member>
        <member name="P:Tensorboard.ConfigProto.Types.Experimental.RecvBufMaxChunk">
            <summary>
            Guidance to formatting of large RecvBuf fields for transfer.
            Any positive value sets the max chunk size.  0 defaults to 4096.
            Any negative value indicates no max, i.e. one chunk only.
            </summary>
        </member>
        <member name="F:Tensorboard.ConfigProto.Types.Experimental.UseNumaAffinityFieldNumber">
            <summary>Field number for the "use_numa_affinity" field.</summary>
        </member>
        <member name="P:Tensorboard.ConfigProto.Types.Experimental.UseNumaAffinity">
            <summary>
            If true, and supported by the platform, the runtime will attempt to
            use NUMA affinity where applicable.  One consequence will be the
            existence of as many CPU devices as there are available NUMA nodes.
            </summary>
        </member>
        <member name="F:Tensorboard.ConfigProto.Types.Experimental.CollectiveDeterministicSequentialExecutionFieldNumber">
            <summary>Field number for the "collective_deterministic_sequential_execution" field.</summary>
        </member>
        <member name="P:Tensorboard.ConfigProto.Types.Experimental.CollectiveDeterministicSequentialExecution">
            <summary>
            If true, make collective op execution order sequential and deterministic
            for potentially concurrent collective instances.
            </summary>
        </member>
        <member name="F:Tensorboard.ConfigProto.Types.Experimental.CollectiveNcclFieldNumber">
            <summary>Field number for the "collective_nccl" field.</summary>
        </member>
        <member name="P:Tensorboard.ConfigProto.Types.Experimental.CollectiveNccl">
            <summary>
            If true, use NCCL for CollectiveOps.  This feature is highly
            experimental.
            </summary>
        </member>
        <member name="F:Tensorboard.ConfigProto.Types.Experimental.ShareSessionStateInClusterspecPropagationFieldNumber">
            <summary>Field number for the "share_session_state_in_clusterspec_propagation" field.</summary>
        </member>
        <member name="P:Tensorboard.ConfigProto.Types.Experimental.ShareSessionStateInClusterspecPropagation">
             <summary>
             In the following, session state means the value of a variable, elements
             in a hash table, or any other resource, accessible by worker sessions
             held by a TF server.
            
             When ClusterSpec propagation is enabled, the value of
             isolate_session_state is ignored when deciding whether to share session
             states in a TF server (for backwards compatibility reasons).
             - If share_session_state_in_clusterspec_propagation is true, the session
             states are shared.
             - If share_session_state_in_clusterspec_propagation is false, session
             states are isolated.
            
             When clusterspec propagation is not used, the value of
             share_session_state_in_clusterspec_propagation is ignored when deciding
             whether to share session states in a TF server.
             - If isolate_session_state is true, session states are isolated.
             - If isolate_session_state is false, session states are shared.
            
             TODO(b/129330037): Add a single API that consistently treats
             isolate_session_state and ClusterSpec propagation.
             </summary>
        </member>
        <member name="F:Tensorboard.ConfigProto.Types.Experimental.DisableThreadSpinningFieldNumber">
            <summary>Field number for the "disable_thread_spinning" field.</summary>
        </member>
        <member name="P:Tensorboard.ConfigProto.Types.Experimental.DisableThreadSpinning">
            <summary>
            If using a direct session, disable spinning while waiting for work in
            the thread pool. This may result in higher latency for completing ops,
            but in the case where there is a lot of spinning may result in lower
            CPU usage.
            </summary>
        </member>
        <member name="F:Tensorboard.ConfigProto.Types.Experimental.ShareClusterDevicesInSessionFieldNumber">
            <summary>Field number for the "share_cluster_devices_in_session" field.</summary>
        </member>
        <member name="P:Tensorboard.ConfigProto.Types.Experimental.ShareClusterDevicesInSession">
            <summary>
            This was promoted to a non-experimental API. Please use
            ConfigProto.share_cluster_devices_in_session instead.
            </summary>
        </member>
        <member name="F:Tensorboard.ConfigProto.Types.Experimental.SessionMetadataFieldNumber">
            <summary>Field number for the "session_metadata" field.</summary>
        </member>
        <member name="P:Tensorboard.ConfigProto.Types.Experimental.SessionMetadata">
             <summary>
             Metadata about the session.
            
             If set, this can be used by the runtime and the Ops for debugging,
             monitoring, etc.
            
             NOTE: This is currently used and propagated only by the direct session.
             </summary>
        </member>
        <member name="F:Tensorboard.ConfigProto.Types.Experimental.OptimizeForStaticGraphFieldNumber">
            <summary>Field number for the "optimize_for_static_graph" field.</summary>
        </member>
        <member name="P:Tensorboard.ConfigProto.Types.Experimental.OptimizeForStaticGraph">
             <summary>
             If true, the session may treat the graph as being static for optimization
             purposes.
            
             If this option is set to true when a session is created, the full
             GraphDef must be passed in a single call to Session::Create(), and
             Session::Extend() may not be supported.
             </summary>
        </member>
        <member name="F:Tensorboard.ConfigProto.Types.Experimental.EnableMlirBridgeFieldNumber">
            <summary>Field number for the "enable_mlir_bridge" field.</summary>
        </member>
        <member name="P:Tensorboard.ConfigProto.Types.Experimental.EnableMlirBridge">
             <summary>
             This field will eventually be deprecated and replaced by
             mlir_bridge_rollout (b/166038521).
            
             Whether to enable the MLIR-based TF->XLA bridge.
            
             This is a replacement to the existing bridge, and not ready for
             production usage yet.
             If this option is set to true when a session is created, MLIR is used to
             perform the set of graph transformations to put the graph in a form that
             can be executed with delegation of some computations to an accelerator.
             This builds on the model of XLA where a subset of the graph is
             encapsulated and attached to a "compile" operation, whose result is fed
             to an "execute" operation. The kernel for these operations is responsible
             to lower the encapsulated graph to a particular device.
             </summary>
        </member>
        <member name="F:Tensorboard.ConfigProto.Types.Experimental.MlirBridgeRolloutFieldNumber">
            <summary>Field number for the "mlir_bridge_rollout" field.</summary>
        </member>
        <member name="P:Tensorboard.ConfigProto.Types.Experimental.MlirBridgeRollout">
             <summary>
             This field is underdevelopment, for now use enable_mlir_bridge
             (b/166038521).
            
             Whether to enable the MLIR-based TF->XLA bridge.
             </summary>
        </member>
        <member name="F:Tensorboard.ConfigProto.Types.Experimental.EnableMlirGraphOptimizationFieldNumber">
            <summary>Field number for the "enable_mlir_graph_optimization" field.</summary>
        </member>
        <member name="P:Tensorboard.ConfigProto.Types.Experimental.EnableMlirGraphOptimization">
             <summary>
             Whether to enable the MLIR-based Graph optimizations.
            
             This will become a part of standard Tensorflow graph optimization
             pipeline, currently this is only used for gradual migration and testing
             new passes that are replacing existing optimizations in Grappler.
             </summary>
        </member>
        <member name="F:Tensorboard.ConfigProto.Types.Experimental.DisableOutputPartitionGraphsFieldNumber">
            <summary>Field number for the "disable_output_partition_graphs" field.</summary>
        </member>
        <member name="P:Tensorboard.ConfigProto.Types.Experimental.DisableOutputPartitionGraphs">
             <summary>
             If true, the session will not store an additional copy of the graph for
             each subgraph.
            
             If this option is set to true when a session is created, the
             `RunOptions.output_partition_graphs` options must not be set.
             </summary>
        </member>
        <member name="F:Tensorboard.ConfigProto.Types.Experimental.XlaFusionAutotunerThreshFieldNumber">
            <summary>Field number for the "xla_fusion_autotuner_thresh" field.</summary>
        </member>
        <member name="P:Tensorboard.ConfigProto.Types.Experimental.XlaFusionAutotunerThresh">
             <summary>
             Minimum number of batches run through the XLA graph before XLA fusion
             autotuner is enabled. Default value of zero disables the autotuner.
            
             The XLA fusion autotuner can improve performance by executing a heuristic
             search on the compiler parameters.
             </summary>
        </member>
        <member name="F:Tensorboard.ConfigProto.Types.Experimental.UseTfrtFieldNumber">
            <summary>Field number for the "use_tfrt" field.</summary>
        </member>
        <member name="P:Tensorboard.ConfigProto.Types.Experimental.UseTfrt">
            <summary>
            Whether runtime execution uses TFRT.
            </summary>
        </member>
        <member name="F:Tensorboard.ConfigProto.Types.Experimental.DisableFunctionalOpsLoweringFieldNumber">
            <summary>Field number for the "disable_functional_ops_lowering" field.</summary>
        </member>
        <member name="P:Tensorboard.ConfigProto.Types.Experimental.DisableFunctionalOpsLowering">
            <summary>
            Whether functional control flow op lowering should be disabled. This is
            useful when executing within a portable runtime where control flow op
            kernels may not be loaded due to selective registration.
            </summary>
        </member>
        <member name="F:Tensorboard.ConfigProto.Types.Experimental.XlaPreferSingleGraphClusterFieldNumber">
            <summary>Field number for the "xla_prefer_single_graph_cluster" field.</summary>
        </member>
        <member name="P:Tensorboard.ConfigProto.Types.Experimental.XlaPreferSingleGraphCluster">
            <summary>
            Provides a hint to XLA auto clustering to prefer forming a single large
            cluster that encompases most of the graph.
            </summary>
        </member>
        <member name="F:Tensorboard.ConfigProto.Types.Experimental.CoordinationConfigFieldNumber">
            <summary>Field number for the "coordination_config" field.</summary>
        </member>
        <member name="P:Tensorboard.ConfigProto.Types.Experimental.CoordinationConfig">
            <summary>
            Distributed coordination service configurations.
            </summary>
        </member>
        <member name="T:Tensorboard.ConfigProto.Types.Experimental.Types">
            <summary>Container for nested types declared in the Experimental message type.</summary>
        </member>
        <member name="T:Tensorboard.ConfigProto.Types.Experimental.Types.MlirBridgeRollout">
            <summary>
            An enum that describes the state of the MLIR bridge rollout.
            </summary>
        </member>
        <member name="F:Tensorboard.ConfigProto.Types.Experimental.Types.MlirBridgeRollout.Unspecified">
            <summary>
            If this field is left unspecified, the MLIR bridge may be selectively
            enabled on a per graph basis.
            </summary>
        </member>
        <member name="F:Tensorboard.ConfigProto.Types.Experimental.Types.MlirBridgeRollout.Enabled">
            <summary>
            Enabling the MLIR bridge enables it for all graphs in this session.
            </summary>
        </member>
        <member name="F:Tensorboard.ConfigProto.Types.Experimental.Types.MlirBridgeRollout.Disabled">
            <summary>
            Disabling the MLIR bridge disables it for all graphs in this session.
            </summary>
        </member>
        <member name="F:Tensorboard.ConfigProto.Types.Experimental.Types.MlirBridgeRollout.SafeModeEnabled">
            <summary>
            Enable the MLIR bridge on a per graph basis based on an analysis of
            the features used in the graph. If the features used by the graph are
            supported by the MLIR bridge, the MLIR bridge will be used to run the
            graph.
            </summary>
        </member>
        <member name="F:Tensorboard.ConfigProto.Types.Experimental.Types.MlirBridgeRollout.SafeModeFallbackEnabled">
            <summary>
            Enable the MLIR bridge in a fallback mode on a per graph basis based
            on an analysis of the features used in the graph.
            Running the MLIR bridge in the fallback mode means that it is
            executed and it commits all the changes to the TF graph in case
            of success. And it does not in case of failures and let the old bridge
            to process the TF graph.
            </summary>
        </member>
        <member name="T:Tensorboard.RunOptions">
            <summary>
            Options for a single Run() call.
            </summary>
        </member>
        <member name="F:Tensorboard.RunOptions.TraceLevelFieldNumber">
            <summary>Field number for the "trace_level" field.</summary>
        </member>
        <member name="F:Tensorboard.RunOptions.TimeoutInMsFieldNumber">
            <summary>Field number for the "timeout_in_ms" field.</summary>
        </member>
        <member name="P:Tensorboard.RunOptions.TimeoutInMs">
            <summary>
            Time to wait for operation to complete in milliseconds.
            </summary>
        </member>
        <member name="F:Tensorboard.RunOptions.InterOpThreadPoolFieldNumber">
            <summary>Field number for the "inter_op_thread_pool" field.</summary>
        </member>
        <member name="P:Tensorboard.RunOptions.InterOpThreadPool">
            <summary>
            The thread pool to use, if session_inter_op_thread_pool is configured.
            To use the caller thread set this to -1 - this uses the caller thread
            to execute Session::Run() and thus avoids a context switch. Using the
            caller thread to execute Session::Run() should be done ONLY for simple
            graphs, where the overhead of an additional context switch is
            comparable with the overhead of Session::Run().
            </summary>
        </member>
        <member name="F:Tensorboard.RunOptions.OutputPartitionGraphsFieldNumber">
            <summary>Field number for the "output_partition_graphs" field.</summary>
        </member>
        <member name="P:Tensorboard.RunOptions.OutputPartitionGraphs">
            <summary>
            Whether the partition graph(s) executed by the executor(s) should be
            outputted via RunMetadata.
            </summary>
        </member>
        <member name="F:Tensorboard.RunOptions.DebugOptionsFieldNumber">
            <summary>Field number for the "debug_options" field.</summary>
        </member>
        <member name="P:Tensorboard.RunOptions.DebugOptions">
            <summary>
            EXPERIMENTAL.  Options used to initialize DebuggerState, if enabled.
            </summary>
        </member>
        <member name="F:Tensorboard.RunOptions.ReportTensorAllocationsUponOomFieldNumber">
            <summary>Field number for the "report_tensor_allocations_upon_oom" field.</summary>
        </member>
        <member name="P:Tensorboard.RunOptions.ReportTensorAllocationsUponOom">
             <summary>
             When enabled, causes tensor allocation information to be included in
             the error message when the Run() call fails because the allocator ran
             out of memory (OOM).
            
             Enabling this option can slow down the Run() call.
             </summary>
        </member>
        <member name="F:Tensorboard.RunOptions.ExperimentalFieldNumber">
            <summary>Field number for the "experimental" field.</summary>
        </member>
        <member name="T:Tensorboard.RunOptions.Types">
            <summary>Container for nested types declared in the RunOptions message type.</summary>
        </member>
        <member name="T:Tensorboard.RunOptions.Types.TraceLevel">
            <summary>
            TODO(pbar) Turn this into a TraceOptions proto which allows
            tracing to be controlled in a more orthogonal manner?
            </summary>
        </member>
        <member name="T:Tensorboard.RunOptions.Types.Experimental">
            <summary>
            Everything inside Experimental is subject to change and is not subject
            to API stability guarantees in
            https://www.tensorflow.org/guide/version_compat.
            </summary>
        </member>
        <member name="F:Tensorboard.RunOptions.Types.Experimental.CollectiveGraphKeyFieldNumber">
            <summary>Field number for the "collective_graph_key" field.</summary>
        </member>
        <member name="P:Tensorboard.RunOptions.Types.Experimental.CollectiveGraphKey">
            <summary>
            If non-zero, declares that this graph is going to use collective
            ops and must synchronize step_ids with any other graph with this
            same group_key value (in a distributed computation where tasks
            run disjoint graphs).
            </summary>
        </member>
        <member name="F:Tensorboard.RunOptions.Types.Experimental.UseRunHandlerPoolFieldNumber">
            <summary>Field number for the "use_run_handler_pool" field.</summary>
        </member>
        <member name="P:Tensorboard.RunOptions.Types.Experimental.UseRunHandlerPool">
            <summary>
            If true, then operations (using the inter-op pool) across all
            session::run() calls will be centrally scheduled, optimizing for (median
            and tail) latency.
            Consider using this option for CPU-bound workloads like inference.
            </summary>
        </member>
        <member name="F:Tensorboard.RunOptions.Types.Experimental.RunHandlerPoolOptionsFieldNumber">
            <summary>Field number for the "run_handler_pool_options" field.</summary>
        </member>
        <member name="T:Tensorboard.RunOptions.Types.Experimental.Types">
            <summary>Container for nested types declared in the Experimental message type.</summary>
        </member>
        <member name="T:Tensorboard.RunOptions.Types.Experimental.Types.RunHandlerPoolOptions">
            <summary>
            Options for run handler thread pool.
            </summary>
        </member>
        <member name="F:Tensorboard.RunOptions.Types.Experimental.Types.RunHandlerPoolOptions.PriorityFieldNumber">
            <summary>Field number for the "priority" field.</summary>
        </member>
        <member name="P:Tensorboard.RunOptions.Types.Experimental.Types.RunHandlerPoolOptions.Priority">
            <summary>
            Priority of the request. The run handler thread pool will schedule ops
            based on the priority number. The larger number means higher priority.
            </summary>
        </member>
        <member name="T:Tensorboard.RunMetadata">
            <summary>
            Metadata output (i.e., non-Tensor) for a single Run() call.
            </summary>
        </member>
        <member name="F:Tensorboard.RunMetadata.StepStatsFieldNumber">
            <summary>Field number for the "step_stats" field.</summary>
        </member>
        <member name="P:Tensorboard.RunMetadata.StepStats">
            <summary>
            Statistics traced for this step. Populated if tracing is turned on via the
            "RunOptions" proto.
            EXPERIMENTAL: The format and set of events may change in future versions.
            </summary>
        </member>
        <member name="F:Tensorboard.RunMetadata.CostGraphFieldNumber">
            <summary>Field number for the "cost_graph" field.</summary>
        </member>
        <member name="P:Tensorboard.RunMetadata.CostGraph">
            <summary>
            The cost graph for the computation defined by the run call.
            </summary>
        </member>
        <member name="F:Tensorboard.RunMetadata.PartitionGraphsFieldNumber">
            <summary>Field number for the "partition_graphs" field.</summary>
        </member>
        <member name="P:Tensorboard.RunMetadata.PartitionGraphs">
            <summary>
            Graphs of the partitions executed by executors.
            </summary>
        </member>
        <member name="F:Tensorboard.RunMetadata.FunctionGraphsFieldNumber">
            <summary>Field number for the "function_graphs" field.</summary>
        </member>
        <member name="P:Tensorboard.RunMetadata.FunctionGraphs">
            <summary>
            This is only populated for graphs that are run as functions in TensorFlow
            V2. There will be an entry below for each function that is traced.
            The main use cases of the post_optimization_graph and the partition_graphs
            is to give the caller insight into the graphs that were actually run by the
            runtime. Additional information (such as those in step_stats) will match
            these graphs.
            We also include the pre_optimization_graph since it is usually easier to
            read, and is helpful in situations where the caller wants to get a high
            level idea of what the built graph looks like (since the various graph
            optimization passes might change the structure of the graph significantly).
            </summary>
        </member>
        <member name="T:Tensorboard.RunMetadata.Types">
            <summary>Container for nested types declared in the RunMetadata message type.</summary>
        </member>
        <member name="F:Tensorboard.RunMetadata.Types.FunctionGraphs.PartitionGraphsFieldNumber">
            <summary>Field number for the "partition_graphs" field.</summary>
        </member>
        <member name="P:Tensorboard.RunMetadata.Types.FunctionGraphs.PartitionGraphs">
            <summary>
            TODO(nareshmodi): Include some sort of function/cache-key identifier?
            </summary>
        </member>
        <member name="F:Tensorboard.RunMetadata.Types.FunctionGraphs.PreOptimizationGraphFieldNumber">
            <summary>Field number for the "pre_optimization_graph" field.</summary>
        </member>
        <member name="F:Tensorboard.RunMetadata.Types.FunctionGraphs.PostOptimizationGraphFieldNumber">
            <summary>Field number for the "post_optimization_graph" field.</summary>
        </member>
        <member name="T:Tensorboard.TensorConnection">
            <summary>
            Defines a connection between two tensors in a `GraphDef`.
            </summary>
        </member>
        <member name="F:Tensorboard.TensorConnection.FromTensorFieldNumber">
            <summary>Field number for the "from_tensor" field.</summary>
        </member>
        <member name="P:Tensorboard.TensorConnection.FromTensor">
            <summary>
            A tensor name. The value of this tensor will be substituted for
            the tensor named in `to_tensor`.
            </summary>
        </member>
        <member name="F:Tensorboard.TensorConnection.ToTensorFieldNumber">
            <summary>Field number for the "to_tensor" field.</summary>
        </member>
        <member name="P:Tensorboard.TensorConnection.ToTensor">
            <summary>
            A tensor name. The value of this tensor will be bound to the
            value of the tensor named in `from_tensor`.
            </summary>
        </member>
        <member name="T:Tensorboard.CallableOptions">
             <summary>
             Defines a subgraph in another `GraphDef` as a set of feed points and nodes
             to be fetched or executed.
            
             Compare with the arguments to `Session::Run()`.
             </summary>
        </member>
        <member name="F:Tensorboard.CallableOptions.FeedFieldNumber">
            <summary>Field number for the "feed" field.</summary>
        </member>
        <member name="P:Tensorboard.CallableOptions.Feed">
            <summary>
            Tensors to be fed in the callable. Each feed is the name of a tensor.
            </summary>
        </member>
        <member name="F:Tensorboard.CallableOptions.FetchFieldNumber">
            <summary>Field number for the "fetch" field.</summary>
        </member>
        <member name="P:Tensorboard.CallableOptions.Fetch">
            <summary>
            Fetches. A list of tensor names. The caller of the callable expects a
            tensor to be returned for each fetch[i] (see RunStepResponse.tensor). The
            order of specified fetches does not change the execution order.
            </summary>
        </member>
        <member name="F:Tensorboard.CallableOptions.TargetFieldNumber">
            <summary>Field number for the "target" field.</summary>
        </member>
        <member name="P:Tensorboard.CallableOptions.Target">
            <summary>
            Target Nodes. A list of node names. The named nodes will be run by the
            callable but their outputs will not be returned.
            </summary>
        </member>
        <member name="F:Tensorboard.CallableOptions.RunOptionsFieldNumber">
            <summary>Field number for the "run_options" field.</summary>
        </member>
        <member name="P:Tensorboard.CallableOptions.RunOptions">
            <summary>
            Options that will be applied to each run.
            </summary>
        </member>
        <member name="F:Tensorboard.CallableOptions.TensorConnectionFieldNumber">
            <summary>Field number for the "tensor_connection" field.</summary>
        </member>
        <member name="P:Tensorboard.CallableOptions.TensorConnection">
            <summary>
            Tensors to be connected in the callable. Each TensorConnection denotes
            a pair of tensors in the graph, between which an edge will be created
            in the callable.
            </summary>
        </member>
        <member name="F:Tensorboard.CallableOptions.FeedDevicesFieldNumber">
            <summary>Field number for the "feed_devices" field.</summary>
        </member>
        <member name="P:Tensorboard.CallableOptions.FeedDevices">
             <summary>
             The Tensor objects fed in the callable and fetched from the callable
             are expected to be backed by host (CPU) memory by default.
            
             The options below allow changing that - feeding tensors backed by
             device memory, or returning tensors that are backed by device memory.
            
             The maps below map the name of a feed/fetch tensor (which appears in
             'feed' or 'fetch' fields above), to the fully qualified name of the device
             owning the memory backing the contents of the tensor.
            
             For example, creating a callable with the following options:
            
             CallableOptions {
               feed: "a:0"
               feed: "b:0"
            
               fetch: "x:0"
               fetch: "y:0"
            
               feed_devices: {
                 "a:0": "/job:localhost/replica:0/task:0/device:GPU:0"
               }
            
               fetch_devices: {
                 "y:0": "/job:localhost/replica:0/task:0/device:GPU:0"
              }
             }
            
             means that the Callable expects:
             - The first argument ("a:0") is a Tensor backed by GPU memory.
             - The second argument ("b:0") is a Tensor backed by host memory.
             and of its return values:
             - The first output ("x:0") will be backed by host memory.
             - The second output ("y:0") will be backed by GPU memory.
            
             FEEDS:
             It is the responsibility of the caller to ensure that the memory of the fed
             tensors will be correctly initialized and synchronized before it is
             accessed by operations executed during the call to Session::RunCallable().
            
             This is typically ensured by using the TensorFlow memory allocators
             (Device::GetAllocator()) to create the Tensor to be fed.
            
             Alternatively, for CUDA-enabled GPU devices, this typically means that the
             operation that produced the contents of the tensor has completed, i.e., the
             CUDA stream has been synchronized (e.g., via cuCtxSynchronize() or
             cuStreamSynchronize()).
             </summary>
        </member>
        <member name="F:Tensorboard.CallableOptions.FetchDevicesFieldNumber">
            <summary>Field number for the "fetch_devices" field.</summary>
        </member>
        <member name="F:Tensorboard.CallableOptions.FetchSkipSyncFieldNumber">
            <summary>Field number for the "fetch_skip_sync" field.</summary>
        </member>
        <member name="P:Tensorboard.CallableOptions.FetchSkipSync">
             <summary>
             By default, RunCallable() will synchronize the GPU stream before returning
             fetched tensors on a GPU device, to ensure that the values in those tensors
             have been produced. This simplifies interacting with the tensors, but
             potentially incurs a performance hit.
            
             If this options is set to true, the caller is responsible for ensuring
             that the values in the fetched tensors have been produced before they are
             used. The caller can do this by invoking `Device::Sync()` on the underlying
             device(s), or by feeding the tensors back to the same Session using
             `feed_devices` with the same corresponding device name.
             </summary>
        </member>
        <member name="T:Tensorboard.CoordinationConfigReflection">
            <summary>Holder for reflection information generated from tensorboard/compat/proto/coordination_config.proto</summary>
        </member>
        <member name="P:Tensorboard.CoordinationConfigReflection.Descriptor">
            <summary>File descriptor for tensorboard/compat/proto/coordination_config.proto</summary>
        </member>
        <member name="T:Tensorboard.CoordinationServiceConfig">
            <summary>
            Coordination service configuration parameters.
            The system picks appropriate values for fields that are not set.
            </summary>
        </member>
        <member name="F:Tensorboard.CoordinationServiceConfig.ServiceTypeFieldNumber">
            <summary>Field number for the "service_type" field.</summary>
        </member>
        <member name="P:Tensorboard.CoordinationServiceConfig.ServiceType">
            <summary>
            Type of coordination service implementation to enable.
            For example, setting the service type as "standalone" starts a service
            instance on the leader task to provide the coordination services such as
            heartbeats and consistent key-value store.
            </summary>
        </member>
        <member name="F:Tensorboard.CoordinationServiceConfig.ServiceLeaderFieldNumber">
            <summary>Field number for the "service_leader" field.</summary>
        </member>
        <member name="P:Tensorboard.CoordinationServiceConfig.ServiceLeader">
            <summary>
            Address where the coordination service instance is hosted.
            </summary>
        </member>
        <member name="F:Tensorboard.CoordinationServiceConfig.EnableHealthCheckFieldNumber">
            <summary>Field number for the "enable_health_check" field.</summary>
        </member>
        <member name="P:Tensorboard.CoordinationServiceConfig.EnableHealthCheck">
            <summary>
            Whether to enable the health check mechanism.
            </summary>
        </member>
        <member name="F:Tensorboard.CoordinationServiceConfig.ClusterRegisterTimeoutInMsFieldNumber">
            <summary>Field number for the "cluster_register_timeout_in_ms" field.</summary>
        </member>
        <member name="P:Tensorboard.CoordinationServiceConfig.ClusterRegisterTimeoutInMs">
            <summary>
            Maximum wait time for all members in the cluster to be registered.
            </summary>
        </member>
        <member name="F:Tensorboard.CoordinationServiceConfig.HeartbeatTimeoutInMsFieldNumber">
            <summary>Field number for the "heartbeat_timeout_in_ms" field.</summary>
        </member>
        <member name="P:Tensorboard.CoordinationServiceConfig.HeartbeatTimeoutInMs">
            <summary>
            Heartbeat timeout, if a task does not record heartbeat in this time
            window, it will be considered disconnected.
            Note: This is also used as a grace period to accept any heartbeats after
            the agent has disconnected, to account for the lag time between the service
            recording the state change and the agent stopping heartbeats.
            </summary>
        </member>
        <member name="F:Tensorboard.CoordinationServiceConfig.CoordinatedJobsFieldNumber">
            <summary>Field number for the "coordinated_jobs" field.</summary>
        </member>
        <member name="P:Tensorboard.CoordinationServiceConfig.CoordinatedJobs">
            <summary>
            The list of jobs that partipate in the coordination service. If empty, all
            jobs will be included in the coordination service by default.
            </summary>
        </member>
        <member name="F:Tensorboard.CoordinationServiceConfig.ShutdownBarrierTimeoutInMsFieldNumber">
            <summary>Field number for the "shutdown_barrier_timeout_in_ms" field.</summary>
        </member>
        <member name="P:Tensorboard.CoordinationServiceConfig.ShutdownBarrierTimeoutInMs">
            <summary>
            Denotes how long to wait for all coordination agents to reach the barriers
            (after the first shutdown request) before disconnecting together. If
            set to 0, no barrier is imposed upon shutdown and each worker can
            disconnect individually.
            </summary>
        </member>
        <member name="F:Tensorboard.CoordinationServiceConfig.AgentDestructionWithoutShutdownFieldNumber">
            <summary>Field number for the "agent_destruction_without_shutdown" field.</summary>
        </member>
        <member name="P:Tensorboard.CoordinationServiceConfig.AgentDestructionWithoutShutdown">
            <summary>
            If set, agents do not make an explicit Shutdown() call. Service will only
            find out about the disconnecte agent via stale heartbeats. Used for
            testing.
            </summary>
        </member>
        <member name="T:Tensorboard.CostGraphReflection">
            <summary>Holder for reflection information generated from tensorboard/compat/proto/cost_graph.proto</summary>
        </member>
        <member name="P:Tensorboard.CostGraphReflection.Descriptor">
            <summary>File descriptor for tensorboard/compat/proto/cost_graph.proto</summary>
        </member>
        <member name="F:Tensorboard.CostGraphDef.NodeFieldNumber">
            <summary>Field number for the "node" field.</summary>
        </member>
        <member name="F:Tensorboard.CostGraphDef.CostFieldNumber">
            <summary>Field number for the "cost" field.</summary>
        </member>
        <member name="T:Tensorboard.CostGraphDef.Types">
            <summary>Container for nested types declared in the CostGraphDef message type.</summary>
        </member>
        <member name="F:Tensorboard.CostGraphDef.Types.Node.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="P:Tensorboard.CostGraphDef.Types.Node.Name">
            <summary>
            The name of the node. Names are globally unique.
            </summary>
        </member>
        <member name="F:Tensorboard.CostGraphDef.Types.Node.DeviceFieldNumber">
            <summary>Field number for the "device" field.</summary>
        </member>
        <member name="P:Tensorboard.CostGraphDef.Types.Node.Device">
            <summary>
            The device of the node. Can be empty if the node is mapped to the
            default partition or partitioning hasn't been run yet.
            </summary>
        </member>
        <member name="F:Tensorboard.CostGraphDef.Types.Node.IdFieldNumber">
            <summary>Field number for the "id" field.</summary>
        </member>
        <member name="P:Tensorboard.CostGraphDef.Types.Node.Id">
            <summary>
            The id of the node. Node ids are only unique inside a partition.
            </summary>
        </member>
        <member name="F:Tensorboard.CostGraphDef.Types.Node.InputInfoFieldNumber">
            <summary>Field number for the "input_info" field.</summary>
        </member>
        <member name="F:Tensorboard.CostGraphDef.Types.Node.OutputInfoFieldNumber">
            <summary>Field number for the "output_info" field.</summary>
        </member>
        <member name="F:Tensorboard.CostGraphDef.Types.Node.TemporaryMemorySizeFieldNumber">
            <summary>Field number for the "temporary_memory_size" field.</summary>
        </member>
        <member name="P:Tensorboard.CostGraphDef.Types.Node.TemporaryMemorySize">
            <summary>
            Temporary memory used by this node.
            </summary>
        </member>
        <member name="F:Tensorboard.CostGraphDef.Types.Node.PersistentMemorySizeFieldNumber">
            <summary>Field number for the "persistent_memory_size" field.</summary>
        </member>
        <member name="P:Tensorboard.CostGraphDef.Types.Node.PersistentMemorySize">
            <summary>
            Persistent memory used by this node.
            </summary>
        </member>
        <member name="F:Tensorboard.CostGraphDef.Types.Node.HostTempMemorySizeFieldNumber">
            <summary>Field number for the "host_temp_memory_size" field.</summary>
        </member>
        <member name="F:Tensorboard.CostGraphDef.Types.Node.DeviceTempMemorySizeFieldNumber">
            <summary>Field number for the "device_temp_memory_size" field.</summary>
        </member>
        <member name="F:Tensorboard.CostGraphDef.Types.Node.DevicePersistentMemorySizeFieldNumber">
            <summary>Field number for the "device_persistent_memory_size" field.</summary>
        </member>
        <member name="F:Tensorboard.CostGraphDef.Types.Node.ComputeCostFieldNumber">
            <summary>Field number for the "compute_cost" field.</summary>
        </member>
        <member name="P:Tensorboard.CostGraphDef.Types.Node.ComputeCost">
            <summary>
            Estimate of the computational cost of this node, in microseconds.
            </summary>
        </member>
        <member name="F:Tensorboard.CostGraphDef.Types.Node.ComputeTimeFieldNumber">
            <summary>Field number for the "compute_time" field.</summary>
        </member>
        <member name="P:Tensorboard.CostGraphDef.Types.Node.ComputeTime">
            <summary>
            Analytical estimate of the computational cost of this node, in
            microseconds.
            </summary>
        </member>
        <member name="F:Tensorboard.CostGraphDef.Types.Node.MemoryTimeFieldNumber">
            <summary>Field number for the "memory_time" field.</summary>
        </member>
        <member name="P:Tensorboard.CostGraphDef.Types.Node.MemoryTime">
            <summary>
            Analytical estimate of the memory access cost of this node, in
            microseconds.
            </summary>
        </member>
        <member name="F:Tensorboard.CostGraphDef.Types.Node.IsFinalFieldNumber">
            <summary>Field number for the "is_final" field.</summary>
        </member>
        <member name="P:Tensorboard.CostGraphDef.Types.Node.IsFinal">
            <summary>
            If true, the output is permanent: it can't be discarded, because this
            node is part of the "final output". Nodes may depend on final nodes.
            </summary>
        </member>
        <member name="F:Tensorboard.CostGraphDef.Types.Node.ControlInputFieldNumber">
            <summary>Field number for the "control_input" field.</summary>
        </member>
        <member name="P:Tensorboard.CostGraphDef.Types.Node.ControlInput">
            <summary>
            Ids of the control inputs for this node.
            </summary>
        </member>
        <member name="F:Tensorboard.CostGraphDef.Types.Node.InaccurateFieldNumber">
            <summary>Field number for the "inaccurate" field.</summary>
        </member>
        <member name="P:Tensorboard.CostGraphDef.Types.Node.Inaccurate">
            <summary>
            Are the costs inaccurate?
            </summary>
        </member>
        <member name="T:Tensorboard.CostGraphDef.Types.Node.Types">
            <summary>Container for nested types declared in the Node message type.</summary>
        </member>
        <member name="T:Tensorboard.CostGraphDef.Types.Node.Types.InputInfo">
            <summary>
            Inputs of this node. They must be executed before this node can be
            executed. An input is a particular output of another node, specified
            by the node id and the output index.
            </summary>
        </member>
        <member name="F:Tensorboard.CostGraphDef.Types.Node.Types.InputInfo.PrecedingNodeFieldNumber">
            <summary>Field number for the "preceding_node" field.</summary>
        </member>
        <member name="F:Tensorboard.CostGraphDef.Types.Node.Types.InputInfo.PrecedingPortFieldNumber">
            <summary>Field number for the "preceding_port" field.</summary>
        </member>
        <member name="T:Tensorboard.CostGraphDef.Types.Node.Types.OutputInfo">
            <summary>
            Outputs of this node.
            </summary>
        </member>
        <member name="F:Tensorboard.CostGraphDef.Types.Node.Types.OutputInfo.SizeFieldNumber">
            <summary>Field number for the "size" field.</summary>
        </member>
        <member name="F:Tensorboard.CostGraphDef.Types.Node.Types.OutputInfo.AliasInputPortFieldNumber">
            <summary>Field number for the "alias_input_port" field.</summary>
        </member>
        <member name="P:Tensorboard.CostGraphDef.Types.Node.Types.OutputInfo.AliasInputPort">
            <summary>
            If >= 0, the output is an alias of an input. Note that an alias input
            may itself be an alias. The algorithm will therefore need to follow
            those pointers.
            </summary>
        </member>
        <member name="F:Tensorboard.CostGraphDef.Types.Node.Types.OutputInfo.ShapeFieldNumber">
            <summary>Field number for the "shape" field.</summary>
        </member>
        <member name="F:Tensorboard.CostGraphDef.Types.Node.Types.OutputInfo.DtypeFieldNumber">
            <summary>Field number for the "dtype" field.</summary>
        </member>
        <member name="T:Tensorboard.CostGraphDef.Types.AggregatedCost">
            <summary>
            Total cost of this graph, typically used for balancing decisions.
            </summary>
        </member>
        <member name="F:Tensorboard.CostGraphDef.Types.AggregatedCost.CostFieldNumber">
            <summary>Field number for the "cost" field.</summary>
        </member>
        <member name="P:Tensorboard.CostGraphDef.Types.AggregatedCost.Cost">
            <summary>
            Aggregated cost value.
            </summary>
        </member>
        <member name="F:Tensorboard.CostGraphDef.Types.AggregatedCost.DimensionFieldNumber">
            <summary>Field number for the "dimension" field.</summary>
        </member>
        <member name="P:Tensorboard.CostGraphDef.Types.AggregatedCost.Dimension">
            <summary>
            Aggregated cost dimension (e.g. 'memory', 'compute', 'network').
            </summary>
        </member>
        <member name="T:Tensorboard.CppShapeInferenceReflection">
            <summary>Holder for reflection information generated from tensorboard/compat/proto/cpp_shape_inference.proto</summary>
        </member>
        <member name="P:Tensorboard.CppShapeInferenceReflection.Descriptor">
            <summary>File descriptor for tensorboard/compat/proto/cpp_shape_inference.proto</summary>
        </member>
        <member name="F:Tensorboard.CppShapeInferenceResult.ShapeFieldNumber">
            <summary>Field number for the "shape" field.</summary>
        </member>
        <member name="F:Tensorboard.CppShapeInferenceResult.HandleDataFieldNumber">
            <summary>Field number for the "handle_data" field.</summary>
        </member>
        <member name="T:Tensorboard.CppShapeInferenceResult.Types">
            <summary>Container for nested types declared in the CppShapeInferenceResult message type.</summary>
        </member>
        <member name="F:Tensorboard.CppShapeInferenceResult.Types.HandleShapeAndType.ShapeFieldNumber">
            <summary>Field number for the "shape" field.</summary>
        </member>
        <member name="F:Tensorboard.CppShapeInferenceResult.Types.HandleShapeAndType.DtypeFieldNumber">
            <summary>Field number for the "dtype" field.</summary>
        </member>
        <member name="F:Tensorboard.CppShapeInferenceResult.Types.HandleShapeAndType.TypeFieldNumber">
            <summary>Field number for the "type" field.</summary>
        </member>
        <member name="F:Tensorboard.CppShapeInferenceResult.Types.HandleData.IsSetFieldNumber">
            <summary>Field number for the "is_set" field.</summary>
        </member>
        <member name="F:Tensorboard.CppShapeInferenceResult.Types.HandleData.ShapeAndTypeFieldNumber">
            <summary>Field number for the "shape_and_type" field.</summary>
        </member>
        <member name="P:Tensorboard.CppShapeInferenceResult.Types.HandleData.ShapeAndType">
            <summary>
            Only valid if &lt;is_set>.
            </summary>
        </member>
        <member name="F:Tensorboard.CppShapeInferenceInputsNeeded.InputTensorsNeededFieldNumber">
            <summary>Field number for the "input_tensors_needed" field.</summary>
        </member>
        <member name="F:Tensorboard.CppShapeInferenceInputsNeeded.InputTensorsAsShapesNeededFieldNumber">
            <summary>Field number for the "input_tensors_as_shapes_needed" field.</summary>
        </member>
        <member name="T:Tensorboard.DebugReflection">
            <summary>Holder for reflection information generated from tensorboard/compat/proto/debug.proto</summary>
        </member>
        <member name="P:Tensorboard.DebugReflection.Descriptor">
            <summary>File descriptor for tensorboard/compat/proto/debug.proto</summary>
        </member>
        <member name="T:Tensorboard.DebugTensorWatch">
            <summary>
            Option for watching a node in TensorFlow Debugger (tfdbg).
            </summary>
        </member>
        <member name="F:Tensorboard.DebugTensorWatch.NodeNameFieldNumber">
            <summary>Field number for the "node_name" field.</summary>
        </member>
        <member name="P:Tensorboard.DebugTensorWatch.NodeName">
            <summary>
            Name of the node to watch.
            Use "*" for wildcard. But note: currently, regex is not supported in
            general.
            </summary>
        </member>
        <member name="F:Tensorboard.DebugTensorWatch.OutputSlotFieldNumber">
            <summary>Field number for the "output_slot" field.</summary>
        </member>
        <member name="P:Tensorboard.DebugTensorWatch.OutputSlot">
            <summary>
            Output slot to watch.
            The semantics of output_slot == -1 is that all outputs of the node
            will be watched (i.e., a wildcard).
            Other negative values of output_slot are invalid and will lead to
            errors currently.
            </summary>
        </member>
        <member name="F:Tensorboard.DebugTensorWatch.DebugOpsFieldNumber">
            <summary>Field number for the "debug_ops" field.</summary>
        </member>
        <member name="P:Tensorboard.DebugTensorWatch.DebugOps">
            <summary>
            Name(s) of the debugging op(s).
            One or more than one probes on a tensor.
            e.g., {"DebugIdentity", "DebugNanCount"}
            </summary>
        </member>
        <member name="F:Tensorboard.DebugTensorWatch.DebugUrlsFieldNumber">
            <summary>Field number for the "debug_urls" field.</summary>
        </member>
        <member name="P:Tensorboard.DebugTensorWatch.DebugUrls">
             <summary>
             URL(s) for debug targets(s).
            
             Supported URL formats are:
               - file:///foo/tfdbg_dump: Writes out Event content to file
                 /foo/tfdbg_dump.  Assumes all directories can be created if they don't
                 already exist.
               - grpc://localhost:11011: Sends an RPC request to an EventListener
                 service running at localhost:11011 with the event.
               - memcbk:///event_key: Routes tensors to clients using the
                 callback registered with the DebugCallbackRegistry for event_key.
            
             Each debug op listed in debug_ops will publish its output tensor (debug
             signal) to all URLs in debug_urls.
            
             N.B. Session::Run() supports concurrent invocations of the same inputs
             (feed keys), outputs and target nodes. If such concurrent invocations
             are to be debugged, the callers of Session::Run() must use distinct
             debug_urls to make sure that the streamed or dumped events do not overlap
             among the invocations.
             TODO(cais): More visible documentation of this in g3docs.
             </summary>
        </member>
        <member name="F:Tensorboard.DebugTensorWatch.TolerateDebugOpCreationFailuresFieldNumber">
            <summary>Field number for the "tolerate_debug_op_creation_failures" field.</summary>
        </member>
        <member name="P:Tensorboard.DebugTensorWatch.TolerateDebugOpCreationFailures">
            <summary>
            Do not error out if debug op creation fails (e.g., due to dtype
            incompatibility). Instead, just log the failure.
            </summary>
        </member>
        <member name="T:Tensorboard.DebugOptions">
            <summary>
            Options for initializing DebuggerState in TensorFlow Debugger (tfdbg).
            </summary>
        </member>
        <member name="F:Tensorboard.DebugOptions.DebugTensorWatchOptsFieldNumber">
            <summary>Field number for the "debug_tensor_watch_opts" field.</summary>
        </member>
        <member name="P:Tensorboard.DebugOptions.DebugTensorWatchOpts">
            <summary>
            Debugging options
            </summary>
        </member>
        <member name="F:Tensorboard.DebugOptions.GlobalStepFieldNumber">
            <summary>Field number for the "global_step" field.</summary>
        </member>
        <member name="P:Tensorboard.DebugOptions.GlobalStep">
            <summary>
            Caller-specified global step count.
            Note that this is distinct from the session run count and the executor
            step count.
            </summary>
        </member>
        <member name="F:Tensorboard.DebugOptions.ResetDiskByteUsageFieldNumber">
            <summary>Field number for the "reset_disk_byte_usage" field.</summary>
        </member>
        <member name="P:Tensorboard.DebugOptions.ResetDiskByteUsage">
            <summary>
            Whether the total disk usage of tfdbg is to be reset to zero
            in this Session.run call. This is used by wrappers and hooks
            such as the local CLI ones to indicate that the dumped tensors
            are cleaned up from the disk after each Session.run.
            </summary>
        </member>
        <member name="F:Tensorboard.DebuggedSourceFile.HostFieldNumber">
            <summary>Field number for the "host" field.</summary>
        </member>
        <member name="P:Tensorboard.DebuggedSourceFile.Host">
            <summary>
            The host name on which a source code file is located.
            </summary>
        </member>
        <member name="F:Tensorboard.DebuggedSourceFile.FilePathFieldNumber">
            <summary>Field number for the "file_path" field.</summary>
        </member>
        <member name="P:Tensorboard.DebuggedSourceFile.FilePath">
            <summary>
            Path to the source code file.
            </summary>
        </member>
        <member name="F:Tensorboard.DebuggedSourceFile.LastModifiedFieldNumber">
            <summary>Field number for the "last_modified" field.</summary>
        </member>
        <member name="P:Tensorboard.DebuggedSourceFile.LastModified">
            <summary>
            The timestamp at which the source code file is last modified.
            </summary>
        </member>
        <member name="F:Tensorboard.DebuggedSourceFile.BytesFieldNumber">
            <summary>Field number for the "bytes" field.</summary>
        </member>
        <member name="P:Tensorboard.DebuggedSourceFile.Bytes">
            <summary>
            Byte size of the file.
            </summary>
        </member>
        <member name="F:Tensorboard.DebuggedSourceFile.LinesFieldNumber">
            <summary>Field number for the "lines" field.</summary>
        </member>
        <member name="P:Tensorboard.DebuggedSourceFile.Lines">
            <summary>
            Line-by-line content of the source code file.
            </summary>
        </member>
        <member name="F:Tensorboard.DebuggedSourceFiles.SourceFilesFieldNumber">
            <summary>Field number for the "source_files" field.</summary>
        </member>
        <member name="P:Tensorboard.DebuggedSourceFiles.SourceFiles">
            <summary>
            A collection of source code files.
            </summary>
        </member>
        <member name="T:Tensorboard.EventReflection">
            <summary>Holder for reflection information generated from tensorboard/compat/proto/event.proto</summary>
        </member>
        <member name="P:Tensorboard.EventReflection.Descriptor">
            <summary>File descriptor for tensorboard/compat/proto/event.proto</summary>
        </member>
        <member name="T:Tensorboard.WorkerHealth">
            <summary>
            Current health status of a worker.
            </summary>
        </member>
        <member name="F:Tensorboard.WorkerHealth.Ok">
            <summary>
            By default a worker is healthy.
            </summary>
        </member>
        <member name="F:Tensorboard.WorkerHealth.ShuttingDown">
            <summary>
            Worker has been instructed to shutdown after a timeout.
            </summary>
        </member>
        <member name="T:Tensorboard.WorkerShutdownMode">
            <summary>
            Indicates the behavior of the worker when an internal error or shutdown
            signal is received.
            </summary>
        </member>
        <member name="T:Tensorboard.Event">
            <summary>
            Protocol buffer representing an event that happened during
            the execution of a Brain model.
            </summary>
        </member>
        <member name="F:Tensorboard.Event.WallTimeFieldNumber">
            <summary>Field number for the "wall_time" field.</summary>
        </member>
        <member name="P:Tensorboard.Event.WallTime">
            <summary>
            Timestamp of the event.
            </summary>
        </member>
        <member name="F:Tensorboard.Event.StepFieldNumber">
            <summary>Field number for the "step" field.</summary>
        </member>
        <member name="P:Tensorboard.Event.Step">
            <summary>
            Global step of the event.
            </summary>
        </member>
        <member name="F:Tensorboard.Event.FileVersionFieldNumber">
            <summary>Field number for the "file_version" field.</summary>
        </member>
        <member name="P:Tensorboard.Event.FileVersion">
            <summary>
            An event file was started, with the specified version.
            This is use to identify the contents of the record IO files
            easily.  Current version is "brain.Event:2".  All versions
            start with "brain.Event:".
            </summary>
        </member>
        <member name="F:Tensorboard.Event.GraphDefFieldNumber">
            <summary>Field number for the "graph_def" field.</summary>
        </member>
        <member name="P:Tensorboard.Event.GraphDef">
            <summary>
            An encoded version of a GraphDef.
            </summary>
        </member>
        <member name="F:Tensorboard.Event.SummaryFieldNumber">
            <summary>Field number for the "summary" field.</summary>
        </member>
        <member name="P:Tensorboard.Event.Summary">
            <summary>
            A summary was generated.
            </summary>
        </member>
        <member name="F:Tensorboard.Event.LogMessageFieldNumber">
            <summary>Field number for the "log_message" field.</summary>
        </member>
        <member name="P:Tensorboard.Event.LogMessage">
            <summary>
            The user output a log message. This was theoretically used by the defunct
            tensorboard_logging module, which has since been removed; this field is
            now deprecated and should not be used.
            </summary>
        </member>
        <member name="F:Tensorboard.Event.SessionLogFieldNumber">
            <summary>Field number for the "session_log" field.</summary>
        </member>
        <member name="P:Tensorboard.Event.SessionLog">
            <summary>
            The state of the session which can be used for restarting after crashes.
            </summary>
        </member>
        <member name="F:Tensorboard.Event.TaggedRunMetadataFieldNumber">
            <summary>Field number for the "tagged_run_metadata" field.</summary>
        </member>
        <member name="P:Tensorboard.Event.TaggedRunMetadata">
            <summary>
            The metadata returned by running a session.run() call.
            </summary>
        </member>
        <member name="F:Tensorboard.Event.MetaGraphDefFieldNumber">
            <summary>Field number for the "meta_graph_def" field.</summary>
        </member>
        <member name="P:Tensorboard.Event.MetaGraphDef">
            <summary>
            An encoded version of a MetaGraphDef.
            </summary>
        </member>
        <member name="T:Tensorboard.Event.WhatOneofCase">
            <summary>Enum of possible cases for the "what" oneof.</summary>
        </member>
        <member name="T:Tensorboard.LogMessage">
             <summary>
             Protocol buffer used for logging messages to the events file.
            
             This was theoretically used by the defunct tensorboard_logging module, which
             has been removed; this message is now deprecated and should not be used.
             </summary>
        </member>
        <member name="F:Tensorboard.LogMessage.LevelFieldNumber">
            <summary>Field number for the "level" field.</summary>
        </member>
        <member name="F:Tensorboard.LogMessage.MessageFieldNumber">
            <summary>Field number for the "message" field.</summary>
        </member>
        <member name="T:Tensorboard.LogMessage.Types">
            <summary>Container for nested types declared in the LogMessage message type.</summary>
        </member>
        <member name="F:Tensorboard.LogMessage.Types.Level.Debugging">
            <summary>
            Note: The logging level 10 cannot be named DEBUG. Some software
            projects compile their C/C++ code with -DDEBUG in debug builds. So the
            C++ code generated from this file should not have an identifier named
            DEBUG.
            </summary>
        </member>
        <member name="T:Tensorboard.SessionLog">
            <summary>
            Protocol buffer used for logging session state.
            </summary>
        </member>
        <member name="F:Tensorboard.SessionLog.StatusFieldNumber">
            <summary>Field number for the "status" field.</summary>
        </member>
        <member name="F:Tensorboard.SessionLog.CheckpointPathFieldNumber">
            <summary>Field number for the "checkpoint_path" field.</summary>
        </member>
        <member name="P:Tensorboard.SessionLog.CheckpointPath">
            <summary>
            This checkpoint_path contains both the path and filename.
            </summary>
        </member>
        <member name="F:Tensorboard.SessionLog.MsgFieldNumber">
            <summary>Field number for the "msg" field.</summary>
        </member>
        <member name="T:Tensorboard.SessionLog.Types">
            <summary>Container for nested types declared in the SessionLog message type.</summary>
        </member>
        <member name="T:Tensorboard.TaggedRunMetadata">
            <summary>
            For logging the metadata output for a single session.run() call.
            </summary>
        </member>
        <member name="F:Tensorboard.TaggedRunMetadata.TagFieldNumber">
            <summary>Field number for the "tag" field.</summary>
        </member>
        <member name="P:Tensorboard.TaggedRunMetadata.Tag">
            <summary>
            Tag name associated with this metadata.
            </summary>
        </member>
        <member name="F:Tensorboard.TaggedRunMetadata.RunMetadataFieldNumber">
            <summary>Field number for the "run_metadata" field.</summary>
        </member>
        <member name="P:Tensorboard.TaggedRunMetadata.RunMetadata">
            <summary>
            Byte-encoded version of the `RunMetadata` proto in order to allow lazy
            deserialization.
            </summary>
        </member>
        <member name="F:Tensorboard.WatchdogConfig.TimeoutMsFieldNumber">
            <summary>Field number for the "timeout_ms" field.</summary>
        </member>
        <member name="F:Tensorboard.RequestedExitCode.ExitCodeFieldNumber">
            <summary>Field number for the "exit_code" field.</summary>
        </member>
        <member name="F:Tensorboard.WorkerHeartbeatRequest.ShutdownModeFieldNumber">
            <summary>Field number for the "shutdown_mode" field.</summary>
        </member>
        <member name="F:Tensorboard.WorkerHeartbeatRequest.WatchdogConfigFieldNumber">
            <summary>Field number for the "watchdog_config" field.</summary>
        </member>
        <member name="F:Tensorboard.WorkerHeartbeatRequest.ExitCodeFieldNumber">
            <summary>Field number for the "exit_code" field.</summary>
        </member>
        <member name="F:Tensorboard.WorkerHeartbeatResponse.HealthStatusFieldNumber">
            <summary>Field number for the "health_status" field.</summary>
        </member>
        <member name="F:Tensorboard.WorkerHeartbeatResponse.WorkerLogFieldNumber">
            <summary>Field number for the "worker_log" field.</summary>
        </member>
        <member name="F:Tensorboard.WorkerHeartbeatResponse.HostnameFieldNumber">
            <summary>Field number for the "hostname" field.</summary>
        </member>
        <member name="T:Tensorboard.FullTypeReflection">
            <summary>Holder for reflection information generated from tensorboard/compat/proto/full_type.proto</summary>
        </member>
        <member name="P:Tensorboard.FullTypeReflection.Descriptor">
            <summary>File descriptor for tensorboard/compat/proto/full_type.proto</summary>
        </member>
        <member name="T:Tensorboard.FullTypeId">
            <summary>
            DISABLED.IfChange
            Experimental. Represents the complete type information of a TensorFlow value.
            </summary>
        </member>
        <member name="F:Tensorboard.FullTypeId.TftUnset">
            <summary>
            The default represents an uninitialized values.
            </summary>
        </member>
        <member name="F:Tensorboard.FullTypeId.TftVar">
             <summary>
             Type variables may serve as placeholder for any other type ID in type
             templates.
            
             Examples:
               TFT_DATASET[TFT_VAR["T"]] is a Dataset returning a type indicated by "T".
               TFT_TENSOR[TFT_VAR["T"]] is a Tensor of n element type indicated by "T".
               TFT_TENSOR[TFT_VAR["T"]], TFT_TENSOR[TFT_VAR["T"]] are two tensors of
                 identical element types.
               TFT_TENSOR[TFT_VAR["P"]], TFT_TENSOR[TFT_VAR["Q"]] are two tensors of
                 independent element types.
             </summary>
        </member>
        <member name="F:Tensorboard.FullTypeId.TftAny">
            <summary>
            Wildcard type. Describes a parameter of unknown type. In TensorFlow, that
            can mean either a "Top" type (accepts any type), or a dynamically typed
            object whose type is unknown in context.
            Important: "unknown" does not necessarily mean undeterminable!
            </summary>
        </member>
        <member name="F:Tensorboard.FullTypeId.TftProduct">
             <summary>
             The algebraic product type. This is an algebraic type that may be used just
             for logical grouping. Not to confused with TFT_TUPLE which describes a
             concrete object of several elements.
            
             Example:
               TFT_DATASET[TFT_PRODUCT[TFT_TENSOR[TFT_INT32], TFT_TENSOR[TFT_FLOAT64]]]
                 is a Dataset producing two tensors, an integer one and a float one.
             </summary>
        </member>
        <member name="F:Tensorboard.FullTypeId.TftNamed">
             <summary>
             Represents a named field, with the name stored in the attribute.
            
             Parametrization:
               TFT_NAMED[&lt;type>]{&lt;name>}
               * &lt;type> is the type of the field
               * &lt;name> is the field name, as string (thpugh can theoretically be an int
                 as well)
            
             Example:
               TFT_RECORD[
                 TFT_NAMED[TFT_TENSOR[TFT_INT32]]{'foo'},
                 TFT_NAMED[TFT_TENSOR[TFT_FLOAT32]]{'bar'},
               ]
                 is a structure with two fields, an int tensor "foo" and a float tensor
                 "bar".
             </summary>
        </member>
        <member name="F:Tensorboard.FullTypeId.TftForEach">
             <summary>
             Template definition. Expands the variables by repeating a template as
             arguments of container.
            
             Parametrization:
               TFT_FOR_EACH[&lt;container_type>, &lt;template>, &lt;expansions>]
               * &lt;container_type> is the type of the container that the template will be
                 expanded into
               * &lt;template> is any type definition that potentially contains type
                 variables
               * &lt;expansions> is a TFT_VAR and may include more types in the future
            
             Example:
               TFT_FOR_EACH[
                     TFT_PRODUCT,
                     TFT_TENSOR[TFT_VAR["t"]],
                     TFT_VAR["t"]
                 ]
                 will substitute a T = TFT_INT32 to TFT_PRODUCT[TFT_TENSOR[TFT_INT32]]
                 and a T = (TFT_INT32, TFT_INT64) to
                 TFT_PRODUCT[TFT_TENSOR[TFT_INT32], TFT_TENSOR[TFT_INT64]].
             </summary>
        </member>
        <member name="F:Tensorboard.FullTypeId.TftCallable">
             <summary>
             Callable types describe functions and ops.
            
             Parametrization:
               TFT_CALLABLE[&lt;arg type>, &lt;return type>]
               * &lt;arg type> is the type of the arguments; TFT_PRODUCT represents
               multiple
                 arguments.
               * &lt;return type> is the return type; TFT_PRODUCT represents multiple
                 return values (that means that callables returning multiple things
                 don't necessarily return a single tuple).
            
             Example:
               TFT_CALLABLE[
                 TFT_ANY,
                 TFT_PRODUCT[TFT_TENSOR[TFT_INT32], TFT_TENSOR[TFT_FLOAT64]],
               ]
                 is a callable with unspecified (for now) input arguments, and
                 two return values of type tensor.
             </summary>
        </member>
        <member name="F:Tensorboard.FullTypeId.TftTensor">
             <summary>
             The usual Tensor. This is a parametric type.
            
             Parametrization:
               TFT_TENSOR[&lt;element type>, &lt;shape type>]
               * &lt;element type> is currently limited to one of the element types
                 defined below.
               * &lt;shape type> is not yet defined, and may only be TFT_UNKNOWN for now.
            
             A TFT_SHAPE type will be defined in the future.
            
             Example:
               TFT_TENSOR[TFT_INT32, TFT_UNKNOWN]
                 is a Tensor of int32 element type and unknown shape.
            
             TODO(mdan): Define TFT_SHAPE and add more examples.
             </summary>
        </member>
        <member name="F:Tensorboard.FullTypeId.TftArray">
             <summary>
             Array (or tensorflow::TensorList in the variant type registry).
             Note: this is not to be confused with the deprecated `TensorArray*` ops
             which are not supported by FullType.
             This type represents a random-access list whose elements can be
             described by a single type. Although immutable, Array is expected to
             support efficient mutation semantics (i.e. element update) in the
             user-facing API.
             The element type may be generic or even TFT_ANY for a heterogenous list.
            
             Parametrization:
               TFT_ARRAY[&lt;element type>]
               * &lt;element type> may be any concrete type.
            
             Examples:
               TFT_ARRAY[TFT_TENSOR[TFT_INT32]] is a TensorArray holding int32 Tensors
                 of any shape.
               TFT_ARRAY[TFT_TENSOR[TFT_UNKNOWN]] is a TensorArray holding Tensors of
                 mixed element types.
               TFT_ARRAY[TFT_UNKNOWN] is a TensorArray holding any element type.
               TFT_ARRAY[] is equivalent to TFT_ARRAY[TFT_UNKNOWN].
               TFT_ARRAY[TFT_ARRAY[]] is an array or arrays (of unknown types).
             </summary>
        </member>
        <member name="F:Tensorboard.FullTypeId.TftOptional">
             <summary>
             Optional (or tensorflow::OptionalVariant in the variant type registry).
             This type represents a value that may either hold an element of a single
             specified type, or nothing at all.
            
             Parametrization:
               TFT_OPTIONAL[&lt;element type>]
               * &lt;element type> may be any concrete type.
            
             Examples:
               TFT_OPTIONAL[TFT_TENSOR[TFT_INT32]] is an Optional holding an int32
                 Tensor of any shape.
             </summary>
        </member>
        <member name="F:Tensorboard.FullTypeId.TftLiteral">
             <summary>
             Literal types describe compile-time constant values.
             Literal types may also participate in dependent types.
            
             Parametrization:
               TFT_LITERAL[&lt;value type>]{&lt;value>}
               * &lt;value type> may be any concrete type compatible that can hold &lt;value>
               * &lt;value> is the type's attribute, and holds the actual literal value
            
             Examples:
               TFT_LITERAL[TFT_INT32]{1} is the compile-time constant 1.
             </summary>
        </member>
        <member name="F:Tensorboard.FullTypeId.TftBool">
            <summary>
            The bool element type.
            TODO(mdan): Quantized types, legacy representations (e.g. ref)
            </summary>
        </member>
        <member name="F:Tensorboard.FullTypeId.TftUint8">
            <summary>
            Integer element types.
            </summary>
        </member>
        <member name="F:Tensorboard.FullTypeId.TftHalf">
            <summary>
            Floating-point element types.
            </summary>
        </member>
        <member name="F:Tensorboard.FullTypeId.TftComplex64">
            <summary>
            Complex element types.
            TODO(mdan): Represent as TFT_COMPLEX[TFT_DOUBLE] instead?
            </summary>
        </member>
        <member name="F:Tensorboard.FullTypeId.TftString">
            <summary>
            The string element type.
            </summary>
        </member>
        <member name="F:Tensorboard.FullTypeId.TftDataset">
             <summary>
             Datasets created by tf.data ops and APIs. Datasets have generator/iterable
             semantics, that is, one can construct an iterator from them. Like
             Array, they are considered to return elements that can be described
             by a single type. Unlike Array, they do not support random access or
             mutation, and can potentially produce an infinite number of elements.
             A datasets can produce logical structures (e.g. multiple elements). This
             is expressed using TFT_PRODUCT.
            
             Parametrization: TFT_ARRAY[&lt;element type>].
               * &lt;element type> may be a concrete type or a type symbol. It represents
                 the data type of the elements produced by the dataset.
            
             Examples:
               TFT_DATSET[TFT_TENSOR[TFT_INT32]] is a Dataset producing single int32
                 Tensors of unknown shape.
               TFT_DATSET[TFT_PRODUCT[TFT_TENSOR[TFT_INT32], TFT_TENSOR[TFT_FLOAT32]] is
                 a Dataset producing pairs of Tensors, one integer and one float.
             Note: The high ID number is to prepare for the eventuality that Datasets
             will be supported by user types in the future.
             </summary>
        </member>
        <member name="F:Tensorboard.FullTypeId.TftRagged">
             <summary>
             A ragged tensor created by tf.ragged ops and APIs.
            
             Parametrization: TFT_RAGGED[&lt;element_type>].
             </summary>
        </member>
        <member name="F:Tensorboard.FullTypeId.TftMutexLock">
             <summary>
             A mutex lock tensor, produced by tf.raw_ops.MutexLock.
             Unlike strict execution models, where ownership of a lock is denoted by
             "running after the lock has been acquired", in non-strict mode, lock
             ownership is in the true sense: "the op argument representing the lock is
             available".
             Mutex locks are the dynamic counterpart of control dependencies.
             TODO(mdan): Properly document this thing.
            
             Parametrization: TFT_MUTEX_LOCK[].
             </summary>
        </member>
        <member name="F:Tensorboard.FullTypeId.TftLegacyVariant">
            <summary>
            The equivalent of a Tensor with DT_VARIANT dtype, kept here to simplify
            translation. This type should not normally appear after type inference.
            Note that LEGACY_VARIANT != ANY: TENSOR[INT32] is a subtype of ANY, but is
            not a subtype of LEGACY_VARIANT.
            </summary>
        </member>
        <member name="T:Tensorboard.FullTypeDef">
            <summary>
            Highly experimental and very likely to change.
            This encoding uses tags instead of dedicated messages for regularity. In
            particular the encoding imposes no restrictions on what the parameters of any
            type should be, which in particular needs to be true for type symbols.
            </summary>
        </member>
        <member name="F:Tensorboard.FullTypeDef.TypeIdFieldNumber">
            <summary>Field number for the "type_id" field.</summary>
        </member>
        <member name="P:Tensorboard.FullTypeDef.TypeId">
            <summary>
            The principal type represented by this object. This may be a concrete type
            (Tensor, Dataset) a type variable (used for dependent types) a type
            symbol (Any, Union). See FullTypeId for details.
            </summary>
        </member>
        <member name="F:Tensorboard.FullTypeDef.ArgsFieldNumber">
            <summary>Field number for the "args" field.</summary>
        </member>
        <member name="F:Tensorboard.FullTypeDef.SFieldNumber">
            <summary>Field number for the "s" field.</summary>
        </member>
        <member name="F:Tensorboard.FullTypeDef.IFieldNumber">
            <summary>Field number for the "i" field.</summary>
        </member>
        <member name="P:Tensorboard.FullTypeDef.I">
            <summary>
            TODO(mdan): list/tensor, map? Need to reconcile with TFT_RECORD, etc.
            </summary>
        </member>
        <member name="T:Tensorboard.FullTypeDef.AttrOneofCase">
            <summary>Enum of possible cases for the "attr" oneof.</summary>
        </member>
        <member name="T:Tensorboard.FunctionReflection">
            <summary>Holder for reflection information generated from tensorboard/compat/proto/function.proto</summary>
        </member>
        <member name="P:Tensorboard.FunctionReflection.Descriptor">
            <summary>File descriptor for tensorboard/compat/proto/function.proto</summary>
        </member>
        <member name="T:Tensorboard.FunctionDefLibrary">
            <summary>
            A library is a set of named functions.
            </summary>
        </member>
        <member name="F:Tensorboard.FunctionDefLibrary.FunctionFieldNumber">
            <summary>Field number for the "function" field.</summary>
        </member>
        <member name="F:Tensorboard.FunctionDefLibrary.GradientFieldNumber">
            <summary>Field number for the "gradient" field.</summary>
        </member>
        <member name="F:Tensorboard.FunctionDefLibrary.RegisteredGradientsFieldNumber">
            <summary>Field number for the "registered_gradients" field.</summary>
        </member>
        <member name="T:Tensorboard.FunctionDef">
             <summary>
             A function can be instantiated when the runtime can bind every attr
             with a value. When a GraphDef has a call to a function, it must
             have binding for every attr defined in the signature.
            
             TODO(zhifengc):
               * device spec, etc.
             </summary>
        </member>
        <member name="F:Tensorboard.FunctionDef.SignatureFieldNumber">
            <summary>Field number for the "signature" field.</summary>
        </member>
        <member name="P:Tensorboard.FunctionDef.Signature">
            <summary>
            The definition of the function's name, arguments, return values,
            attrs etc.
            </summary>
        </member>
        <member name="F:Tensorboard.FunctionDef.AttrFieldNumber">
            <summary>Field number for the "attr" field.</summary>
        </member>
        <member name="P:Tensorboard.FunctionDef.Attr">
            <summary>
            Attributes specific to this function definition.
            </summary>
        </member>
        <member name="F:Tensorboard.FunctionDef.ArgAttrFieldNumber">
            <summary>Field number for the "arg_attr" field.</summary>
        </member>
        <member name="F:Tensorboard.FunctionDef.ResourceArgUniqueIdFieldNumber">
            <summary>Field number for the "resource_arg_unique_id" field.</summary>
        </member>
        <member name="P:Tensorboard.FunctionDef.ResourceArgUniqueId">
             <summary>
             Unique IDs for each resource argument, used to track aliasing resources. If
             Argument A and Argument B alias each other, then
             resource_arg_unique_ids[A.index] == resource_arg_unique_ids[B.index].
            
             If this field is empty, none of the arguments could alias; otherwise, every
             resource argument should have an entry in this field.
            
             When instantiated, the unique IDs will be attached to the _Arg nodes'
             "_resource_arg_unique_id" attribute.
             </summary>
        </member>
        <member name="F:Tensorboard.FunctionDef.NodeDefFieldNumber">
            <summary>Field number for the "node_def" field.</summary>
        </member>
        <member name="P:Tensorboard.FunctionDef.NodeDef">
            <summary>
            By convention, "op" in node_def is resolved by consulting with a
            user-defined library first. If not resolved, "func" is assumed to
            be a builtin op.
            </summary>
        </member>
        <member name="F:Tensorboard.FunctionDef.RetFieldNumber">
            <summary>Field number for the "ret" field.</summary>
        </member>
        <member name="P:Tensorboard.FunctionDef.Ret">
            <summary>
            A mapping from the output arg names from `signature` to the
            outputs from `node_def` that should be returned by the function.
            </summary>
        </member>
        <member name="F:Tensorboard.FunctionDef.ControlRetFieldNumber">
            <summary>Field number for the "control_ret" field.</summary>
        </member>
        <member name="P:Tensorboard.FunctionDef.ControlRet">
            <summary>
            A mapping from control output names from `signature` to node names in
            `node_def` which should be control outputs of this function.
            </summary>
        </member>
        <member name="T:Tensorboard.FunctionDef.Types">
            <summary>Container for nested types declared in the FunctionDef message type.</summary>
        </member>
        <member name="T:Tensorboard.FunctionDef.Types.ArgAttrs">
            <summary>
            Attributes for function arguments. These attributes are the same set of
            valid attributes as to _Arg nodes.
            </summary>
        </member>
        <member name="F:Tensorboard.FunctionDef.Types.ArgAttrs.AttrFieldNumber">
            <summary>Field number for the "attr" field.</summary>
        </member>
        <member name="T:Tensorboard.GradientDef">
             <summary>
             GradientDef defines the gradient function of a function defined in
             a function library.
            
             A gradient function g (specified by gradient_func) for a function f
             (specified by function_name) must follow the following:
            
             The function 'f' must be a numerical function which takes N inputs
             and produces M outputs. Its gradient function 'g', which is a
             function taking N + M inputs and produces N outputs.
            
             I.e. if we have
                (y1, y2, ..., y_M) = f(x1, x2, ..., x_N),
             then, g is
                (dL/dx1, dL/dx2, ..., dL/dx_N) = g(x1, x2, ..., x_N,
                                                  dL/dy1, dL/dy2, ..., dL/dy_M),
             where L is a scalar-value function of (x1, x2, ..., xN) (e.g., the
             loss function). dL/dx_i is the partial derivative of L with respect
             to x_i.
             </summary>
        </member>
        <member name="F:Tensorboard.GradientDef.FunctionNameFieldNumber">
            <summary>Field number for the "function_name" field.</summary>
        </member>
        <member name="P:Tensorboard.GradientDef.FunctionName">
            <summary>
            The function name.
            </summary>
        </member>
        <member name="F:Tensorboard.GradientDef.GradientFuncFieldNumber">
            <summary>Field number for the "gradient_func" field.</summary>
        </member>
        <member name="P:Tensorboard.GradientDef.GradientFunc">
            <summary>
            The gradient function's name.
            </summary>
        </member>
        <member name="T:Tensorboard.RegisteredGradient">
            <summary>
            RegisteredGradient stores a gradient function that is registered in the
            gradients library and used in the ops of a function in the function library.
            Unlike GradientDef, these gradients are identified by op type, and not
            directly linked to any function.
            </summary>
        </member>
        <member name="F:Tensorboard.RegisteredGradient.GradientFuncFieldNumber">
            <summary>Field number for the "gradient_func" field.</summary>
        </member>
        <member name="P:Tensorboard.RegisteredGradient.GradientFunc">
            <summary>
            The gradient function's name.
            </summary>
        </member>
        <member name="F:Tensorboard.RegisteredGradient.RegisteredOpTypeFieldNumber">
            <summary>Field number for the "registered_op_type" field.</summary>
        </member>
        <member name="P:Tensorboard.RegisteredGradient.RegisteredOpType">
            <summary>
            The gradient function's registered op type.
            </summary>
        </member>
        <member name="T:Tensorboard.GraphReflection">
            <summary>Holder for reflection information generated from tensorboard/compat/proto/graph.proto</summary>
        </member>
        <member name="P:Tensorboard.GraphReflection.Descriptor">
            <summary>File descriptor for tensorboard/compat/proto/graph.proto</summary>
        </member>
        <member name="T:Tensorboard.GraphDef">
            <summary>
            Represents the graph of operations
            </summary>
        </member>
        <member name="F:Tensorboard.GraphDef.NodeFieldNumber">
            <summary>Field number for the "node" field.</summary>
        </member>
        <member name="F:Tensorboard.GraphDef.VersionsFieldNumber">
            <summary>Field number for the "versions" field.</summary>
        </member>
        <member name="P:Tensorboard.GraphDef.Versions">
            <summary>
            Compatibility versions of the graph.  See core/public/version.h for version
            history.  The GraphDef version is distinct from the TensorFlow version, and
            each release of TensorFlow will support a range of GraphDef versions.
            </summary>
        </member>
        <member name="F:Tensorboard.GraphDef.VersionFieldNumber">
            <summary>Field number for the "version" field.</summary>
        </member>
        <member name="P:Tensorboard.GraphDef.Version">
            <summary>
            Deprecated single version field; use versions above instead.  Since all
            GraphDef changes before "versions" was introduced were forward
            compatible, this field is entirely ignored.
            </summary>
        </member>
        <member name="F:Tensorboard.GraphDef.LibraryFieldNumber">
            <summary>Field number for the "library" field.</summary>
        </member>
        <member name="P:Tensorboard.GraphDef.Library">
             <summary>
             "library" provides user-defined functions.
            
             Naming:
               * library.function.name are in a flat namespace.
                 NOTE: We may need to change it to be hierarchical to support
                 different orgs. E.g.,
                 { "/google/nn", { ... }},
                 { "/google/vision", { ... }}
                 { "/org_foo/module_bar", { ... }}
                 map&lt;string, FunctionDefLib> named_lib;
               * If node[i].op is the name of one function in "library",
                 node[i] is deemed as a function call. Otherwise, node[i].op
                 must be a primitive operation supported by the runtime.
            
             Function call semantics:
            
               * The callee may start execution as soon as some of its inputs
                 are ready. The caller may want to use Tuple() mechanism to
                 ensure all inputs are ready in the same time.
            
               * The consumer of return values may start executing as soon as
                 the return values the consumer depends on are ready.  The
                 consumer may want to use Tuple() mechanism to ensure the
                 consumer does not start until all return values of the callee
                 function are ready.
             </summary>
        </member>
        <member name="T:Tensorboard.MetaGraphReflection">
            <summary>Holder for reflection information generated from tensorboard/compat/proto/meta_graph.proto</summary>
        </member>
        <member name="P:Tensorboard.MetaGraphReflection.Descriptor">
            <summary>File descriptor for tensorboard/compat/proto/meta_graph.proto</summary>
        </member>
        <member name="T:Tensorboard.MetaGraphDef">
             <summary>
             NOTE: This protocol buffer is evolving, and will go through revisions in the
             coming months.
            
             Protocol buffer containing the following which are necessary to restart
             training, run inference. It can be used to serialize/de-serialize memory
             objects necessary for running computation in a graph when crossing the
             process boundary. It can be used for long term storage of graphs,
             cross-language execution of graphs, etc.
               MetaInfoDef
               GraphDef
               SaverDef
               CollectionDef
               TensorInfo
               SignatureDef
             </summary>
        </member>
        <member name="F:Tensorboard.MetaGraphDef.MetaInfoDefFieldNumber">
            <summary>Field number for the "meta_info_def" field.</summary>
        </member>
        <member name="F:Tensorboard.MetaGraphDef.GraphDefFieldNumber">
            <summary>Field number for the "graph_def" field.</summary>
        </member>
        <member name="P:Tensorboard.MetaGraphDef.GraphDef">
            <summary>
            GraphDef.
            </summary>
        </member>
        <member name="F:Tensorboard.MetaGraphDef.SaverDefFieldNumber">
            <summary>Field number for the "saver_def" field.</summary>
        </member>
        <member name="P:Tensorboard.MetaGraphDef.SaverDef">
            <summary>
            SaverDef.
            </summary>
        </member>
        <member name="F:Tensorboard.MetaGraphDef.CollectionDefFieldNumber">
            <summary>Field number for the "collection_def" field.</summary>
        </member>
        <member name="P:Tensorboard.MetaGraphDef.CollectionDef">
            <summary>
            collection_def: Map from collection name to collections.
            See CollectionDef section for details.
            </summary>
        </member>
        <member name="F:Tensorboard.MetaGraphDef.SignatureDefFieldNumber">
            <summary>Field number for the "signature_def" field.</summary>
        </member>
        <member name="P:Tensorboard.MetaGraphDef.SignatureDef">
            <summary>
            signature_def: Map from user supplied key for a signature to a single
            SignatureDef.
            </summary>
        </member>
        <member name="F:Tensorboard.MetaGraphDef.AssetFileDefFieldNumber">
            <summary>Field number for the "asset_file_def" field.</summary>
        </member>
        <member name="P:Tensorboard.MetaGraphDef.AssetFileDef">
            <summary>
            Asset file def to be used with the defined graph.
            </summary>
        </member>
        <member name="F:Tensorboard.MetaGraphDef.ObjectGraphDefFieldNumber">
            <summary>Field number for the "object_graph_def" field.</summary>
        </member>
        <member name="P:Tensorboard.MetaGraphDef.ObjectGraphDef">
            <summary>
            Extra information about the structure of functions and stateful objects.
            </summary>
        </member>
        <member name="T:Tensorboard.MetaGraphDef.Types">
            <summary>Container for nested types declared in the MetaGraphDef message type.</summary>
        </member>
        <member name="T:Tensorboard.MetaGraphDef.Types.MetaInfoDef">
            <summary>
            Meta information regarding the graph to be exported.  To be used by users
            of this protocol buffer to encode information regarding their meta graph.
            </summary>
        </member>
        <member name="F:Tensorboard.MetaGraphDef.Types.MetaInfoDef.MetaGraphVersionFieldNumber">
            <summary>Field number for the "meta_graph_version" field.</summary>
        </member>
        <member name="P:Tensorboard.MetaGraphDef.Types.MetaInfoDef.MetaGraphVersion">
            <summary>
            User specified Version string. Can be the name of the model and revision,
            steps this model has been trained to, etc.
            </summary>
        </member>
        <member name="F:Tensorboard.MetaGraphDef.Types.MetaInfoDef.StrippedOpListFieldNumber">
            <summary>Field number for the "stripped_op_list" field.</summary>
        </member>
        <member name="P:Tensorboard.MetaGraphDef.Types.MetaInfoDef.StrippedOpList">
            <summary>
            A copy of the OpDefs used by the producer of this graph_def.
            Descriptions and Ops not used in graph_def are stripped out.
            </summary>
        </member>
        <member name="F:Tensorboard.MetaGraphDef.Types.MetaInfoDef.AnyInfoFieldNumber">
            <summary>Field number for the "any_info" field.</summary>
        </member>
        <member name="P:Tensorboard.MetaGraphDef.Types.MetaInfoDef.AnyInfo">
            <summary>
            A serialized protobuf. Can be the time this meta graph is created, or
            modified, or name of the model.
            </summary>
        </member>
        <member name="F:Tensorboard.MetaGraphDef.Types.MetaInfoDef.TagsFieldNumber">
            <summary>Field number for the "tags" field.</summary>
        </member>
        <member name="P:Tensorboard.MetaGraphDef.Types.MetaInfoDef.Tags">
             <summary>
             User supplied tag(s) on the meta_graph and included graph_def.
            
             MetaGraphDefs should be tagged with their capabilities or use-cases.
             Examples: "train", "serve", "gpu", "tpu", etc.
             These tags enable loaders to access the MetaGraph(s) appropriate for a
             specific use-case or runtime environment.
             </summary>
        </member>
        <member name="F:Tensorboard.MetaGraphDef.Types.MetaInfoDef.TensorflowVersionFieldNumber">
            <summary>Field number for the "tensorflow_version" field.</summary>
        </member>
        <member name="P:Tensorboard.MetaGraphDef.Types.MetaInfoDef.TensorflowVersion">
            <summary>
            The __version__ string of the tensorflow build used to write this graph.
            This will be populated by the framework, which will overwrite any user
            supplied value.
            </summary>
        </member>
        <member name="F:Tensorboard.MetaGraphDef.Types.MetaInfoDef.TensorflowGitVersionFieldNumber">
            <summary>Field number for the "tensorflow_git_version" field.</summary>
        </member>
        <member name="P:Tensorboard.MetaGraphDef.Types.MetaInfoDef.TensorflowGitVersion">
            <summary>
            The __git_version__ string of the tensorflow build used to write this
            graph. This will be populated by the framework, which will overwrite any
            user supplied value.
            </summary>
        </member>
        <member name="F:Tensorboard.MetaGraphDef.Types.MetaInfoDef.StrippedDefaultAttrsFieldNumber">
            <summary>Field number for the "stripped_default_attrs" field.</summary>
        </member>
        <member name="P:Tensorboard.MetaGraphDef.Types.MetaInfoDef.StrippedDefaultAttrs">
            <summary>
            A flag to denote whether default-valued attrs have been stripped from
            the nodes in this graph_def.
            </summary>
        </member>
        <member name="F:Tensorboard.MetaGraphDef.Types.MetaInfoDef.FunctionAliasesFieldNumber">
            <summary>Field number for the "function_aliases" field.</summary>
        </member>
        <member name="P:Tensorboard.MetaGraphDef.Types.MetaInfoDef.FunctionAliases">
            <summary>
            FunctionDef name to aliases mapping.
            </summary>
        </member>
        <member name="T:Tensorboard.CollectionDef">
             <summary>
             CollectionDef should cover most collections.
             To add a user-defined collection, do one of the following:
             1. For simple data types, such as string, int, float:
                  tf.add_to_collection("your_collection_name", your_simple_value)
                strings will be stored as bytes_list.
            
             2. For Protobuf types, there are three ways to add them:
                1) tf.add_to_collection("your_collection_name",
                     your_proto.SerializeToString())
            
                   collection_def {
                     key: "user_defined_bytes_collection"
                     value {
                       bytes_list {
                         value: "queue_name: \"test_queue\"\n"
                       }
                     }
                   }
            
              or
            
                2) tf.add_to_collection("your_collection_name", str(your_proto))
            
                   collection_def {
                     key: "user_defined_string_collection"
                     value {
                      bytes_list {
                         value: "\n\ntest_queue"
                       }
                     }
                   }
            
              or
            
                3) any_buf = any_pb2.Any()
                   tf.add_to_collection("your_collection_name",
                     any_buf.Pack(your_proto))
            
                   collection_def {
                     key: "user_defined_any_collection"
                     value {
                       any_list {
                         value {
                           type_url: "type.googleapis.com/tensorflow.QueueRunnerDef"
                           value: "\n\ntest_queue"
                         }
                       }
                     }
                   }
            
             3. For Python objects, implement to_proto() and from_proto(), and register
                them in the following manner:
                ops.register_proto_function("your_collection_name",
                                            proto_type,
                                            to_proto=YourPythonObject.to_proto,
                                            from_proto=YourPythonObject.from_proto)
                These functions will be invoked to serialize and de-serialize the
                collection. For example,
                ops.register_proto_function(ops.GraphKeys.GLOBAL_VARIABLES,
                                            proto_type=variable_pb2.VariableDef,
                                            to_proto=Variable.to_proto,
                                            from_proto=Variable.from_proto)
             </summary>
        </member>
        <member name="F:Tensorboard.CollectionDef.NodeListFieldNumber">
            <summary>Field number for the "node_list" field.</summary>
        </member>
        <member name="F:Tensorboard.CollectionDef.BytesListFieldNumber">
            <summary>Field number for the "bytes_list" field.</summary>
        </member>
        <member name="F:Tensorboard.CollectionDef.Int64ListFieldNumber">
            <summary>Field number for the "int64_list" field.</summary>
        </member>
        <member name="F:Tensorboard.CollectionDef.FloatListFieldNumber">
            <summary>Field number for the "float_list" field.</summary>
        </member>
        <member name="F:Tensorboard.CollectionDef.AnyListFieldNumber">
            <summary>Field number for the "any_list" field.</summary>
        </member>
        <member name="T:Tensorboard.CollectionDef.KindOneofCase">
            <summary>Enum of possible cases for the "kind" oneof.</summary>
        </member>
        <member name="T:Tensorboard.CollectionDef.Types">
            <summary>Container for nested types declared in the CollectionDef message type.</summary>
        </member>
        <member name="T:Tensorboard.CollectionDef.Types.NodeList">
            <summary>
            NodeList is used for collecting nodes in graph. For example
            collection_def {
              key: "summaries"
              value {
                node_list {
                  value: "input_producer/ScalarSummary:0"
                  value: "shuffle_batch/ScalarSummary:0"
                  value: "ImageSummary:0"
                }
              }
            </summary>
        </member>
        <member name="F:Tensorboard.CollectionDef.Types.NodeList.ValueFieldNumber">
            <summary>Field number for the "value" field.</summary>
        </member>
        <member name="T:Tensorboard.CollectionDef.Types.BytesList">
            <summary>
            BytesList is used for collecting strings and serialized protobufs. For
            example:
            collection_def {
              key: "trainable_variables"
              value {
                bytes_list {
                  value: "\n\017conv1/weights:0\022\024conv1/weights/Assign
                         \032\024conv1/weights/read:0"
                  value: "\n\016conv1/biases:0\022\023conv1/biases/Assign\032
                         \023conv1/biases/read:0"
                }
              }
            }
            </summary>
        </member>
        <member name="F:Tensorboard.CollectionDef.Types.BytesList.ValueFieldNumber">
            <summary>Field number for the "value" field.</summary>
        </member>
        <member name="T:Tensorboard.CollectionDef.Types.Int64List">
            <summary>
            Int64List is used for collecting int, int64 and long values.
            </summary>
        </member>
        <member name="F:Tensorboard.CollectionDef.Types.Int64List.ValueFieldNumber">
            <summary>Field number for the "value" field.</summary>
        </member>
        <member name="T:Tensorboard.CollectionDef.Types.FloatList">
            <summary>
            FloatList is used for collecting float values.
            </summary>
        </member>
        <member name="F:Tensorboard.CollectionDef.Types.FloatList.ValueFieldNumber">
            <summary>Field number for the "value" field.</summary>
        </member>
        <member name="T:Tensorboard.CollectionDef.Types.AnyList">
            <summary>
            AnyList is used for collecting Any protos.
            </summary>
        </member>
        <member name="F:Tensorboard.CollectionDef.Types.AnyList.ValueFieldNumber">
            <summary>Field number for the "value" field.</summary>
        </member>
        <member name="T:Tensorboard.TensorInfo">
            <summary>
            Information about a Tensor necessary for feeding or retrieval.
            </summary>
        </member>
        <member name="F:Tensorboard.TensorInfo.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="P:Tensorboard.TensorInfo.Name">
            <summary>
            For dense `Tensor`s, the name of the tensor in the graph.
            </summary>
        </member>
        <member name="F:Tensorboard.TensorInfo.CooSparseFieldNumber">
            <summary>Field number for the "coo_sparse" field.</summary>
        </member>
        <member name="P:Tensorboard.TensorInfo.CooSparse">
            <summary>
            There are many possible encodings of sparse matrices
            (https://en.wikipedia.org/wiki/Sparse_matrix).  Currently, TensorFlow
            uses only the COO encoding.  This is supported and documented in the
            SparseTensor Python class.
            </summary>
        </member>
        <member name="F:Tensorboard.TensorInfo.CompositeTensorFieldNumber">
            <summary>Field number for the "composite_tensor" field.</summary>
        </member>
        <member name="P:Tensorboard.TensorInfo.CompositeTensor">
            <summary>
            Generic encoding for CompositeTensors.
            </summary>
        </member>
        <member name="F:Tensorboard.TensorInfo.DtypeFieldNumber">
            <summary>Field number for the "dtype" field.</summary>
        </member>
        <member name="F:Tensorboard.TensorInfo.TensorShapeFieldNumber">
            <summary>Field number for the "tensor_shape" field.</summary>
        </member>
        <member name="P:Tensorboard.TensorInfo.TensorShape">
            <summary>
            The static shape should be recorded here, to the extent that it can
            be known in advance.  In the case of a SparseTensor, this field describes
            the logical shape of the represented tensor (aka dense_shape).
            </summary>
        </member>
        <member name="T:Tensorboard.TensorInfo.EncodingOneofCase">
            <summary>Enum of possible cases for the "encoding" oneof.</summary>
        </member>
        <member name="T:Tensorboard.TensorInfo.Types">
            <summary>Container for nested types declared in the TensorInfo message type.</summary>
        </member>
        <member name="T:Tensorboard.TensorInfo.Types.CooSparse">
            <summary>
            For sparse tensors, The COO encoding stores a triple of values, indices,
            and shape.
            </summary>
        </member>
        <member name="F:Tensorboard.TensorInfo.Types.CooSparse.ValuesTensorNameFieldNumber">
            <summary>Field number for the "values_tensor_name" field.</summary>
        </member>
        <member name="P:Tensorboard.TensorInfo.Types.CooSparse.ValuesTensorName">
            <summary>
            The shape of the values Tensor is [?].  Its dtype must be the dtype of
            the SparseTensor as a whole, given in the enclosing TensorInfo.
            </summary>
        </member>
        <member name="F:Tensorboard.TensorInfo.Types.CooSparse.IndicesTensorNameFieldNumber">
            <summary>Field number for the "indices_tensor_name" field.</summary>
        </member>
        <member name="P:Tensorboard.TensorInfo.Types.CooSparse.IndicesTensorName">
            <summary>
            The indices Tensor must have dtype int64 and shape [?, ?].
            </summary>
        </member>
        <member name="F:Tensorboard.TensorInfo.Types.CooSparse.DenseShapeTensorNameFieldNumber">
            <summary>Field number for the "dense_shape_tensor_name" field.</summary>
        </member>
        <member name="P:Tensorboard.TensorInfo.Types.CooSparse.DenseShapeTensorName">
            <summary>
            The dynamic logical shape represented by the SparseTensor is recorded in
            the Tensor referenced here.  It must have dtype int64 and shape [?].
            </summary>
        </member>
        <member name="T:Tensorboard.TensorInfo.Types.CompositeTensor">
            <summary>
            Generic encoding for composite tensors.
            </summary>
        </member>
        <member name="F:Tensorboard.TensorInfo.Types.CompositeTensor.TypeSpecFieldNumber">
            <summary>Field number for the "type_spec" field.</summary>
        </member>
        <member name="P:Tensorboard.TensorInfo.Types.CompositeTensor.TypeSpec">
            <summary>
            The serialized TypeSpec for the composite tensor.
            </summary>
        </member>
        <member name="F:Tensorboard.TensorInfo.Types.CompositeTensor.ComponentsFieldNumber">
            <summary>Field number for the "components" field.</summary>
        </member>
        <member name="P:Tensorboard.TensorInfo.Types.CompositeTensor.Components">
            <summary>
            A TensorInfo for each flattened component tensor.
            </summary>
        </member>
        <member name="T:Tensorboard.SignatureDef">
             <summary>
             SignatureDef defines the signature of a computation supported by a TensorFlow
             graph.
            
             For example, a model with two loss computations, sharing a single input,
             might have the following signature_def map, in a MetaGraphDef message.
            
             Note that across the two SignatureDefs "loss_A" and "loss_B", the input key,
             output key, and method_name are identical, and will be used by system(s) that
             implement or rely upon this particular loss method. The output tensor names
             differ, demonstrating how different outputs can exist for the same method.
            
             signature_def {
               key: "loss_A"
               value {
                 inputs {
                   key: "input"
                   value {
                     name: "input:0"
                     dtype: DT_STRING
                     tensor_shape: ...
                   }
                 }
                 outputs {
                   key: "loss_output"
                   value {
                     name: "loss_output_A:0"
                     dtype: DT_FLOAT
                     tensor_shape: ...
                   }
                 }
                 method_name: "some/package/compute_loss"
               }
               ...
             }
             signature_def {
               key: "loss_B"
               value {
                 inputs {
                   key: "input"
                   value {
                     name: "input:0"
                     dtype: DT_STRING
                     tensor_shape: ...
                   }
                 }
                 outputs {
                   key: "loss_output"
                   value {
                     name: "loss_output_B:0"
                     dtype: DT_FLOAT
                     tensor_shape: ...
                   }
                 }
                 method_name: "some/package/compute_loss"
               }
               ...
             }
             </summary>
        </member>
        <member name="F:Tensorboard.SignatureDef.InputsFieldNumber">
            <summary>Field number for the "inputs" field.</summary>
        </member>
        <member name="P:Tensorboard.SignatureDef.Inputs">
            <summary>
            Named input parameters.
            </summary>
        </member>
        <member name="F:Tensorboard.SignatureDef.OutputsFieldNumber">
            <summary>Field number for the "outputs" field.</summary>
        </member>
        <member name="P:Tensorboard.SignatureDef.Outputs">
            <summary>
            Named output parameters.
            </summary>
        </member>
        <member name="F:Tensorboard.SignatureDef.MethodNameFieldNumber">
            <summary>Field number for the "method_name" field.</summary>
        </member>
        <member name="P:Tensorboard.SignatureDef.MethodName">
             <summary>
             Extensible method_name information enabling third-party users to mark a
             SignatureDef as supporting a particular method. This enables producers and
             consumers of SignatureDefs, e.g. a model definition library and a serving
             library to have a clear hand-off regarding the semantics of a computation.
            
             Note that multiple SignatureDefs in a single MetaGraphDef may have the same
             method_name. This is commonly used to support multi-headed computation,
             where a single graph computation may return multiple results.
             </summary>
        </member>
        <member name="T:Tensorboard.AssetFileDef">
            <summary>
            An asset file def for a single file or a set of sharded files with the same
            name.
            </summary>
        </member>
        <member name="F:Tensorboard.AssetFileDef.TensorInfoFieldNumber">
            <summary>Field number for the "tensor_info" field.</summary>
        </member>
        <member name="P:Tensorboard.AssetFileDef.TensorInfo">
            <summary>
            The tensor to bind the asset filename to.
            </summary>
        </member>
        <member name="F:Tensorboard.AssetFileDef.FilenameFieldNumber">
            <summary>Field number for the "filename" field.</summary>
        </member>
        <member name="P:Tensorboard.AssetFileDef.Filename">
            <summary>
            The filename within an assets directory. Note: does not include the path
            prefix, i.e. directories. For an asset at /tmp/path/vocab.txt, the filename
            would be "vocab.txt".
            </summary>
        </member>
        <member name="T:Tensorboard.NodeDefReflection">
            <summary>Holder for reflection information generated from tensorboard/compat/proto/node_def.proto</summary>
        </member>
        <member name="P:Tensorboard.NodeDefReflection.Descriptor">
            <summary>File descriptor for tensorboard/compat/proto/node_def.proto</summary>
        </member>
        <member name="F:Tensorboard.NodeDef.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="P:Tensorboard.NodeDef.Name">
            <summary>
            The name given to this operator. Used for naming inputs,
            logging, visualization, etc.  Unique within a single GraphDef.
            Must match the regexp "[A-Za-z0-9.][A-Za-z0-9_>./]*".
            </summary>
        </member>
        <member name="F:Tensorboard.NodeDef.OpFieldNumber">
            <summary>Field number for the "op" field.</summary>
        </member>
        <member name="P:Tensorboard.NodeDef.Op">
            <summary>
            The operation name.  There may be custom parameters in attrs.
            Op names starting with an underscore are reserved for internal use.
            </summary>
        </member>
        <member name="F:Tensorboard.NodeDef.InputFieldNumber">
            <summary>Field number for the "input" field.</summary>
        </member>
        <member name="P:Tensorboard.NodeDef.Input">
            <summary>
            Each input is "node:src_output" with "node" being a string name and
            "src_output" indicating which output tensor to use from "node". If
            "src_output" is 0 the ":0" suffix can be omitted.  Regular inputs
            may optionally be followed by control inputs that have the format
            "^node".
            </summary>
        </member>
        <member name="F:Tensorboard.NodeDef.DeviceFieldNumber">
            <summary>Field number for the "device" field.</summary>
        </member>
        <member name="P:Tensorboard.NodeDef.Device">
             <summary>
             A (possibly partial) specification for the device on which this
             node should be placed.
             The expected syntax for this string is as follows:
            
             DEVICE_SPEC ::= PARTIAL_SPEC
            
             PARTIAL_SPEC ::= ("/" CONSTRAINT) *
             CONSTRAINT ::= ("job:" JOB_NAME)
                          | ("replica:" [1-9][0-9]*)
                          | ("task:" [1-9][0-9]*)
                          | ("device:" [A-Za-z]* ":" ([1-9][0-9]* | "*") )
            
             Valid values for this string include:
             * "/job:worker/replica:0/task:1/device:GPU:3"  (full specification)
             * "/job:worker/device:GPU:3"                   (partial specification)
             * ""                                    (no specification)
            
             If the constraints do not resolve to a single device (or if this
             field is empty or not present), the runtime will attempt to
             choose a device automatically.
             </summary>
        </member>
        <member name="F:Tensorboard.NodeDef.AttrFieldNumber">
            <summary>Field number for the "attr" field.</summary>
        </member>
        <member name="P:Tensorboard.NodeDef.Attr">
            <summary>
            Operation-specific graph-construction-time configuration.
            Note that this should include all attrs defined in the
            corresponding OpDef, including those with a value matching
            the default -- this allows the default to change and makes
            NodeDefs easier to interpret on their own.  However, if
            an attr with a default is not specified in this list, the
            default will be used.
            The "names" (keys) must match the regexp "[a-z][a-z0-9_]+" (and
            one of the names from the corresponding OpDef's attr field).
            The values must have a type matching the corresponding OpDef
            attr's type field.
            TODO(josh11b): Add some examples here showing best practices.
            </summary>
        </member>
        <member name="F:Tensorboard.NodeDef.ExperimentalDebugInfoFieldNumber">
            <summary>Field number for the "experimental_debug_info" field.</summary>
        </member>
        <member name="P:Tensorboard.NodeDef.ExperimentalDebugInfo">
            <summary>
            This stores debug information associated with the node.
            </summary>
        </member>
        <member name="F:Tensorboard.NodeDef.ExperimentalTypeFieldNumber">
            <summary>Field number for the "experimental_type" field.</summary>
        </member>
        <member name="P:Tensorboard.NodeDef.ExperimentalType">
            <summary>
            The complete type of this node. Experimental and subject to change.
            Currently, the field only contains the return types of the node. That will
            extend in the future to contain the entire signature of the node, as a
            function type.
            </summary>
        </member>
        <member name="T:Tensorboard.NodeDef.Types">
            <summary>Container for nested types declared in the NodeDef message type.</summary>
        </member>
        <member name="F:Tensorboard.NodeDef.Types.ExperimentalDebugInfo.OriginalNodeNamesFieldNumber">
            <summary>Field number for the "original_node_names" field.</summary>
        </member>
        <member name="P:Tensorboard.NodeDef.Types.ExperimentalDebugInfo.OriginalNodeNames">
             <summary>
             Opaque string inserted into error messages created by the runtime.
            
             This is intended to store the list of names of the nodes from the
             original graph that this node was derived. For example if this node, say
             C, was result of a fusion of 2 nodes A and B, then 'original_node' would
             be {A, B}. This information can be used to map errors originating at the
             current node to some top level source code.
             </summary>
        </member>
        <member name="F:Tensorboard.NodeDef.Types.ExperimentalDebugInfo.OriginalFuncNamesFieldNumber">
            <summary>Field number for the "original_func_names" field.</summary>
        </member>
        <member name="P:Tensorboard.NodeDef.Types.ExperimentalDebugInfo.OriginalFuncNames">
            <summary>
            This is intended to store the list of names of the functions from the
            original graph that this node was derived. For example if this node, say
            C, was result of a fusion of node A in function FA and node B in function
            FB, then `original_funcs` would be {FA, FB}. If the node is in the top
            level graph, the `original_func` is empty. This information, with the
            `original_node_names` can be used to map errors originating at the
            current ndoe to some top level source code.
            </summary>
        </member>
        <member name="T:Tensorboard.OpDefReflection">
            <summary>Holder for reflection information generated from tensorboard/compat/proto/op_def.proto</summary>
        </member>
        <member name="P:Tensorboard.OpDefReflection.Descriptor">
            <summary>File descriptor for tensorboard/compat/proto/op_def.proto</summary>
        </member>
        <member name="T:Tensorboard.OpDef">
            <summary>
            Defines an operation. A NodeDef in a GraphDef specifies an Op by
            using the "op" field which should match the name of a OpDef.
            DISABLED.IfChange
            </summary>
        </member>
        <member name="F:Tensorboard.OpDef.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="P:Tensorboard.OpDef.Name">
            <summary>
            Op names starting with an underscore are reserved for internal use.
            Names should be CamelCase and match the regexp "[A-Z][a-zA-Z0-9>_]*".
            </summary>
        </member>
        <member name="F:Tensorboard.OpDef.InputArgFieldNumber">
            <summary>Field number for the "input_arg" field.</summary>
        </member>
        <member name="P:Tensorboard.OpDef.InputArg">
            <summary>
            Description of the input(s).
            </summary>
        </member>
        <member name="F:Tensorboard.OpDef.OutputArgFieldNumber">
            <summary>Field number for the "output_arg" field.</summary>
        </member>
        <member name="P:Tensorboard.OpDef.OutputArg">
            <summary>
            Description of the output(s).
            </summary>
        </member>
        <member name="F:Tensorboard.OpDef.ControlOutputFieldNumber">
            <summary>Field number for the "control_output" field.</summary>
        </member>
        <member name="P:Tensorboard.OpDef.ControlOutput">
            <summary>
            Named control outputs for this operation. Useful only for composite
            operations (i.e. functions) which want to name different control outputs.
            </summary>
        </member>
        <member name="F:Tensorboard.OpDef.AttrFieldNumber">
            <summary>Field number for the "attr" field.</summary>
        </member>
        <member name="F:Tensorboard.OpDef.DeprecationFieldNumber">
            <summary>Field number for the "deprecation" field.</summary>
        </member>
        <member name="P:Tensorboard.OpDef.Deprecation">
            <summary>
            Optional deprecation based on GraphDef versions.
            </summary>
        </member>
        <member name="F:Tensorboard.OpDef.SummaryFieldNumber">
            <summary>Field number for the "summary" field.</summary>
        </member>
        <member name="P:Tensorboard.OpDef.Summary">
            <summary>
            One-line human-readable description of what the Op does.
            </summary>
        </member>
        <member name="F:Tensorboard.OpDef.DescriptionFieldNumber">
            <summary>Field number for the "description" field.</summary>
        </member>
        <member name="P:Tensorboard.OpDef.Description">
            <summary>
            Additional, longer human-readable description of what the Op does.
            </summary>
        </member>
        <member name="F:Tensorboard.OpDef.IsCommutativeFieldNumber">
            <summary>Field number for the "is_commutative" field.</summary>
        </member>
        <member name="P:Tensorboard.OpDef.IsCommutative">
            <summary>
            True if the operation is commutative ("op(a,b) == op(b,a)" for all inputs)
            </summary>
        </member>
        <member name="F:Tensorboard.OpDef.IsAggregateFieldNumber">
            <summary>Field number for the "is_aggregate" field.</summary>
        </member>
        <member name="P:Tensorboard.OpDef.IsAggregate">
            <summary>
            If is_aggregate is true, then this operation accepts N >= 2
            inputs and produces 1 output all of the same type.  Should be
            associative and commutative, and produce output with the same
            shape as the input.  The optimizer may replace an aggregate op
            taking input from multiple devices with a tree of aggregate ops
            that aggregate locally within each device (and possibly within
            groups of nearby devices) before communicating.
            TODO(josh11b): Implement that optimization.
            </summary>
        </member>
        <member name="F:Tensorboard.OpDef.IsStatefulFieldNumber">
            <summary>Field number for the "is_stateful" field.</summary>
        </member>
        <member name="P:Tensorboard.OpDef.IsStateful">
             <summary>
             Ops are marked as stateful if their behavior depends on some state beyond
             their input tensors (e.g. variable reading op) or if they have
             a side-effect (e.g. printing or asserting ops). Equivalently, stateless ops
             must always produce the same output for the same input and have
             no side-effects.
            
             By default Ops may be moved between devices.  Stateful ops should
             either not be moved, or should only be moved if that state can also
             be moved (e.g. via some sort of save / restore).
             Stateful ops are guaranteed to never be optimized away by Common
             Subexpression Elimination (CSE).
             </summary>
        </member>
        <member name="F:Tensorboard.OpDef.AllowsUninitializedInputFieldNumber">
            <summary>Field number for the "allows_uninitialized_input" field.</summary>
        </member>
        <member name="P:Tensorboard.OpDef.AllowsUninitializedInput">
            <summary>
            By default, all inputs to an Op must be initialized Tensors.  Ops
            that may initialize tensors for the first time should set this
            field to true, to allow the Op to take an uninitialized Tensor as
            input.
            </summary>
        </member>
        <member name="F:Tensorboard.OpDef.IsDistributedCommunicationFieldNumber">
            <summary>Field number for the "is_distributed_communication" field.</summary>
        </member>
        <member name="P:Tensorboard.OpDef.IsDistributedCommunication">
            <summary>
            Indicates whether the op implementation uses distributed communication.
            If True, the op is allowed to return errors for network disconnection and
            trigger TF network failure handling logics.
            </summary>
        </member>
        <member name="T:Tensorboard.OpDef.Types">
            <summary>Container for nested types declared in the OpDef message type.</summary>
        </member>
        <member name="T:Tensorboard.OpDef.Types.ArgDef">
            <summary>
            For describing inputs and outputs.
            </summary>
        </member>
        <member name="F:Tensorboard.OpDef.Types.ArgDef.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="P:Tensorboard.OpDef.Types.ArgDef.Name">
            <summary>
            Name for the input/output.  Should match the regexp "[a-z][a-z0-9_]*".
            </summary>
        </member>
        <member name="F:Tensorboard.OpDef.Types.ArgDef.DescriptionFieldNumber">
            <summary>Field number for the "description" field.</summary>
        </member>
        <member name="P:Tensorboard.OpDef.Types.ArgDef.Description">
            <summary>
            Human readable description.
            </summary>
        </member>
        <member name="F:Tensorboard.OpDef.Types.ArgDef.TypeFieldNumber">
            <summary>Field number for the "type" field.</summary>
        </member>
        <member name="P:Tensorboard.OpDef.Types.ArgDef.Type">
            <summary>
            Describes the type of one or more tensors that are accepted/produced
            by this input/output arg.  The only legal combinations are:
            * For a single tensor: either the "type" field is set or the
              "type_attr" field is set to the name of an attr with type "type".
            * For a sequence of tensors with the same type: the "number_attr"
              field will be set to the name of an attr with type "int", and
              either the "type" or "type_attr" field will be set as for
              single tensors.
            * For a sequence of tensors, the "type_list_attr" field will be set
              to the name of an attr with type "list(type)".
            </summary>
        </member>
        <member name="F:Tensorboard.OpDef.Types.ArgDef.TypeAttrFieldNumber">
            <summary>Field number for the "type_attr" field.</summary>
        </member>
        <member name="P:Tensorboard.OpDef.Types.ArgDef.TypeAttr">
            <summary>
            if specified, attr must have type "type"
            </summary>
        </member>
        <member name="F:Tensorboard.OpDef.Types.ArgDef.NumberAttrFieldNumber">
            <summary>Field number for the "number_attr" field.</summary>
        </member>
        <member name="P:Tensorboard.OpDef.Types.ArgDef.NumberAttr">
            <summary>
            if specified, attr must have type "int"
            </summary>
        </member>
        <member name="F:Tensorboard.OpDef.Types.ArgDef.TypeListAttrFieldNumber">
            <summary>Field number for the "type_list_attr" field.</summary>
        </member>
        <member name="P:Tensorboard.OpDef.Types.ArgDef.TypeListAttr">
            <summary>
            If specified, attr must have type "list(type)", and none of
            type, type_attr, and number_attr may be specified.
            </summary>
        </member>
        <member name="F:Tensorboard.OpDef.Types.ArgDef.HandleDataFieldNumber">
            <summary>Field number for the "handle_data" field.</summary>
        </member>
        <member name="P:Tensorboard.OpDef.Types.ArgDef.HandleData">
            <summary>
            The handle data for resource inputs.
            </summary>
        </member>
        <member name="F:Tensorboard.OpDef.Types.ArgDef.IsRefFieldNumber">
            <summary>Field number for the "is_ref" field.</summary>
        </member>
        <member name="P:Tensorboard.OpDef.Types.ArgDef.IsRef">
            <summary>
            For inputs: if true, the inputs are required to be refs.
              By default, inputs can be either refs or non-refs.
            For outputs: if true, outputs are refs, otherwise they are not.
            </summary>
        </member>
        <member name="F:Tensorboard.OpDef.Types.ArgDef.ExperimentalFullTypeFieldNumber">
            <summary>Field number for the "experimental_full_type" field.</summary>
        </member>
        <member name="P:Tensorboard.OpDef.Types.ArgDef.ExperimentalFullType">
             <summary>
             Experimental. Full type declaration for this argument.
             The full type specification combines type, type_attr, type_list_attr,
             etc. into a unified representation.
             This declaration may contain non-concrete types (for example,
             Tensor&lt;TypeVar&lt;'T'>> is a valid type declaration.
            
             Note: this is a transient field. The long-term aim is to represent the
             entire OpDef as a single type: a callable. In that context, this field is
             just the type of a single argument.
             </summary>
        </member>
        <member name="T:Tensorboard.OpDef.Types.AttrDef">
            <summary>
            Description of the graph-construction-time configuration of this
            Op.  That is to say, this describes the attr fields that will
            be specified in the NodeDef.
            </summary>
        </member>
        <member name="F:Tensorboard.OpDef.Types.AttrDef.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="P:Tensorboard.OpDef.Types.AttrDef.Name">
            <summary>
            A descriptive name for the argument.  May be used, e.g. by the
            Python client, as a keyword argument name, and so should match
            the regexp "[a-z][a-z0-9_]+".
            </summary>
        </member>
        <member name="F:Tensorboard.OpDef.Types.AttrDef.TypeFieldNumber">
            <summary>Field number for the "type" field.</summary>
        </member>
        <member name="P:Tensorboard.OpDef.Types.AttrDef.Type">
            <summary>
            One of the type names from attr_value.proto ("string", "list(string)",
            "int", etc.).
            </summary>
        </member>
        <member name="F:Tensorboard.OpDef.Types.AttrDef.DefaultValueFieldNumber">
            <summary>Field number for the "default_value" field.</summary>
        </member>
        <member name="P:Tensorboard.OpDef.Types.AttrDef.DefaultValue">
            <summary>
            A reasonable default for this attribute if the user does not supply
            a value.  If not specified, the user must supply a value.
            </summary>
        </member>
        <member name="F:Tensorboard.OpDef.Types.AttrDef.DescriptionFieldNumber">
            <summary>Field number for the "description" field.</summary>
        </member>
        <member name="P:Tensorboard.OpDef.Types.AttrDef.Description">
            <summary>
            Human-readable description.
            </summary>
        </member>
        <member name="F:Tensorboard.OpDef.Types.AttrDef.HasMinimumFieldNumber">
            <summary>Field number for the "has_minimum" field.</summary>
        </member>
        <member name="P:Tensorboard.OpDef.Types.AttrDef.HasMinimum">
            <summary>
            For type == "int", this is a minimum value.  For "list(___)"
            types, this is the minimum length.
            </summary>
        </member>
        <member name="F:Tensorboard.OpDef.Types.AttrDef.MinimumFieldNumber">
            <summary>Field number for the "minimum" field.</summary>
        </member>
        <member name="F:Tensorboard.OpDef.Types.AttrDef.AllowedValuesFieldNumber">
            <summary>Field number for the "allowed_values" field.</summary>
        </member>
        <member name="P:Tensorboard.OpDef.Types.AttrDef.AllowedValues">
            <summary>
            The set of allowed values.  Has type that is the "list" version
            of the "type" field above (uses the "list" field of AttrValue).
            If type == "type" or "list(type)" above, then the "type" field
            of "allowed_values.list" has the set of allowed DataTypes.
            If type == "string" or "list(string)", then the "s" field of
            "allowed_values.list" has the set of allowed strings.
            </summary>
        </member>
        <member name="T:Tensorboard.OpDeprecation">
            <summary>
            Information about version-dependent deprecation of an op
            </summary>
        </member>
        <member name="F:Tensorboard.OpDeprecation.VersionFieldNumber">
            <summary>Field number for the "version" field.</summary>
        </member>
        <member name="P:Tensorboard.OpDeprecation.Version">
            <summary>
            First GraphDef version at which the op is disallowed.
            </summary>
        </member>
        <member name="F:Tensorboard.OpDeprecation.ExplanationFieldNumber">
            <summary>Field number for the "explanation" field.</summary>
        </member>
        <member name="P:Tensorboard.OpDeprecation.Explanation">
            <summary>
            Explanation of why it was deprecated and what to use instead.
            </summary>
        </member>
        <member name="T:Tensorboard.OpList">
            <summary>
            A collection of OpDefs
            </summary>
        </member>
        <member name="F:Tensorboard.OpList.OpFieldNumber">
            <summary>Field number for the "op" field.</summary>
        </member>
        <member name="T:Tensorboard.ResourceHandleReflection">
            <summary>Holder for reflection information generated from tensorboard/compat/proto/resource_handle.proto</summary>
        </member>
        <member name="P:Tensorboard.ResourceHandleReflection.Descriptor">
            <summary>File descriptor for tensorboard/compat/proto/resource_handle.proto</summary>
        </member>
        <member name="T:Tensorboard.ResourceHandleProto">
            <summary>
            Protocol buffer representing a handle to a tensorflow resource. Handles are
            not valid across executions, but can be serialized back and forth from within
            a single run.
            </summary>
        </member>
        <member name="F:Tensorboard.ResourceHandleProto.DeviceFieldNumber">
            <summary>Field number for the "device" field.</summary>
        </member>
        <member name="P:Tensorboard.ResourceHandleProto.Device">
            <summary>
            Unique name for the device containing the resource.
            </summary>
        </member>
        <member name="F:Tensorboard.ResourceHandleProto.ContainerFieldNumber">
            <summary>Field number for the "container" field.</summary>
        </member>
        <member name="P:Tensorboard.ResourceHandleProto.Container">
            <summary>
            Container in which this resource is placed.
            </summary>
        </member>
        <member name="F:Tensorboard.ResourceHandleProto.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="P:Tensorboard.ResourceHandleProto.Name">
            <summary>
            Unique name of this resource.
            </summary>
        </member>
        <member name="F:Tensorboard.ResourceHandleProto.HashCodeFieldNumber">
            <summary>Field number for the "hash_code" field.</summary>
        </member>
        <member name="P:Tensorboard.ResourceHandleProto.HashCode">
            <summary>
            Hash code for the type of the resource. Is only valid in the same device
            and in the same execution.
            </summary>
        </member>
        <member name="F:Tensorboard.ResourceHandleProto.MaybeTypeNameFieldNumber">
            <summary>Field number for the "maybe_type_name" field.</summary>
        </member>
        <member name="P:Tensorboard.ResourceHandleProto.MaybeTypeName">
            <summary>
            For debug-only, the name of the type pointed to by this handle, if
            available.
            </summary>
        </member>
        <member name="F:Tensorboard.ResourceHandleProto.DtypesAndShapesFieldNumber">
            <summary>Field number for the "dtypes_and_shapes" field.</summary>
        </member>
        <member name="P:Tensorboard.ResourceHandleProto.DtypesAndShapes">
            <summary>
            Data types and shapes for the underlying resource.
            </summary>
        </member>
        <member name="T:Tensorboard.ResourceHandleProto.Types">
            <summary>Container for nested types declared in the ResourceHandleProto message type.</summary>
        </member>
        <member name="T:Tensorboard.ResourceHandleProto.Types.DtypeAndShape">
            <summary>
            Protocol buffer representing a pair of (data type, tensor shape).
            </summary>
        </member>
        <member name="F:Tensorboard.ResourceHandleProto.Types.DtypeAndShape.DtypeFieldNumber">
            <summary>Field number for the "dtype" field.</summary>
        </member>
        <member name="F:Tensorboard.ResourceHandleProto.Types.DtypeAndShape.ShapeFieldNumber">
            <summary>Field number for the "shape" field.</summary>
        </member>
        <member name="T:Tensorboard.RewriterConfigReflection">
            <summary>Holder for reflection information generated from tensorboard/compat/proto/rewriter_config.proto</summary>
        </member>
        <member name="P:Tensorboard.RewriterConfigReflection.Descriptor">
            <summary>File descriptor for tensorboard/compat/proto/rewriter_config.proto</summary>
        </member>
        <member name="F:Tensorboard.AutoParallelOptions.EnableFieldNumber">
            <summary>Field number for the "enable" field.</summary>
        </member>
        <member name="F:Tensorboard.AutoParallelOptions.NumReplicasFieldNumber">
            <summary>Field number for the "num_replicas" field.</summary>
        </member>
        <member name="F:Tensorboard.ScopedAllocatorOptions.EnableOpFieldNumber">
            <summary>Field number for the "enable_op" field.</summary>
        </member>
        <member name="P:Tensorboard.ScopedAllocatorOptions.EnableOp">
            <summary>
            If present, only perform optimization for these ops.
            </summary>
        </member>
        <member name="T:Tensorboard.RewriterConfig">
            <summary>
            Graph rewriting is experimental and subject to change, not covered by any
            API stability guarantees.
            </summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.CpuLayoutConversionFieldNumber">
            <summary>Field number for the "cpu_layout_conversion" field.</summary>
        </member>
        <member name="P:Tensorboard.RewriterConfig.CpuLayoutConversion">
            <summary>
            CPU Conversion settings between NHCW and NCHW.
            </summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.LayoutOptimizerFieldNumber">
            <summary>Field number for the "layout_optimizer" field.</summary>
        </member>
        <member name="P:Tensorboard.RewriterConfig.LayoutOptimizer">
            <summary>
            Optimize tensor layouts (default is ON)
            e.g. This will try to use NCHW layout on GPU which is faster.
            </summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.ConstantFoldingFieldNumber">
            <summary>Field number for the "constant_folding" field.</summary>
        </member>
        <member name="P:Tensorboard.RewriterConfig.ConstantFolding">
            <summary>
            Fold constants (default is ON)
            Statically infer the value of tensors when possible, and materialize the
            result using constants.
            </summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.ShapeOptimizationFieldNumber">
            <summary>Field number for the "shape_optimization" field.</summary>
        </member>
        <member name="P:Tensorboard.RewriterConfig.ShapeOptimization">
            <summary>
            Shape optimizations (default is ON)
            Simplify computations made on shapes.
            </summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.RemappingFieldNumber">
            <summary>Field number for the "remapping" field.</summary>
        </member>
        <member name="P:Tensorboard.RewriterConfig.Remapping">
            <summary>
            Remapping (default is ON)
            Remap subgraphs onto more efficient implementations.
            </summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.CommonSubgraphEliminationFieldNumber">
            <summary>Field number for the "common_subgraph_elimination" field.</summary>
        </member>
        <member name="P:Tensorboard.RewriterConfig.CommonSubgraphElimination">
            <summary>
            Common subgraph elimination (default is ON)
            e.g. Simplify arithmetic ops; merge ops with same value (like constants).
            </summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.ArithmeticOptimizationFieldNumber">
            <summary>Field number for the "arithmetic_optimization" field.</summary>
        </member>
        <member name="P:Tensorboard.RewriterConfig.ArithmeticOptimization">
            <summary>
            Arithmetic optimizations (default is ON)
            e.g. Simplify arithmetic ops; merge ops with same value (like constants).
            </summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.DependencyOptimizationFieldNumber">
            <summary>Field number for the "dependency_optimization" field.</summary>
        </member>
        <member name="P:Tensorboard.RewriterConfig.DependencyOptimization">
            <summary>
            Control dependency optimizations (default is ON).
            Remove redundant control dependencies, which may enable other optimization.
            </summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.LoopOptimizationFieldNumber">
            <summary>Field number for the "loop_optimization" field.</summary>
        </member>
        <member name="P:Tensorboard.RewriterConfig.LoopOptimization">
            <summary>
            Loop optimizations (default is ON).
            </summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.FunctionOptimizationFieldNumber">
            <summary>Field number for the "function_optimization" field.</summary>
        </member>
        <member name="P:Tensorboard.RewriterConfig.FunctionOptimization">
            <summary>
            Function optimizations (default is ON).
            </summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.DebugStripperFieldNumber">
            <summary>Field number for the "debug_stripper" field.</summary>
        </member>
        <member name="P:Tensorboard.RewriterConfig.DebugStripper">
            <summary>
            Strips debug-related nodes from the graph (off by default).
            </summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.DisableModelPruningFieldNumber">
            <summary>Field number for the "disable_model_pruning" field.</summary>
        </member>
        <member name="P:Tensorboard.RewriterConfig.DisableModelPruning">
            <summary>
            If true, don't remove unnecessary ops from the graph
            </summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.ScopedAllocatorOptimizationFieldNumber">
            <summary>Field number for the "scoped_allocator_optimization" field.</summary>
        </member>
        <member name="P:Tensorboard.RewriterConfig.ScopedAllocatorOptimization">
            <summary>
            Try to allocate some independent Op outputs contiguously in order to
            merge or eliminate downstream Ops (off by default).
            </summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.PinToHostOptimizationFieldNumber">
            <summary>Field number for the "pin_to_host_optimization" field.</summary>
        </member>
        <member name="P:Tensorboard.RewriterConfig.PinToHostOptimization">
            <summary>
            Force small ops onto the CPU (default is OFF).
            </summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.ImplementationSelectorFieldNumber">
            <summary>Field number for the "implementation_selector" field.</summary>
        </member>
        <member name="P:Tensorboard.RewriterConfig.ImplementationSelector">
            <summary>
            Enable the swap of kernel implementations based on the device placement
            (default is ON).
            </summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.AutoMixedPrecisionFieldNumber">
            <summary>Field number for the "auto_mixed_precision" field.</summary>
        </member>
        <member name="P:Tensorboard.RewriterConfig.AutoMixedPrecision">
            <summary>
            Optimize data types for CUDA (default is OFF).
            This will try to use float16 on GPU which is faster.
            Note that this can change the numerical stability of the graph and may
            require the use of loss scaling to maintain model convergence.
            </summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.AutoMixedPrecisionMklFieldNumber">
            <summary>Field number for the "auto_mixed_precision_mkl" field.</summary>
        </member>
        <member name="P:Tensorboard.RewriterConfig.AutoMixedPrecisionMkl">
            <summary>
            Optimize data types for MKL (default is OFF).
            This will try to use bfloat16 on CPUs, which is faster.
            Note that this can change the numerical stability of the graph.
            </summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.AutoMixedPrecisionCpuFieldNumber">
            <summary>Field number for the "auto_mixed_precision_cpu" field.</summary>
        </member>
        <member name="P:Tensorboard.RewriterConfig.AutoMixedPrecisionCpu">
            <summary>
            Emulate a model using data type float16 on CPU (default is OFF).
            This will try to emulate the float16 inputs and outputs of an operator
            on CPU to have better correlation with float16 on GPU; however the
            computation in the operator is based on float32.
            Note that this can change the numerical stability of the graph.
            </summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.DisableMetaOptimizerFieldNumber">
            <summary>Field number for the "disable_meta_optimizer" field.</summary>
        </member>
        <member name="P:Tensorboard.RewriterConfig.DisableMetaOptimizer">
            <summary>
            Disable the entire meta optimizer (off by default).
            </summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.UsePluginOptimizersFieldNumber">
            <summary>Field number for the "use_plugin_optimizers" field.</summary>
        </member>
        <member name="P:Tensorboard.RewriterConfig.UsePluginOptimizers">
            <summary>
            Optimizers registered by plugin (default is ON)
            </summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.MetaOptimizerIterationsFieldNumber">
            <summary>Field number for the "meta_optimizer_iterations" field.</summary>
        </member>
        <member name="P:Tensorboard.RewriterConfig.MetaOptimizerIterations">
            <summary>
            Controls how many times we run the optimizers in meta optimizer (default
            is once).
            </summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.MinGraphNodesFieldNumber">
            <summary>Field number for the "min_graph_nodes" field.</summary>
        </member>
        <member name="P:Tensorboard.RewriterConfig.MinGraphNodes">
            <summary>
            The minimum number of nodes in a graph to optimizer. For smaller graphs,
            optimization is skipped.
            0 means the system picks an appropriate number.
            &lt; 0 means do not skip optimization.
            </summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.ExperimentalDisableCompressedTensorOptimizationFieldNumber">
            <summary>Field number for the "experimental_disable_compressed_tensor_optimization" field.</summary>
        </member>
        <member name="P:Tensorboard.RewriterConfig.ExperimentalDisableCompressedTensorOptimization">
            <summary>
            Disable optimizations that assume compressed tensors. Note that this flag
            is experimental and may be removed in the future.
            </summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.ExperimentalDisableFoldingQuantizationEmulationFieldNumber">
            <summary>Field number for the "experimental_disable_folding_quantization_emulation" field.</summary>
        </member>
        <member name="P:Tensorboard.RewriterConfig.ExperimentalDisableFoldingQuantizationEmulation">
            <summary>
            Disable folding quantization emulation ops such as FakeQuantWithMinMax* and
            QuantizeAndDequantize*. Some compilers (e.g. the TF-to-tflite converter)
            have to extract quantization configs (e.g. min/max range, number of bits,
            and per-channel) from the quantization emulation ops. Note that this flag
            is experimental and may be removed in the future. See b/174138564 for more
            details.
            </summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.MemoryOptimizationFieldNumber">
            <summary>Field number for the "memory_optimization" field.</summary>
        </member>
        <member name="P:Tensorboard.RewriterConfig.MemoryOptimization">
            <summary>
            Configures memory optimization passes through the meta-optimizer. Has no
            effect on manually requested memory optimization passes in the optimizers
            field.
            </summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.MemoryOptimizerTargetNodeNameScopeFieldNumber">
            <summary>Field number for the "memory_optimizer_target_node_name_scope" field.</summary>
        </member>
        <member name="P:Tensorboard.RewriterConfig.MemoryOptimizerTargetNodeNameScope">
            <summary>
            A node name scope for node names which are valid outputs of recomputations.
            Inputs to nodes that match this scope may be recomputed (subject either to
            manual annotation of those input nodes or to manual annotation and
            heuristics depending on memory_optimization), but the nodes themselves will
            not be recomputed. This matches any sub-scopes as well, meaning the scope
            can appear not just as a top-level scope. For example, if the value is
            "gradients/", the default, it will match node name "gradients/foo",
            "foo/gradients/bar", but not "foo_gradients/"
            </summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.MetaOptimizerTimeoutMsFieldNumber">
            <summary>Field number for the "meta_optimizer_timeout_ms" field.</summary>
        </member>
        <member name="P:Tensorboard.RewriterConfig.MetaOptimizerTimeoutMs">
            <summary>
            Maximum number of milliseconds to spend optimizing a single graph before
            timing out. If less than or equal to 0 (default value) the optimizer will
            never time out.
            </summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.AutoParallelFieldNumber">
            <summary>Field number for the "auto_parallel" field.</summary>
        </member>
        <member name="P:Tensorboard.RewriterConfig.AutoParallel">
            <summary>
            Configures AutoParallel optimization passes either through the
            meta-optimizer or when manually specified through the optimizers field.
            </summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.FailOnOptimizerErrorsFieldNumber">
            <summary>Field number for the "fail_on_optimizer_errors" field.</summary>
        </member>
        <member name="P:Tensorboard.RewriterConfig.FailOnOptimizerErrors">
            <summary>
            If true, any optimization pass failing will cause the MetaOptimizer to
            stop with an error. By default - or when set to false, failing passes are
            skipped silently.
            </summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.ScopedAllocatorOptsFieldNumber">
            <summary>Field number for the "scoped_allocator_opts" field.</summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.OptimizersFieldNumber">
            <summary>Field number for the "optimizers" field.</summary>
        </member>
        <member name="P:Tensorboard.RewriterConfig.Optimizers">
             <summary>
             If non-empty, will use this as an alternative way to specify a list of
             optimizations to turn on and the order of the optimizations (replacing the
             meta-optimizer).
            
             Of the RewriterConfig options, only the AutoParallel configuration options
             (the auto_parallel field) apply to manually requested optimization passes
             ("autoparallel"). Memory optimization passes ("memory") invoked here are
             not configurable (in contrast to memory optimization passes through the
             meta-optimizer) and act only on manual op annotations.
            
             Custom optimizers (see custom_optimizers) that are not part of this
             schedule will be run after - in the order that they were specified.
             </summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.CustomOptimizersFieldNumber">
            <summary>Field number for the "custom_optimizers" field.</summary>
        </member>
        <member name="P:Tensorboard.RewriterConfig.CustomOptimizers">
            <summary>
            list of CustomGraphOptimizers to apply.
            </summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.InterOptimizerVerifierConfigFieldNumber">
            <summary>Field number for the "inter_optimizer_verifier_config" field.</summary>
        </member>
        <member name="P:Tensorboard.RewriterConfig.InterOptimizerVerifierConfig">
            <summary>
            VerifierConfig specifying the verifiers to be run after every optimizer.
            </summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.PostOptimizationVerifierConfigFieldNumber">
            <summary>Field number for the "post_optimization_verifier_config" field.</summary>
        </member>
        <member name="P:Tensorboard.RewriterConfig.PostOptimizationVerifierConfig">
            <summary>
            VerifierConfig specifying the verifiers to be run at the end, after all
            optimizers have run.
            </summary>
        </member>
        <member name="T:Tensorboard.RewriterConfig.Types">
            <summary>Container for nested types declared in the RewriterConfig message type.</summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.Types.Toggle.Aggressive">
            <summary>
            Enable some aggressive optimizations that use assumptions that TF graphs
            may break. For example, assume the shape of a placeholder matches its
            actual feed.
            </summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.Types.Toggle.ExperimentalMlir">
            <summary>
            Run MLIR pass if there's one implemented in TFG, do nothing otherwise.
            I.e., if there's no corresponding TFG pass, it's an OFF. This is supposed
            to be mapped with `ON` and there's no `AGGRESSIVE` in MLIR pass now.
            </summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.Types.Toggle.ExperimentalBoth">
            <summary>
            Run both MLIR and Grappler passes consecutively and MLIR pass will come
            first.
            </summary>
        </member>
        <member name="T:Tensorboard.RewriterConfig.Types.CpuLayout">
            <summary>
            Enum for layout conversion between NCHW and NHWC on CPU. Default is OFF.
            </summary>
        </member>
        <member name="T:Tensorboard.RewriterConfig.Types.NumIterationsType">
            <summary>
            Enum controlling the number of times to run optimizers. The default is to
            run them twice.
            </summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.Types.MemOptType.DefaultMemOpt">
            <summary>
            The default setting (SCHEDULING and SWAPPING HEURISTICS only)
            </summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.Types.MemOptType.NoMemOpt">
            <summary>
            Disabled in the meta-optimizer.
            </summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.Types.MemOptType.Manual">
            <summary>
            Driven by manual op-level annotations.
            </summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.Types.MemOptType.SwappingHeuristics">
            <summary>
            Swapping heuristic will move a tensor from the GPU to the CPU and move
            it back when needed to reduce peak memory usage.
            </summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.Types.MemOptType.RecomputationHeuristics">
            <summary>
            Recomputation heuristics will recompute ops (such as Relu activation)
            during backprop instead of storing them, reducing peak memory usage.
            </summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.Types.MemOptType.SchedulingHeuristics">
            <summary>
            Scheduling will split big ops such as AddN and try to enforce a schedule
            of the new computations that decreases peak memory usage.
            </summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.Types.MemOptType.Heuristics">
            <summary>
            Use any combination of swapping and recomputation heuristics.
            </summary>
        </member>
        <member name="T:Tensorboard.RewriterConfig.Types.CustomGraphOptimizer">
            <summary>
            Message to describe custom graph optimizer and its parameters
            </summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.Types.CustomGraphOptimizer.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="F:Tensorboard.RewriterConfig.Types.CustomGraphOptimizer.ParameterMapFieldNumber">
            <summary>Field number for the "parameter_map" field.</summary>
        </member>
        <member name="T:Tensorboard.SavedObjectGraphReflection">
            <summary>Holder for reflection information generated from tensorboard/compat/proto/saved_object_graph.proto</summary>
        </member>
        <member name="P:Tensorboard.SavedObjectGraphReflection.Descriptor">
            <summary>File descriptor for tensorboard/compat/proto/saved_object_graph.proto</summary>
        </member>
        <member name="F:Tensorboard.SavedObjectGraph.NodesFieldNumber">
            <summary>Field number for the "nodes" field.</summary>
        </member>
        <member name="P:Tensorboard.SavedObjectGraph.Nodes">
             <summary>
             Flattened list of objects in the object graph.
            
             The position of the object in this list indicates its id.
             Nodes[0] is considered the root node.
             </summary>
        </member>
        <member name="F:Tensorboard.SavedObjectGraph.ConcreteFunctionsFieldNumber">
            <summary>Field number for the "concrete_functions" field.</summary>
        </member>
        <member name="P:Tensorboard.SavedObjectGraph.ConcreteFunctions">
            <summary>
            Information about captures and output structures in concrete functions.
            Referenced from SavedBareConcreteFunction and SavedFunction.
            </summary>
        </member>
        <member name="F:Tensorboard.SavedObject.ChildrenFieldNumber">
            <summary>Field number for the "children" field.</summary>
        </member>
        <member name="P:Tensorboard.SavedObject.Children">
             <summary>
             Objects which this object depends on: named edges in the dependency
             graph.
            
             Note: All kinds of SavedObject may have children, except
             "constant" and "captured_tensor".
             </summary>
        </member>
        <member name="F:Tensorboard.SavedObject.DependenciesFieldNumber">
            <summary>Field number for the "dependencies" field.</summary>
        </member>
        <member name="P:Tensorboard.SavedObject.Dependencies">
            <summary>
            Ordered list of dependencies that must be loaded before this object.
            SavedModel loads with the bottom-up approach, by first creating all objects
            (in the order defined by the dependencies), then connecting the edges.
            </summary>
        </member>
        <member name="F:Tensorboard.SavedObject.SlotVariablesFieldNumber">
            <summary>Field number for the "slot_variables" field.</summary>
        </member>
        <member name="P:Tensorboard.SavedObject.SlotVariables">
             <summary>
             Slot variables owned by this object. This describes the three-way
             (optimizer, variable, slot variable) relationship; none of the three
             depend on the others directly.
            
             Note: currently only valid if kind == "user_object".
             </summary>
        </member>
        <member name="F:Tensorboard.SavedObject.UserObjectFieldNumber">
            <summary>Field number for the "user_object" field.</summary>
        </member>
        <member name="F:Tensorboard.SavedObject.AssetFieldNumber">
            <summary>Field number for the "asset" field.</summary>
        </member>
        <member name="F:Tensorboard.SavedObject.FunctionFieldNumber">
            <summary>Field number for the "function" field.</summary>
        </member>
        <member name="F:Tensorboard.SavedObject.VariableFieldNumber">
            <summary>Field number for the "variable" field.</summary>
        </member>
        <member name="F:Tensorboard.SavedObject.BareConcreteFunctionFieldNumber">
            <summary>Field number for the "bare_concrete_function" field.</summary>
        </member>
        <member name="F:Tensorboard.SavedObject.ConstantFieldNumber">
            <summary>Field number for the "constant" field.</summary>
        </member>
        <member name="F:Tensorboard.SavedObject.ResourceFieldNumber">
            <summary>Field number for the "resource" field.</summary>
        </member>
        <member name="F:Tensorboard.SavedObject.CapturedTensorFieldNumber">
            <summary>Field number for the "captured_tensor" field.</summary>
        </member>
        <member name="F:Tensorboard.SavedObject.SaveableObjectsFieldNumber">
            <summary>Field number for the "saveable_objects" field.</summary>
        </member>
        <member name="P:Tensorboard.SavedObject.SaveableObjects">
            <summary>
            Stores the functions used to save and restore this object. At most one of
            `saveable_objects` or `registered_saver` is defined for each SavedObject.
            See the comment below for the difference between SaveableObject and
            registered savers.
            </summary>
        </member>
        <member name="F:Tensorboard.SavedObject.RegisteredNameFieldNumber">
            <summary>Field number for the "registered_name" field.</summary>
        </member>
        <member name="P:Tensorboard.SavedObject.RegisteredName">
            <summary>
            The name of the registered class of the form "{package}.{class_name}".
            This field is used to search for the registered class at loading time.
            </summary>
        </member>
        <member name="F:Tensorboard.SavedObject.SerializedUserProtoFieldNumber">
            <summary>Field number for the "serialized_user_proto" field.</summary>
        </member>
        <member name="P:Tensorboard.SavedObject.SerializedUserProto">
            <summary>
            The user-generated proto storing metadata for this object, to be passed to
            the registered classes's _deserialize_from_proto method when this object is
            loaded from the SavedModel.
            </summary>
        </member>
        <member name="F:Tensorboard.SavedObject.RegisteredSaverFieldNumber">
            <summary>Field number for the "registered_saver" field.</summary>
        </member>
        <member name="P:Tensorboard.SavedObject.RegisteredSaver">
            <summary>
            String name of the registered saver. At most one of `saveable_objects` or
            `registered_saver` is defined for each SavedObject.
            </summary>
        </member>
        <member name="T:Tensorboard.SavedObject.KindOneofCase">
            <summary>Enum of possible cases for the "kind" oneof.</summary>
        </member>
        <member name="T:Tensorboard.SavedUserObject">
             <summary>
             A SavedUserObject is an object (in the object-oriented language of the
             TensorFlow program) of some user- or framework-defined class other than
             those handled specifically by the other kinds of SavedObjects.
            
             This object cannot be evaluated as a tensor, and therefore cannot be bound
             to an input of a function.
             </summary>
        </member>
        <member name="F:Tensorboard.SavedUserObject.IdentifierFieldNumber">
            <summary>Field number for the "identifier" field.</summary>
        </member>
        <member name="P:Tensorboard.SavedUserObject.Identifier">
            <summary>
            Corresponds to a registration of the type to use in the loading program.
            </summary>
        </member>
        <member name="F:Tensorboard.SavedUserObject.VersionFieldNumber">
            <summary>Field number for the "version" field.</summary>
        </member>
        <member name="P:Tensorboard.SavedUserObject.Version">
            <summary>
            Version information from the producer of this SavedUserObject.
            </summary>
        </member>
        <member name="F:Tensorboard.SavedUserObject.MetadataFieldNumber">
            <summary>Field number for the "metadata" field.</summary>
        </member>
        <member name="P:Tensorboard.SavedUserObject.Metadata">
             <summary>
             Metadata for deserializing this object.
            
             Deprecated! At the time of deprecation, Keras was the only user of this
             field, and its saving and loading code will be updated shortly.
             Please save your application-specific metadata to a separate file.
             </summary>
        </member>
        <member name="T:Tensorboard.SavedAsset">
             <summary>
             A SavedAsset points to an asset in the MetaGraph.
            
             When bound to a function this object evaluates to a tensor with the absolute
             filename. Users should not depend on a particular part of the filename to
             remain stable (e.g. basename could be changed).
             </summary>
        </member>
        <member name="F:Tensorboard.SavedAsset.AssetFileDefIndexFieldNumber">
            <summary>Field number for the "asset_file_def_index" field.</summary>
        </member>
        <member name="P:Tensorboard.SavedAsset.AssetFileDefIndex">
             <summary>
             Index into `MetaGraphDef.asset_file_def[]` that describes the Asset.
            
             Only the field `AssetFileDef.filename` is used. Other fields, such as
             `AssetFileDef.tensor_info`, MUST be ignored.
             </summary>
        </member>
        <member name="T:Tensorboard.SavedFunction">
            <summary>
            A function with multiple signatures, possibly with non-Tensor arguments.
            </summary>
        </member>
        <member name="F:Tensorboard.SavedFunction.ConcreteFunctionsFieldNumber">
            <summary>Field number for the "concrete_functions" field.</summary>
        </member>
        <member name="F:Tensorboard.SavedFunction.FunctionSpecFieldNumber">
            <summary>Field number for the "function_spec" field.</summary>
        </member>
        <member name="F:Tensorboard.CapturedTensor.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="P:Tensorboard.CapturedTensor.Name">
            <summary>
            Name of captured tensor
            </summary>
        </member>
        <member name="F:Tensorboard.CapturedTensor.ConcreteFunctionFieldNumber">
            <summary>Field number for the "concrete_function" field.</summary>
        </member>
        <member name="P:Tensorboard.CapturedTensor.ConcreteFunction">
            <summary>
            Name of concrete function which contains the computed graph tensor.
            </summary>
        </member>
        <member name="T:Tensorboard.SavedConcreteFunction">
            <summary>
            Stores low-level information about a concrete function. Referenced in either
            a SavedFunction or a SavedBareConcreteFunction.
            </summary>
        </member>
        <member name="F:Tensorboard.SavedConcreteFunction.BoundInputsFieldNumber">
            <summary>Field number for the "bound_inputs" field.</summary>
        </member>
        <member name="F:Tensorboard.SavedConcreteFunction.CanonicalizedInputSignatureFieldNumber">
            <summary>Field number for the "canonicalized_input_signature" field.</summary>
        </member>
        <member name="P:Tensorboard.SavedConcreteFunction.CanonicalizedInputSignature">
            <summary>
            Input in canonicalized form that was received to create this concrete
            function.
            </summary>
        </member>
        <member name="F:Tensorboard.SavedConcreteFunction.OutputSignatureFieldNumber">
            <summary>Field number for the "output_signature" field.</summary>
        </member>
        <member name="P:Tensorboard.SavedConcreteFunction.OutputSignature">
            <summary>
            Output that was the return value of this function after replacing all
            Tensors with TensorSpecs. This can be an arbitrary nested function and will
            be used to reconstruct the full structure from pure tensors.
            </summary>
        </member>
        <member name="F:Tensorboard.SavedBareConcreteFunction.ConcreteFunctionNameFieldNumber">
            <summary>Field number for the "concrete_function_name" field.</summary>
        </member>
        <member name="P:Tensorboard.SavedBareConcreteFunction.ConcreteFunctionName">
            <summary>
            Identifies a SavedConcreteFunction.
            </summary>
        </member>
        <member name="F:Tensorboard.SavedBareConcreteFunction.ArgumentKeywordsFieldNumber">
            <summary>Field number for the "argument_keywords" field.</summary>
        </member>
        <member name="P:Tensorboard.SavedBareConcreteFunction.ArgumentKeywords">
            <summary>
            A sequence of unique strings, one per Tensor argument.
            </summary>
        </member>
        <member name="F:Tensorboard.SavedBareConcreteFunction.AllowedPositionalArgumentsFieldNumber">
            <summary>Field number for the "allowed_positional_arguments" field.</summary>
        </member>
        <member name="P:Tensorboard.SavedBareConcreteFunction.AllowedPositionalArguments">
            <summary>
            The prefix of `argument_keywords` which may be identified by position.
            </summary>
        </member>
        <member name="F:Tensorboard.SavedBareConcreteFunction.FunctionSpecFieldNumber">
            <summary>Field number for the "function_spec" field.</summary>
        </member>
        <member name="P:Tensorboard.SavedBareConcreteFunction.FunctionSpec">
            <summary>
            The spec of the function that this ConcreteFunction is traced from. This
            allows the ConcreteFunction to be called with nest structure inputs. This
            field may not be populated. If this field is absent, the concrete function
            can only be called with flat inputs.
            TODO(b/169361281): support calling saved ConcreteFunction with structured
            inputs in C++ SavedModel API.
            </summary>
        </member>
        <member name="F:Tensorboard.SavedConstant.OperationFieldNumber">
            <summary>Field number for the "operation" field.</summary>
        </member>
        <member name="P:Tensorboard.SavedConstant.Operation">
            <summary>
            An Operation name for a ConstantOp in this SavedObjectGraph's MetaGraph.
            </summary>
        </member>
        <member name="T:Tensorboard.SavedVariable">
            <summary>
            Represents a Variable that is initialized by loading the contents from the
            checkpoint.
            </summary>
        </member>
        <member name="F:Tensorboard.SavedVariable.DtypeFieldNumber">
            <summary>Field number for the "dtype" field.</summary>
        </member>
        <member name="F:Tensorboard.SavedVariable.ShapeFieldNumber">
            <summary>Field number for the "shape" field.</summary>
        </member>
        <member name="F:Tensorboard.SavedVariable.TrainableFieldNumber">
            <summary>Field number for the "trainable" field.</summary>
        </member>
        <member name="F:Tensorboard.SavedVariable.SynchronizationFieldNumber">
            <summary>Field number for the "synchronization" field.</summary>
        </member>
        <member name="F:Tensorboard.SavedVariable.AggregationFieldNumber">
            <summary>Field number for the "aggregation" field.</summary>
        </member>
        <member name="F:Tensorboard.SavedVariable.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="F:Tensorboard.SavedVariable.DeviceFieldNumber">
            <summary>Field number for the "device" field.</summary>
        </member>
        <member name="F:Tensorboard.SavedVariable.ExperimentalDistributedVariableComponentsFieldNumber">
            <summary>Field number for the "experimental_distributed_variable_components" field.</summary>
        </member>
        <member name="P:Tensorboard.SavedVariable.ExperimentalDistributedVariableComponents">
             <summary>
             List of component variables for a distributed variable.
            
             When this field is non-empty, the SavedVariable will be assumed
             to be a distributed variable defined by the components listed here.
            
             This is only supported by experimental loaders at the moment.
             </summary>
        </member>
        <member name="T:Tensorboard.FunctionSpec">
            <summary>
            Represents `FunctionSpec` used in `Function`. This represents a
            function that has been wrapped as a TensorFlow `Function`.
            </summary>
        </member>
        <member name="F:Tensorboard.FunctionSpec.FullargspecFieldNumber">
            <summary>Field number for the "fullargspec" field.</summary>
        </member>
        <member name="P:Tensorboard.FunctionSpec.Fullargspec">
            <summary>
            Full arg spec from inspect.getfullargspec().
            </summary>
        </member>
        <member name="F:Tensorboard.FunctionSpec.IsMethodFieldNumber">
            <summary>Field number for the "is_method" field.</summary>
        </member>
        <member name="P:Tensorboard.FunctionSpec.IsMethod">
            <summary>
            Whether this represents a class method.
            </summary>
        </member>
        <member name="F:Tensorboard.FunctionSpec.InputSignatureFieldNumber">
            <summary>Field number for the "input_signature" field.</summary>
        </member>
        <member name="P:Tensorboard.FunctionSpec.InputSignature">
            <summary>
            The input signature, if specified.
            </summary>
        </member>
        <member name="F:Tensorboard.FunctionSpec.JitCompileFieldNumber">
            <summary>Field number for the "jit_compile" field.</summary>
        </member>
        <member name="T:Tensorboard.FunctionSpec.Types">
            <summary>Container for nested types declared in the FunctionSpec message type.</summary>
        </member>
        <member name="T:Tensorboard.FunctionSpec.Types.JitCompile">
             <summary>
             Whether the function should be compiled by XLA.
            
             The public interface to `tf.function` uses an optional boolean to
             represent three distinct states for this field.  Unfortunately, proto3
             removes the ability to explicitly check for the presence or absence of a
             field, so we instead map to an enum.
            
             See `tf.function` for details.
             </summary>
        </member>
        <member name="T:Tensorboard.SavedResource">
            <summary>
            A SavedResource represents a TF object that holds state during its lifetime.
            An object of this type can have a reference to a:
            create_resource() and an initialize() function.
            </summary>
        </member>
        <member name="F:Tensorboard.SavedResource.DeviceFieldNumber">
            <summary>Field number for the "device" field.</summary>
        </member>
        <member name="P:Tensorboard.SavedResource.Device">
            <summary>
            A device specification indicating a required placement for the resource
            creation function, e.g. "CPU". An empty string allows the user to select a
            device.
            </summary>
        </member>
        <member name="F:Tensorboard.SaveableObject.SaveFunctionFieldNumber">
            <summary>Field number for the "save_function" field.</summary>
        </member>
        <member name="P:Tensorboard.SaveableObject.SaveFunction">
            <summary>
            Node ids of concrete functions for saving and loading from a checkpoint.
            These functions save and restore directly from tensors.
            </summary>
        </member>
        <member name="F:Tensorboard.SaveableObject.RestoreFunctionFieldNumber">
            <summary>Field number for the "restore_function" field.</summary>
        </member>
        <member name="T:Tensorboard.SaverReflection">
            <summary>Holder for reflection information generated from tensorboard/compat/proto/saver.proto</summary>
        </member>
        <member name="P:Tensorboard.SaverReflection.Descriptor">
            <summary>File descriptor for tensorboard/compat/proto/saver.proto</summary>
        </member>
        <member name="T:Tensorboard.SaverDef">
            <summary>
            Protocol buffer representing the configuration of a Saver.
            </summary>
        </member>
        <member name="F:Tensorboard.SaverDef.FilenameTensorNameFieldNumber">
            <summary>Field number for the "filename_tensor_name" field.</summary>
        </member>
        <member name="P:Tensorboard.SaverDef.FilenameTensorName">
            <summary>
            The name of the tensor in which to specify the filename when saving or
            restoring a model checkpoint.
            </summary>
        </member>
        <member name="F:Tensorboard.SaverDef.SaveTensorNameFieldNumber">
            <summary>Field number for the "save_tensor_name" field.</summary>
        </member>
        <member name="P:Tensorboard.SaverDef.SaveTensorName">
            <summary>
            The operation to run when saving a model checkpoint.
            </summary>
        </member>
        <member name="F:Tensorboard.SaverDef.RestoreOpNameFieldNumber">
            <summary>Field number for the "restore_op_name" field.</summary>
        </member>
        <member name="P:Tensorboard.SaverDef.RestoreOpName">
            <summary>
            The operation to run when restoring a model checkpoint.
            </summary>
        </member>
        <member name="F:Tensorboard.SaverDef.MaxToKeepFieldNumber">
            <summary>Field number for the "max_to_keep" field.</summary>
        </member>
        <member name="P:Tensorboard.SaverDef.MaxToKeep">
            <summary>
            Maximum number of checkpoints to keep.  If 0, no checkpoints are deleted.
            </summary>
        </member>
        <member name="F:Tensorboard.SaverDef.ShardedFieldNumber">
            <summary>Field number for the "sharded" field.</summary>
        </member>
        <member name="P:Tensorboard.SaverDef.Sharded">
            <summary>
            Shard the save files, one per device that has Variable nodes.
            </summary>
        </member>
        <member name="F:Tensorboard.SaverDef.KeepCheckpointEveryNHoursFieldNumber">
            <summary>Field number for the "keep_checkpoint_every_n_hours" field.</summary>
        </member>
        <member name="P:Tensorboard.SaverDef.KeepCheckpointEveryNHours">
            <summary>
            How often to keep an additional checkpoint. If not specified, only the last
            "max_to_keep" checkpoints are kept; if specified, in addition to keeping
            the last "max_to_keep" checkpoints, an additional checkpoint will be kept
            for every n hours of training.
            </summary>
        </member>
        <member name="F:Tensorboard.SaverDef.VersionFieldNumber">
            <summary>Field number for the "version" field.</summary>
        </member>
        <member name="T:Tensorboard.SaverDef.Types">
            <summary>Container for nested types declared in the SaverDef message type.</summary>
        </member>
        <member name="T:Tensorboard.SaverDef.Types.CheckpointFormatVersion">
            <summary>
            A version number that identifies a different on-disk checkpoint format.
            Usually, each subclass of BaseSaverBuilder works with a particular
            version/format.  However, it is possible that the same builder may be
            upgraded to support a newer checkpoint format in the future.
            </summary>
        </member>
        <member name="F:Tensorboard.SaverDef.Types.CheckpointFormatVersion.Legacy">
            <summary>
            Internal legacy format.
            </summary>
        </member>
        <member name="F:Tensorboard.SaverDef.Types.CheckpointFormatVersion.V1">
            <summary>
            Deprecated format: tf.Saver() which works with tensorflow::table::Table.
            </summary>
        </member>
        <member name="F:Tensorboard.SaverDef.Types.CheckpointFormatVersion.V2">
            <summary>
            Current format: more efficient.
            </summary>
        </member>
        <member name="T:Tensorboard.StepStatsReflection">
            <summary>Holder for reflection information generated from tensorboard/compat/proto/step_stats.proto</summary>
        </member>
        <member name="P:Tensorboard.StepStatsReflection.Descriptor">
            <summary>File descriptor for tensorboard/compat/proto/step_stats.proto</summary>
        </member>
        <member name="T:Tensorboard.AllocationRecord">
            <summary>
            An allocation/de-allocation operation performed by the allocator.
            </summary>
        </member>
        <member name="F:Tensorboard.AllocationRecord.AllocMicrosFieldNumber">
            <summary>Field number for the "alloc_micros" field.</summary>
        </member>
        <member name="P:Tensorboard.AllocationRecord.AllocMicros">
            <summary>
            The timestamp of the operation.
            </summary>
        </member>
        <member name="F:Tensorboard.AllocationRecord.AllocBytesFieldNumber">
            <summary>Field number for the "alloc_bytes" field.</summary>
        </member>
        <member name="P:Tensorboard.AllocationRecord.AllocBytes">
            <summary>
            Number of bytes allocated, or de-allocated if negative.
            </summary>
        </member>
        <member name="F:Tensorboard.AllocatorMemoryUsed.AllocatorNameFieldNumber">
            <summary>Field number for the "allocator_name" field.</summary>
        </member>
        <member name="F:Tensorboard.AllocatorMemoryUsed.TotalBytesFieldNumber">
            <summary>Field number for the "total_bytes" field.</summary>
        </member>
        <member name="P:Tensorboard.AllocatorMemoryUsed.TotalBytes">
            <summary>
            These are per-node allocator memory stats.
            </summary>
        </member>
        <member name="F:Tensorboard.AllocatorMemoryUsed.PeakBytesFieldNumber">
            <summary>Field number for the "peak_bytes" field.</summary>
        </member>
        <member name="F:Tensorboard.AllocatorMemoryUsed.LiveBytesFieldNumber">
            <summary>Field number for the "live_bytes" field.</summary>
        </member>
        <member name="P:Tensorboard.AllocatorMemoryUsed.LiveBytes">
            <summary>
            The bytes that are not deallocated.
            </summary>
        </member>
        <member name="F:Tensorboard.AllocatorMemoryUsed.AllocationRecordsFieldNumber">
            <summary>Field number for the "allocation_records" field.</summary>
        </member>
        <member name="P:Tensorboard.AllocatorMemoryUsed.AllocationRecords">
            <summary>
            The allocation and deallocation timeline.
            </summary>
        </member>
        <member name="F:Tensorboard.AllocatorMemoryUsed.AllocatorBytesInUseFieldNumber">
            <summary>Field number for the "allocator_bytes_in_use" field.</summary>
        </member>
        <member name="P:Tensorboard.AllocatorMemoryUsed.AllocatorBytesInUse">
            <summary>
            These are snapshots of the overall allocator memory stats.
            The number of live bytes currently allocated by the allocator.
            </summary>
        </member>
        <member name="T:Tensorboard.NodeOutput">
            <summary>
            Output sizes recorded for a single execution of a graph node.
            </summary>
        </member>
        <member name="F:Tensorboard.NodeOutput.SlotFieldNumber">
            <summary>Field number for the "slot" field.</summary>
        </member>
        <member name="F:Tensorboard.NodeOutput.TensorDescriptionFieldNumber">
            <summary>Field number for the "tensor_description" field.</summary>
        </member>
        <member name="T:Tensorboard.MemoryStats">
            <summary>
            For memory tracking.
            </summary>
        </member>
        <member name="F:Tensorboard.MemoryStats.TempMemorySizeFieldNumber">
            <summary>Field number for the "temp_memory_size" field.</summary>
        </member>
        <member name="F:Tensorboard.MemoryStats.PersistentMemorySizeFieldNumber">
            <summary>Field number for the "persistent_memory_size" field.</summary>
        </member>
        <member name="F:Tensorboard.MemoryStats.PersistentTensorAllocIdsFieldNumber">
            <summary>Field number for the "persistent_tensor_alloc_ids" field.</summary>
        </member>
        <member name="F:Tensorboard.MemoryStats.DeviceTempMemorySizeFieldNumber">
            <summary>Field number for the "device_temp_memory_size" field.</summary>
        </member>
        <member name="F:Tensorboard.MemoryStats.DevicePersistentMemorySizeFieldNumber">
            <summary>Field number for the "device_persistent_memory_size" field.</summary>
        </member>
        <member name="F:Tensorboard.MemoryStats.DevicePersistentTensorAllocIdsFieldNumber">
            <summary>Field number for the "device_persistent_tensor_alloc_ids" field.</summary>
        </member>
        <member name="T:Tensorboard.NodeExecStats">
            <summary>
            Time/size stats recorded for a single execution of a graph node.
            </summary>
        </member>
        <member name="F:Tensorboard.NodeExecStats.NodeNameFieldNumber">
            <summary>Field number for the "node_name" field.</summary>
        </member>
        <member name="P:Tensorboard.NodeExecStats.NodeName">
            <summary>
            TODO(tucker): Use some more compact form of node identity than
            the full string name.  Either all processes should agree on a
            global id (cost_id?) for each node, or we should use a hash of
            the name.
            </summary>
        </member>
        <member name="F:Tensorboard.NodeExecStats.AllStartMicrosFieldNumber">
            <summary>Field number for the "all_start_micros" field.</summary>
        </member>
        <member name="F:Tensorboard.NodeExecStats.OpStartRelMicrosFieldNumber">
            <summary>Field number for the "op_start_rel_micros" field.</summary>
        </member>
        <member name="F:Tensorboard.NodeExecStats.OpEndRelMicrosFieldNumber">
            <summary>Field number for the "op_end_rel_micros" field.</summary>
        </member>
        <member name="F:Tensorboard.NodeExecStats.AllEndRelMicrosFieldNumber">
            <summary>Field number for the "all_end_rel_micros" field.</summary>
        </member>
        <member name="F:Tensorboard.NodeExecStats.MemoryFieldNumber">
            <summary>Field number for the "memory" field.</summary>
        </member>
        <member name="F:Tensorboard.NodeExecStats.OutputFieldNumber">
            <summary>Field number for the "output" field.</summary>
        </member>
        <member name="F:Tensorboard.NodeExecStats.TimelineLabelFieldNumber">
            <summary>Field number for the "timeline_label" field.</summary>
        </member>
        <member name="F:Tensorboard.NodeExecStats.ScheduledMicrosFieldNumber">
            <summary>Field number for the "scheduled_micros" field.</summary>
        </member>
        <member name="F:Tensorboard.NodeExecStats.ThreadIdFieldNumber">
            <summary>Field number for the "thread_id" field.</summary>
        </member>
        <member name="F:Tensorboard.NodeExecStats.ReferencedTensorFieldNumber">
            <summary>Field number for the "referenced_tensor" field.</summary>
        </member>
        <member name="F:Tensorboard.NodeExecStats.MemoryStatsFieldNumber">
            <summary>Field number for the "memory_stats" field.</summary>
        </member>
        <member name="F:Tensorboard.NodeExecStats.AllStartNanosFieldNumber">
            <summary>Field number for the "all_start_nanos" field.</summary>
        </member>
        <member name="F:Tensorboard.NodeExecStats.OpStartRelNanosFieldNumber">
            <summary>Field number for the "op_start_rel_nanos" field.</summary>
        </member>
        <member name="F:Tensorboard.NodeExecStats.OpEndRelNanosFieldNumber">
            <summary>Field number for the "op_end_rel_nanos" field.</summary>
        </member>
        <member name="F:Tensorboard.NodeExecStats.AllEndRelNanosFieldNumber">
            <summary>Field number for the "all_end_rel_nanos" field.</summary>
        </member>
        <member name="F:Tensorboard.NodeExecStats.ScheduledNanosFieldNumber">
            <summary>Field number for the "scheduled_nanos" field.</summary>
        </member>
        <member name="F:Tensorboard.DeviceStepStats.DeviceFieldNumber">
            <summary>Field number for the "device" field.</summary>
        </member>
        <member name="F:Tensorboard.DeviceStepStats.NodeStatsFieldNumber">
            <summary>Field number for the "node_stats" field.</summary>
        </member>
        <member name="F:Tensorboard.DeviceStepStats.ThreadNamesFieldNumber">
            <summary>Field number for the "thread_names" field.</summary>
        </member>
        <member name="P:Tensorboard.DeviceStepStats.ThreadNames">
            <summary>
            Its key is thread id.
            </summary>
        </member>
        <member name="F:Tensorboard.StepStats.DevStatsFieldNumber">
            <summary>Field number for the "dev_stats" field.</summary>
        </member>
        <member name="T:Tensorboard.StructReflection">
            <summary>Holder for reflection information generated from tensorboard/compat/proto/struct.proto</summary>
        </member>
        <member name="P:Tensorboard.StructReflection.Descriptor">
            <summary>File descriptor for tensorboard/compat/proto/struct.proto</summary>
        </member>
        <member name="T:Tensorboard.StructuredValue">
             <summary>
             `StructuredValue` represents a dynamically typed value representing various
             data structures that are inspired by Python data structures typically used in
             TensorFlow functions as inputs and outputs.
            
             For example when saving a Layer there may be a `training` argument. If the
             user passes a boolean True/False, that switches between two concrete
             TensorFlow functions. In order to switch between them in the same way after
             loading the SavedModel, we need to represent "True" and "False".
            
             A more advanced example might be a function which takes a list of
             dictionaries mapping from strings to Tensors. In order to map from
             user-specified arguments `[{"a": tf.constant(1.)}, {"q": tf.constant(3.)}]`
             after load to the right saved TensorFlow function, we need to represent the
             nested structure and the strings, recording that we have a trace for anything
             matching `[{"a": tf.TensorSpec(None, tf.float32)}, {"q": tf.TensorSpec([],
             tf.float64)}]` as an example.
            
             Likewise functions may return nested structures of Tensors, for example
             returning a dictionary mapping from strings to Tensors. In order for the
             loaded function to return the same structure we need to serialize it.
            
             This is an ergonomic aid for working with loaded SavedModels, not a promise
             to serialize all possible function signatures. For example we do not expect
             to pickle generic Python objects, and ideally we'd stay language-agnostic.
             </summary>
        </member>
        <member name="F:Tensorboard.StructuredValue.NoneValueFieldNumber">
            <summary>Field number for the "none_value" field.</summary>
        </member>
        <member name="P:Tensorboard.StructuredValue.NoneValue">
            <summary>
            Represents None.
            </summary>
        </member>
        <member name="F:Tensorboard.StructuredValue.Float64ValueFieldNumber">
            <summary>Field number for the "float64_value" field.</summary>
        </member>
        <member name="P:Tensorboard.StructuredValue.Float64Value">
            <summary>
            Represents a double-precision floating-point value (a Python `float`).
            </summary>
        </member>
        <member name="F:Tensorboard.StructuredValue.Int64ValueFieldNumber">
            <summary>Field number for the "int64_value" field.</summary>
        </member>
        <member name="P:Tensorboard.StructuredValue.Int64Value">
            <summary>
            Represents a signed integer value, limited to 64 bits.
            Larger values from Python's arbitrary-precision integers are unsupported.
            </summary>
        </member>
        <member name="F:Tensorboard.StructuredValue.StringValueFieldNumber">
            <summary>Field number for the "string_value" field.</summary>
        </member>
        <member name="P:Tensorboard.StructuredValue.StringValue">
            <summary>
            Represents a string of Unicode characters stored in a Python `str`.
            In Python 3, this is exactly what type `str` is.
            In Python 2, this is the UTF-8 encoding of the characters.
            For strings with ASCII characters only (as often used in TensorFlow code)
            there is effectively no difference between the language versions.
            The obsolescent `unicode` type of Python 2 is not supported here.
            </summary>
        </member>
        <member name="F:Tensorboard.StructuredValue.BoolValueFieldNumber">
            <summary>Field number for the "bool_value" field.</summary>
        </member>
        <member name="P:Tensorboard.StructuredValue.BoolValue">
            <summary>
            Represents a boolean value.
            </summary>
        </member>
        <member name="F:Tensorboard.StructuredValue.TensorShapeValueFieldNumber">
            <summary>Field number for the "tensor_shape_value" field.</summary>
        </member>
        <member name="P:Tensorboard.StructuredValue.TensorShapeValue">
            <summary>
            Represents a TensorShape.
            </summary>
        </member>
        <member name="F:Tensorboard.StructuredValue.TensorDtypeValueFieldNumber">
            <summary>Field number for the "tensor_dtype_value" field.</summary>
        </member>
        <member name="P:Tensorboard.StructuredValue.TensorDtypeValue">
            <summary>
            Represents an enum value for dtype.
            </summary>
        </member>
        <member name="F:Tensorboard.StructuredValue.TensorSpecValueFieldNumber">
            <summary>Field number for the "tensor_spec_value" field.</summary>
        </member>
        <member name="P:Tensorboard.StructuredValue.TensorSpecValue">
            <summary>
            Represents a value for tf.TensorSpec.
            </summary>
        </member>
        <member name="F:Tensorboard.StructuredValue.TypeSpecValueFieldNumber">
            <summary>Field number for the "type_spec_value" field.</summary>
        </member>
        <member name="P:Tensorboard.StructuredValue.TypeSpecValue">
            <summary>
            Represents a value for tf.TypeSpec.
            </summary>
        </member>
        <member name="F:Tensorboard.StructuredValue.BoundedTensorSpecValueFieldNumber">
            <summary>Field number for the "bounded_tensor_spec_value" field.</summary>
        </member>
        <member name="P:Tensorboard.StructuredValue.BoundedTensorSpecValue">
            <summary>
            Represents a value for tf.BoundedTensorSpec.
            </summary>
        </member>
        <member name="F:Tensorboard.StructuredValue.ListValueFieldNumber">
            <summary>Field number for the "list_value" field.</summary>
        </member>
        <member name="P:Tensorboard.StructuredValue.ListValue">
            <summary>
            Represents a list of `Value`.
            </summary>
        </member>
        <member name="F:Tensorboard.StructuredValue.TupleValueFieldNumber">
            <summary>Field number for the "tuple_value" field.</summary>
        </member>
        <member name="P:Tensorboard.StructuredValue.TupleValue">
            <summary>
            Represents a tuple of `Value`.
            </summary>
        </member>
        <member name="F:Tensorboard.StructuredValue.DictValueFieldNumber">
            <summary>Field number for the "dict_value" field.</summary>
        </member>
        <member name="P:Tensorboard.StructuredValue.DictValue">
            <summary>
            Represents a dict `Value`.
            </summary>
        </member>
        <member name="F:Tensorboard.StructuredValue.NamedTupleValueFieldNumber">
            <summary>Field number for the "named_tuple_value" field.</summary>
        </member>
        <member name="P:Tensorboard.StructuredValue.NamedTupleValue">
            <summary>
            Represents Python's namedtuple.
            </summary>
        </member>
        <member name="T:Tensorboard.StructuredValue.KindOneofCase">
            <summary>Enum of possible cases for the "kind" oneof.</summary>
        </member>
        <member name="T:Tensorboard.NoneValue">
            <summary>
            Represents None.
            </summary>
        </member>
        <member name="T:Tensorboard.ListValue">
            <summary>
            Represents a Python list.
            </summary>
        </member>
        <member name="F:Tensorboard.ListValue.ValuesFieldNumber">
            <summary>Field number for the "values" field.</summary>
        </member>
        <member name="T:Tensorboard.TupleValue">
            <summary>
            Represents a Python tuple.
            </summary>
        </member>
        <member name="F:Tensorboard.TupleValue.ValuesFieldNumber">
            <summary>Field number for the "values" field.</summary>
        </member>
        <member name="T:Tensorboard.DictValue">
            <summary>
            Represents a Python dict keyed by `str`.
            The comment on Unicode from Value.string_value applies analogously.
            </summary>
        </member>
        <member name="F:Tensorboard.DictValue.FieldsFieldNumber">
            <summary>Field number for the "fields" field.</summary>
        </member>
        <member name="T:Tensorboard.PairValue">
            <summary>
            Represents a (key, value) pair.
            </summary>
        </member>
        <member name="F:Tensorboard.PairValue.KeyFieldNumber">
            <summary>Field number for the "key" field.</summary>
        </member>
        <member name="F:Tensorboard.PairValue.ValueFieldNumber">
            <summary>Field number for the "value" field.</summary>
        </member>
        <member name="T:Tensorboard.NamedTupleValue">
            <summary>
            Represents Python's namedtuple.
            </summary>
        </member>
        <member name="F:Tensorboard.NamedTupleValue.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="F:Tensorboard.NamedTupleValue.ValuesFieldNumber">
            <summary>Field number for the "values" field.</summary>
        </member>
        <member name="T:Tensorboard.TensorSpecProto">
            <summary>
            A protobuf to represent tf.TensorSpec.
            </summary>
        </member>
        <member name="F:Tensorboard.TensorSpecProto.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="F:Tensorboard.TensorSpecProto.ShapeFieldNumber">
            <summary>Field number for the "shape" field.</summary>
        </member>
        <member name="F:Tensorboard.TensorSpecProto.DtypeFieldNumber">
            <summary>Field number for the "dtype" field.</summary>
        </member>
        <member name="T:Tensorboard.BoundedTensorSpecProto">
            <summary>
            A protobuf to represent tf.BoundedTensorSpec.
            </summary>
        </member>
        <member name="F:Tensorboard.BoundedTensorSpecProto.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="F:Tensorboard.BoundedTensorSpecProto.ShapeFieldNumber">
            <summary>Field number for the "shape" field.</summary>
        </member>
        <member name="F:Tensorboard.BoundedTensorSpecProto.DtypeFieldNumber">
            <summary>Field number for the "dtype" field.</summary>
        </member>
        <member name="F:Tensorboard.BoundedTensorSpecProto.MinimumFieldNumber">
            <summary>Field number for the "minimum" field.</summary>
        </member>
        <member name="F:Tensorboard.BoundedTensorSpecProto.MaximumFieldNumber">
            <summary>Field number for the "maximum" field.</summary>
        </member>
        <member name="T:Tensorboard.TypeSpecProto">
            <summary>
            Represents a tf.TypeSpec
            </summary>
        </member>
        <member name="F:Tensorboard.TypeSpecProto.TypeSpecClassFieldNumber">
            <summary>Field number for the "type_spec_class" field.</summary>
        </member>
        <member name="F:Tensorboard.TypeSpecProto.TypeStateFieldNumber">
            <summary>Field number for the "type_state" field.</summary>
        </member>
        <member name="P:Tensorboard.TypeSpecProto.TypeState">
            <summary>
            The value returned by TypeSpec._serialize().
            </summary>
        </member>
        <member name="F:Tensorboard.TypeSpecProto.TypeSpecClassNameFieldNumber">
            <summary>Field number for the "type_spec_class_name" field.</summary>
        </member>
        <member name="P:Tensorboard.TypeSpecProto.TypeSpecClassName">
            <summary>
            The name of the TypeSpec class.
             * If type_spec_class == REGISTERED_TYPE_SPEC, the TypeSpec class is
               the one registered under this name. For types registered outside
               core TensorFlow by an add-on library, that library must be loaded
               before this value can be deserialized by nested_structure_coder.
             * If type_spec_class specifies a particular TypeSpec class, this field is
               redundant with the type_spec_class enum, and is only used for error
               reporting in older binaries that do not know the tupe_spec_class enum.
            </summary>
        </member>
        <member name="F:Tensorboard.TypeSpecProto.NumFlatComponentsFieldNumber">
            <summary>Field number for the "num_flat_components" field.</summary>
        </member>
        <member name="P:Tensorboard.TypeSpecProto.NumFlatComponents">
            <summary>
            The number of flat tensor components required by this TypeSpec.
            </summary>
        </member>
        <member name="T:Tensorboard.TypeSpecProto.Types">
            <summary>Container for nested types declared in the TypeSpecProto message type.</summary>
        </member>
        <member name="F:Tensorboard.TypeSpecProto.Types.TypeSpecClass.SparseTensorSpec">
            <summary>
            tf.SparseTensorSpec
            </summary>
        </member>
        <member name="F:Tensorboard.TypeSpecProto.Types.TypeSpecClass.IndexedSlicesSpec">
            <summary>
            tf.IndexedSlicesSpec
            </summary>
        </member>
        <member name="F:Tensorboard.TypeSpecProto.Types.TypeSpecClass.RaggedTensorSpec">
            <summary>
            tf.RaggedTensorSpec
            </summary>
        </member>
        <member name="F:Tensorboard.TypeSpecProto.Types.TypeSpecClass.TensorArraySpec">
            <summary>
            tf.TensorArraySpec
            </summary>
        </member>
        <member name="F:Tensorboard.TypeSpecProto.Types.TypeSpecClass.DataDatasetSpec">
            <summary>
            tf.data.DatasetSpec
            </summary>
        </member>
        <member name="F:Tensorboard.TypeSpecProto.Types.TypeSpecClass.DataIteratorSpec">
            <summary>
            IteratorSpec from data/ops/iterator_ops.py
            </summary>
        </member>
        <member name="F:Tensorboard.TypeSpecProto.Types.TypeSpecClass.OptionalSpec">
            <summary>
            tf.OptionalSpec
            </summary>
        </member>
        <member name="F:Tensorboard.TypeSpecProto.Types.TypeSpecClass.PerReplicaSpec">
            <summary>
            PerReplicaSpec from distribute/values.py
            </summary>
        </member>
        <member name="F:Tensorboard.TypeSpecProto.Types.TypeSpecClass.VariableSpec">
            <summary>
            tf.VariableSpec
            </summary>
        </member>
        <member name="F:Tensorboard.TypeSpecProto.Types.TypeSpecClass.RowPartitionSpec">
            <summary>
            RowPartitionSpec from ragged/row_partition.py
            </summary>
        </member>
        <member name="F:Tensorboard.TypeSpecProto.Types.TypeSpecClass.RegisteredTypeSpec">
            <summary>
            The type registered as type_spec_class_name.
            </summary>
        </member>
        <member name="F:Tensorboard.TypeSpecProto.Types.TypeSpecClass.ExtensionTypeSpec">
            <summary>
            Subclasses of tf.ExtensionType
            </summary>
        </member>
        <member name="T:Tensorboard.SummaryReflection">
            <summary>Holder for reflection information generated from tensorboard/compat/proto/summary.proto</summary>
        </member>
        <member name="P:Tensorboard.SummaryReflection.Descriptor">
            <summary>File descriptor for tensorboard/compat/proto/summary.proto</summary>
        </member>
        <member name="F:Tensorboard.DataClass.Unknown">
            <summary>
            Unknown data class, used (implicitly) for legacy data. Will not be
            processed by data ingestion pipelines.
            </summary>
        </member>
        <member name="F:Tensorboard.DataClass.Scalar">
            <summary>
            Scalar time series. Each `Value` for the corresponding tag must have
            `tensor` set to a rank-0 tensor of type `DT_FLOAT` (float32).
            </summary>
        </member>
        <member name="F:Tensorboard.DataClass.Tensor">
            <summary>
            Tensor time series. Each `Value` for the corresponding tag must have
            `tensor` set. The tensor value is arbitrary, but should be small to
            accommodate direct storage in database backends: an upper bound of a few
            kilobytes is a reasonable rule of thumb.
            </summary>
        </member>
        <member name="F:Tensorboard.DataClass.BlobSequence">
            <summary>
            Blob sequence time series. Each `Value` for the corresponding tag must
            have `tensor` set to a rank-1 tensor of bytestring dtype.
            </summary>
        </member>
        <member name="T:Tensorboard.SummaryDescription">
            <summary>
            Metadata associated with a series of Summary data
            </summary>
        </member>
        <member name="F:Tensorboard.SummaryDescription.TypeHintFieldNumber">
            <summary>Field number for the "type_hint" field.</summary>
        </member>
        <member name="P:Tensorboard.SummaryDescription.TypeHint">
            <summary>
            Hint on how plugins should process the data in this series.
            Supported values include "scalar", "histogram", "image", "audio"
            </summary>
        </member>
        <member name="T:Tensorboard.HistogramProto">
            <summary>
            Serialization format for histogram module in
            core/lib/histogram/histogram.h
            </summary>
        </member>
        <member name="F:Tensorboard.HistogramProto.MinFieldNumber">
            <summary>Field number for the "min" field.</summary>
        </member>
        <member name="F:Tensorboard.HistogramProto.MaxFieldNumber">
            <summary>Field number for the "max" field.</summary>
        </member>
        <member name="F:Tensorboard.HistogramProto.NumFieldNumber">
            <summary>Field number for the "num" field.</summary>
        </member>
        <member name="F:Tensorboard.HistogramProto.SumFieldNumber">
            <summary>Field number for the "sum" field.</summary>
        </member>
        <member name="F:Tensorboard.HistogramProto.SumSquaresFieldNumber">
            <summary>Field number for the "sum_squares" field.</summary>
        </member>
        <member name="F:Tensorboard.HistogramProto.BucketLimitFieldNumber">
            <summary>Field number for the "bucket_limit" field.</summary>
        </member>
        <member name="P:Tensorboard.HistogramProto.BucketLimit">
            <summary>
            Parallel arrays encoding the bucket boundaries and the bucket values.
            bucket(i) is the count for the bucket i.  The range for
            a bucket is:
              i == 0:  -DBL_MAX .. bucket_limit(0)
              i != 0:  bucket_limit(i-1) .. bucket_limit(i)
            </summary>
        </member>
        <member name="F:Tensorboard.HistogramProto.BucketFieldNumber">
            <summary>Field number for the "bucket" field.</summary>
        </member>
        <member name="T:Tensorboard.SummaryMetadata">
            <summary>
            A SummaryMetadata encapsulates information on which plugins are able to make
            use of a certain summary value.
            </summary>
        </member>
        <member name="F:Tensorboard.SummaryMetadata.PluginDataFieldNumber">
            <summary>Field number for the "plugin_data" field.</summary>
        </member>
        <member name="P:Tensorboard.SummaryMetadata.PluginData">
            <summary>
            Data that associates a summary with a certain plugin.
            </summary>
        </member>
        <member name="F:Tensorboard.SummaryMetadata.DisplayNameFieldNumber">
            <summary>Field number for the "display_name" field.</summary>
        </member>
        <member name="P:Tensorboard.SummaryMetadata.DisplayName">
            <summary>
            Display name for viewing in TensorBoard.
            </summary>
        </member>
        <member name="F:Tensorboard.SummaryMetadata.SummaryDescriptionFieldNumber">
            <summary>Field number for the "summary_description" field.</summary>
        </member>
        <member name="P:Tensorboard.SummaryMetadata.SummaryDescription">
            <summary>
            Longform readable description of the summary sequence. Markdown supported.
            </summary>
        </member>
        <member name="F:Tensorboard.SummaryMetadata.DataClassFieldNumber">
            <summary>Field number for the "data_class" field.</summary>
        </member>
        <member name="P:Tensorboard.SummaryMetadata.DataClass">
            <summary>
            Class of data stored in this time series. Required for compatibility with
            TensorBoard's generic data facilities (`DataProvider`, et al.). This value
            imposes constraints on the dtype and shape of the corresponding tensor
            values. See `DataClass` docs for details.
            </summary>
        </member>
        <member name="T:Tensorboard.SummaryMetadata.Types">
            <summary>Container for nested types declared in the SummaryMetadata message type.</summary>
        </member>
        <member name="F:Tensorboard.SummaryMetadata.Types.PluginData.PluginNameFieldNumber">
            <summary>Field number for the "plugin_name" field.</summary>
        </member>
        <member name="P:Tensorboard.SummaryMetadata.Types.PluginData.PluginName">
            <summary>
            The name of the plugin this data pertains to.
            </summary>
        </member>
        <member name="F:Tensorboard.SummaryMetadata.Types.PluginData.ContentFieldNumber">
            <summary>Field number for the "content" field.</summary>
        </member>
        <member name="P:Tensorboard.SummaryMetadata.Types.PluginData.Content">
            <summary>
            The content to store for the plugin. The best practice is for this to be
            a binary serialized protocol buffer.
            </summary>
        </member>
        <member name="T:Tensorboard.Summary">
             <summary>
             A Summary is a set of named values to be displayed by the
             visualizer.
            
             Summaries are produced regularly during training, as controlled by
             the "summary_interval_secs" attribute of the training operation.
             Summaries are also produced at the end of an evaluation.
             </summary>
        </member>
        <member name="F:Tensorboard.Summary.ValueFieldNumber">
            <summary>Field number for the "value" field.</summary>
        </member>
        <member name="P:Tensorboard.Summary.Value">
            <summary>
            Set of values for the summary.
            </summary>
        </member>
        <member name="T:Tensorboard.Summary.Types">
            <summary>Container for nested types declared in the Summary message type.</summary>
        </member>
        <member name="F:Tensorboard.Summary.Types.Image.HeightFieldNumber">
            <summary>Field number for the "height" field.</summary>
        </member>
        <member name="P:Tensorboard.Summary.Types.Image.Height">
            <summary>
            Dimensions of the image.
            </summary>
        </member>
        <member name="F:Tensorboard.Summary.Types.Image.WidthFieldNumber">
            <summary>Field number for the "width" field.</summary>
        </member>
        <member name="F:Tensorboard.Summary.Types.Image.ColorspaceFieldNumber">
            <summary>Field number for the "colorspace" field.</summary>
        </member>
        <member name="P:Tensorboard.Summary.Types.Image.Colorspace">
            <summary>
            Valid colorspace values are
              1 - grayscale
              2 - grayscale + alpha
              3 - RGB
              4 - RGBA
              5 - DIGITAL_YUV
              6 - BGRA
            </summary>
        </member>
        <member name="F:Tensorboard.Summary.Types.Image.EncodedImageStringFieldNumber">
            <summary>Field number for the "encoded_image_string" field.</summary>
        </member>
        <member name="P:Tensorboard.Summary.Types.Image.EncodedImageString">
            <summary>
            Image data in encoded format.  All image formats supported by
            image_codec::CoderUtil can be stored here.
            </summary>
        </member>
        <member name="F:Tensorboard.Summary.Types.Audio.SampleRateFieldNumber">
            <summary>Field number for the "sample_rate" field.</summary>
        </member>
        <member name="P:Tensorboard.Summary.Types.Audio.SampleRate">
            <summary>
            Sample rate of the audio in Hz.
            </summary>
        </member>
        <member name="F:Tensorboard.Summary.Types.Audio.NumChannelsFieldNumber">
            <summary>Field number for the "num_channels" field.</summary>
        </member>
        <member name="P:Tensorboard.Summary.Types.Audio.NumChannels">
            <summary>
            Number of channels of audio.
            </summary>
        </member>
        <member name="F:Tensorboard.Summary.Types.Audio.LengthFramesFieldNumber">
            <summary>Field number for the "length_frames" field.</summary>
        </member>
        <member name="P:Tensorboard.Summary.Types.Audio.LengthFrames">
            <summary>
            Length of the audio in frames (samples per channel).
            </summary>
        </member>
        <member name="F:Tensorboard.Summary.Types.Audio.EncodedAudioStringFieldNumber">
            <summary>Field number for the "encoded_audio_string" field.</summary>
        </member>
        <member name="P:Tensorboard.Summary.Types.Audio.EncodedAudioString">
            <summary>
            Encoded audio data and its associated RFC 2045 content type (e.g.
            "audio/wav").
            </summary>
        </member>
        <member name="F:Tensorboard.Summary.Types.Audio.ContentTypeFieldNumber">
            <summary>Field number for the "content_type" field.</summary>
        </member>
        <member name="F:Tensorboard.Summary.Types.Value.NodeNameFieldNumber">
            <summary>Field number for the "node_name" field.</summary>
        </member>
        <member name="P:Tensorboard.Summary.Types.Value.NodeName">
            <summary>
            This field is deprecated and will not be set.
            </summary>
        </member>
        <member name="F:Tensorboard.Summary.Types.Value.TagFieldNumber">
            <summary>Field number for the "tag" field.</summary>
        </member>
        <member name="P:Tensorboard.Summary.Types.Value.Tag">
            <summary>
            Tag name for the data. Used by TensorBoard plugins to organize data. Tags
            are often organized by scope (which contains slashes to convey
            hierarchy). For example: foo/bar/0
            </summary>
        </member>
        <member name="F:Tensorboard.Summary.Types.Value.MetadataFieldNumber">
            <summary>Field number for the "metadata" field.</summary>
        </member>
        <member name="P:Tensorboard.Summary.Types.Value.Metadata">
            <summary>
            Contains metadata on the summary value such as which plugins may use it.
            Take note that many summary values may lack a metadata field. This is
            because the FileWriter only keeps a metadata object on the first summary
            value with a certain tag for each tag. TensorBoard then remembers which
            tags are associated with which plugins. This saves space.
            </summary>
        </member>
        <member name="F:Tensorboard.Summary.Types.Value.SimpleValueFieldNumber">
            <summary>Field number for the "simple_value" field.</summary>
        </member>
        <member name="F:Tensorboard.Summary.Types.Value.ObsoleteOldStyleHistogramFieldNumber">
            <summary>Field number for the "obsolete_old_style_histogram" field.</summary>
        </member>
        <member name="F:Tensorboard.Summary.Types.Value.ImageFieldNumber">
            <summary>Field number for the "image" field.</summary>
        </member>
        <member name="F:Tensorboard.Summary.Types.Value.HistoFieldNumber">
            <summary>Field number for the "histo" field.</summary>
        </member>
        <member name="F:Tensorboard.Summary.Types.Value.AudioFieldNumber">
            <summary>Field number for the "audio" field.</summary>
        </member>
        <member name="F:Tensorboard.Summary.Types.Value.TensorFieldNumber">
            <summary>Field number for the "tensor" field.</summary>
        </member>
        <member name="T:Tensorboard.Summary.Types.Value.ValueOneofCase">
            <summary>Enum of possible cases for the "value" oneof.</summary>
        </member>
        <member name="T:Tensorboard.TensorReflection">
            <summary>Holder for reflection information generated from tensorboard/compat/proto/tensor.proto</summary>
        </member>
        <member name="P:Tensorboard.TensorReflection.Descriptor">
            <summary>File descriptor for tensorboard/compat/proto/tensor.proto</summary>
        </member>
        <member name="T:Tensorboard.TensorProto">
            <summary>
            Protocol buffer representing a tensor.
            </summary>
        </member>
        <member name="F:Tensorboard.TensorProto.DtypeFieldNumber">
            <summary>Field number for the "dtype" field.</summary>
        </member>
        <member name="F:Tensorboard.TensorProto.TensorShapeFieldNumber">
            <summary>Field number for the "tensor_shape" field.</summary>
        </member>
        <member name="P:Tensorboard.TensorProto.TensorShape">
            <summary>
            Shape of the tensor.  TODO(touts): sort out the 0-rank issues.
            </summary>
        </member>
        <member name="F:Tensorboard.TensorProto.VersionNumberFieldNumber">
            <summary>Field number for the "version_number" field.</summary>
        </member>
        <member name="P:Tensorboard.TensorProto.VersionNumber">
             <summary>
             Version number.
            
             In version 0, if the "repeated xxx" representations contain only one
             element, that element is repeated to fill the shape.  This makes it easy
             to represent a constant Tensor with a single value.
             </summary>
        </member>
        <member name="F:Tensorboard.TensorProto.TensorContentFieldNumber">
            <summary>Field number for the "tensor_content" field.</summary>
        </member>
        <member name="P:Tensorboard.TensorProto.TensorContent">
            <summary>
            Serialized raw tensor content from either Tensor::AsProtoTensorContent or
            memcpy in tensorflow::grpc::EncodeTensorToByteBuffer. This representation
            can be used for all tensor types. The purpose of this representation is to
            reduce serialization overhead during RPC call by avoiding serialization of
            many repeated small items.
            </summary>
        </member>
        <member name="F:Tensorboard.TensorProto.HalfValFieldNumber">
            <summary>Field number for the "half_val" field.</summary>
        </member>
        <member name="P:Tensorboard.TensorProto.HalfVal">
            <summary>
            DT_HALF, DT_BFLOAT16. Note that since protobuf has no int16 type, we'll
            have some pointless zero padding for each value here.
            </summary>
        </member>
        <member name="F:Tensorboard.TensorProto.FloatValFieldNumber">
            <summary>Field number for the "float_val" field.</summary>
        </member>
        <member name="P:Tensorboard.TensorProto.FloatVal">
            <summary>
            DT_FLOAT.
            </summary>
        </member>
        <member name="F:Tensorboard.TensorProto.DoubleValFieldNumber">
            <summary>Field number for the "double_val" field.</summary>
        </member>
        <member name="P:Tensorboard.TensorProto.DoubleVal">
            <summary>
            DT_DOUBLE.
            </summary>
        </member>
        <member name="F:Tensorboard.TensorProto.IntValFieldNumber">
            <summary>Field number for the "int_val" field.</summary>
        </member>
        <member name="P:Tensorboard.TensorProto.IntVal">
            <summary>
            DT_INT32, DT_INT16, DT_UINT16, DT_INT8, DT_UINT8.
            </summary>
        </member>
        <member name="F:Tensorboard.TensorProto.StringValFieldNumber">
            <summary>Field number for the "string_val" field.</summary>
        </member>
        <member name="P:Tensorboard.TensorProto.StringVal">
            <summary>
            DT_STRING
            </summary>
        </member>
        <member name="F:Tensorboard.TensorProto.ScomplexValFieldNumber">
            <summary>Field number for the "scomplex_val" field.</summary>
        </member>
        <member name="P:Tensorboard.TensorProto.ScomplexVal">
            <summary>
            DT_COMPLEX64. scomplex_val(2*i) and scomplex_val(2*i+1) are real
            and imaginary parts of i-th single precision complex.
            </summary>
        </member>
        <member name="F:Tensorboard.TensorProto.Int64ValFieldNumber">
            <summary>Field number for the "int64_val" field.</summary>
        </member>
        <member name="P:Tensorboard.TensorProto.Int64Val">
            <summary>
            DT_INT64
            </summary>
        </member>
        <member name="F:Tensorboard.TensorProto.BoolValFieldNumber">
            <summary>Field number for the "bool_val" field.</summary>
        </member>
        <member name="P:Tensorboard.TensorProto.BoolVal">
            <summary>
            DT_BOOL
            </summary>
        </member>
        <member name="F:Tensorboard.TensorProto.DcomplexValFieldNumber">
            <summary>Field number for the "dcomplex_val" field.</summary>
        </member>
        <member name="P:Tensorboard.TensorProto.DcomplexVal">
            <summary>
            DT_COMPLEX128. dcomplex_val(2*i) and dcomplex_val(2*i+1) are real
            and imaginary parts of i-th double precision complex.
            </summary>
        </member>
        <member name="F:Tensorboard.TensorProto.ResourceHandleValFieldNumber">
            <summary>Field number for the "resource_handle_val" field.</summary>
        </member>
        <member name="P:Tensorboard.TensorProto.ResourceHandleVal">
            <summary>
            DT_RESOURCE
            </summary>
        </member>
        <member name="F:Tensorboard.TensorProto.VariantValFieldNumber">
            <summary>Field number for the "variant_val" field.</summary>
        </member>
        <member name="P:Tensorboard.TensorProto.VariantVal">
            <summary>
            DT_VARIANT
            </summary>
        </member>
        <member name="F:Tensorboard.TensorProto.Uint32ValFieldNumber">
            <summary>Field number for the "uint32_val" field.</summary>
        </member>
        <member name="P:Tensorboard.TensorProto.Uint32Val">
            <summary>
            DT_UINT32
            </summary>
        </member>
        <member name="F:Tensorboard.TensorProto.Uint64ValFieldNumber">
            <summary>Field number for the "uint64_val" field.</summary>
        </member>
        <member name="P:Tensorboard.TensorProto.Uint64Val">
            <summary>
            DT_UINT64
            </summary>
        </member>
        <member name="T:Tensorboard.VariantTensorDataProto">
            <summary>
            Protocol buffer representing the serialization format of DT_VARIANT tensors.
            </summary>
        </member>
        <member name="F:Tensorboard.VariantTensorDataProto.TypeNameFieldNumber">
            <summary>Field number for the "type_name" field.</summary>
        </member>
        <member name="P:Tensorboard.VariantTensorDataProto.TypeName">
            <summary>
            Name of the type of objects being serialized.
            </summary>
        </member>
        <member name="F:Tensorboard.VariantTensorDataProto.MetadataFieldNumber">
            <summary>Field number for the "metadata" field.</summary>
        </member>
        <member name="P:Tensorboard.VariantTensorDataProto.Metadata">
            <summary>
            Portions of the object that are not Tensors.
            </summary>
        </member>
        <member name="F:Tensorboard.VariantTensorDataProto.TensorsFieldNumber">
            <summary>Field number for the "tensors" field.</summary>
        </member>
        <member name="P:Tensorboard.VariantTensorDataProto.Tensors">
            <summary>
            Tensors contained within objects being serialized.
            </summary>
        </member>
        <member name="T:Tensorboard.TensorDescriptionReflection">
            <summary>Holder for reflection information generated from tensorboard/compat/proto/tensor_description.proto</summary>
        </member>
        <member name="P:Tensorboard.TensorDescriptionReflection.Descriptor">
            <summary>File descriptor for tensorboard/compat/proto/tensor_description.proto</summary>
        </member>
        <member name="F:Tensorboard.TensorDescription.DtypeFieldNumber">
            <summary>Field number for the "dtype" field.</summary>
        </member>
        <member name="P:Tensorboard.TensorDescription.Dtype">
            <summary>
            Data type of tensor elements
            </summary>
        </member>
        <member name="F:Tensorboard.TensorDescription.ShapeFieldNumber">
            <summary>Field number for the "shape" field.</summary>
        </member>
        <member name="P:Tensorboard.TensorDescription.Shape">
            <summary>
            Shape of the tensor.
            </summary>
        </member>
        <member name="F:Tensorboard.TensorDescription.AllocationDescriptionFieldNumber">
            <summary>Field number for the "allocation_description" field.</summary>
        </member>
        <member name="P:Tensorboard.TensorDescription.AllocationDescription">
            <summary>
            Information about the size and allocator used for the data
            </summary>
        </member>
        <member name="T:Tensorboard.TensorShapeReflection">
            <summary>Holder for reflection information generated from tensorboard/compat/proto/tensor_shape.proto</summary>
        </member>
        <member name="P:Tensorboard.TensorShapeReflection.Descriptor">
            <summary>File descriptor for tensorboard/compat/proto/tensor_shape.proto</summary>
        </member>
        <member name="T:Tensorboard.TensorShapeProto">
            <summary>
            Dimensions of a tensor.
            </summary>
        </member>
        <member name="F:Tensorboard.TensorShapeProto.DimFieldNumber">
            <summary>Field number for the "dim" field.</summary>
        </member>
        <member name="P:Tensorboard.TensorShapeProto.Dim">
             <summary>
             Dimensions of the tensor, such as {"input", 30}, {"output", 40}
             for a 30 x 40 2D tensor.  If an entry has size -1, this
             corresponds to a dimension of unknown size. The names are
             optional.
            
             The order of entries in "dim" matters: It indicates the layout of the
             values in the tensor in-memory representation.
            
             The first entry in "dim" is the outermost dimension used to layout the
             values, the last entry is the innermost dimension.  This matches the
             in-memory layout of RowMajor Eigen tensors.
            
             If "dim.size()" > 0, "unknown_rank" must be false.
             </summary>
        </member>
        <member name="F:Tensorboard.TensorShapeProto.UnknownRankFieldNumber">
            <summary>Field number for the "unknown_rank" field.</summary>
        </member>
        <member name="P:Tensorboard.TensorShapeProto.UnknownRank">
             <summary>
             If true, the number of dimensions in the shape is unknown.
            
             If true, "dim.size()" must be 0.
             </summary>
        </member>
        <member name="T:Tensorboard.TensorShapeProto.Types">
            <summary>Container for nested types declared in the TensorShapeProto message type.</summary>
        </member>
        <member name="T:Tensorboard.TensorShapeProto.Types.Dim">
            <summary>
            One dimension of the tensor.
            </summary>
        </member>
        <member name="F:Tensorboard.TensorShapeProto.Types.Dim.SizeFieldNumber">
            <summary>Field number for the "size" field.</summary>
        </member>
        <member name="P:Tensorboard.TensorShapeProto.Types.Dim.Size">
            <summary>
            Size of the tensor in that dimension.
            This value must be >= -1, but values of -1 are reserved for "unknown"
            shapes (values of -1 mean "unknown" dimension).  Certain wrappers
            that work with TensorShapeProto may fail at runtime when deserializing
            a TensorShapeProto containing a dim value of -1.
            </summary>
        </member>
        <member name="F:Tensorboard.TensorShapeProto.Types.Dim.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="P:Tensorboard.TensorShapeProto.Types.Dim.Name">
            <summary>
            Optional name of the tensor dimension.
            </summary>
        </member>
        <member name="T:Tensorboard.TfprofLogReflection">
            <summary>Holder for reflection information generated from tensorboard/compat/proto/tfprof_log.proto</summary>
        </member>
        <member name="P:Tensorboard.TfprofLogReflection.Descriptor">
            <summary>File descriptor for tensorboard/compat/proto/tfprof_log.proto</summary>
        </member>
        <member name="T:Tensorboard.CodeDef">
            <summary>
            It specifies the Python callstack that creates an op.
            </summary>
        </member>
        <member name="F:Tensorboard.CodeDef.TracesFieldNumber">
            <summary>Field number for the "traces" field.</summary>
        </member>
        <member name="T:Tensorboard.CodeDef.Types">
            <summary>Container for nested types declared in the CodeDef message type.</summary>
        </member>
        <member name="F:Tensorboard.CodeDef.Types.Trace.FileFieldNumber">
            <summary>Field number for the "file" field.</summary>
        </member>
        <member name="P:Tensorboard.CodeDef.Types.Trace.File">
            <summary>
            deprecated by file_id.
            </summary>
        </member>
        <member name="F:Tensorboard.CodeDef.Types.Trace.FileIdFieldNumber">
            <summary>Field number for the "file_id" field.</summary>
        </member>
        <member name="F:Tensorboard.CodeDef.Types.Trace.LinenoFieldNumber">
            <summary>Field number for the "lineno" field.</summary>
        </member>
        <member name="F:Tensorboard.CodeDef.Types.Trace.FunctionFieldNumber">
            <summary>Field number for the "function" field.</summary>
        </member>
        <member name="P:Tensorboard.CodeDef.Types.Trace.Function">
            <summary>
            deprecated by function_id.
            </summary>
        </member>
        <member name="F:Tensorboard.CodeDef.Types.Trace.FunctionIdFieldNumber">
            <summary>Field number for the "function_id" field.</summary>
        </member>
        <member name="F:Tensorboard.CodeDef.Types.Trace.LineFieldNumber">
            <summary>Field number for the "line" field.</summary>
        </member>
        <member name="P:Tensorboard.CodeDef.Types.Trace.Line">
            <summary>
            deprecated line_id.
            </summary>
        </member>
        <member name="F:Tensorboard.CodeDef.Types.Trace.LineIdFieldNumber">
            <summary>Field number for the "line_id" field.</summary>
        </member>
        <member name="F:Tensorboard.CodeDef.Types.Trace.FuncStartLineFieldNumber">
            <summary>Field number for the "func_start_line" field.</summary>
        </member>
        <member name="F:Tensorboard.OpLogEntry.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="P:Tensorboard.OpLogEntry.Name">
            <summary>
            op name.
            </summary>
        </member>
        <member name="F:Tensorboard.OpLogEntry.FloatOpsFieldNumber">
            <summary>Field number for the "float_ops" field.</summary>
        </member>
        <member name="P:Tensorboard.OpLogEntry.FloatOps">
            <summary>
            float_ops is filled by tfprof Python API when called. It requires the
            op has RegisterStatistics defined. Currently, Conv2D, MatMul, etc, are
            implemented.
            </summary>
        </member>
        <member name="F:Tensorboard.OpLogEntry.Types_FieldNumber">
            <summary>Field number for the "types" field.</summary>
        </member>
        <member name="P:Tensorboard.OpLogEntry.Types_">
            <summary>
            User can define extra op type information for an op. This allows the user
            to select a group of ops precisely using op_type as a key.
            </summary>
        </member>
        <member name="F:Tensorboard.OpLogEntry.CodeDefFieldNumber">
            <summary>Field number for the "code_def" field.</summary>
        </member>
        <member name="P:Tensorboard.OpLogEntry.CodeDef">
            <summary>
            Used to support tfprof "code" view.
            </summary>
        </member>
        <member name="F:Tensorboard.OpLogProto.LogEntriesFieldNumber">
            <summary>Field number for the "log_entries" field.</summary>
        </member>
        <member name="F:Tensorboard.OpLogProto.IdToStringFieldNumber">
            <summary>Field number for the "id_to_string" field.</summary>
        </member>
        <member name="P:Tensorboard.OpLogProto.IdToString">
            <summary>
            Maps from id of CodeDef file,function,line to its string
            In the future can also map other id of other fields to string.
            </summary>
        </member>
        <member name="T:Tensorboard.ProfileProto">
             <summary>
             A proto representation of the profiler's profile.
             It allows serialization, shipping around and deserialization of the profiles.
            
             Please don't depend on the internals of the profile proto.
             </summary>
        </member>
        <member name="F:Tensorboard.ProfileProto.NodesFieldNumber">
            <summary>Field number for the "nodes" field.</summary>
        </member>
        <member name="F:Tensorboard.ProfileProto.HasTraceFieldNumber">
            <summary>Field number for the "has_trace" field.</summary>
        </member>
        <member name="P:Tensorboard.ProfileProto.HasTrace">
            <summary>
            Whether or not has code traces.
            </summary>
        </member>
        <member name="F:Tensorboard.ProfileProto.MissAcceleratorStreamFieldNumber">
            <summary>Field number for the "miss_accelerator_stream" field.</summary>
        </member>
        <member name="P:Tensorboard.ProfileProto.MissAcceleratorStream">
            <summary>
            Whether or not the TF device tracer fails to return accelerator
            information (which could lead to 0 accelerator execution time).
            </summary>
        </member>
        <member name="F:Tensorboard.ProfileProto.StepsFieldNumber">
            <summary>Field number for the "steps" field.</summary>
        </member>
        <member name="P:Tensorboard.ProfileProto.Steps">
            <summary>
            Traced steps.
            </summary>
        </member>
        <member name="F:Tensorboard.ProfileProto.IdToStringFieldNumber">
            <summary>Field number for the "id_to_string" field.</summary>
        </member>
        <member name="P:Tensorboard.ProfileProto.IdToString">
            <summary>
            Maps from id of CodeDef file,function,line to its string
            In the future can also map other id of other fields to string.
            </summary>
        </member>
        <member name="F:Tensorboard.ProfileNode.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="P:Tensorboard.ProfileNode.Name">
            <summary>
            graph node name.
            </summary>
        </member>
        <member name="F:Tensorboard.ProfileNode.OpFieldNumber">
            <summary>Field number for the "op" field.</summary>
        </member>
        <member name="P:Tensorboard.ProfileNode.Op">
            <summary>
            graph operation type.
            </summary>
        </member>
        <member name="F:Tensorboard.ProfileNode.IdFieldNumber">
            <summary>Field number for the "id" field.</summary>
        </member>
        <member name="P:Tensorboard.ProfileNode.Id">
            <summary>
            A unique id for the node.
            </summary>
        </member>
        <member name="F:Tensorboard.ProfileNode.InputsFieldNumber">
            <summary>Field number for the "inputs" field.</summary>
        </member>
        <member name="F:Tensorboard.ProfileNode.InputShapesFieldNumber">
            <summary>Field number for the "input_shapes" field.</summary>
        </member>
        <member name="F:Tensorboard.ProfileNode.OutputsFieldNumber">
            <summary>Field number for the "outputs" field.</summary>
        </member>
        <member name="F:Tensorboard.ProfileNode.OutputShapesFieldNumber">
            <summary>Field number for the "output_shapes" field.</summary>
        </member>
        <member name="F:Tensorboard.ProfileNode.SrcOutputIndexFieldNumber">
            <summary>Field number for the "src_output_index" field.</summary>
        </member>
        <member name="P:Tensorboard.ProfileNode.SrcOutputIndex">
            <summary>
            A map from source node id to its output index to current node.
            </summary>
        </member>
        <member name="F:Tensorboard.ProfileNode.ShapeFieldNumber">
            <summary>Field number for the "shape" field.</summary>
        </member>
        <member name="F:Tensorboard.ProfileNode.OpTypesFieldNumber">
            <summary>Field number for the "op_types" field.</summary>
        </member>
        <member name="F:Tensorboard.ProfileNode.CanonicalDeviceFieldNumber">
            <summary>Field number for the "canonical_device" field.</summary>
        </member>
        <member name="F:Tensorboard.ProfileNode.HostDeviceFieldNumber">
            <summary>Field number for the "host_device" field.</summary>
        </member>
        <member name="F:Tensorboard.ProfileNode.FloatOpsFieldNumber">
            <summary>Field number for the "float_ops" field.</summary>
        </member>
        <member name="F:Tensorboard.ProfileNode.TraceFieldNumber">
            <summary>Field number for the "trace" field.</summary>
        </member>
        <member name="F:Tensorboard.ProfileNode.AttrsFieldNumber">
            <summary>Field number for the "attrs" field.</summary>
        </member>
        <member name="F:Tensorboard.ProfileNode.ExecsFieldNumber">
            <summary>Field number for the "execs" field.</summary>
        </member>
        <member name="F:Tensorboard.ExecProfile.RunCountFieldNumber">
            <summary>Field number for the "run_count" field.</summary>
        </member>
        <member name="P:Tensorboard.ExecProfile.RunCount">
            <summary>
            Can be larger than 1 if run multiple times in loop.
            </summary>
        </member>
        <member name="F:Tensorboard.ExecProfile.AllStartMicrosFieldNumber">
            <summary>Field number for the "all_start_micros" field.</summary>
        </member>
        <member name="P:Tensorboard.ExecProfile.AllStartMicros">
            <summary>
            The earliest/latest time including scheduling and execution.
            </summary>
        </member>
        <member name="F:Tensorboard.ExecProfile.LatestEndMicrosFieldNumber">
            <summary>Field number for the "latest_end_micros" field.</summary>
        </member>
        <member name="F:Tensorboard.ExecProfile.AcceleratorExecsFieldNumber">
            <summary>Field number for the "accelerator_execs" field.</summary>
        </member>
        <member name="P:Tensorboard.ExecProfile.AcceleratorExecs">
            <summary>
            device -> vector of {op_start_micros, op_exec_micros} pairs.
            accelerator_execs: gpu:id/stream:all -> {op_start_micros, op_exec_micros}
            For accelerator, vector size can be larger than 1, multiple kernel fires
            or in tf.while_loop.
            </summary>
        </member>
        <member name="F:Tensorboard.ExecProfile.CpuExecsFieldNumber">
            <summary>Field number for the "cpu_execs" field.</summary>
        </member>
        <member name="P:Tensorboard.ExecProfile.CpuExecs">
            <summary>
            cpu_execs: cpu/gpu:id -> {op_start_micros, op_exec_micros}
            For cpu, vector size can be larger than 1 if in tf.while_loop.
            </summary>
        </member>
        <member name="F:Tensorboard.ExecProfile.MemoryExecsFieldNumber">
            <summary>Field number for the "memory_execs" field.</summary>
        </member>
        <member name="P:Tensorboard.ExecProfile.MemoryExecs">
            <summary>
            Each entry to memory information of a scheduling of the node.
            Normally, there will be multiple entries in while_loop.
            </summary>
        </member>
        <member name="F:Tensorboard.ExecProfile.AllocationsFieldNumber">
            <summary>Field number for the "allocations" field.</summary>
        </member>
        <member name="P:Tensorboard.ExecProfile.Allocations">
            <summary>
            The allocation and deallocation times and sizes throughout execution.
            </summary>
        </member>
        <member name="F:Tensorboard.ExecProfile.DevicesFieldNumber">
            <summary>Field number for the "devices" field.</summary>
        </member>
        <member name="P:Tensorboard.ExecProfile.Devices">
            <summary>
            The devices related to this execution.
            </summary>
        </member>
        <member name="F:Tensorboard.ExecTime.TimesFieldNumber">
            <summary>Field number for the "times" field.</summary>
        </member>
        <member name="F:Tensorboard.ExecMemory.MemoryMicrosFieldNumber">
            <summary>Field number for the "memory_micros" field.</summary>
        </member>
        <member name="P:Tensorboard.ExecMemory.MemoryMicros">
            <summary>
            This is the timestamp when the memory information was tracked.
            </summary>
        </member>
        <member name="F:Tensorboard.ExecMemory.HostTempBytesFieldNumber">
            <summary>Field number for the "host_temp_bytes" field.</summary>
        </member>
        <member name="P:Tensorboard.ExecMemory.HostTempBytes">
            <summary>
            NOTE: Please don't depend on the following 4 fields yet. Due to
            TensorFlow internal tracing issues, the numbers can be quite wrong.
            TODO(xpan): Fix the TensorFlow internal tracing.
            </summary>
        </member>
        <member name="F:Tensorboard.ExecMemory.HostPersistentBytesFieldNumber">
            <summary>Field number for the "host_persistent_bytes" field.</summary>
        </member>
        <member name="F:Tensorboard.ExecMemory.AcceleratorTempBytesFieldNumber">
            <summary>Field number for the "accelerator_temp_bytes" field.</summary>
        </member>
        <member name="F:Tensorboard.ExecMemory.AcceleratorPersistentBytesFieldNumber">
            <summary>Field number for the "accelerator_persistent_bytes" field.</summary>
        </member>
        <member name="F:Tensorboard.ExecMemory.RequestedBytesFieldNumber">
            <summary>Field number for the "requested_bytes" field.</summary>
        </member>
        <member name="P:Tensorboard.ExecMemory.RequestedBytes">
            <summary>
            Total bytes requested by the op.
            </summary>
        </member>
        <member name="F:Tensorboard.ExecMemory.PeakBytesFieldNumber">
            <summary>Field number for the "peak_bytes" field.</summary>
        </member>
        <member name="P:Tensorboard.ExecMemory.PeakBytes">
            <summary>
            Total bytes requested by the op and released before op end.
            </summary>
        </member>
        <member name="F:Tensorboard.ExecMemory.ResidualBytesFieldNumber">
            <summary>Field number for the "residual_bytes" field.</summary>
        </member>
        <member name="P:Tensorboard.ExecMemory.ResidualBytes">
            <summary>
            Total bytes requested by the op and not released after op end.
            </summary>
        </member>
        <member name="F:Tensorboard.ExecMemory.OutputBytesFieldNumber">
            <summary>Field number for the "output_bytes" field.</summary>
        </member>
        <member name="P:Tensorboard.ExecMemory.OutputBytes">
            <summary>
            Total bytes output by the op (not necessarily requested by the op).
            </summary>
        </member>
        <member name="F:Tensorboard.ExecMemory.AllocatorBytesInUseFieldNumber">
            <summary>Field number for the "allocator_bytes_in_use" field.</summary>
        </member>
        <member name="P:Tensorboard.ExecMemory.AllocatorBytesInUse">
            <summary>
            The total number of bytes currently allocated by the allocator if >0.
            </summary>
        </member>
        <member name="F:Tensorboard.ExecMemory.OutputMemoryFieldNumber">
            <summary>Field number for the "output_memory" field.</summary>
        </member>
        <member name="P:Tensorboard.ExecMemory.OutputMemory">
            <summary>
            The memory of each output of the operation.
            </summary>
        </member>
        <member name="F:Tensorboard.Tuple.Int64ValuesFieldNumber">
            <summary>Field number for the "int64_values" field.</summary>
        </member>
        <member name="F:Tensorboard.Memory.BytesFieldNumber">
            <summary>Field number for the "bytes" field.</summary>
        </member>
        <member name="F:Tensorboard.Memory.PtrFieldNumber">
            <summary>Field number for the "ptr" field.</summary>
        </member>
        <member name="T:Tensorboard.TrackableObjectGraphReflection">
            <summary>Holder for reflection information generated from tensorboard/compat/proto/trackable_object_graph.proto</summary>
        </member>
        <member name="P:Tensorboard.TrackableObjectGraphReflection.Descriptor">
            <summary>File descriptor for tensorboard/compat/proto/trackable_object_graph.proto</summary>
        </member>
        <member name="F:Tensorboard.TrackableObjectGraph.NodesFieldNumber">
            <summary>Field number for the "nodes" field.</summary>
        </member>
        <member name="T:Tensorboard.TrackableObjectGraph.Types">
            <summary>Container for nested types declared in the TrackableObjectGraph message type.</summary>
        </member>
        <member name="F:Tensorboard.TrackableObjectGraph.Types.TrackableObject.ChildrenFieldNumber">
            <summary>Field number for the "children" field.</summary>
        </member>
        <member name="P:Tensorboard.TrackableObjectGraph.Types.TrackableObject.Children">
            <summary>
            Objects which this object depends on.
            </summary>
        </member>
        <member name="F:Tensorboard.TrackableObjectGraph.Types.TrackableObject.AttributesFieldNumber">
            <summary>Field number for the "attributes" field.</summary>
        </member>
        <member name="P:Tensorboard.TrackableObjectGraph.Types.TrackableObject.Attributes">
            <summary>
            Serialized data specific to this object.
            </summary>
        </member>
        <member name="F:Tensorboard.TrackableObjectGraph.Types.TrackableObject.SlotVariablesFieldNumber">
            <summary>Field number for the "slot_variables" field.</summary>
        </member>
        <member name="P:Tensorboard.TrackableObjectGraph.Types.TrackableObject.SlotVariables">
            <summary>
            Slot variables owned by this object.
            </summary>
        </member>
        <member name="F:Tensorboard.TrackableObjectGraph.Types.TrackableObject.RegisteredSaverFieldNumber">
            <summary>Field number for the "registered_saver" field.</summary>
        </member>
        <member name="P:Tensorboard.TrackableObjectGraph.Types.TrackableObject.RegisteredSaver">
            <summary>
            The registered saver used to save this object. If this saver is not
            present when loading the checkpoint, then loading will fail.
            </summary>
        </member>
        <member name="F:Tensorboard.TrackableObjectGraph.Types.TrackableObject.HasCheckpointValuesFieldNumber">
            <summary>Field number for the "has_checkpoint_values" field.</summary>
        </member>
        <member name="P:Tensorboard.TrackableObjectGraph.Types.TrackableObject.HasCheckpointValues">
            <summary>
            Whether this object has checkpoint values or descendants with checkpoint
            values. This is computed at save time to avoid traversing the entire
            object graph proto when restoring (which also has to traverse the live
            object graph).
            </summary>
        </member>
        <member name="T:Tensorboard.TrackableObjectGraph.Types.TrackableObject.Types">
            <summary>Container for nested types declared in the TrackableObject message type.</summary>
        </member>
        <member name="F:Tensorboard.TrackableObjectGraph.Types.TrackableObject.Types.ObjectReference.NodeIdFieldNumber">
            <summary>Field number for the "node_id" field.</summary>
        </member>
        <member name="P:Tensorboard.TrackableObjectGraph.Types.TrackableObject.Types.ObjectReference.NodeId">
            <summary>
            An index into `TrackableObjectGraph.nodes`, indicating the object
            being referenced.
            </summary>
        </member>
        <member name="F:Tensorboard.TrackableObjectGraph.Types.TrackableObject.Types.ObjectReference.LocalNameFieldNumber">
            <summary>Field number for the "local_name" field.</summary>
        </member>
        <member name="P:Tensorboard.TrackableObjectGraph.Types.TrackableObject.Types.ObjectReference.LocalName">
            <summary>
            A user-provided name for the edge.
            </summary>
        </member>
        <member name="F:Tensorboard.TrackableObjectGraph.Types.TrackableObject.Types.SerializedTensor.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="P:Tensorboard.TrackableObjectGraph.Types.TrackableObject.Types.SerializedTensor.Name">
            <summary>
            A name for the Tensor. Simple variables have only one
            `SerializedTensor` named "VARIABLE_VALUE" by convention. This value may
            be restored on object creation as an optimization.
            </summary>
        </member>
        <member name="F:Tensorboard.TrackableObjectGraph.Types.TrackableObject.Types.SerializedTensor.FullNameFieldNumber">
            <summary>Field number for the "full_name" field.</summary>
        </member>
        <member name="P:Tensorboard.TrackableObjectGraph.Types.TrackableObject.Types.SerializedTensor.FullName">
            <summary>
            The full name of the variable/tensor, if applicable. Used to allow
            name-based loading of checkpoints which were saved using an
            object-based API. Should match the checkpoint key which would have been
            assigned by tf.train.Saver.
            </summary>
        </member>
        <member name="F:Tensorboard.TrackableObjectGraph.Types.TrackableObject.Types.SerializedTensor.CheckpointKeyFieldNumber">
            <summary>Field number for the "checkpoint_key" field.</summary>
        </member>
        <member name="P:Tensorboard.TrackableObjectGraph.Types.TrackableObject.Types.SerializedTensor.CheckpointKey">
            <summary>
            The generated name of the Tensor in the checkpoint.
            </summary>
        </member>
        <member name="F:Tensorboard.TrackableObjectGraph.Types.TrackableObject.Types.SlotVariableReference.OriginalVariableNodeIdFieldNumber">
            <summary>Field number for the "original_variable_node_id" field.</summary>
        </member>
        <member name="P:Tensorboard.TrackableObjectGraph.Types.TrackableObject.Types.SlotVariableReference.OriginalVariableNodeId">
            <summary>
            An index into `TrackableObjectGraph.nodes`, indicating the
            variable object this slot was created for.
            </summary>
        </member>
        <member name="F:Tensorboard.TrackableObjectGraph.Types.TrackableObject.Types.SlotVariableReference.SlotNameFieldNumber">
            <summary>Field number for the "slot_name" field.</summary>
        </member>
        <member name="P:Tensorboard.TrackableObjectGraph.Types.TrackableObject.Types.SlotVariableReference.SlotName">
            <summary>
            The name of the slot (e.g. "m"/"v").
            </summary>
        </member>
        <member name="F:Tensorboard.TrackableObjectGraph.Types.TrackableObject.Types.SlotVariableReference.SlotVariableNodeIdFieldNumber">
            <summary>Field number for the "slot_variable_node_id" field.</summary>
        </member>
        <member name="P:Tensorboard.TrackableObjectGraph.Types.TrackableObject.Types.SlotVariableReference.SlotVariableNodeId">
            <summary>
            An index into `TrackableObjectGraph.nodes`, indicating the
            `Object` with the value of the slot variable.
            </summary>
        </member>
        <member name="F:Tensorboard.RegisteredSaver.NameFieldNumber">
            <summary>Field number for the "name" field.</summary>
        </member>
        <member name="P:Tensorboard.RegisteredSaver.Name">
            <summary>
            The name of the registered saver/restore function.
            </summary>
        </member>
        <member name="F:Tensorboard.RegisteredSaver.ObjectNameFieldNumber">
            <summary>Field number for the "object_name" field.</summary>
        </member>
        <member name="P:Tensorboard.RegisteredSaver.ObjectName">
            <summary>
            Unique auto-generated name of the object.
            </summary>
        </member>
        <member name="T:Tensorboard.TypesReflection">
            <summary>Holder for reflection information generated from tensorboard/compat/proto/types.proto</summary>
        </member>
        <member name="P:Tensorboard.TypesReflection.Descriptor">
            <summary>File descriptor for tensorboard/compat/proto/types.proto</summary>
        </member>
        <member name="T:Tensorboard.DataType">
            <summary>
            (== suppress_warning documentation-presence ==)
            DISABLED.IfChange
            </summary>
        </member>
        <member name="F:Tensorboard.DataType.DtInvalid">
            <summary>
            Not a legal value for DataType.  Used to indicate a DataType field
            has not been set.
            </summary>
        </member>
        <member name="F:Tensorboard.DataType.DtFloat">
            <summary>
            Data types that all computation devices are expected to be
            capable to support.
            </summary>
        </member>
        <member name="F:Tensorboard.DataType.DtComplex64">
            <summary>
            Single-precision complex
            </summary>
        </member>
        <member name="F:Tensorboard.DataType.DtQint8">
            <summary>
            Quantized int8
            </summary>
        </member>
        <member name="F:Tensorboard.DataType.DtQuint8">
            <summary>
            Quantized uint8
            </summary>
        </member>
        <member name="F:Tensorboard.DataType.DtQint32">
            <summary>
            Quantized int32
            </summary>
        </member>
        <member name="F:Tensorboard.DataType.DtBfloat16">
            <summary>
            Float32 truncated to 16 bits.  Only for cast ops.
            </summary>
        </member>
        <member name="F:Tensorboard.DataType.DtQint16">
            <summary>
            Quantized int16
            </summary>
        </member>
        <member name="F:Tensorboard.DataType.DtQuint16">
            <summary>
            Quantized uint16
            </summary>
        </member>
        <member name="F:Tensorboard.DataType.DtComplex128">
            <summary>
            Double-precision complex
            </summary>
        </member>
        <member name="F:Tensorboard.DataType.DtVariant">
            <summary>
            Arbitrary C++ data types
            </summary>
        </member>
        <member name="F:Tensorboard.DataType.DtFloatRef">
            <summary>
            Do not use!  These are only for parameters.  Every enum above
            should have a corresponding value below (verified by types_test).
            </summary>
        </member>
        <member name="T:Tensorboard.VariableReflection">
            <summary>Holder for reflection information generated from tensorboard/compat/proto/variable.proto</summary>
        </member>
        <member name="P:Tensorboard.VariableReflection.Descriptor">
            <summary>File descriptor for tensorboard/compat/proto/variable.proto</summary>
        </member>
        <member name="T:Tensorboard.VariableSynchronization">
            <summary>
            Indicates when a distributed variable will be synced.
            </summary>
        </member>
        <member name="F:Tensorboard.VariableSynchronization.Auto">
            <summary>
            `AUTO`: Indicates that the synchronization will be determined by the
            current `DistributionStrategy` (eg. With `MirroredStrategy` this would be
            `ON_WRITE`).
            </summary>
        </member>
        <member name="F:Tensorboard.VariableSynchronization.None">
            <summary>
            `NONE`: Indicates that there will only be one copy of the variable, so
            there is no need to sync.
            </summary>
        </member>
        <member name="F:Tensorboard.VariableSynchronization.OnWrite">
            <summary>
            `ON_WRITE`: Indicates that the variable will be updated across devices
            every time it is written.
            </summary>
        </member>
        <member name="F:Tensorboard.VariableSynchronization.OnRead">
            <summary>
            `ON_READ`: Indicates that the variable will be aggregated across devices
            when it is read (eg. when checkpointing or when evaluating an op that uses
            the variable).
            </summary>
        </member>
        <member name="T:Tensorboard.VariableAggregation">
            <summary>
            Indicates how a distributed variable will be aggregated.
            </summary>
        </member>
        <member name="F:Tensorboard.VariableAggregation.None">
            <summary>
            `NONE`: This is the default, giving an error if you use a
            variable-update operation with multiple replicas.
            </summary>
        </member>
        <member name="F:Tensorboard.VariableAggregation.Sum">
            <summary>
            `SUM`: Add the updates across replicas.
            </summary>
        </member>
        <member name="F:Tensorboard.VariableAggregation.Mean">
            <summary>
            `MEAN`: Take the arithmetic mean ("average") of the updates across
            replicas.
            </summary>
        </member>
        <member name="F:Tensorboard.VariableAggregation.OnlyFirstReplica">
            <summary>
            `ONLY_FIRST_REPLICA`: This is for when every replica is performing the same
            update, but we only want to perform the update once. Used, e.g., for the
            global step counter.
            </summary>
        </member>
        <member name="T:Tensorboard.VariableDef">
            <summary>
            Protocol buffer representing a Variable.
            </summary>
        </member>
        <member name="F:Tensorboard.VariableDef.VariableNameFieldNumber">
            <summary>Field number for the "variable_name" field.</summary>
        </member>
        <member name="P:Tensorboard.VariableDef.VariableName">
            <summary>
            Name of the variable tensor.
            </summary>
        </member>
        <member name="F:Tensorboard.VariableDef.InitialValueNameFieldNumber">
            <summary>Field number for the "initial_value_name" field.</summary>
        </member>
        <member name="P:Tensorboard.VariableDef.InitialValueName">
            <summary>
            Name of the tensor holding the variable's initial value.
            </summary>
        </member>
        <member name="F:Tensorboard.VariableDef.InitializerNameFieldNumber">
            <summary>Field number for the "initializer_name" field.</summary>
        </member>
        <member name="P:Tensorboard.VariableDef.InitializerName">
            <summary>
            Name of the initializer op.
            </summary>
        </member>
        <member name="F:Tensorboard.VariableDef.SnapshotNameFieldNumber">
            <summary>Field number for the "snapshot_name" field.</summary>
        </member>
        <member name="P:Tensorboard.VariableDef.SnapshotName">
            <summary>
            Name of the snapshot tensor.
            </summary>
        </member>
        <member name="F:Tensorboard.VariableDef.SaveSliceInfoDefFieldNumber">
            <summary>Field number for the "save_slice_info_def" field.</summary>
        </member>
        <member name="P:Tensorboard.VariableDef.SaveSliceInfoDef">
            <summary>
            Support for saving variables as slices of a larger variable.
            </summary>
        </member>
        <member name="F:Tensorboard.VariableDef.IsResourceFieldNumber">
            <summary>Field number for the "is_resource" field.</summary>
        </member>
        <member name="P:Tensorboard.VariableDef.IsResource">
            <summary>
            Whether to represent this as a ResourceVariable.
            </summary>
        </member>
        <member name="F:Tensorboard.VariableDef.TrainableFieldNumber">
            <summary>Field number for the "trainable" field.</summary>
        </member>
        <member name="P:Tensorboard.VariableDef.Trainable">
            <summary>
            Whether this variable should be trained.
            </summary>
        </member>
        <member name="F:Tensorboard.VariableDef.SynchronizationFieldNumber">
            <summary>Field number for the "synchronization" field.</summary>
        </member>
        <member name="P:Tensorboard.VariableDef.Synchronization">
            <summary>
            Indicates when a distributed variable will be synced.
            </summary>
        </member>
        <member name="F:Tensorboard.VariableDef.AggregationFieldNumber">
            <summary>Field number for the "aggregation" field.</summary>
        </member>
        <member name="P:Tensorboard.VariableDef.Aggregation">
            <summary>
            Indicates how a distributed variable will be aggregated.
            </summary>
        </member>
        <member name="F:Tensorboard.SaveSliceInfoDef.FullNameFieldNumber">
            <summary>Field number for the "full_name" field.</summary>
        </member>
        <member name="P:Tensorboard.SaveSliceInfoDef.FullName">
            <summary>
            Name of the full variable of which this is a slice.
            </summary>
        </member>
        <member name="F:Tensorboard.SaveSliceInfoDef.FullShapeFieldNumber">
            <summary>Field number for the "full_shape" field.</summary>
        </member>
        <member name="P:Tensorboard.SaveSliceInfoDef.FullShape">
            <summary>
            Shape of the full variable.
            </summary>
        </member>
        <member name="F:Tensorboard.SaveSliceInfoDef.VarOffsetFieldNumber">
            <summary>Field number for the "var_offset" field.</summary>
        </member>
        <member name="P:Tensorboard.SaveSliceInfoDef.VarOffset">
            <summary>
            Offset of this variable into the full variable.
            </summary>
        </member>
        <member name="F:Tensorboard.SaveSliceInfoDef.VarShapeFieldNumber">
            <summary>Field number for the "var_shape" field.</summary>
        </member>
        <member name="P:Tensorboard.SaveSliceInfoDef.VarShape">
            <summary>
            Shape of this variable.
            </summary>
        </member>
        <member name="T:Tensorboard.VerifierConfigReflection">
            <summary>Holder for reflection information generated from tensorboard/compat/proto/verifier_config.proto</summary>
        </member>
        <member name="P:Tensorboard.VerifierConfigReflection.Descriptor">
            <summary>File descriptor for tensorboard/compat/proto/verifier_config.proto</summary>
        </member>
        <member name="T:Tensorboard.VerifierConfig">
            <summary>
            The config for graph verifiers.
            </summary>
        </member>
        <member name="F:Tensorboard.VerifierConfig.VerificationTimeoutInMsFieldNumber">
            <summary>Field number for the "verification_timeout_in_ms" field.</summary>
        </member>
        <member name="P:Tensorboard.VerifierConfig.VerificationTimeoutInMs">
            <summary>
            Deadline for completion of all verification i.e. all the Toggle ON
            verifiers must complete execution within this time.
            </summary>
        </member>
        <member name="F:Tensorboard.VerifierConfig.StructureVerifierFieldNumber">
            <summary>Field number for the "structure_verifier" field.</summary>
        </member>
        <member name="P:Tensorboard.VerifierConfig.StructureVerifier">
            <summary>
            Perform structural validation on a tensorflow graph. Default is OFF.
            </summary>
        </member>
        <member name="T:Tensorboard.VerifierConfig.Types">
            <summary>Container for nested types declared in the VerifierConfig message type.</summary>
        </member>
        <member name="T:Tensorboard.VersionsReflection">
            <summary>Holder for reflection information generated from tensorboard/compat/proto/versions.proto</summary>
        </member>
        <member name="P:Tensorboard.VersionsReflection.Descriptor">
            <summary>File descriptor for tensorboard/compat/proto/versions.proto</summary>
        </member>
        <member name="T:Tensorboard.VersionDef">
             <summary>
             Version information for a piece of serialized data
            
             There are different types of versions for each type of data
             (GraphDef, etc.), but they all have the same common shape
             described here.
            
             Each consumer has "consumer" and "min_producer" versions (specified
             elsewhere).  A consumer is allowed to consume this data if
            
               producer >= min_producer
               consumer >= min_consumer
               consumer not in bad_consumers
             </summary>
        </member>
        <member name="F:Tensorboard.VersionDef.ProducerFieldNumber">
            <summary>Field number for the "producer" field.</summary>
        </member>
        <member name="P:Tensorboard.VersionDef.Producer">
            <summary>
            The version of the code that produced this data.
            </summary>
        </member>
        <member name="F:Tensorboard.VersionDef.MinConsumerFieldNumber">
            <summary>Field number for the "min_consumer" field.</summary>
        </member>
        <member name="P:Tensorboard.VersionDef.MinConsumer">
            <summary>
            Any consumer below this version is not allowed to consume this data.
            </summary>
        </member>
        <member name="F:Tensorboard.VersionDef.BadConsumersFieldNumber">
            <summary>Field number for the "bad_consumers" field.</summary>
        </member>
        <member name="P:Tensorboard.VersionDef.BadConsumers">
            <summary>
            Specific consumer versions which are disallowed (e.g. due to bugs).
            </summary>
        </member>
    </members>
</doc>
